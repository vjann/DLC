2019-06-27 13:09:58 Config:
{'all_joints': [[0], [1], [2]],
 'all_joints_names': ['Nose', 'RightHand', 'Pellet'],
 'batch_size': 4,
 'bottomheight': 400,
 'crop': True,
 'crop_pad': 0,
 'cropratio': 0.4,
 'dataset': 'training-datasets\\iteration-1\\UnaugmentedDataSet_pelletJun26\\pellet_vj90shuffle1.mat',
 'dataset_type': 'default',
 'display_iters': 1000,
 'fg_fraction': 0.25,
 'global_scale': 0.8,
 'init_weights': 'C:\\Users\\vjj14\\.conda\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\models\\pretrained\\resnet_v1_50.ckpt',
 'intermediate_supervision': False,
 'intermediate_supervision_layer': 12,
 'leftwidth': 400,
 'location_refinement': True,
 'locref_huber_loss': True,
 'locref_loss_weight': 0.05,
 'locref_stdev': 7.2801,
 'log_dir': 'log',
 'max_input_size': 1500,
 'mean_pixel': [123.68, 116.779, 103.939],
 'metadataset': 'training-datasets\\iteration-1\\UnaugmentedDataSet_pelletJun26\\Documentation_data-pellet_90shuffle1.pickle',
 'min_input_size': 64,
 'minsize': 100,
 'mirror': False,
 'multi_step': [[0.005, 10000],
                [0.02, 430000],
                [0.002, 730000],
                [0.001, 1030000]],
 'net_type': 'resnet_50',
 'num_joints': 3,
 'optimizer': 'sgd',
 'pos_dist_thresh': 17,
 'project_path': 'C:\\Users\\vjj14\\Desktop\\DeepLabCut\\pellet-vj-2019-06-26',
 'regularize': False,
 'rightwidth': 400,
 'save_iters': 50000,
 'scale_jitter_lo': 0.5,
 'scale_jitter_up': 1.25,
 'scoremap_dir': 'test',
 'shuffle': True,
 'snapshot_prefix': 'C:\\Users\\vjj14\\Desktop\\DeepLabCut\\pellet-vj-2019-06-26\\dlc-models\\iteration-1\\pelletJun26-trainset90shuffle1\\train\\snapshot',
 'stride': 8.0,
 'topheight': 400,
 'use_gt_segm': False,
 'video': False,
 'video_batch': False,
 'weigh_negatives': False,
 'weigh_only_present_joints': False,
 'weigh_part_predictions': False,
 'weight_decay': 0.0001}
2019-06-27 13:11:44 iteration: 100 loss: 0.0451 lr: 0.005
2019-06-27 13:13:05 iteration: 200 loss: 0.0171 lr: 0.005
2019-06-27 13:14:13 iteration: 300 loss: 0.0150 lr: 0.005
2019-06-27 13:15:20 iteration: 400 loss: 0.0136 lr: 0.005
2019-06-27 13:16:19 iteration: 500 loss: 0.0134 lr: 0.005
2019-06-27 13:17:14 iteration: 600 loss: 0.0122 lr: 0.005
2019-06-27 13:18:09 iteration: 700 loss: 0.0117 lr: 0.005
2019-06-27 13:19:03 iteration: 800 loss: 0.0118 lr: 0.005
2019-06-27 13:19:52 iteration: 900 loss: 0.0105 lr: 0.005
2019-06-27 13:20:38 iteration: 1000 loss: 0.0104 lr: 0.005
2019-06-27 13:21:24 iteration: 1100 loss: 0.0091 lr: 0.005
2019-06-27 13:22:08 iteration: 1200 loss: 0.0090 lr: 0.005
2019-06-27 13:22:49 iteration: 1300 loss: 0.0088 lr: 0.005
2019-06-27 13:23:29 iteration: 1400 loss: 0.0088 lr: 0.005
2019-06-27 13:24:13 iteration: 1500 loss: 0.0081 lr: 0.005
2019-06-27 13:24:58 iteration: 1600 loss: 0.0093 lr: 0.005
2019-06-27 13:25:40 iteration: 1700 loss: 0.0092 lr: 0.005
2019-06-27 13:26:26 iteration: 1800 loss: 0.0086 lr: 0.005
2019-06-27 13:27:01 iteration: 1900 loss: 0.0079 lr: 0.005
2019-06-27 13:27:43 iteration: 2000 loss: 0.0078 lr: 0.005
2019-06-27 13:28:19 iteration: 2100 loss: 0.0072 lr: 0.005
2019-06-27 13:28:57 iteration: 2200 loss: 0.0087 lr: 0.005
2019-06-27 13:29:32 iteration: 2300 loss: 0.0078 lr: 0.005
2019-06-27 13:30:10 iteration: 2400 loss: 0.0080 lr: 0.005
2019-06-27 13:30:52 iteration: 2500 loss: 0.0081 lr: 0.005
2019-06-27 13:31:33 iteration: 2600 loss: 0.0072 lr: 0.005
2019-06-27 13:32:12 iteration: 2700 loss: 0.0070 lr: 0.005
2019-06-27 13:32:54 iteration: 2800 loss: 0.0073 lr: 0.005
2019-06-27 13:33:37 iteration: 2900 loss: 0.0071 lr: 0.005
2019-06-27 13:34:17 iteration: 3000 loss: 0.0074 lr: 0.005
2019-06-27 13:35:00 iteration: 3100 loss: 0.0069 lr: 0.005
2019-06-27 13:35:36 iteration: 3200 loss: 0.0068 lr: 0.005
2019-06-27 13:36:12 iteration: 3300 loss: 0.0071 lr: 0.005
2019-06-27 13:36:46 iteration: 3400 loss: 0.0066 lr: 0.005
2019-06-27 13:37:22 iteration: 3500 loss: 0.0070 lr: 0.005
2019-06-27 13:37:59 iteration: 3600 loss: 0.0067 lr: 0.005
2019-06-27 13:38:35 iteration: 3700 loss: 0.0070 lr: 0.005
2019-06-27 13:39:16 iteration: 3800 loss: 0.0072 lr: 0.005
2019-06-27 13:39:48 iteration: 3900 loss: 0.0066 lr: 0.005
2019-06-27 13:40:21 iteration: 4000 loss: 0.0067 lr: 0.005
2019-06-27 13:40:55 iteration: 4100 loss: 0.0071 lr: 0.005
2019-06-27 13:41:25 iteration: 4200 loss: 0.0064 lr: 0.005
2019-06-27 13:41:57 iteration: 4300 loss: 0.0065 lr: 0.005
2019-06-27 13:42:28 iteration: 4400 loss: 0.0059 lr: 0.005
2019-06-27 13:42:57 iteration: 4500 loss: 0.0067 lr: 0.005
2019-06-27 13:43:20 iteration: 4600 loss: 0.0061 lr: 0.005
2019-06-27 13:43:51 iteration: 4700 loss: 0.0062 lr: 0.005
2019-06-27 13:44:20 iteration: 4800 loss: 0.0057 lr: 0.005
2019-06-27 13:44:44 iteration: 4900 loss: 0.0056 lr: 0.005
2019-06-27 13:45:09 iteration: 5000 loss: 0.0055 lr: 0.005
2019-06-27 13:45:46 iteration: 5100 loss: 0.0059 lr: 0.005
2019-06-27 13:46:13 iteration: 5200 loss: 0.0056 lr: 0.005
2019-06-27 13:46:44 iteration: 5300 loss: 0.0056 lr: 0.005
2019-06-27 13:47:15 iteration: 5400 loss: 0.0060 lr: 0.005
2019-06-27 13:47:43 iteration: 5500 loss: 0.0057 lr: 0.005
2019-06-27 13:48:14 iteration: 5600 loss: 0.0056 lr: 0.005
2019-06-27 13:48:40 iteration: 5700 loss: 0.0055 lr: 0.005
2019-06-27 13:49:08 iteration: 5800 loss: 0.0054 lr: 0.005
2019-06-27 13:49:35 iteration: 5900 loss: 0.0052 lr: 0.005
2019-06-27 13:49:59 iteration: 6000 loss: 0.0056 lr: 0.005
2019-06-27 13:50:29 iteration: 6100 loss: 0.0054 lr: 0.005
2019-06-27 13:50:56 iteration: 6200 loss: 0.0053 lr: 0.005
2019-06-27 13:51:22 iteration: 6300 loss: 0.0053 lr: 0.005
2019-06-27 13:51:45 iteration: 6400 loss: 0.0045 lr: 0.005
2019-06-27 13:52:09 iteration: 6500 loss: 0.0052 lr: 0.005
2019-06-27 13:52:35 iteration: 6600 loss: 0.0052 lr: 0.005
2019-06-27 13:53:03 iteration: 6700 loss: 0.0055 lr: 0.005
2019-06-27 13:53:29 iteration: 6800 loss: 0.0053 lr: 0.005
2019-06-27 13:54:01 iteration: 6900 loss: 0.0050 lr: 0.005
2019-06-27 13:54:30 iteration: 7000 loss: 0.0049 lr: 0.005
2019-06-27 13:54:55 iteration: 7100 loss: 0.0049 lr: 0.005
2019-06-27 13:55:21 iteration: 7200 loss: 0.0057 lr: 0.005
2019-06-27 13:55:46 iteration: 7300 loss: 0.0050 lr: 0.005
2019-06-27 13:56:08 iteration: 7400 loss: 0.0046 lr: 0.005
2019-06-27 13:56:38 iteration: 7500 loss: 0.0052 lr: 0.005
2019-06-27 13:56:58 iteration: 7600 loss: 0.0051 lr: 0.005
2019-06-27 13:57:25 iteration: 7700 loss: 0.0052 lr: 0.005
2019-06-27 13:57:51 iteration: 7800 loss: 0.0049 lr: 0.005
2019-06-27 13:58:14 iteration: 7900 loss: 0.0047 lr: 0.005
2019-06-27 13:58:41 iteration: 8000 loss: 0.0049 lr: 0.005
2019-06-27 13:59:09 iteration: 8100 loss: 0.0050 lr: 0.005
2019-06-27 13:59:36 iteration: 8200 loss: 0.0050 lr: 0.005
2019-06-27 14:00:03 iteration: 8300 loss: 0.0045 lr: 0.005
2019-06-27 14:00:26 iteration: 8400 loss: 0.0044 lr: 0.005
2019-06-27 14:00:51 iteration: 8500 loss: 0.0045 lr: 0.005
2019-06-27 14:01:21 iteration: 8600 loss: 0.0049 lr: 0.005
2019-06-27 14:01:46 iteration: 8700 loss: 0.0044 lr: 0.005
2019-06-27 14:02:12 iteration: 8800 loss: 0.0040 lr: 0.005
2019-06-27 14:02:42 iteration: 8900 loss: 0.0047 lr: 0.005
2019-06-27 14:03:08 iteration: 9000 loss: 0.0048 lr: 0.005
2019-06-27 14:03:35 iteration: 9100 loss: 0.0042 lr: 0.005
2019-06-27 14:03:56 iteration: 9200 loss: 0.0042 lr: 0.005
2019-06-27 14:04:23 iteration: 9300 loss: 0.0047 lr: 0.005
2019-06-27 14:04:47 iteration: 9400 loss: 0.0044 lr: 0.005
2019-06-27 14:05:09 iteration: 9500 loss: 0.0042 lr: 0.005
2019-06-27 14:05:36 iteration: 9600 loss: 0.0042 lr: 0.005
2019-06-27 14:06:01 iteration: 9700 loss: 0.0048 lr: 0.005
2019-06-27 14:06:23 iteration: 9800 loss: 0.0048 lr: 0.005
2019-06-27 14:06:49 iteration: 9900 loss: 0.0044 lr: 0.005
2019-06-27 14:07:12 iteration: 10000 loss: 0.0040 lr: 0.005
2019-06-27 14:07:43 iteration: 10100 loss: 0.0070 lr: 0.02
2019-06-27 14:08:09 iteration: 10200 loss: 0.0067 lr: 0.02
2019-06-27 14:08:33 iteration: 10300 loss: 0.0080 lr: 0.02
2019-06-27 14:08:57 iteration: 10400 loss: 0.0071 lr: 0.02
2019-06-27 14:09:20 iteration: 10500 loss: 0.0067 lr: 0.02
2019-06-27 14:09:41 iteration: 10600 loss: 0.0062 lr: 0.02
2019-06-27 14:10:05 iteration: 10700 loss: 0.0069 lr: 0.02
2019-06-27 14:10:29 iteration: 10800 loss: 0.0066 lr: 0.02
2019-06-27 14:10:54 iteration: 10900 loss: 0.0063 lr: 0.02
2019-06-27 14:11:16 iteration: 11000 loss: 0.0063 lr: 0.02
2019-06-27 14:11:44 iteration: 11100 loss: 0.0067 lr: 0.02
2019-06-27 14:12:07 iteration: 11200 loss: 0.0063 lr: 0.02
2019-06-27 14:12:28 iteration: 11300 loss: 0.0060 lr: 0.02
2019-06-27 14:12:50 iteration: 11400 loss: 0.0056 lr: 0.02
2019-06-27 14:13:10 iteration: 11500 loss: 0.0054 lr: 0.02
2019-06-27 14:13:32 iteration: 11600 loss: 0.0061 lr: 0.02
2019-06-27 14:13:55 iteration: 11700 loss: 0.0053 lr: 0.02
2019-06-27 14:14:17 iteration: 11800 loss: 0.0054 lr: 0.02
2019-06-27 14:14:40 iteration: 11900 loss: 0.0060 lr: 0.02
2019-06-27 14:15:03 iteration: 12000 loss: 0.0053 lr: 0.02
2019-06-27 14:15:30 iteration: 12100 loss: 0.0053 lr: 0.02
2019-06-27 14:15:52 iteration: 12200 loss: 0.0051 lr: 0.02
2019-06-27 14:16:15 iteration: 12300 loss: 0.0053 lr: 0.02
2019-06-27 14:16:37 iteration: 12400 loss: 0.0048 lr: 0.02
2019-06-27 14:17:00 iteration: 12500 loss: 0.0049 lr: 0.02
2019-06-27 14:17:22 iteration: 12600 loss: 0.0044 lr: 0.02
2019-06-27 14:17:41 iteration: 12700 loss: 0.0044 lr: 0.02
2019-06-27 14:18:03 iteration: 12800 loss: 0.0055 lr: 0.02
2019-06-27 14:18:22 iteration: 12900 loss: 0.0047 lr: 0.02
2019-06-27 14:18:45 iteration: 13000 loss: 0.0052 lr: 0.02
2019-06-27 14:19:10 iteration: 13100 loss: 0.0045 lr: 0.02
2019-06-27 14:19:29 iteration: 13200 loss: 0.0044 lr: 0.02
2019-06-27 14:19:53 iteration: 13300 loss: 0.0046 lr: 0.02
2019-06-27 14:20:18 iteration: 13400 loss: 0.0051 lr: 0.02
2019-06-27 14:20:39 iteration: 13500 loss: 0.0042 lr: 0.02
2019-06-27 14:21:04 iteration: 13600 loss: 0.0046 lr: 0.02
2019-06-27 14:21:27 iteration: 13700 loss: 0.0045 lr: 0.02
2019-06-27 14:21:47 iteration: 13800 loss: 0.0048 lr: 0.02
2019-06-27 14:22:07 iteration: 13900 loss: 0.0051 lr: 0.02
2019-06-27 14:22:27 iteration: 14000 loss: 0.0041 lr: 0.02
2019-06-27 14:22:55 iteration: 14100 loss: 0.0046 lr: 0.02
2019-06-27 14:23:14 iteration: 14200 loss: 0.0046 lr: 0.02
2019-06-27 14:23:35 iteration: 14300 loss: 0.0041 lr: 0.02
2019-06-27 14:23:58 iteration: 14400 loss: 0.0045 lr: 0.02
2019-06-27 14:24:18 iteration: 14500 loss: 0.0041 lr: 0.02
2019-06-27 14:24:40 iteration: 14600 loss: 0.0046 lr: 0.02
2019-06-27 14:25:00 iteration: 14700 loss: 0.0039 lr: 0.02
2019-06-27 14:25:21 iteration: 14800 loss: 0.0040 lr: 0.02
2019-06-27 14:25:46 iteration: 14900 loss: 0.0040 lr: 0.02
2019-06-27 14:26:07 iteration: 15000 loss: 0.0041 lr: 0.02
2019-06-27 14:26:36 iteration: 15100 loss: 0.0043 lr: 0.02
2019-06-27 14:26:57 iteration: 15200 loss: 0.0042 lr: 0.02
2019-06-27 14:27:20 iteration: 15300 loss: 0.0042 lr: 0.02
2019-06-27 14:27:43 iteration: 15400 loss: 0.0042 lr: 0.02
2019-06-27 14:28:03 iteration: 15500 loss: 0.0043 lr: 0.02
2019-06-27 14:28:23 iteration: 15600 loss: 0.0041 lr: 0.02
2019-06-27 14:28:44 iteration: 15700 loss: 0.0035 lr: 0.02
2019-06-27 14:29:07 iteration: 15800 loss: 0.0039 lr: 0.02
2019-06-27 14:29:27 iteration: 15900 loss: 0.0037 lr: 0.02
2019-06-27 14:29:49 iteration: 16000 loss: 0.0038 lr: 0.02
2019-06-27 14:30:15 iteration: 16100 loss: 0.0042 lr: 0.02
2019-06-27 14:30:37 iteration: 16200 loss: 0.0040 lr: 0.02
2019-06-27 14:30:57 iteration: 16300 loss: 0.0040 lr: 0.02
2019-06-27 14:31:23 iteration: 16400 loss: 0.0035 lr: 0.02
2019-06-27 14:31:41 iteration: 16500 loss: 0.0038 lr: 0.02
2019-06-27 14:32:01 iteration: 16600 loss: 0.0040 lr: 0.02
2019-06-27 14:32:24 iteration: 16700 loss: 0.0040 lr: 0.02
2019-06-27 14:32:43 iteration: 16800 loss: 0.0034 lr: 0.02
2019-06-27 14:33:04 iteration: 16900 loss: 0.0035 lr: 0.02
2019-06-27 14:33:25 iteration: 17000 loss: 0.0035 lr: 0.02
2019-06-27 14:33:52 iteration: 17100 loss: 0.0037 lr: 0.02
2019-06-27 14:34:12 iteration: 17200 loss: 0.0033 lr: 0.02
2019-06-27 14:34:33 iteration: 17300 loss: 0.0036 lr: 0.02
2019-06-27 14:34:55 iteration: 17400 loss: 0.0039 lr: 0.02
2019-06-27 14:35:16 iteration: 17500 loss: 0.0037 lr: 0.02
2019-06-27 14:35:34 iteration: 17600 loss: 0.0037 lr: 0.02
2019-06-27 14:35:54 iteration: 17700 loss: 0.0038 lr: 0.02
2019-06-27 14:36:12 iteration: 17800 loss: 0.0037 lr: 0.02
2019-06-27 14:36:30 iteration: 17900 loss: 0.0035 lr: 0.02
2019-06-27 14:36:48 iteration: 18000 loss: 0.0035 lr: 0.02
2019-06-27 14:37:11 iteration: 18100 loss: 0.0035 lr: 0.02
2019-06-27 14:37:32 iteration: 18200 loss: 0.0033 lr: 0.02
2019-06-27 14:37:53 iteration: 18300 loss: 0.0036 lr: 0.02
2019-06-27 14:38:10 iteration: 18400 loss: 0.0032 lr: 0.02
2019-06-27 14:38:29 iteration: 18500 loss: 0.0034 lr: 0.02
2019-06-27 14:38:49 iteration: 18600 loss: 0.0033 lr: 0.02
2019-06-27 14:39:11 iteration: 18700 loss: 0.0032 lr: 0.02
2019-06-27 14:39:32 iteration: 18800 loss: 0.0035 lr: 0.02
2019-06-27 14:39:50 iteration: 18900 loss: 0.0033 lr: 0.02
2019-06-27 14:40:06 iteration: 19000 loss: 0.0036 lr: 0.02
2019-06-27 14:40:30 iteration: 19100 loss: 0.0033 lr: 0.02
2019-06-27 14:40:48 iteration: 19200 loss: 0.0030 lr: 0.02
2019-06-27 14:41:08 iteration: 19300 loss: 0.0032 lr: 0.02
2019-06-27 14:41:28 iteration: 19400 loss: 0.0033 lr: 0.02
2019-06-27 14:41:48 iteration: 19500 loss: 0.0030 lr: 0.02
2019-06-27 14:42:08 iteration: 19600 loss: 0.0034 lr: 0.02
2019-06-27 14:42:27 iteration: 19700 loss: 0.0030 lr: 0.02
2019-06-27 14:42:46 iteration: 19800 loss: 0.0031 lr: 0.02
2019-06-27 14:43:06 iteration: 19900 loss: 0.0031 lr: 0.02
2019-06-27 14:43:25 iteration: 20000 loss: 0.0031 lr: 0.02
2019-06-27 14:43:47 iteration: 20100 loss: 0.0031 lr: 0.02
2019-06-27 14:44:06 iteration: 20200 loss: 0.0032 lr: 0.02
2019-06-27 14:44:24 iteration: 20300 loss: 0.0029 lr: 0.02
2019-06-27 14:44:43 iteration: 20400 loss: 0.0028 lr: 0.02
2019-06-27 14:45:04 iteration: 20500 loss: 0.0031 lr: 0.02
2019-06-27 14:45:26 iteration: 20600 loss: 0.0030 lr: 0.02
2019-06-27 14:45:49 iteration: 20700 loss: 0.0032 lr: 0.02
2019-06-27 14:46:08 iteration: 20800 loss: 0.0031 lr: 0.02
2019-06-27 14:46:28 iteration: 20900 loss: 0.0028 lr: 0.02
2019-06-27 14:46:44 iteration: 21000 loss: 0.0028 lr: 0.02
2019-06-27 14:47:10 iteration: 21100 loss: 0.0029 lr: 0.02
2019-06-27 14:47:29 iteration: 21200 loss: 0.0029 lr: 0.02
2019-06-27 14:47:47 iteration: 21300 loss: 0.0029 lr: 0.02
2019-06-27 14:48:06 iteration: 21400 loss: 0.0025 lr: 0.02
2019-06-27 14:48:23 iteration: 21500 loss: 0.0027 lr: 0.02
2019-06-27 14:48:43 iteration: 21600 loss: 0.0027 lr: 0.02
2019-06-27 14:49:01 iteration: 21700 loss: 0.0030 lr: 0.02
2019-06-27 14:49:19 iteration: 21800 loss: 0.0025 lr: 0.02
2019-06-27 14:49:36 iteration: 21900 loss: 0.0029 lr: 0.02
2019-06-27 14:49:55 iteration: 22000 loss: 0.0029 lr: 0.02
2019-06-27 14:50:17 iteration: 22100 loss: 0.0026 lr: 0.02
2019-06-27 14:50:42 iteration: 22200 loss: 0.0030 lr: 0.02
2019-06-27 14:50:58 iteration: 22300 loss: 0.0029 lr: 0.02
2019-06-27 14:51:16 iteration: 22400 loss: 0.0032 lr: 0.02
2019-06-27 14:51:34 iteration: 22500 loss: 0.0026 lr: 0.02
2019-06-27 14:51:54 iteration: 22600 loss: 0.0027 lr: 0.02
2019-06-27 14:52:13 iteration: 22700 loss: 0.0030 lr: 0.02
2019-06-27 14:52:31 iteration: 22800 loss: 0.0028 lr: 0.02
2019-06-27 14:52:48 iteration: 22900 loss: 0.0028 lr: 0.02
2019-06-27 14:53:06 iteration: 23000 loss: 0.0025 lr: 0.02
2019-06-27 14:53:27 iteration: 23100 loss: 0.0025 lr: 0.02
2019-06-27 14:53:46 iteration: 23200 loss: 0.0028 lr: 0.02
2019-06-27 14:54:07 iteration: 23300 loss: 0.0029 lr: 0.02
2019-06-27 14:54:26 iteration: 23400 loss: 0.0027 lr: 0.02
2019-06-27 14:54:43 iteration: 23500 loss: 0.0027 lr: 0.02
2019-06-27 14:55:01 iteration: 23600 loss: 0.0025 lr: 0.02
2019-06-27 14:55:19 iteration: 23700 loss: 0.0029 lr: 0.02
2019-06-27 14:55:37 iteration: 23800 loss: 0.0026 lr: 0.02
2019-06-27 14:55:53 iteration: 23900 loss: 0.0028 lr: 0.02
2019-06-27 14:56:12 iteration: 24000 loss: 0.0030 lr: 0.02
2019-06-27 14:56:36 iteration: 24100 loss: 0.0029 lr: 0.02
2019-06-27 14:56:57 iteration: 24200 loss: 0.0032 lr: 0.02
2019-06-27 14:57:16 iteration: 24300 loss: 0.0027 lr: 0.02
2019-06-27 14:57:36 iteration: 24400 loss: 0.0024 lr: 0.02
2019-06-27 14:57:56 iteration: 24500 loss: 0.0026 lr: 0.02
2019-06-27 14:58:14 iteration: 24600 loss: 0.0029 lr: 0.02
2019-06-27 14:58:33 iteration: 24700 loss: 0.0026 lr: 0.02
2019-06-27 14:58:54 iteration: 24800 loss: 0.0029 lr: 0.02
2019-06-27 14:59:09 iteration: 24900 loss: 0.0026 lr: 0.02
2019-06-27 14:59:29 iteration: 25000 loss: 0.0025 lr: 0.02
2019-06-27 14:59:52 iteration: 25100 loss: 0.0030 lr: 0.02
2019-06-27 15:00:10 iteration: 25200 loss: 0.0025 lr: 0.02
2019-06-27 15:00:29 iteration: 25300 loss: 0.0027 lr: 0.02
2019-06-27 15:00:44 iteration: 25400 loss: 0.0024 lr: 0.02
2019-06-27 15:01:03 iteration: 25500 loss: 0.0026 lr: 0.02
2019-06-27 15:01:22 iteration: 25600 loss: 0.0026 lr: 0.02
2019-06-27 15:01:43 iteration: 25700 loss: 0.0026 lr: 0.02
2019-06-27 15:02:00 iteration: 25800 loss: 0.0027 lr: 0.02
2019-06-27 15:02:19 iteration: 25900 loss: 0.0029 lr: 0.02
2019-06-27 15:02:37 iteration: 26000 loss: 0.0026 lr: 0.02
2019-06-27 15:02:59 iteration: 26100 loss: 0.0025 lr: 0.02
2019-06-27 15:03:19 iteration: 26200 loss: 0.0025 lr: 0.02
2019-06-27 15:03:37 iteration: 26300 loss: 0.0026 lr: 0.02
2019-06-27 15:03:57 iteration: 26400 loss: 0.0024 lr: 0.02
2019-06-27 15:04:16 iteration: 26500 loss: 0.0025 lr: 0.02
2019-06-27 15:04:36 iteration: 26600 loss: 0.0027 lr: 0.02
2019-06-27 15:04:55 iteration: 26700 loss: 0.0026 lr: 0.02
2019-06-27 15:05:14 iteration: 26800 loss: 0.0023 lr: 0.02
2019-06-27 15:05:31 iteration: 26900 loss: 0.0025 lr: 0.02
2019-06-27 15:05:49 iteration: 27000 loss: 0.0022 lr: 0.02
2019-06-27 15:06:11 iteration: 27100 loss: 0.0023 lr: 0.02
2019-06-27 15:06:30 iteration: 27200 loss: 0.0024 lr: 0.02
2019-06-27 15:06:48 iteration: 27300 loss: 0.0024 lr: 0.02
2019-06-27 15:07:09 iteration: 27400 loss: 0.0023 lr: 0.02
2019-06-27 15:07:28 iteration: 27500 loss: 0.0024 lr: 0.02
2019-06-27 15:07:45 iteration: 27600 loss: 0.0022 lr: 0.02
2019-06-27 15:08:01 iteration: 27700 loss: 0.0026 lr: 0.02
2019-06-27 15:08:16 iteration: 27800 loss: 0.0025 lr: 0.02
2019-06-27 15:08:35 iteration: 27900 loss: 0.0030 lr: 0.02
2019-06-27 15:08:53 iteration: 28000 loss: 0.0025 lr: 0.02
2019-06-27 15:09:14 iteration: 28100 loss: 0.0026 lr: 0.02
2019-06-27 15:09:30 iteration: 28200 loss: 0.0026 lr: 0.02
2019-06-27 15:09:51 iteration: 28300 loss: 0.0026 lr: 0.02
2019-06-27 15:10:07 iteration: 28400 loss: 0.0028 lr: 0.02
2019-06-27 15:10:24 iteration: 28500 loss: 0.0026 lr: 0.02
2019-06-27 15:10:45 iteration: 28600 loss: 0.0025 lr: 0.02
2019-06-27 15:11:05 iteration: 28700 loss: 0.0026 lr: 0.02
2019-06-27 15:11:24 iteration: 28800 loss: 0.0024 lr: 0.02
2019-06-27 15:11:45 iteration: 28900 loss: 0.0026 lr: 0.02
2019-06-27 15:12:02 iteration: 29000 loss: 0.0024 lr: 0.02
2019-06-27 15:12:22 iteration: 29100 loss: 0.0025 lr: 0.02
2019-06-27 15:12:36 iteration: 29200 loss: 0.0022 lr: 0.02
2019-06-27 15:12:55 iteration: 29300 loss: 0.0023 lr: 0.02
2019-06-27 15:13:15 iteration: 29400 loss: 0.0026 lr: 0.02
2019-06-27 15:13:34 iteration: 29500 loss: 0.0023 lr: 0.02
2019-06-27 15:13:51 iteration: 29600 loss: 0.0022 lr: 0.02
2019-06-27 15:14:11 iteration: 29700 loss: 0.0025 lr: 0.02
2019-06-27 15:14:31 iteration: 29800 loss: 0.0023 lr: 0.02
2019-06-27 15:14:47 iteration: 29900 loss: 0.0023 lr: 0.02
2019-06-27 15:15:04 iteration: 30000 loss: 0.0024 lr: 0.02
2019-06-27 15:15:26 iteration: 30100 loss: 0.0024 lr: 0.02
2019-06-27 15:15:44 iteration: 30200 loss: 0.0023 lr: 0.02
2019-06-27 15:16:01 iteration: 30300 loss: 0.0022 lr: 0.02
2019-06-27 15:16:16 iteration: 30400 loss: 0.0023 lr: 0.02
2019-06-27 15:16:35 iteration: 30500 loss: 0.0026 lr: 0.02
2019-06-27 15:16:53 iteration: 30600 loss: 0.0024 lr: 0.02
2019-06-27 15:17:13 iteration: 30700 loss: 0.0026 lr: 0.02
2019-06-27 15:17:31 iteration: 30800 loss: 0.0024 lr: 0.02
2019-06-27 15:17:49 iteration: 30900 loss: 0.0023 lr: 0.02
2019-06-27 15:18:11 iteration: 31000 loss: 0.0021 lr: 0.02
2019-06-27 15:18:33 iteration: 31100 loss: 0.0026 lr: 0.02
2019-06-27 15:18:51 iteration: 31200 loss: 0.0025 lr: 0.02
2019-06-27 15:19:12 iteration: 31300 loss: 0.0026 lr: 0.02
2019-06-27 15:19:29 iteration: 31400 loss: 0.0022 lr: 0.02
2019-06-27 15:19:45 iteration: 31500 loss: 0.0024 lr: 0.02
2019-06-27 15:20:02 iteration: 31600 loss: 0.0022 lr: 0.02
2019-06-27 15:20:19 iteration: 31700 loss: 0.0025 lr: 0.02
2019-06-27 15:20:35 iteration: 31800 loss: 0.0022 lr: 0.02
2019-06-27 15:20:53 iteration: 31900 loss: 0.0023 lr: 0.02
2019-06-27 15:21:09 iteration: 32000 loss: 0.0023 lr: 0.02
2019-06-27 15:21:32 iteration: 32100 loss: 0.0022 lr: 0.02
2019-06-27 15:21:49 iteration: 32200 loss: 0.0021 lr: 0.02
2019-06-27 15:22:09 iteration: 32300 loss: 0.0022 lr: 0.02
2019-06-27 15:22:27 iteration: 32400 loss: 0.0020 lr: 0.02
2019-06-27 15:22:43 iteration: 32500 loss: 0.0021 lr: 0.02
2019-06-27 15:23:01 iteration: 32600 loss: 0.0021 lr: 0.02
2019-06-27 15:23:20 iteration: 32700 loss: 0.0026 lr: 0.02
2019-06-27 15:23:36 iteration: 32800 loss: 0.0022 lr: 0.02
2019-06-27 15:23:53 iteration: 32900 loss: 0.0024 lr: 0.02
2019-06-27 15:24:11 iteration: 33000 loss: 0.0022 lr: 0.02
2019-06-27 15:24:30 iteration: 33100 loss: 0.0021 lr: 0.02
2019-06-27 15:24:45 iteration: 33200 loss: 0.0023 lr: 0.02
2019-06-27 15:25:03 iteration: 33300 loss: 0.0026 lr: 0.02
2019-06-27 15:25:21 iteration: 33400 loss: 0.0019 lr: 0.02
2019-06-27 15:25:37 iteration: 33500 loss: 0.0023 lr: 0.02
2019-06-27 15:25:53 iteration: 33600 loss: 0.0024 lr: 0.02
2019-06-27 15:26:12 iteration: 33700 loss: 0.0021 lr: 0.02
2019-06-27 15:26:28 iteration: 33800 loss: 0.0019 lr: 0.02
2019-06-27 15:26:45 iteration: 33900 loss: 0.0021 lr: 0.02
2019-06-27 15:27:02 iteration: 34000 loss: 0.0025 lr: 0.02
2019-06-27 15:27:23 iteration: 34100 loss: 0.0025 lr: 0.02
2019-06-27 15:27:41 iteration: 34200 loss: 0.0025 lr: 0.02
2019-06-27 15:27:56 iteration: 34300 loss: 0.0022 lr: 0.02
2019-06-27 15:28:12 iteration: 34400 loss: 0.0021 lr: 0.02
2019-06-27 15:28:26 iteration: 34500 loss: 0.0023 lr: 0.02
2019-06-27 15:28:50 iteration: 34600 loss: 0.0025 lr: 0.02
2019-06-27 15:29:08 iteration: 34700 loss: 0.0019 lr: 0.02
2019-06-27 15:29:26 iteration: 34800 loss: 0.0027 lr: 0.02
2019-06-27 15:29:43 iteration: 34900 loss: 0.0021 lr: 0.02
2019-06-27 15:29:59 iteration: 35000 loss: 0.0021 lr: 0.02
2019-06-27 15:30:20 iteration: 35100 loss: 0.0020 lr: 0.02
2019-06-27 15:30:37 iteration: 35200 loss: 0.0022 lr: 0.02
2019-06-27 15:30:55 iteration: 35300 loss: 0.0020 lr: 0.02
2019-06-27 15:31:11 iteration: 35400 loss: 0.0022 lr: 0.02
2019-06-27 15:31:28 iteration: 35500 loss: 0.0023 lr: 0.02
2019-06-27 15:31:44 iteration: 35600 loss: 0.0023 lr: 0.02
2019-06-27 15:32:01 iteration: 35700 loss: 0.0019 lr: 0.02
2019-06-27 15:32:18 iteration: 35800 loss: 0.0022 lr: 0.02
2019-06-27 15:32:35 iteration: 35900 loss: 0.0023 lr: 0.02
2019-06-27 15:32:55 iteration: 36000 loss: 0.0022 lr: 0.02
2019-06-27 15:33:16 iteration: 36100 loss: 0.0022 lr: 0.02
2019-06-27 15:33:32 iteration: 36200 loss: 0.0021 lr: 0.02
2019-06-27 15:33:48 iteration: 36300 loss: 0.0020 lr: 0.02
2019-06-27 15:34:07 iteration: 36400 loss: 0.0020 lr: 0.02
2019-06-27 15:34:22 iteration: 36500 loss: 0.0022 lr: 0.02
2019-06-27 15:34:41 iteration: 36600 loss: 0.0020 lr: 0.02
2019-06-27 15:34:56 iteration: 36700 loss: 0.0021 lr: 0.02
2019-06-27 15:35:11 iteration: 36800 loss: 0.0021 lr: 0.02
2019-06-27 15:35:30 iteration: 36900 loss: 0.0024 lr: 0.02
2019-06-27 15:35:46 iteration: 37000 loss: 0.0023 lr: 0.02
2019-06-27 15:36:06 iteration: 37100 loss: 0.0021 lr: 0.02
2019-06-27 15:36:20 iteration: 37200 loss: 0.0019 lr: 0.02
2019-06-27 15:36:34 iteration: 37300 loss: 0.0022 lr: 0.02
2019-06-27 15:36:50 iteration: 37400 loss: 0.0021 lr: 0.02
2019-06-27 15:37:06 iteration: 37500 loss: 0.0019 lr: 0.02
2019-06-27 15:37:22 iteration: 37600 loss: 0.0021 lr: 0.02
2019-06-27 15:37:40 iteration: 37700 loss: 0.0020 lr: 0.02
2019-06-27 15:37:58 iteration: 37800 loss: 0.0017 lr: 0.02
2019-06-27 15:38:13 iteration: 37900 loss: 0.0022 lr: 0.02
2019-06-27 15:38:29 iteration: 38000 loss: 0.0021 lr: 0.02
2019-06-27 15:38:47 iteration: 38100 loss: 0.0017 lr: 0.02
2019-06-27 15:39:03 iteration: 38200 loss: 0.0021 lr: 0.02
2019-06-27 15:39:19 iteration: 38300 loss: 0.0022 lr: 0.02
2019-06-27 15:39:34 iteration: 38400 loss: 0.0020 lr: 0.02
2019-06-27 15:39:49 iteration: 38500 loss: 0.0019 lr: 0.02
2019-06-27 15:40:04 iteration: 38600 loss: 0.0020 lr: 0.02
2019-06-27 15:40:18 iteration: 38700 loss: 0.0019 lr: 0.02
2019-06-27 15:40:37 iteration: 38800 loss: 0.0018 lr: 0.02
2019-06-27 15:40:52 iteration: 38900 loss: 0.0019 lr: 0.02
2019-06-27 15:41:10 iteration: 39000 loss: 0.0020 lr: 0.02
2019-06-27 15:41:30 iteration: 39100 loss: 0.0020 lr: 0.02
2019-06-27 15:41:46 iteration: 39200 loss: 0.0022 lr: 0.02
2019-06-27 15:42:01 iteration: 39300 loss: 0.0022 lr: 0.02
2019-06-27 15:42:17 iteration: 39400 loss: 0.0022 lr: 0.02
2019-06-27 15:42:32 iteration: 39500 loss: 0.0019 lr: 0.02
2019-06-27 15:42:49 iteration: 39600 loss: 0.0019 lr: 0.02
2019-06-27 15:43:04 iteration: 39700 loss: 0.0021 lr: 0.02
2019-06-27 15:43:21 iteration: 39800 loss: 0.0019 lr: 0.02
2019-06-27 15:43:38 iteration: 39900 loss: 0.0021 lr: 0.02
2019-06-27 15:43:54 iteration: 40000 loss: 0.0018 lr: 0.02
2019-06-27 15:44:13 iteration: 40100 loss: 0.0020 lr: 0.02
2019-06-27 15:44:31 iteration: 40200 loss: 0.0020 lr: 0.02
2019-06-27 15:44:48 iteration: 40300 loss: 0.0021 lr: 0.02
2019-06-27 15:45:04 iteration: 40400 loss: 0.0020 lr: 0.02
2019-06-27 15:45:20 iteration: 40500 loss: 0.0020 lr: 0.02
2019-06-27 15:45:35 iteration: 40600 loss: 0.0021 lr: 0.02
2019-06-27 15:45:51 iteration: 40700 loss: 0.0021 lr: 0.02
2019-06-27 15:46:06 iteration: 40800 loss: 0.0021 lr: 0.02
2019-06-27 15:46:23 iteration: 40900 loss: 0.0021 lr: 0.02
2019-06-27 15:46:38 iteration: 41000 loss: 0.0020 lr: 0.02
2019-06-27 15:46:58 iteration: 41100 loss: 0.0018 lr: 0.02
2019-06-27 15:47:16 iteration: 41200 loss: 0.0019 lr: 0.02
2019-06-27 15:47:30 iteration: 41300 loss: 0.0019 lr: 0.02
2019-06-27 15:47:46 iteration: 41400 loss: 0.0019 lr: 0.02
2019-06-27 15:48:02 iteration: 41500 loss: 0.0019 lr: 0.02
2019-06-27 15:48:20 iteration: 41600 loss: 0.0020 lr: 0.02
2019-06-27 15:48:34 iteration: 41700 loss: 0.0020 lr: 0.02
2019-06-27 15:48:50 iteration: 41800 loss: 0.0019 lr: 0.02
2019-06-27 15:49:08 iteration: 41900 loss: 0.0021 lr: 0.02
2019-06-27 15:49:24 iteration: 42000 loss: 0.0019 lr: 0.02
2019-06-27 15:49:42 iteration: 42100 loss: 0.0021 lr: 0.02
2019-06-27 15:50:03 iteration: 42200 loss: 0.0020 lr: 0.02
2019-06-27 15:50:21 iteration: 42300 loss: 0.0020 lr: 0.02
2019-06-27 15:50:39 iteration: 42400 loss: 0.0019 lr: 0.02
2019-06-27 15:50:56 iteration: 42500 loss: 0.0020 lr: 0.02
2019-06-27 15:51:11 iteration: 42600 loss: 0.0020 lr: 0.02
2019-06-27 15:51:27 iteration: 42700 loss: 0.0020 lr: 0.02
2019-06-27 15:51:44 iteration: 42800 loss: 0.0019 lr: 0.02
2019-06-27 15:52:01 iteration: 42900 loss: 0.0018 lr: 0.02
2019-06-27 15:52:19 iteration: 43000 loss: 0.0021 lr: 0.02
2019-06-27 15:52:38 iteration: 43100 loss: 0.0023 lr: 0.02
2019-06-27 15:52:55 iteration: 43200 loss: 0.0020 lr: 0.02
2019-06-27 15:53:12 iteration: 43300 loss: 0.0020 lr: 0.02
2019-06-27 15:53:28 iteration: 43400 loss: 0.0019 lr: 0.02
2019-06-27 15:53:42 iteration: 43500 loss: 0.0019 lr: 0.02
2019-06-27 15:54:00 iteration: 43600 loss: 0.0022 lr: 0.02
2019-06-27 15:54:15 iteration: 43700 loss: 0.0019 lr: 0.02
2019-06-27 15:54:29 iteration: 43800 loss: 0.0018 lr: 0.02
2019-06-27 15:54:45 iteration: 43900 loss: 0.0022 lr: 0.02
2019-06-27 15:54:59 iteration: 44000 loss: 0.0020 lr: 0.02
2019-06-27 15:55:21 iteration: 44100 loss: 0.0019 lr: 0.02
2019-06-27 15:55:37 iteration: 44200 loss: 0.0017 lr: 0.02
2019-06-27 15:55:52 iteration: 44300 loss: 0.0019 lr: 0.02
2019-06-27 15:56:08 iteration: 44400 loss: 0.0018 lr: 0.02
2019-06-27 15:56:25 iteration: 44500 loss: 0.0018 lr: 0.02
2019-06-27 15:56:40 iteration: 44600 loss: 0.0017 lr: 0.02
2019-06-27 15:56:56 iteration: 44700 loss: 0.0017 lr: 0.02
2019-06-27 15:57:10 iteration: 44800 loss: 0.0017 lr: 0.02
2019-06-27 15:57:23 iteration: 44900 loss: 0.0019 lr: 0.02
2019-06-27 15:57:37 iteration: 45000 loss: 0.0017 lr: 0.02
2019-06-27 15:57:57 iteration: 45100 loss: 0.0018 lr: 0.02
2019-06-27 15:58:12 iteration: 45200 loss: 0.0020 lr: 0.02
2019-06-27 15:58:28 iteration: 45300 loss: 0.0018 lr: 0.02
2019-06-27 15:58:44 iteration: 45400 loss: 0.0018 lr: 0.02
2019-06-27 15:59:01 iteration: 45500 loss: 0.0020 lr: 0.02
2019-06-27 15:59:18 iteration: 45600 loss: 0.0021 lr: 0.02
2019-06-27 15:59:34 iteration: 45700 loss: 0.0019 lr: 0.02
2019-06-27 15:59:49 iteration: 45800 loss: 0.0018 lr: 0.02
2019-06-27 16:00:04 iteration: 45900 loss: 0.0020 lr: 0.02
2019-06-27 16:00:21 iteration: 46000 loss: 0.0019 lr: 0.02
2019-06-27 16:00:40 iteration: 46100 loss: 0.0020 lr: 0.02
2019-06-27 16:00:57 iteration: 46200 loss: 0.0020 lr: 0.02
2019-06-27 16:01:15 iteration: 46300 loss: 0.0017 lr: 0.02
2019-06-27 16:01:30 iteration: 46400 loss: 0.0020 lr: 0.02
2019-06-27 16:01:46 iteration: 46500 loss: 0.0018 lr: 0.02
2019-06-27 16:02:02 iteration: 46600 loss: 0.0022 lr: 0.02
2019-06-27 16:02:16 iteration: 46700 loss: 0.0019 lr: 0.02
2019-06-27 16:02:33 iteration: 46800 loss: 0.0020 lr: 0.02
2019-06-27 16:02:48 iteration: 46900 loss: 0.0019 lr: 0.02
2019-06-27 16:03:03 iteration: 47000 loss: 0.0018 lr: 0.02
2019-06-27 16:03:20 iteration: 47100 loss: 0.0019 lr: 0.02
2019-06-27 16:03:36 iteration: 47200 loss: 0.0020 lr: 0.02
2019-06-27 16:03:52 iteration: 47300 loss: 0.0018 lr: 0.02
2019-06-27 16:04:07 iteration: 47400 loss: 0.0020 lr: 0.02
2019-06-27 16:04:24 iteration: 47500 loss: 0.0019 lr: 0.02
2019-06-27 16:04:37 iteration: 47600 loss: 0.0017 lr: 0.02
2019-06-27 16:04:53 iteration: 47700 loss: 0.0020 lr: 0.02
2019-06-27 16:05:09 iteration: 47800 loss: 0.0017 lr: 0.02
2019-06-27 16:05:24 iteration: 47900 loss: 0.0017 lr: 0.02
2019-06-27 16:05:41 iteration: 48000 loss: 0.0020 lr: 0.02
2019-06-27 16:06:00 iteration: 48100 loss: 0.0019 lr: 0.02
2019-06-27 16:06:15 iteration: 48200 loss: 0.0019 lr: 0.02
2019-06-27 16:06:34 iteration: 48300 loss: 0.0019 lr: 0.02
2019-06-27 16:06:51 iteration: 48400 loss: 0.0016 lr: 0.02
2019-06-27 16:07:05 iteration: 48500 loss: 0.0020 lr: 0.02
2019-06-27 16:07:22 iteration: 48600 loss: 0.0018 lr: 0.02
2019-06-27 16:07:39 iteration: 48700 loss: 0.0018 lr: 0.02
2019-06-27 16:07:55 iteration: 48800 loss: 0.0020 lr: 0.02
2019-06-27 16:08:11 iteration: 48900 loss: 0.0020 lr: 0.02
2019-06-27 16:08:27 iteration: 49000 loss: 0.0017 lr: 0.02
2019-06-27 16:08:46 iteration: 49100 loss: 0.0019 lr: 0.02
2019-06-27 16:09:01 iteration: 49200 loss: 0.0017 lr: 0.02
2019-06-27 16:09:16 iteration: 49300 loss: 0.0016 lr: 0.02
2019-06-27 16:09:32 iteration: 49400 loss: 0.0018 lr: 0.02
2019-06-27 16:09:48 iteration: 49500 loss: 0.0020 lr: 0.02
2019-06-27 16:10:03 iteration: 49600 loss: 0.0020 lr: 0.02
2019-06-27 16:10:20 iteration: 49700 loss: 0.0017 lr: 0.02
2019-06-27 16:10:33 iteration: 49800 loss: 0.0019 lr: 0.02
2019-06-27 16:10:49 iteration: 49900 loss: 0.0018 lr: 0.02
2019-06-27 16:11:05 iteration: 50000 loss: 0.0015 lr: 0.02
2019-06-27 16:11:24 iteration: 50100 loss: 0.0020 lr: 0.02
2019-06-27 16:11:40 iteration: 50200 loss: 0.0020 lr: 0.02
2019-06-27 16:11:56 iteration: 50300 loss: 0.0016 lr: 0.02
2019-06-27 16:12:12 iteration: 50400 loss: 0.0016 lr: 0.02
2019-06-27 16:12:26 iteration: 50500 loss: 0.0018 lr: 0.02
2019-06-27 16:12:41 iteration: 50600 loss: 0.0019 lr: 0.02
2019-06-27 16:12:56 iteration: 50700 loss: 0.0016 lr: 0.02
2019-06-27 16:13:10 iteration: 50800 loss: 0.0017 lr: 0.02
2019-06-27 16:13:28 iteration: 50900 loss: 0.0017 lr: 0.02
2019-06-27 16:13:43 iteration: 51000 loss: 0.0018 lr: 0.02
2019-06-27 16:14:04 iteration: 51100 loss: 0.0018 lr: 0.02
2019-06-27 16:14:19 iteration: 51200 loss: 0.0023 lr: 0.02
2019-06-27 16:14:34 iteration: 51300 loss: 0.0019 lr: 0.02
2019-06-27 16:14:49 iteration: 51400 loss: 0.0018 lr: 0.02
2019-06-27 16:15:04 iteration: 51500 loss: 0.0017 lr: 0.02
2019-06-27 16:15:19 iteration: 51600 loss: 0.0016 lr: 0.02
2019-06-27 16:15:35 iteration: 51700 loss: 0.0017 lr: 0.02
2019-06-27 16:15:50 iteration: 51800 loss: 0.0018 lr: 0.02
2019-06-27 16:16:06 iteration: 51900 loss: 0.0016 lr: 0.02
2019-06-27 16:16:18 iteration: 52000 loss: 0.0019 lr: 0.02
2019-06-27 16:16:38 iteration: 52100 loss: 0.0018 lr: 0.02
2019-06-27 16:16:53 iteration: 52200 loss: 0.0018 lr: 0.02
2019-06-27 16:17:09 iteration: 52300 loss: 0.0016 lr: 0.02
2019-06-27 16:17:24 iteration: 52400 loss: 0.0019 lr: 0.02
2019-06-27 16:17:41 iteration: 52500 loss: 0.0021 lr: 0.02
2019-06-27 16:17:56 iteration: 52600 loss: 0.0015 lr: 0.02
2019-06-27 16:18:09 iteration: 52700 loss: 0.0020 lr: 0.02
2019-06-27 16:18:24 iteration: 52800 loss: 0.0018 lr: 0.02
2019-06-27 16:18:42 iteration: 52900 loss: 0.0018 lr: 0.02
2019-06-27 16:18:56 iteration: 53000 loss: 0.0017 lr: 0.02
2019-06-27 16:19:15 iteration: 53100 loss: 0.0019 lr: 0.02
2019-06-27 16:19:30 iteration: 53200 loss: 0.0017 lr: 0.02
2019-06-27 16:19:49 iteration: 53300 loss: 0.0018 lr: 0.02
2019-06-27 16:20:04 iteration: 53400 loss: 0.0016 lr: 0.02
2019-06-27 16:20:18 iteration: 53500 loss: 0.0018 lr: 0.02
2019-06-27 16:20:31 iteration: 53600 loss: 0.0018 lr: 0.02
2019-06-27 16:20:47 iteration: 53700 loss: 0.0017 lr: 0.02
2019-06-27 16:21:01 iteration: 53800 loss: 0.0018 lr: 0.02
2019-06-27 16:21:17 iteration: 53900 loss: 0.0018 lr: 0.02
2019-06-27 16:21:33 iteration: 54000 loss: 0.0019 lr: 0.02
2019-06-27 16:21:51 iteration: 54100 loss: 0.0017 lr: 0.02
2019-06-27 16:22:06 iteration: 54200 loss: 0.0018 lr: 0.02
2019-06-27 16:22:20 iteration: 54300 loss: 0.0017 lr: 0.02
2019-06-27 16:22:36 iteration: 54400 loss: 0.0017 lr: 0.02
2019-06-27 16:22:51 iteration: 54500 loss: 0.0017 lr: 0.02
2019-06-27 16:23:05 iteration: 54600 loss: 0.0018 lr: 0.02
2019-06-27 16:23:20 iteration: 54700 loss: 0.0019 lr: 0.02
2019-06-27 16:23:36 iteration: 54800 loss: 0.0019 lr: 0.02
2019-06-27 16:23:50 iteration: 54900 loss: 0.0018 lr: 0.02
2019-06-27 16:24:07 iteration: 55000 loss: 0.0018 lr: 0.02
2019-06-27 16:24:25 iteration: 55100 loss: 0.0021 lr: 0.02
2019-06-27 16:24:38 iteration: 55200 loss: 0.0018 lr: 0.02
2019-06-27 16:24:53 iteration: 55300 loss: 0.0017 lr: 0.02
2019-06-27 16:25:07 iteration: 55400 loss: 0.0019 lr: 0.02
2019-06-27 16:25:22 iteration: 55500 loss: 0.0016 lr: 0.02
2019-06-27 16:25:36 iteration: 55600 loss: 0.0017 lr: 0.02
2019-06-27 16:25:49 iteration: 55700 loss: 0.0018 lr: 0.02
2019-06-27 16:26:05 iteration: 55800 loss: 0.0017 lr: 0.02
2019-06-27 16:26:21 iteration: 55900 loss: 0.0017 lr: 0.02
2019-06-27 16:26:37 iteration: 56000 loss: 0.0017 lr: 0.02
2019-06-27 16:26:55 iteration: 56100 loss: 0.0018 lr: 0.02
2019-06-27 16:27:09 iteration: 56200 loss: 0.0019 lr: 0.02
2019-06-27 16:27:24 iteration: 56300 loss: 0.0021 lr: 0.02
2019-06-27 16:27:39 iteration: 56400 loss: 0.0018 lr: 0.02
2019-06-27 16:27:52 iteration: 56500 loss: 0.0016 lr: 0.02
2019-06-27 16:28:08 iteration: 56600 loss: 0.0017 lr: 0.02
2019-06-27 16:28:22 iteration: 56700 loss: 0.0019 lr: 0.02
2019-06-27 16:28:36 iteration: 56800 loss: 0.0019 lr: 0.02
2019-06-27 16:28:50 iteration: 56900 loss: 0.0019 lr: 0.02
2019-06-27 16:29:05 iteration: 57000 loss: 0.0018 lr: 0.02
2019-06-27 16:29:26 iteration: 57100 loss: 0.0019 lr: 0.02
2019-06-27 16:29:40 iteration: 57200 loss: 0.0018 lr: 0.02
2019-06-27 16:29:54 iteration: 57300 loss: 0.0017 lr: 0.02
2019-06-27 16:30:09 iteration: 57400 loss: 0.0018 lr: 0.02
2019-06-27 16:30:24 iteration: 57500 loss: 0.0016 lr: 0.02
2019-06-27 16:30:40 iteration: 57600 loss: 0.0017 lr: 0.02
2019-06-27 16:30:55 iteration: 57700 loss: 0.0017 lr: 0.02
2019-06-27 16:31:11 iteration: 57800 loss: 0.0017 lr: 0.02
2019-06-27 16:31:27 iteration: 57900 loss: 0.0016 lr: 0.02
2019-06-27 16:31:39 iteration: 58000 loss: 0.0020 lr: 0.02
2019-06-27 16:31:58 iteration: 58100 loss: 0.0017 lr: 0.02
2019-06-27 16:32:12 iteration: 58200 loss: 0.0017 lr: 0.02
2019-06-27 16:32:26 iteration: 58300 loss: 0.0017 lr: 0.02
2019-06-27 16:32:40 iteration: 58400 loss: 0.0016 lr: 0.02
2019-06-27 16:32:56 iteration: 58500 loss: 0.0018 lr: 0.02
2019-06-27 16:33:11 iteration: 58600 loss: 0.0018 lr: 0.02
2019-06-27 16:33:24 iteration: 58700 loss: 0.0017 lr: 0.02
2019-06-27 16:33:41 iteration: 58800 loss: 0.0017 lr: 0.02
2019-06-27 16:33:56 iteration: 58900 loss: 0.0017 lr: 0.02
2019-06-27 16:34:13 iteration: 59000 loss: 0.0016 lr: 0.02
2019-06-27 16:34:30 iteration: 59100 loss: 0.0017 lr: 0.02
2019-06-27 16:34:45 iteration: 59200 loss: 0.0015 lr: 0.02
2019-06-27 16:34:59 iteration: 59300 loss: 0.0018 lr: 0.02
2019-06-27 16:35:13 iteration: 59400 loss: 0.0016 lr: 0.02
2019-06-27 16:35:28 iteration: 59500 loss: 0.0018 lr: 0.02
2019-06-27 16:35:44 iteration: 59600 loss: 0.0017 lr: 0.02
2019-06-27 16:35:58 iteration: 59700 loss: 0.0016 lr: 0.02
2019-06-27 16:36:12 iteration: 59800 loss: 0.0016 lr: 0.02
2019-06-27 16:36:29 iteration: 59900 loss: 0.0013 lr: 0.02
2019-06-27 16:36:44 iteration: 60000 loss: 0.0017 lr: 0.02
2019-06-27 16:37:01 iteration: 60100 loss: 0.0017 lr: 0.02
2019-06-27 16:37:15 iteration: 60200 loss: 0.0018 lr: 0.02
2019-06-27 16:37:32 iteration: 60300 loss: 0.0017 lr: 0.02
2019-06-27 16:37:47 iteration: 60400 loss: 0.0016 lr: 0.02
2019-06-27 16:38:02 iteration: 60500 loss: 0.0016 lr: 0.02
2019-06-27 16:38:17 iteration: 60600 loss: 0.0015 lr: 0.02
2019-06-27 16:38:32 iteration: 60700 loss: 0.0015 lr: 0.02
2019-06-27 16:38:45 iteration: 60800 loss: 0.0015 lr: 0.02
2019-06-27 16:39:00 iteration: 60900 loss: 0.0019 lr: 0.02
2019-06-27 16:39:14 iteration: 61000 loss: 0.0019 lr: 0.02
2019-06-27 16:39:32 iteration: 61100 loss: 0.0016 lr: 0.02
2019-06-27 16:39:48 iteration: 61200 loss: 0.0016 lr: 0.02
2019-06-27 16:40:02 iteration: 61300 loss: 0.0018 lr: 0.02
2019-06-27 16:40:19 iteration: 61400 loss: 0.0019 lr: 0.02
2019-06-27 16:40:34 iteration: 61500 loss: 0.0016 lr: 0.02
2019-06-27 16:40:48 iteration: 61600 loss: 0.0019 lr: 0.02
2019-06-27 16:41:03 iteration: 61700 loss: 0.0016 lr: 0.02
2019-06-27 16:41:19 iteration: 61800 loss: 0.0018 lr: 0.02
2019-06-27 16:41:35 iteration: 61900 loss: 0.0021 lr: 0.02
2019-06-27 16:41:49 iteration: 62000 loss: 0.0017 lr: 0.02
2019-06-27 16:42:07 iteration: 62100 loss: 0.0018 lr: 0.02
2019-06-27 16:42:20 iteration: 62200 loss: 0.0019 lr: 0.02
2019-06-27 16:42:35 iteration: 62300 loss: 0.0017 lr: 0.02
2019-06-27 16:42:51 iteration: 62400 loss: 0.0019 lr: 0.02
2019-06-27 16:43:07 iteration: 62500 loss: 0.0018 lr: 0.02
2019-06-27 16:43:21 iteration: 62600 loss: 0.0017 lr: 0.02
2019-06-27 16:43:36 iteration: 62700 loss: 0.0017 lr: 0.02
2019-06-27 16:43:52 iteration: 62800 loss: 0.0015 lr: 0.02
2019-06-27 16:44:07 iteration: 62900 loss: 0.0016 lr: 0.02
2019-06-27 16:44:22 iteration: 63000 loss: 0.0016 lr: 0.02
2019-06-27 16:44:42 iteration: 63100 loss: 0.0016 lr: 0.02
2019-06-27 16:44:58 iteration: 63200 loss: 0.0016 lr: 0.02
2019-06-27 16:45:12 iteration: 63300 loss: 0.0018 lr: 0.02
2019-06-27 16:45:27 iteration: 63400 loss: 0.0015 lr: 0.02
2019-06-27 16:45:43 iteration: 63500 loss: 0.0017 lr: 0.02
2019-06-27 16:45:56 iteration: 63600 loss: 0.0017 lr: 0.02
2019-06-27 16:46:11 iteration: 63700 loss: 0.0016 lr: 0.02
2019-06-27 16:46:27 iteration: 63800 loss: 0.0016 lr: 0.02
2019-06-27 16:46:41 iteration: 63900 loss: 0.0017 lr: 0.02
2019-06-27 16:46:55 iteration: 64000 loss: 0.0016 lr: 0.02
2019-06-27 16:47:13 iteration: 64100 loss: 0.0016 lr: 0.02
2019-06-27 16:47:27 iteration: 64200 loss: 0.0016 lr: 0.02
2019-06-27 16:47:40 iteration: 64300 loss: 0.0015 lr: 0.02
2019-06-27 16:47:55 iteration: 64400 loss: 0.0016 lr: 0.02
2019-06-27 16:48:09 iteration: 64500 loss: 0.0017 lr: 0.02
2019-06-27 16:48:26 iteration: 64600 loss: 0.0018 lr: 0.02
2019-06-27 16:48:41 iteration: 64700 loss: 0.0016 lr: 0.02
2019-06-27 16:48:55 iteration: 64800 loss: 0.0015 lr: 0.02
2019-06-27 16:49:07 iteration: 64900 loss: 0.0016 lr: 0.02
2019-06-27 16:49:25 iteration: 65000 loss: 0.0017 lr: 0.02
2019-06-27 16:49:43 iteration: 65100 loss: 0.0016 lr: 0.02
2019-06-27 16:50:01 iteration: 65200 loss: 0.0015 lr: 0.02
2019-06-27 16:50:14 iteration: 65300 loss: 0.0014 lr: 0.02
2019-06-27 16:50:27 iteration: 65400 loss: 0.0018 lr: 0.02
2019-06-27 16:50:42 iteration: 65500 loss: 0.0016 lr: 0.02
2019-06-27 16:50:56 iteration: 65600 loss: 0.0015 lr: 0.02
2019-06-27 16:51:10 iteration: 65700 loss: 0.0018 lr: 0.02
2019-06-27 16:51:25 iteration: 65800 loss: 0.0015 lr: 0.02
2019-06-27 16:51:40 iteration: 65900 loss: 0.0018 lr: 0.02
2019-06-27 16:51:53 iteration: 66000 loss: 0.0019 lr: 0.02
2019-06-27 16:52:10 iteration: 66100 loss: 0.0016 lr: 0.02
2019-06-27 16:52:23 iteration: 66200 loss: 0.0018 lr: 0.02
2019-06-27 16:52:37 iteration: 66300 loss: 0.0016 lr: 0.02
2019-06-27 16:52:50 iteration: 66400 loss: 0.0017 lr: 0.02
2019-06-27 16:53:04 iteration: 66500 loss: 0.0017 lr: 0.02
2019-06-27 16:53:19 iteration: 66600 loss: 0.0016 lr: 0.02
2019-06-27 16:53:34 iteration: 66700 loss: 0.0017 lr: 0.02
2019-06-27 16:53:47 iteration: 66800 loss: 0.0016 lr: 0.02
2019-06-27 16:54:02 iteration: 66900 loss: 0.0016 lr: 0.02
2019-06-27 16:54:20 iteration: 67000 loss: 0.0015 lr: 0.02
2019-06-27 16:54:36 iteration: 67100 loss: 0.0016 lr: 0.02
2019-06-27 16:54:51 iteration: 67200 loss: 0.0015 lr: 0.02
2019-06-27 16:55:04 iteration: 67300 loss: 0.0016 lr: 0.02
2019-06-27 16:55:18 iteration: 67400 loss: 0.0017 lr: 0.02
2019-06-27 16:55:33 iteration: 67500 loss: 0.0017 lr: 0.02
2019-06-27 16:55:46 iteration: 67600 loss: 0.0018 lr: 0.02
2019-06-27 16:55:59 iteration: 67700 loss: 0.0018 lr: 0.02
2019-06-27 16:56:15 iteration: 67800 loss: 0.0015 lr: 0.02
2019-06-27 16:56:29 iteration: 67900 loss: 0.0015 lr: 0.02
2019-06-27 16:56:41 iteration: 68000 loss: 0.0017 lr: 0.02
2019-06-27 16:57:02 iteration: 68100 loss: 0.0016 lr: 0.02
2019-06-27 16:57:16 iteration: 68200 loss: 0.0016 lr: 0.02
2019-06-27 16:57:31 iteration: 68300 loss: 0.0017 lr: 0.02
2019-06-27 16:57:45 iteration: 68400 loss: 0.0017 lr: 0.02
2019-06-27 16:57:59 iteration: 68500 loss: 0.0017 lr: 0.02
2019-06-27 16:58:13 iteration: 68600 loss: 0.0018 lr: 0.02
2019-06-27 16:58:28 iteration: 68700 loss: 0.0017 lr: 0.02
2019-06-27 16:58:42 iteration: 68800 loss: 0.0017 lr: 0.02
2019-06-27 16:58:56 iteration: 68900 loss: 0.0017 lr: 0.02
2019-06-27 16:59:10 iteration: 69000 loss: 0.0018 lr: 0.02
2019-06-27 16:59:28 iteration: 69100 loss: 0.0016 lr: 0.02
2019-06-27 16:59:41 iteration: 69200 loss: 0.0016 lr: 0.02
2019-06-27 16:59:55 iteration: 69300 loss: 0.0014 lr: 0.02
2019-06-28 10:07:45 iteration: 69400 loss: 0.0015 lr: 0.02
2019-06-28 10:08:00 iteration: 69500 loss: 0.0016 lr: 0.02
2019-06-28 10:08:12 iteration: 69600 loss: 0.0015 lr: 0.02
2019-06-28 10:08:25 iteration: 69700 loss: 0.0018 lr: 0.02
2019-06-28 10:08:39 iteration: 69800 loss: 0.0016 lr: 0.02
2019-06-28 10:08:51 iteration: 69900 loss: 0.0017 lr: 0.02
2019-06-28 10:09:03 iteration: 70000 loss: 0.0015 lr: 0.02
2019-06-28 10:09:20 iteration: 70100 loss: 0.0017 lr: 0.02
2019-06-28 10:09:32 iteration: 70200 loss: 0.0017 lr: 0.02
2019-06-28 10:09:46 iteration: 70300 loss: 0.0015 lr: 0.02
2019-06-28 10:09:58 iteration: 70400 loss: 0.0015 lr: 0.02
2019-06-28 10:10:11 iteration: 70500 loss: 0.0016 lr: 0.02
2019-06-28 10:10:25 iteration: 70600 loss: 0.0016 lr: 0.02
2019-06-28 10:10:39 iteration: 70700 loss: 0.0016 lr: 0.02
2019-06-28 10:10:52 iteration: 70800 loss: 0.0016 lr: 0.02
2019-06-28 10:11:06 iteration: 70900 loss: 0.0015 lr: 0.02
2019-06-28 10:11:22 iteration: 71000 loss: 0.0014 lr: 0.02
2019-06-28 10:11:39 iteration: 71100 loss: 0.0016 lr: 0.02
2019-06-28 10:11:52 iteration: 71200 loss: 0.0015 lr: 0.02
2019-06-28 10:12:05 iteration: 71300 loss: 0.0017 lr: 0.02
2019-06-28 10:12:17 iteration: 71400 loss: 0.0017 lr: 0.02
2019-06-28 10:12:31 iteration: 71500 loss: 0.0014 lr: 0.02
2019-06-28 10:12:46 iteration: 71600 loss: 0.0016 lr: 0.02
2019-06-28 10:12:59 iteration: 71700 loss: 0.0015 lr: 0.02
2019-06-28 10:13:15 iteration: 71800 loss: 0.0017 lr: 0.02
2019-06-28 10:13:31 iteration: 71900 loss: 0.0014 lr: 0.02
2019-06-28 10:13:45 iteration: 72000 loss: 0.0015 lr: 0.02
2019-06-28 10:14:02 iteration: 72100 loss: 0.0014 lr: 0.02
2019-06-28 10:14:18 iteration: 72200 loss: 0.0016 lr: 0.02
2019-06-28 10:14:31 iteration: 72300 loss: 0.0017 lr: 0.02
2019-06-28 10:14:46 iteration: 72400 loss: 0.0016 lr: 0.02
2019-06-28 10:15:00 iteration: 72500 loss: 0.0016 lr: 0.02
2019-06-28 10:15:14 iteration: 72600 loss: 0.0018 lr: 0.02
2019-06-28 10:15:29 iteration: 72700 loss: 0.0016 lr: 0.02
2019-06-28 10:15:43 iteration: 72800 loss: 0.0017 lr: 0.02
2019-06-28 10:15:56 iteration: 72900 loss: 0.0016 lr: 0.02
2019-06-28 10:16:10 iteration: 73000 loss: 0.0014 lr: 0.02
2019-06-28 10:16:28 iteration: 73100 loss: 0.0017 lr: 0.02
2019-06-28 10:16:42 iteration: 73200 loss: 0.0016 lr: 0.02
2019-06-28 10:16:55 iteration: 73300 loss: 0.0016 lr: 0.02
2019-06-28 10:17:11 iteration: 73400 loss: 0.0014 lr: 0.02
2019-06-28 10:17:27 iteration: 73500 loss: 0.0018 lr: 0.02
2019-06-28 10:17:40 iteration: 73600 loss: 0.0016 lr: 0.02
2019-06-28 10:17:55 iteration: 73700 loss: 0.0016 lr: 0.02
2019-06-28 10:18:09 iteration: 73800 loss: 0.0014 lr: 0.02
2019-06-28 10:18:23 iteration: 73900 loss: 0.0017 lr: 0.02
2019-06-28 10:18:37 iteration: 74000 loss: 0.0017 lr: 0.02
2019-06-28 10:18:56 iteration: 74100 loss: 0.0013 lr: 0.02
2019-06-28 10:19:12 iteration: 74200 loss: 0.0016 lr: 0.02
2019-06-28 10:19:27 iteration: 74300 loss: 0.0016 lr: 0.02
2019-06-28 10:19:42 iteration: 74400 loss: 0.0015 lr: 0.02
2019-06-28 10:19:58 iteration: 74500 loss: 0.0016 lr: 0.02
2019-06-28 10:20:12 iteration: 74600 loss: 0.0013 lr: 0.02
2019-06-28 10:20:26 iteration: 74700 loss: 0.0015 lr: 0.02
2019-06-28 10:20:39 iteration: 74800 loss: 0.0016 lr: 0.02
2019-06-28 10:20:53 iteration: 74900 loss: 0.0015 lr: 0.02
2019-06-28 10:21:07 iteration: 75000 loss: 0.0014 lr: 0.02
2019-06-28 10:21:25 iteration: 75100 loss: 0.0016 lr: 0.02
2019-06-28 10:21:37 iteration: 75200 loss: 0.0016 lr: 0.02
2019-06-28 10:21:51 iteration: 75300 loss: 0.0016 lr: 0.02
2019-06-28 10:22:06 iteration: 75400 loss: 0.0014 lr: 0.02
2019-06-28 10:22:18 iteration: 75500 loss: 0.0014 lr: 0.02
2019-06-28 10:22:33 iteration: 75600 loss: 0.0016 lr: 0.02
2019-06-28 10:22:47 iteration: 75700 loss: 0.0016 lr: 0.02
2019-06-28 10:23:02 iteration: 75800 loss: 0.0018 lr: 0.02
2019-06-28 10:23:15 iteration: 75900 loss: 0.0014 lr: 0.02
2019-06-28 10:23:30 iteration: 76000 loss: 0.0015 lr: 0.02
2019-06-28 10:23:48 iteration: 76100 loss: 0.0014 lr: 0.02
2019-06-28 10:24:02 iteration: 76200 loss: 0.0015 lr: 0.02
2019-06-28 10:24:15 iteration: 76300 loss: 0.0017 lr: 0.02
2019-06-28 10:24:30 iteration: 76400 loss: 0.0016 lr: 0.02
2019-06-28 10:24:42 iteration: 76500 loss: 0.0016 lr: 0.02
2019-06-28 10:24:57 iteration: 76600 loss: 0.0016 lr: 0.02
2019-06-28 10:25:13 iteration: 76700 loss: 0.0017 lr: 0.02
2019-06-28 10:25:26 iteration: 76800 loss: 0.0017 lr: 0.02
2019-06-28 10:25:40 iteration: 76900 loss: 0.0015 lr: 0.02
2019-06-28 10:25:55 iteration: 77000 loss: 0.0014 lr: 0.02
2019-06-28 10:26:12 iteration: 77100 loss: 0.0014 lr: 0.02
2019-06-28 10:26:26 iteration: 77200 loss: 0.0016 lr: 0.02
2019-06-28 10:26:39 iteration: 77300 loss: 0.0015 lr: 0.02
2019-06-28 10:26:53 iteration: 77400 loss: 0.0013 lr: 0.02
2019-06-28 10:27:08 iteration: 77500 loss: 0.0015 lr: 0.02
2019-06-28 10:27:22 iteration: 77600 loss: 0.0018 lr: 0.02
2019-06-28 10:27:36 iteration: 77700 loss: 0.0014 lr: 0.02
2019-06-28 10:27:48 iteration: 77800 loss: 0.0014 lr: 0.02
2019-06-28 10:28:02 iteration: 77900 loss: 0.0016 lr: 0.02
2019-06-28 10:28:15 iteration: 78000 loss: 0.0016 lr: 0.02
2019-06-28 10:28:33 iteration: 78100 loss: 0.0015 lr: 0.02
2019-06-28 10:28:46 iteration: 78200 loss: 0.0017 lr: 0.02
2019-06-28 10:29:02 iteration: 78300 loss: 0.0015 lr: 0.02
2019-06-28 10:29:15 iteration: 78400 loss: 0.0016 lr: 0.02
2019-06-28 10:29:29 iteration: 78500 loss: 0.0013 lr: 0.02
2019-06-28 10:29:44 iteration: 78600 loss: 0.0015 lr: 0.02
2019-06-28 10:29:58 iteration: 78700 loss: 0.0014 lr: 0.02
2019-06-28 10:30:10 iteration: 78800 loss: 0.0017 lr: 0.02
2019-06-28 10:30:23 iteration: 78900 loss: 0.0019 lr: 0.02
2019-06-28 10:30:38 iteration: 79000 loss: 0.0015 lr: 0.02
2019-06-28 10:30:55 iteration: 79100 loss: 0.0015 lr: 0.02
2019-06-28 10:31:09 iteration: 79200 loss: 0.0015 lr: 0.02
2019-06-28 10:31:23 iteration: 79300 loss: 0.0017 lr: 0.02
2019-06-28 10:31:36 iteration: 79400 loss: 0.0016 lr: 0.02
2019-06-28 10:31:51 iteration: 79500 loss: 0.0017 lr: 0.02
2019-06-28 10:32:04 iteration: 79600 loss: 0.0015 lr: 0.02
2019-06-28 10:32:21 iteration: 79700 loss: 0.0015 lr: 0.02
2019-06-28 10:32:34 iteration: 79800 loss: 0.0015 lr: 0.02
2019-06-28 10:32:49 iteration: 79900 loss: 0.0017 lr: 0.02
2019-06-28 10:33:02 iteration: 80000 loss: 0.0016 lr: 0.02
2019-06-28 10:33:19 iteration: 80100 loss: 0.0016 lr: 0.02
2019-06-28 10:33:33 iteration: 80200 loss: 0.0015 lr: 0.02
2019-06-28 10:33:46 iteration: 80300 loss: 0.0014 lr: 0.02
2019-06-28 10:34:01 iteration: 80400 loss: 0.0014 lr: 0.02
2019-06-28 10:34:14 iteration: 80500 loss: 0.0016 lr: 0.02
2019-06-28 10:34:28 iteration: 80600 loss: 0.0016 lr: 0.02
2019-06-28 10:34:45 iteration: 80700 loss: 0.0015 lr: 0.02
2019-06-28 10:34:59 iteration: 80800 loss: 0.0014 lr: 0.02
2019-06-28 10:35:14 iteration: 80900 loss: 0.0015 lr: 0.02
2019-06-28 10:35:29 iteration: 81000 loss: 0.0015 lr: 0.02
2019-06-28 10:35:48 iteration: 81100 loss: 0.0014 lr: 0.02
2019-06-28 10:36:01 iteration: 81200 loss: 0.0013 lr: 0.02
2019-06-28 10:36:13 iteration: 81300 loss: 0.0016 lr: 0.02
2019-06-28 10:36:26 iteration: 81400 loss: 0.0013 lr: 0.02
2019-06-28 10:36:42 iteration: 81500 loss: 0.0015 lr: 0.02
2019-06-28 10:36:55 iteration: 81600 loss: 0.0015 lr: 0.02
2019-06-28 10:37:11 iteration: 81700 loss: 0.0017 lr: 0.02
2019-06-28 10:37:24 iteration: 81800 loss: 0.0015 lr: 0.02
2019-06-28 10:37:36 iteration: 81900 loss: 0.0016 lr: 0.02
2019-06-28 10:37:49 iteration: 82000 loss: 0.0016 lr: 0.02
2019-06-28 10:38:06 iteration: 82100 loss: 0.0016 lr: 0.02
2019-06-28 10:38:19 iteration: 82200 loss: 0.0015 lr: 0.02
2019-06-28 10:38:33 iteration: 82300 loss: 0.0017 lr: 0.02
2019-06-28 10:38:47 iteration: 82400 loss: 0.0014 lr: 0.02
2019-06-28 10:39:00 iteration: 82500 loss: 0.0014 lr: 0.02
2019-06-28 10:39:14 iteration: 82600 loss: 0.0014 lr: 0.02
2019-06-28 10:39:27 iteration: 82700 loss: 0.0015 lr: 0.02
2019-06-28 10:39:42 iteration: 82800 loss: 0.0016 lr: 0.02
2019-06-28 10:39:57 iteration: 82900 loss: 0.0015 lr: 0.02
2019-06-28 10:40:11 iteration: 83000 loss: 0.0015 lr: 0.02
2019-06-28 10:40:29 iteration: 83100 loss: 0.0014 lr: 0.02
2019-06-28 10:40:44 iteration: 83200 loss: 0.0016 lr: 0.02
2019-06-28 10:40:57 iteration: 83300 loss: 0.0017 lr: 0.02
2019-06-28 10:41:12 iteration: 83400 loss: 0.0014 lr: 0.02
2019-06-28 10:41:27 iteration: 83500 loss: 0.0016 lr: 0.02
2019-06-28 10:41:43 iteration: 83600 loss: 0.0016 lr: 0.02
2019-06-28 10:41:58 iteration: 83700 loss: 0.0016 lr: 0.02
2019-06-28 10:42:11 iteration: 83800 loss: 0.0013 lr: 0.02
2019-06-28 10:42:24 iteration: 83900 loss: 0.0016 lr: 0.02
2019-06-28 10:42:39 iteration: 84000 loss: 0.0015 lr: 0.02
2019-06-28 10:42:55 iteration: 84100 loss: 0.0015 lr: 0.02
2019-06-28 10:43:08 iteration: 84200 loss: 0.0014 lr: 0.02
2019-06-28 10:43:20 iteration: 84300 loss: 0.0014 lr: 0.02
2019-06-28 10:43:33 iteration: 84400 loss: 0.0017 lr: 0.02
2019-06-28 10:43:48 iteration: 84500 loss: 0.0014 lr: 0.02
2019-06-28 10:44:00 iteration: 84600 loss: 0.0015 lr: 0.02
2019-06-28 10:44:15 iteration: 84700 loss: 0.0015 lr: 0.02
2019-06-28 10:44:29 iteration: 84800 loss: 0.0015 lr: 0.02
2019-06-28 10:44:42 iteration: 84900 loss: 0.0016 lr: 0.02
2019-06-28 10:44:56 iteration: 85000 loss: 0.0014 lr: 0.02
2019-06-28 10:45:13 iteration: 85100 loss: 0.0014 lr: 0.02
2019-06-28 10:45:25 iteration: 85200 loss: 0.0014 lr: 0.02
2019-06-28 10:45:40 iteration: 85300 loss: 0.0015 lr: 0.02
2019-06-28 10:45:52 iteration: 85400 loss: 0.0014 lr: 0.02
2019-06-28 10:46:05 iteration: 85500 loss: 0.0015 lr: 0.02
2019-06-28 10:46:20 iteration: 85600 loss: 0.0016 lr: 0.02
2019-06-28 10:46:34 iteration: 85700 loss: 0.0016 lr: 0.02
2019-06-28 10:46:48 iteration: 85800 loss: 0.0015 lr: 0.02
2019-06-28 10:47:02 iteration: 85900 loss: 0.0015 lr: 0.02
2019-06-28 10:47:16 iteration: 86000 loss: 0.0017 lr: 0.02
2019-06-28 10:47:34 iteration: 86100 loss: 0.0013 lr: 0.02
2019-06-28 10:47:47 iteration: 86200 loss: 0.0015 lr: 0.02
2019-06-28 10:48:02 iteration: 86300 loss: 0.0015 lr: 0.02
2019-06-28 10:48:15 iteration: 86400 loss: 0.0015 lr: 0.02
2019-06-28 10:48:29 iteration: 86500 loss: 0.0015 lr: 0.02
2019-06-28 10:48:42 iteration: 86600 loss: 0.0014 lr: 0.02
2019-06-28 10:48:56 iteration: 86700 loss: 0.0014 lr: 0.02
2019-06-28 10:49:11 iteration: 86800 loss: 0.0015 lr: 0.02
2019-06-28 10:49:22 iteration: 86900 loss: 0.0016 lr: 0.02
2019-06-28 10:49:35 iteration: 87000 loss: 0.0016 lr: 0.02
2019-06-28 10:49:51 iteration: 87100 loss: 0.0014 lr: 0.02
2019-06-28 10:50:06 iteration: 87200 loss: 0.0017 lr: 0.02
2019-06-28 10:50:19 iteration: 87300 loss: 0.0017 lr: 0.02
2019-06-28 10:50:34 iteration: 87400 loss: 0.0015 lr: 0.02
2019-06-28 10:50:47 iteration: 87500 loss: 0.0014 lr: 0.02
2019-06-28 10:51:02 iteration: 87600 loss: 0.0015 lr: 0.02
2019-06-28 10:51:15 iteration: 87700 loss: 0.0016 lr: 0.02
2019-06-28 10:51:27 iteration: 87800 loss: 0.0016 lr: 0.02
2019-06-28 10:51:39 iteration: 87900 loss: 0.0016 lr: 0.02
2019-06-28 10:51:54 iteration: 88000 loss: 0.0015 lr: 0.02
2019-06-28 10:52:10 iteration: 88100 loss: 0.0017 lr: 0.02
2019-06-28 10:52:26 iteration: 88200 loss: 0.0015 lr: 0.02
2019-06-28 10:52:41 iteration: 88300 loss: 0.0015 lr: 0.02
2019-06-28 10:52:54 iteration: 88400 loss: 0.0014 lr: 0.02
2019-06-28 10:53:07 iteration: 88500 loss: 0.0017 lr: 0.02
2019-06-28 10:53:19 iteration: 88600 loss: 0.0016 lr: 0.02
2019-06-28 10:53:33 iteration: 88700 loss: 0.0017 lr: 0.02
2019-06-28 10:53:46 iteration: 88800 loss: 0.0015 lr: 0.02
2019-06-28 10:54:00 iteration: 88900 loss: 0.0014 lr: 0.02
2019-06-28 10:54:14 iteration: 89000 loss: 0.0014 lr: 0.02
2019-06-28 10:54:30 iteration: 89100 loss: 0.0014 lr: 0.02
2019-06-28 10:54:43 iteration: 89200 loss: 0.0014 lr: 0.02
2019-06-28 10:54:58 iteration: 89300 loss: 0.0016 lr: 0.02
2019-06-28 10:55:09 iteration: 89400 loss: 0.0015 lr: 0.02
2019-06-28 10:55:22 iteration: 89500 loss: 0.0014 lr: 0.02
2019-06-28 10:55:33 iteration: 89600 loss: 0.0014 lr: 0.02
2019-06-28 10:55:47 iteration: 89700 loss: 0.0013 lr: 0.02
2019-06-28 10:56:02 iteration: 89800 loss: 0.0015 lr: 0.02
2019-06-28 10:56:16 iteration: 89900 loss: 0.0016 lr: 0.02
2019-06-28 10:56:29 iteration: 90000 loss: 0.0016 lr: 0.02
2019-06-28 10:56:44 iteration: 90100 loss: 0.0016 lr: 0.02
2019-06-28 10:56:58 iteration: 90200 loss: 0.0015 lr: 0.02
2019-06-28 10:57:10 iteration: 90300 loss: 0.0014 lr: 0.02
2019-06-28 10:57:24 iteration: 90400 loss: 0.0017 lr: 0.02
2019-06-28 10:57:43 iteration: 90500 loss: 0.0016 lr: 0.02
2019-06-28 10:57:55 iteration: 90600 loss: 0.0015 lr: 0.02
2019-06-28 10:58:09 iteration: 90700 loss: 0.0015 lr: 0.02
2019-06-28 10:58:21 iteration: 90800 loss: 0.0015 lr: 0.02
2019-06-28 10:58:35 iteration: 90900 loss: 0.0013 lr: 0.02
2019-06-28 10:58:48 iteration: 91000 loss: 0.0013 lr: 0.02
2019-06-28 10:59:05 iteration: 91100 loss: 0.0015 lr: 0.02
2019-06-28 10:59:19 iteration: 91200 loss: 0.0015 lr: 0.02
2019-06-28 10:59:31 iteration: 91300 loss: 0.0015 lr: 0.02
2019-06-28 10:59:45 iteration: 91400 loss: 0.0014 lr: 0.02
2019-06-28 10:59:58 iteration: 91500 loss: 0.0013 lr: 0.02
2019-06-28 11:00:12 iteration: 91600 loss: 0.0012 lr: 0.02
2019-06-28 11:00:26 iteration: 91700 loss: 0.0013 lr: 0.02
2019-06-28 11:00:40 iteration: 91800 loss: 0.0015 lr: 0.02
2019-06-28 11:00:53 iteration: 91900 loss: 0.0016 lr: 0.02
2019-06-28 11:01:09 iteration: 92000 loss: 0.0013 lr: 0.02
2019-06-28 11:01:25 iteration: 92100 loss: 0.0015 lr: 0.02
2019-06-28 11:01:39 iteration: 92200 loss: 0.0015 lr: 0.02
2019-06-28 11:01:54 iteration: 92300 loss: 0.0015 lr: 0.02
2019-06-28 11:02:08 iteration: 92400 loss: 0.0016 lr: 0.02
2019-06-28 11:02:22 iteration: 92500 loss: 0.0013 lr: 0.02
2019-06-28 11:02:36 iteration: 92600 loss: 0.0014 lr: 0.02
2019-06-28 11:02:49 iteration: 92700 loss: 0.0014 lr: 0.02
2019-06-28 11:03:02 iteration: 92800 loss: 0.0015 lr: 0.02
2019-06-28 11:03:15 iteration: 92900 loss: 0.0016 lr: 0.02
2019-06-28 11:03:26 iteration: 93000 loss: 0.0014 lr: 0.02
2019-06-28 11:03:43 iteration: 93100 loss: 0.0014 lr: 0.02
2019-06-28 11:03:56 iteration: 93200 loss: 0.0013 lr: 0.02
2019-06-28 11:04:09 iteration: 93300 loss: 0.0013 lr: 0.02
2019-06-28 11:04:23 iteration: 93400 loss: 0.0014 lr: 0.02
2019-06-28 11:04:37 iteration: 93500 loss: 0.0014 lr: 0.02
2019-06-28 11:04:51 iteration: 93600 loss: 0.0013 lr: 0.02
2019-06-28 11:05:04 iteration: 93700 loss: 0.0016 lr: 0.02
2019-06-28 11:05:17 iteration: 93800 loss: 0.0015 lr: 0.02
2019-06-28 11:05:30 iteration: 93900 loss: 0.0014 lr: 0.02
2019-06-28 11:05:42 iteration: 94000 loss: 0.0015 lr: 0.02
2019-06-28 11:05:57 iteration: 94100 loss: 0.0014 lr: 0.02
2019-06-28 11:06:11 iteration: 94200 loss: 0.0015 lr: 0.02
2019-06-28 11:06:23 iteration: 94300 loss: 0.0015 lr: 0.02
2019-06-28 11:06:37 iteration: 94400 loss: 0.0015 lr: 0.02
2019-06-28 11:06:51 iteration: 94500 loss: 0.0016 lr: 0.02
2019-06-28 11:07:05 iteration: 94600 loss: 0.0015 lr: 0.02
2019-06-28 11:07:19 iteration: 94700 loss: 0.0015 lr: 0.02
2019-06-28 11:07:30 iteration: 94800 loss: 0.0015 lr: 0.02
2019-06-28 11:07:44 iteration: 94900 loss: 0.0017 lr: 0.02
2019-06-28 11:07:58 iteration: 95000 loss: 0.0016 lr: 0.02
2019-06-28 11:08:18 iteration: 95100 loss: 0.0015 lr: 0.02
2019-06-28 11:08:31 iteration: 95200 loss: 0.0016 lr: 0.02
2019-06-28 11:08:46 iteration: 95300 loss: 0.0014 lr: 0.02
2019-06-28 11:08:59 iteration: 95400 loss: 0.0015 lr: 0.02
2019-06-28 11:09:12 iteration: 95500 loss: 0.0016 lr: 0.02
2019-06-28 11:09:27 iteration: 95600 loss: 0.0016 lr: 0.02
2019-06-28 11:09:39 iteration: 95700 loss: 0.0015 lr: 0.02
2019-06-28 11:09:53 iteration: 95800 loss: 0.0014 lr: 0.02
2019-06-28 11:10:05 iteration: 95900 loss: 0.0014 lr: 0.02
2019-06-28 11:10:15 iteration: 96000 loss: 0.0015 lr: 0.02
2019-06-28 11:10:30 iteration: 96100 loss: 0.0016 lr: 0.02
2019-06-28 11:10:44 iteration: 96200 loss: 0.0014 lr: 0.02
2019-06-28 11:10:57 iteration: 96300 loss: 0.0015 lr: 0.02
2019-06-28 11:11:11 iteration: 96400 loss: 0.0016 lr: 0.02
2019-06-28 11:11:23 iteration: 96500 loss: 0.0014 lr: 0.02
2019-06-28 11:11:35 iteration: 96600 loss: 0.0015 lr: 0.02
2019-06-28 11:11:49 iteration: 96700 loss: 0.0014 lr: 0.02
2019-06-28 11:12:00 iteration: 96800 loss: 0.0014 lr: 0.02
2019-06-28 11:12:13 iteration: 96900 loss: 0.0014 lr: 0.02
2019-06-28 11:12:26 iteration: 97000 loss: 0.0015 lr: 0.02
2019-06-28 11:12:41 iteration: 97100 loss: 0.0014 lr: 0.02
2019-06-28 11:12:53 iteration: 97200 loss: 0.0014 lr: 0.02
2019-06-28 11:13:06 iteration: 97300 loss: 0.0014 lr: 0.02
2019-06-28 11:13:18 iteration: 97400 loss: 0.0015 lr: 0.02
2019-06-28 11:13:31 iteration: 97500 loss: 0.0014 lr: 0.02
2019-06-28 11:13:43 iteration: 97600 loss: 0.0017 lr: 0.02
2019-06-28 11:13:58 iteration: 97700 loss: 0.0016 lr: 0.02
2019-06-28 11:14:12 iteration: 97800 loss: 0.0015 lr: 0.02
2019-06-28 11:14:27 iteration: 97900 loss: 0.0013 lr: 0.02
2019-06-28 11:14:39 iteration: 98000 loss: 0.0014 lr: 0.02
2019-06-28 11:14:56 iteration: 98100 loss: 0.0014 lr: 0.02
2019-06-28 11:15:09 iteration: 98200 loss: 0.0015 lr: 0.02
2019-06-28 11:15:22 iteration: 98300 loss: 0.0013 lr: 0.02
2019-06-28 11:15:33 iteration: 98400 loss: 0.0015 lr: 0.02
2019-06-28 11:15:47 iteration: 98500 loss: 0.0013 lr: 0.02
2019-06-28 11:16:01 iteration: 98600 loss: 0.0015 lr: 0.02
2019-06-28 11:16:15 iteration: 98700 loss: 0.0014 lr: 0.02
2019-06-28 11:16:29 iteration: 98800 loss: 0.0015 lr: 0.02
2019-06-28 11:16:41 iteration: 98900 loss: 0.0015 lr: 0.02
2019-06-28 11:16:54 iteration: 99000 loss: 0.0014 lr: 0.02
2019-06-28 11:17:10 iteration: 99100 loss: 0.0014 lr: 0.02
2019-06-28 11:17:22 iteration: 99200 loss: 0.0015 lr: 0.02
2019-06-28 11:17:34 iteration: 99300 loss: 0.0013 lr: 0.02
2019-06-28 11:17:46 iteration: 99400 loss: 0.0016 lr: 0.02
2019-06-28 11:17:59 iteration: 99500 loss: 0.0014 lr: 0.02
2019-06-28 11:18:14 iteration: 99600 loss: 0.0014 lr: 0.02
2019-06-28 11:18:25 iteration: 99700 loss: 0.0014 lr: 0.02
2019-06-28 11:18:38 iteration: 99800 loss: 0.0014 lr: 0.02
2019-06-28 11:18:51 iteration: 99900 loss: 0.0012 lr: 0.02
2019-06-28 11:19:04 iteration: 100000 loss: 0.0013 lr: 0.02
2019-06-28 11:19:22 iteration: 100100 loss: 0.0014 lr: 0.02
2019-06-28 11:19:36 iteration: 100200 loss: 0.0016 lr: 0.02
2019-06-28 11:19:48 iteration: 100300 loss: 0.0014 lr: 0.02
2019-06-28 11:20:00 iteration: 100400 loss: 0.0013 lr: 0.02
2019-06-28 11:20:14 iteration: 100500 loss: 0.0016 lr: 0.02
2019-06-28 11:20:28 iteration: 100600 loss: 0.0014 lr: 0.02
2019-06-28 11:20:40 iteration: 100700 loss: 0.0017 lr: 0.02
2019-06-28 11:20:52 iteration: 100800 loss: 0.0015 lr: 0.02
2019-06-28 11:21:07 iteration: 100900 loss: 0.0014 lr: 0.02
2019-06-28 11:21:20 iteration: 101000 loss: 0.0014 lr: 0.02
2019-06-28 11:21:37 iteration: 101100 loss: 0.0014 lr: 0.02
2019-06-28 11:21:50 iteration: 101200 loss: 0.0015 lr: 0.02
2019-06-28 11:22:05 iteration: 101300 loss: 0.0013 lr: 0.02
2019-06-28 11:22:18 iteration: 101400 loss: 0.0015 lr: 0.02
2019-06-28 11:22:30 iteration: 101500 loss: 0.0017 lr: 0.02
2019-06-28 11:22:44 iteration: 101600 loss: 0.0014 lr: 0.02
2019-06-28 11:22:57 iteration: 101700 loss: 0.0014 lr: 0.02
2019-06-28 11:23:11 iteration: 101800 loss: 0.0015 lr: 0.02
2019-06-28 11:23:25 iteration: 101900 loss: 0.0013 lr: 0.02
2019-06-28 11:23:39 iteration: 102000 loss: 0.0012 lr: 0.02
2019-06-28 11:23:57 iteration: 102100 loss: 0.0013 lr: 0.02
2019-06-28 11:24:11 iteration: 102200 loss: 0.0012 lr: 0.02
2019-06-28 11:24:24 iteration: 102300 loss: 0.0014 lr: 0.02
2019-06-28 11:24:37 iteration: 102400 loss: 0.0014 lr: 0.02
2019-06-28 11:24:50 iteration: 102500 loss: 0.0014 lr: 0.02
2019-06-28 11:25:03 iteration: 102600 loss: 0.0014 lr: 0.02
2019-06-28 11:25:16 iteration: 102700 loss: 0.0013 lr: 0.02
2019-06-28 11:25:29 iteration: 102800 loss: 0.0013 lr: 0.02
2019-06-28 11:25:43 iteration: 102900 loss: 0.0016 lr: 0.02
2019-06-28 11:25:55 iteration: 103000 loss: 0.0014 lr: 0.02
2019-06-28 11:26:12 iteration: 103100 loss: 0.0015 lr: 0.02
2019-06-28 11:26:26 iteration: 103200 loss: 0.0015 lr: 0.02
2019-06-28 11:26:40 iteration: 103300 loss: 0.0016 lr: 0.02
2019-06-28 11:26:54 iteration: 103400 loss: 0.0014 lr: 0.02
2019-06-28 11:27:07 iteration: 103500 loss: 0.0015 lr: 0.02
2019-06-28 11:27:20 iteration: 103600 loss: 0.0013 lr: 0.02
2019-06-28 11:27:32 iteration: 103700 loss: 0.0014 lr: 0.02
2019-06-28 11:27:43 iteration: 103800 loss: 0.0015 lr: 0.02
2019-06-28 11:27:54 iteration: 103900 loss: 0.0015 lr: 0.02
2019-06-28 11:28:07 iteration: 104000 loss: 0.0014 lr: 0.02
2019-06-28 11:28:23 iteration: 104100 loss: 0.0013 lr: 0.02
2019-06-28 11:28:36 iteration: 104200 loss: 0.0014 lr: 0.02
2019-06-28 11:28:48 iteration: 104300 loss: 0.0014 lr: 0.02
2019-06-28 11:29:01 iteration: 104400 loss: 0.0012 lr: 0.02
2019-06-28 11:29:15 iteration: 104500 loss: 0.0015 lr: 0.02
2019-06-28 11:29:29 iteration: 104600 loss: 0.0015 lr: 0.02
2019-06-28 11:29:41 iteration: 104700 loss: 0.0015 lr: 0.02
2019-06-28 11:29:54 iteration: 104800 loss: 0.0014 lr: 0.02
2019-06-28 11:30:06 iteration: 104900 loss: 0.0013 lr: 0.02
2019-06-28 11:30:19 iteration: 105000 loss: 0.0014 lr: 0.02
2019-06-28 11:30:34 iteration: 105100 loss: 0.0013 lr: 0.02
2019-06-28 11:30:47 iteration: 105200 loss: 0.0013 lr: 0.02
2019-06-28 11:31:01 iteration: 105300 loss: 0.0015 lr: 0.02
2019-06-28 11:31:14 iteration: 105400 loss: 0.0014 lr: 0.02
2019-06-28 11:31:28 iteration: 105500 loss: 0.0014 lr: 0.02
2019-06-28 11:31:39 iteration: 105600 loss: 0.0015 lr: 0.02
2019-06-28 11:31:53 iteration: 105700 loss: 0.0012 lr: 0.02
2019-06-28 11:32:07 iteration: 105800 loss: 0.0013 lr: 0.02
2019-06-28 11:32:20 iteration: 105900 loss: 0.0015 lr: 0.02
2019-06-28 11:32:32 iteration: 106000 loss: 0.0014 lr: 0.02
2019-06-28 11:32:49 iteration: 106100 loss: 0.0014 lr: 0.02
2019-06-28 11:33:02 iteration: 106200 loss: 0.0013 lr: 0.02
2019-06-28 11:33:15 iteration: 106300 loss: 0.0013 lr: 0.02
2019-06-28 11:33:28 iteration: 106400 loss: 0.0013 lr: 0.02
2019-06-28 11:33:42 iteration: 106500 loss: 0.0014 lr: 0.02
2019-06-28 11:33:57 iteration: 106600 loss: 0.0013 lr: 0.02
2019-06-28 11:34:09 iteration: 106700 loss: 0.0015 lr: 0.02
2019-06-28 11:34:21 iteration: 106800 loss: 0.0015 lr: 0.02
2019-06-28 11:34:36 iteration: 106900 loss: 0.0014 lr: 0.02
2019-06-28 11:34:50 iteration: 107000 loss: 0.0014 lr: 0.02
2019-06-28 11:35:07 iteration: 107100 loss: 0.0016 lr: 0.02
2019-06-28 11:35:20 iteration: 107200 loss: 0.0016 lr: 0.02
2019-06-28 11:35:33 iteration: 107300 loss: 0.0014 lr: 0.02
2019-06-28 11:35:45 iteration: 107400 loss: 0.0014 lr: 0.02
2019-06-28 11:35:57 iteration: 107500 loss: 0.0015 lr: 0.02
2019-06-28 11:36:10 iteration: 107600 loss: 0.0016 lr: 0.02
2019-06-28 11:36:23 iteration: 107700 loss: 0.0016 lr: 0.02
2019-06-28 11:36:36 iteration: 107800 loss: 0.0014 lr: 0.02
2019-06-28 11:36:49 iteration: 107900 loss: 0.0013 lr: 0.02
2019-06-28 11:37:04 iteration: 108000 loss: 0.0015 lr: 0.02
2019-06-28 11:37:19 iteration: 108100 loss: 0.0013 lr: 0.02
2019-06-28 11:37:32 iteration: 108200 loss: 0.0016 lr: 0.02
2019-06-28 11:37:45 iteration: 108300 loss: 0.0015 lr: 0.02
2019-06-28 11:38:00 iteration: 108400 loss: 0.0013 lr: 0.02
2019-06-28 11:38:14 iteration: 108500 loss: 0.0014 lr: 0.02
2019-06-28 11:38:28 iteration: 108600 loss: 0.0013 lr: 0.02
2019-06-28 11:38:41 iteration: 108700 loss: 0.0012 lr: 0.02
2019-06-28 11:38:54 iteration: 108800 loss: 0.0014 lr: 0.02
2019-06-28 11:39:06 iteration: 108900 loss: 0.0013 lr: 0.02
2019-06-28 11:39:22 iteration: 109000 loss: 0.0015 lr: 0.02
2019-06-28 11:39:40 iteration: 109100 loss: 0.0013 lr: 0.02
2019-06-28 11:39:55 iteration: 109200 loss: 0.0013 lr: 0.02
2019-06-28 11:40:08 iteration: 109300 loss: 0.0015 lr: 0.02
2019-06-28 11:40:19 iteration: 109400 loss: 0.0015 lr: 0.02
2019-06-28 11:40:32 iteration: 109500 loss: 0.0013 lr: 0.02
2019-06-28 11:40:46 iteration: 109600 loss: 0.0013 lr: 0.02
2019-06-28 11:40:58 iteration: 109700 loss: 0.0014 lr: 0.02
2019-06-28 11:41:10 iteration: 109800 loss: 0.0013 lr: 0.02
2019-06-28 11:41:23 iteration: 109900 loss: 0.0013 lr: 0.02
2019-06-28 11:41:37 iteration: 110000 loss: 0.0014 lr: 0.02
2019-06-28 11:41:53 iteration: 110100 loss: 0.0016 lr: 0.02
2019-06-28 11:42:05 iteration: 110200 loss: 0.0014 lr: 0.02
2019-06-28 11:42:19 iteration: 110300 loss: 0.0013 lr: 0.02
2019-06-28 11:42:31 iteration: 110400 loss: 0.0013 lr: 0.02
2019-06-28 11:42:46 iteration: 110500 loss: 0.0013 lr: 0.02
2019-06-28 11:42:58 iteration: 110600 loss: 0.0014 lr: 0.02
2019-06-28 11:43:11 iteration: 110700 loss: 0.0015 lr: 0.02
2019-06-28 11:43:27 iteration: 110800 loss: 0.0015 lr: 0.02
2019-06-28 11:43:42 iteration: 110900 loss: 0.0013 lr: 0.02
2019-06-28 11:43:56 iteration: 111000 loss: 0.0014 lr: 0.02
2019-06-28 11:44:13 iteration: 111100 loss: 0.0013 lr: 0.02
2019-06-28 11:44:26 iteration: 111200 loss: 0.0015 lr: 0.02
2019-06-28 11:44:39 iteration: 111300 loss: 0.0013 lr: 0.02
2019-06-28 11:44:53 iteration: 111400 loss: 0.0014 lr: 0.02
2019-06-28 11:45:06 iteration: 111500 loss: 0.0013 lr: 0.02
2019-06-28 11:45:19 iteration: 111600 loss: 0.0016 lr: 0.02
2019-06-28 11:45:33 iteration: 111700 loss: 0.0016 lr: 0.02
2019-06-28 11:45:45 iteration: 111800 loss: 0.0013 lr: 0.02
2019-06-28 11:45:59 iteration: 111900 loss: 0.0014 lr: 0.02
2019-06-28 11:46:11 iteration: 112000 loss: 0.0014 lr: 0.02
2019-06-28 11:46:26 iteration: 112100 loss: 0.0015 lr: 0.02
2019-06-28 11:46:37 iteration: 112200 loss: 0.0016 lr: 0.02
2019-06-28 11:46:50 iteration: 112300 loss: 0.0016 lr: 0.02
2019-06-28 11:47:02 iteration: 112400 loss: 0.0013 lr: 0.02
2019-06-28 11:47:14 iteration: 112500 loss: 0.0013 lr: 0.02
2019-06-28 11:47:27 iteration: 112600 loss: 0.0013 lr: 0.02
2019-06-28 11:47:41 iteration: 112700 loss: 0.0012 lr: 0.02
2019-06-28 11:47:55 iteration: 112800 loss: 0.0012 lr: 0.02
2019-06-28 11:48:08 iteration: 112900 loss: 0.0013 lr: 0.02
2019-06-28 11:48:21 iteration: 113000 loss: 0.0014 lr: 0.02
2019-06-28 11:48:37 iteration: 113100 loss: 0.0013 lr: 0.02
2019-06-28 11:48:50 iteration: 113200 loss: 0.0012 lr: 0.02
2019-06-28 11:49:04 iteration: 113300 loss: 0.0012 lr: 0.02
2019-06-28 11:49:18 iteration: 113400 loss: 0.0014 lr: 0.02
2019-06-28 11:49:30 iteration: 113500 loss: 0.0012 lr: 0.02
2019-06-28 11:49:43 iteration: 113600 loss: 0.0012 lr: 0.02
2019-06-28 11:49:54 iteration: 113700 loss: 0.0014 lr: 0.02
2019-06-28 11:50:06 iteration: 113800 loss: 0.0013 lr: 0.02
2019-06-28 11:50:19 iteration: 113900 loss: 0.0014 lr: 0.02
2019-06-28 11:50:32 iteration: 114000 loss: 0.0013 lr: 0.02
2019-06-28 11:50:48 iteration: 114100 loss: 0.0013 lr: 0.02
2019-06-28 11:51:01 iteration: 114200 loss: 0.0013 lr: 0.02
2019-06-28 11:51:14 iteration: 114300 loss: 0.0014 lr: 0.02
2019-06-28 11:51:26 iteration: 114400 loss: 0.0015 lr: 0.02
2019-06-28 11:51:40 iteration: 114500 loss: 0.0013 lr: 0.02
2019-06-28 11:51:55 iteration: 114600 loss: 0.0013 lr: 0.02
2019-06-28 11:52:08 iteration: 114700 loss: 0.0013 lr: 0.02
2019-06-28 11:52:21 iteration: 114800 loss: 0.0014 lr: 0.02
2019-06-28 11:52:34 iteration: 114900 loss: 0.0012 lr: 0.02
2019-06-28 11:52:48 iteration: 115000 loss: 0.0013 lr: 0.02
2019-06-28 11:53:04 iteration: 115100 loss: 0.0012 lr: 0.02
2019-06-28 11:53:17 iteration: 115200 loss: 0.0014 lr: 0.02
2019-06-28 11:53:27 iteration: 115300 loss: 0.0014 lr: 0.02
2019-06-28 11:53:39 iteration: 115400 loss: 0.0016 lr: 0.02
2019-06-28 11:53:51 iteration: 115500 loss: 0.0014 lr: 0.02
2019-06-28 11:54:04 iteration: 115600 loss: 0.0013 lr: 0.02
2019-06-28 11:54:18 iteration: 115700 loss: 0.0011 lr: 0.02
2019-06-28 11:54:31 iteration: 115800 loss: 0.0013 lr: 0.02
2019-06-28 11:54:42 iteration: 115900 loss: 0.0014 lr: 0.02
2019-06-28 11:54:55 iteration: 116000 loss: 0.0015 lr: 0.02
2019-06-28 11:55:10 iteration: 116100 loss: 0.0012 lr: 0.02
2019-06-28 11:55:22 iteration: 116200 loss: 0.0014 lr: 0.02
2019-06-28 11:55:34 iteration: 116300 loss: 0.0014 lr: 0.02
2019-06-28 11:55:47 iteration: 116400 loss: 0.0015 lr: 0.02
2019-06-28 11:56:00 iteration: 116500 loss: 0.0014 lr: 0.02
2019-06-28 11:56:12 iteration: 116600 loss: 0.0012 lr: 0.02
2019-06-28 11:56:24 iteration: 116700 loss: 0.0015 lr: 0.02
2019-06-28 11:56:36 iteration: 116800 loss: 0.0014 lr: 0.02
2019-06-28 11:56:48 iteration: 116900 loss: 0.0014 lr: 0.02
2019-06-28 11:57:01 iteration: 117000 loss: 0.0013 lr: 0.02
2019-06-28 11:57:17 iteration: 117100 loss: 0.0013 lr: 0.02
2019-06-28 11:57:29 iteration: 117200 loss: 0.0013 lr: 0.02
2019-06-28 11:57:42 iteration: 117300 loss: 0.0013 lr: 0.02
2019-06-28 11:57:54 iteration: 117400 loss: 0.0014 lr: 0.02
2019-06-28 11:58:07 iteration: 117500 loss: 0.0013 lr: 0.02
2019-06-28 11:58:18 iteration: 117600 loss: 0.0013 lr: 0.02
2019-06-28 11:58:31 iteration: 117700 loss: 0.0012 lr: 0.02
2019-06-28 11:58:45 iteration: 117800 loss: 0.0013 lr: 0.02
2019-06-28 11:58:57 iteration: 117900 loss: 0.0013 lr: 0.02
2019-06-28 11:59:10 iteration: 118000 loss: 0.0014 lr: 0.02
2019-06-28 11:59:25 iteration: 118100 loss: 0.0014 lr: 0.02
2019-06-28 11:59:39 iteration: 118200 loss: 0.0013 lr: 0.02
2019-06-28 11:59:52 iteration: 118300 loss: 0.0014 lr: 0.02
2019-06-28 12:00:06 iteration: 118400 loss: 0.0011 lr: 0.02
2019-06-28 12:00:21 iteration: 118500 loss: 0.0015 lr: 0.02
2019-06-28 12:00:33 iteration: 118600 loss: 0.0015 lr: 0.02
2019-06-28 12:00:44 iteration: 118700 loss: 0.0014 lr: 0.02
2019-06-28 12:00:56 iteration: 118800 loss: 0.0014 lr: 0.02
2019-06-28 12:01:08 iteration: 118900 loss: 0.0014 lr: 0.02
2019-06-28 12:01:22 iteration: 119000 loss: 0.0014 lr: 0.02
2019-06-28 12:01:39 iteration: 119100 loss: 0.0014 lr: 0.02
2019-06-28 12:01:52 iteration: 119200 loss: 0.0015 lr: 0.02
2019-06-28 12:02:03 iteration: 119300 loss: 0.0015 lr: 0.02
2019-06-28 12:02:17 iteration: 119400 loss: 0.0013 lr: 0.02
2019-06-28 12:02:30 iteration: 119500 loss: 0.0012 lr: 0.02
2019-06-28 12:02:42 iteration: 119600 loss: 0.0014 lr: 0.02
2019-06-28 12:02:56 iteration: 119700 loss: 0.0014 lr: 0.02
2019-06-28 12:03:09 iteration: 119800 loss: 0.0014 lr: 0.02
2019-06-28 12:03:21 iteration: 119900 loss: 0.0014 lr: 0.02
2019-06-28 12:03:33 iteration: 120000 loss: 0.0014 lr: 0.02
2019-06-28 12:03:48 iteration: 120100 loss: 0.0013 lr: 0.02
2019-06-28 12:04:01 iteration: 120200 loss: 0.0014 lr: 0.02
2019-06-28 12:04:14 iteration: 120300 loss: 0.0014 lr: 0.02
2019-06-28 12:04:28 iteration: 120400 loss: 0.0014 lr: 0.02
2019-06-28 12:04:40 iteration: 120500 loss: 0.0011 lr: 0.02
2019-06-28 12:04:53 iteration: 120600 loss: 0.0014 lr: 0.02
2019-06-28 12:05:06 iteration: 120700 loss: 0.0013 lr: 0.02
2019-06-28 12:05:21 iteration: 120800 loss: 0.0014 lr: 0.02
2019-06-28 12:05:33 iteration: 120900 loss: 0.0012 lr: 0.02
2019-06-28 12:05:47 iteration: 121000 loss: 0.0011 lr: 0.02
2019-06-28 12:06:02 iteration: 121100 loss: 0.0013 lr: 0.02
2019-06-28 12:06:15 iteration: 121200 loss: 0.0015 lr: 0.02
2019-06-28 12:06:27 iteration: 121300 loss: 0.0014 lr: 0.02
2019-06-28 12:06:39 iteration: 121400 loss: 0.0013 lr: 0.02
2019-06-28 12:06:53 iteration: 121500 loss: 0.0014 lr: 0.02
2019-06-28 12:07:06 iteration: 121600 loss: 0.0013 lr: 0.02
2019-06-28 12:07:19 iteration: 121700 loss: 0.0014 lr: 0.02
2019-06-28 12:07:30 iteration: 121800 loss: 0.0013 lr: 0.02
2019-06-28 12:07:42 iteration: 121900 loss: 0.0013 lr: 0.02
2019-06-28 12:07:54 iteration: 122000 loss: 0.0013 lr: 0.02
2019-06-28 12:08:10 iteration: 122100 loss: 0.0016 lr: 0.02
2019-06-28 12:08:22 iteration: 122200 loss: 0.0012 lr: 0.02
2019-06-28 12:08:37 iteration: 122300 loss: 0.0013 lr: 0.02
2019-06-28 12:08:50 iteration: 122400 loss: 0.0014 lr: 0.02
2019-06-28 12:09:04 iteration: 122500 loss: 0.0015 lr: 0.02
2019-06-28 12:09:17 iteration: 122600 loss: 0.0012 lr: 0.02
2019-06-28 12:09:33 iteration: 122700 loss: 0.0013 lr: 0.02
2019-06-28 12:09:51 iteration: 122800 loss: 0.0012 lr: 0.02
2019-06-28 12:10:09 iteration: 122900 loss: 0.0013 lr: 0.02
2019-06-28 12:10:25 iteration: 123000 loss: 0.0013 lr: 0.02
2019-06-28 12:10:44 iteration: 123100 loss: 0.0013 lr: 0.02
2019-06-28 12:11:01 iteration: 123200 loss: 0.0012 lr: 0.02
2019-06-28 12:11:15 iteration: 123300 loss: 0.0012 lr: 0.02
2019-06-28 12:11:30 iteration: 123400 loss: 0.0014 lr: 0.02
2019-06-28 12:11:44 iteration: 123500 loss: 0.0013 lr: 0.02
2019-06-28 12:11:59 iteration: 123600 loss: 0.0015 lr: 0.02
2019-06-28 12:12:12 iteration: 123700 loss: 0.0013 lr: 0.02
2019-06-28 12:12:28 iteration: 123800 loss: 0.0012 lr: 0.02
2019-06-28 12:12:45 iteration: 123900 loss: 0.0014 lr: 0.02
2019-06-28 12:13:01 iteration: 124000 loss: 0.0012 lr: 0.02
2019-06-28 12:13:19 iteration: 124100 loss: 0.0013 lr: 0.02
2019-06-28 12:13:35 iteration: 124200 loss: 0.0013 lr: 0.02
2019-06-28 12:13:51 iteration: 124300 loss: 0.0012 lr: 0.02
2019-06-28 12:14:06 iteration: 124400 loss: 0.0014 lr: 0.02
2019-06-28 12:14:21 iteration: 124500 loss: 0.0014 lr: 0.02
2019-06-28 12:14:36 iteration: 124600 loss: 0.0014 lr: 0.02
2019-06-28 12:14:52 iteration: 124700 loss: 0.0014 lr: 0.02
2019-06-28 12:15:08 iteration: 124800 loss: 0.0013 lr: 0.02
2019-06-28 12:15:22 iteration: 124900 loss: 0.0014 lr: 0.02
2019-06-28 12:15:37 iteration: 125000 loss: 0.0013 lr: 0.02
2019-06-28 12:15:54 iteration: 125100 loss: 0.0013 lr: 0.02
2019-06-28 12:16:09 iteration: 125200 loss: 0.0013 lr: 0.02
2019-06-28 12:16:24 iteration: 125300 loss: 0.0015 lr: 0.02
2019-06-28 12:16:40 iteration: 125400 loss: 0.0014 lr: 0.02
2019-06-28 12:16:55 iteration: 125500 loss: 0.0014 lr: 0.02
2019-06-28 12:17:10 iteration: 125600 loss: 0.0013 lr: 0.02
2019-06-28 12:17:25 iteration: 125700 loss: 0.0014 lr: 0.02
2019-06-28 12:17:39 iteration: 125800 loss: 0.0013 lr: 0.02
2019-06-28 12:17:53 iteration: 125900 loss: 0.0014 lr: 0.02
2019-06-28 12:18:08 iteration: 126000 loss: 0.0013 lr: 0.02
2019-06-28 12:18:25 iteration: 126100 loss: 0.0014 lr: 0.02
2019-06-28 12:18:42 iteration: 126200 loss: 0.0013 lr: 0.02
2019-06-28 12:18:56 iteration: 126300 loss: 0.0014 lr: 0.02
2019-06-28 12:19:10 iteration: 126400 loss: 0.0014 lr: 0.02
2019-06-28 12:19:23 iteration: 126500 loss: 0.0014 lr: 0.02
2019-06-28 12:19:38 iteration: 126600 loss: 0.0013 lr: 0.02
2019-06-28 12:19:53 iteration: 126700 loss: 0.0015 lr: 0.02
2019-06-28 12:20:09 iteration: 126800 loss: 0.0013 lr: 0.02
2019-06-28 12:20:23 iteration: 126900 loss: 0.0012 lr: 0.02
2019-06-28 12:20:36 iteration: 127000 loss: 0.0013 lr: 0.02
2019-06-28 12:20:57 iteration: 127100 loss: 0.0013 lr: 0.02
2019-06-28 12:21:10 iteration: 127200 loss: 0.0013 lr: 0.02
2019-06-28 12:21:24 iteration: 127300 loss: 0.0015 lr: 0.02
2019-06-28 12:21:38 iteration: 127400 loss: 0.0013 lr: 0.02
2019-06-28 12:21:52 iteration: 127500 loss: 0.0013 lr: 0.02
2019-06-28 12:22:08 iteration: 127600 loss: 0.0013 lr: 0.02
2019-06-28 12:22:22 iteration: 127700 loss: 0.0013 lr: 0.02
2019-06-28 12:22:37 iteration: 127800 loss: 0.0012 lr: 0.02
2019-06-28 12:22:51 iteration: 127900 loss: 0.0013 lr: 0.02
2019-06-28 12:23:08 iteration: 128000 loss: 0.0013 lr: 0.02
2019-06-28 12:23:27 iteration: 128100 loss: 0.0014 lr: 0.02
2019-06-28 12:23:41 iteration: 128200 loss: 0.0014 lr: 0.02
2019-06-28 12:23:57 iteration: 128300 loss: 0.0013 lr: 0.02
2019-06-28 12:24:10 iteration: 128400 loss: 0.0014 lr: 0.02
2019-06-28 12:24:27 iteration: 128500 loss: 0.0014 lr: 0.02
2019-06-28 12:24:41 iteration: 128600 loss: 0.0013 lr: 0.02
2019-06-28 12:24:54 iteration: 128700 loss: 0.0014 lr: 0.02
2019-06-28 12:25:08 iteration: 128800 loss: 0.0014 lr: 0.02
2019-06-28 12:25:23 iteration: 128900 loss: 0.0015 lr: 0.02
2019-06-28 12:25:40 iteration: 129000 loss: 0.0013 lr: 0.02
2019-06-28 12:25:57 iteration: 129100 loss: 0.0015 lr: 0.02
2019-06-28 12:26:11 iteration: 129200 loss: 0.0012 lr: 0.02
2019-06-28 12:26:25 iteration: 129300 loss: 0.0013 lr: 0.02
2019-06-28 12:26:40 iteration: 129400 loss: 0.0014 lr: 0.02
2019-06-28 12:26:55 iteration: 129500 loss: 0.0014 lr: 0.02
2019-06-28 12:27:09 iteration: 129600 loss: 0.0014 lr: 0.02
2019-06-28 12:27:23 iteration: 129700 loss: 0.0014 lr: 0.02
2019-06-28 12:27:37 iteration: 129800 loss: 0.0013 lr: 0.02
2019-06-28 12:27:51 iteration: 129900 loss: 0.0014 lr: 0.02
2019-06-28 12:28:05 iteration: 130000 loss: 0.0012 lr: 0.02
2019-06-28 12:28:23 iteration: 130100 loss: 0.0012 lr: 0.02
2019-06-28 12:28:38 iteration: 130200 loss: 0.0011 lr: 0.02
2019-06-28 12:28:53 iteration: 130300 loss: 0.0013 lr: 0.02
2019-06-28 12:29:07 iteration: 130400 loss: 0.0015 lr: 0.02
2019-06-28 12:29:22 iteration: 130500 loss: 0.0012 lr: 0.02
2019-06-28 12:29:36 iteration: 130600 loss: 0.0012 lr: 0.02
2019-06-28 12:29:51 iteration: 130700 loss: 0.0015 lr: 0.02
2019-06-28 12:30:06 iteration: 130800 loss: 0.0013 lr: 0.02
2019-06-28 12:30:21 iteration: 130900 loss: 0.0012 lr: 0.02
2019-06-28 12:30:37 iteration: 131000 loss: 0.0016 lr: 0.02
2019-06-28 12:30:54 iteration: 131100 loss: 0.0014 lr: 0.02
2019-06-28 12:31:08 iteration: 131200 loss: 0.0014 lr: 0.02
2019-06-28 12:31:23 iteration: 131300 loss: 0.0013 lr: 0.02
2019-06-28 12:31:38 iteration: 131400 loss: 0.0013 lr: 0.02
2019-06-28 12:31:53 iteration: 131500 loss: 0.0011 lr: 0.02
2019-06-28 12:32:07 iteration: 131600 loss: 0.0013 lr: 0.02
2019-06-28 12:32:19 iteration: 131700 loss: 0.0015 lr: 0.02
2019-06-28 12:32:35 iteration: 131800 loss: 0.0012 lr: 0.02
2019-06-28 12:32:50 iteration: 131900 loss: 0.0012 lr: 0.02
2019-06-28 12:33:03 iteration: 132000 loss: 0.0013 lr: 0.02
2019-06-28 12:33:22 iteration: 132100 loss: 0.0015 lr: 0.02
2019-06-28 12:33:35 iteration: 132200 loss: 0.0013 lr: 0.02
2019-06-28 12:33:50 iteration: 132300 loss: 0.0014 lr: 0.02
2019-06-28 12:34:05 iteration: 132400 loss: 0.0013 lr: 0.02
2019-06-28 12:34:18 iteration: 132500 loss: 0.0013 lr: 0.02
2019-06-28 12:34:33 iteration: 132600 loss: 0.0013 lr: 0.02
2019-06-28 12:34:47 iteration: 132700 loss: 0.0013 lr: 0.02
2019-06-28 12:35:02 iteration: 132800 loss: 0.0012 lr: 0.02
2019-06-28 12:35:16 iteration: 132900 loss: 0.0012 lr: 0.02
2019-06-28 12:35:31 iteration: 133000 loss: 0.0013 lr: 0.02
2019-06-28 12:35:48 iteration: 133100 loss: 0.0014 lr: 0.02
2019-06-28 12:36:01 iteration: 133200 loss: 0.0014 lr: 0.02
2019-06-28 12:36:17 iteration: 133300 loss: 0.0011 lr: 0.02
2019-06-28 12:36:31 iteration: 133400 loss: 0.0013 lr: 0.02
2019-06-28 12:36:45 iteration: 133500 loss: 0.0012 lr: 0.02
2019-06-28 12:37:00 iteration: 133600 loss: 0.0013 lr: 0.02
2019-06-28 12:37:14 iteration: 133700 loss: 0.0012 lr: 0.02
2019-06-28 12:37:30 iteration: 133800 loss: 0.0014 lr: 0.02
2019-06-28 12:37:48 iteration: 133900 loss: 0.0013 lr: 0.02
2019-06-28 12:38:03 iteration: 134000 loss: 0.0013 lr: 0.02
2019-06-28 12:38:21 iteration: 134100 loss: 0.0013 lr: 0.02
2019-06-28 12:38:39 iteration: 134200 loss: 0.0014 lr: 0.02
2019-06-28 12:38:54 iteration: 134300 loss: 0.0012 lr: 0.02
2019-06-28 12:39:08 iteration: 134400 loss: 0.0013 lr: 0.02
2019-06-28 12:39:23 iteration: 134500 loss: 0.0011 lr: 0.02
2019-06-28 12:39:38 iteration: 134600 loss: 0.0011 lr: 0.02
2019-06-28 12:39:53 iteration: 134700 loss: 0.0013 lr: 0.02
2019-06-28 12:40:06 iteration: 134800 loss: 0.0013 lr: 0.02
2019-06-28 12:40:18 iteration: 134900 loss: 0.0014 lr: 0.02
2019-06-28 12:40:32 iteration: 135000 loss: 0.0013 lr: 0.02
2019-06-28 12:40:51 iteration: 135100 loss: 0.0013 lr: 0.02
2019-06-28 12:41:05 iteration: 135200 loss: 0.0013 lr: 0.02
2019-06-28 12:41:21 iteration: 135300 loss: 0.0014 lr: 0.02
2019-06-28 12:41:37 iteration: 135400 loss: 0.0013 lr: 0.02
2019-06-28 12:41:50 iteration: 135500 loss: 0.0013 lr: 0.02
2019-06-28 12:42:04 iteration: 135600 loss: 0.0014 lr: 0.02
2019-06-28 12:42:17 iteration: 135700 loss: 0.0013 lr: 0.02
2019-06-28 12:42:31 iteration: 135800 loss: 0.0011 lr: 0.02
2019-06-28 12:42:45 iteration: 135900 loss: 0.0012 lr: 0.02
2019-06-28 12:42:59 iteration: 136000 loss: 0.0013 lr: 0.02
2019-06-28 12:43:15 iteration: 136100 loss: 0.0014 lr: 0.02
2019-06-28 12:43:31 iteration: 136200 loss: 0.0012 lr: 0.02
2019-06-28 12:43:46 iteration: 136300 loss: 0.0013 lr: 0.02
2019-06-28 12:44:01 iteration: 136400 loss: 0.0012 lr: 0.02
2019-06-28 12:44:17 iteration: 136500 loss: 0.0013 lr: 0.02
2019-06-28 12:44:31 iteration: 136600 loss: 0.0013 lr: 0.02
2019-06-28 12:44:45 iteration: 136700 loss: 0.0012 lr: 0.02
2019-06-28 12:44:59 iteration: 136800 loss: 0.0013 lr: 0.02
2019-06-28 12:45:13 iteration: 136900 loss: 0.0013 lr: 0.02
2019-06-28 12:45:25 iteration: 137000 loss: 0.0013 lr: 0.02
2019-06-28 12:45:42 iteration: 137100 loss: 0.0013 lr: 0.02
2019-06-28 12:45:56 iteration: 137200 loss: 0.0013 lr: 0.02
2019-06-28 12:46:10 iteration: 137300 loss: 0.0012 lr: 0.02
2019-06-28 12:46:24 iteration: 137400 loss: 0.0013 lr: 0.02
2019-06-28 12:46:39 iteration: 137500 loss: 0.0013 lr: 0.02
2019-06-28 12:46:53 iteration: 137600 loss: 0.0011 lr: 0.02
2019-06-28 12:47:05 iteration: 137700 loss: 0.0013 lr: 0.02
2019-06-28 12:47:19 iteration: 137800 loss: 0.0012 lr: 0.02
2019-06-28 12:47:32 iteration: 137900 loss: 0.0012 lr: 0.02
2019-06-28 12:47:46 iteration: 138000 loss: 0.0012 lr: 0.02
2019-06-28 12:48:02 iteration: 138100 loss: 0.0013 lr: 0.02
2019-06-28 12:48:16 iteration: 138200 loss: 0.0014 lr: 0.02
2019-06-28 12:48:31 iteration: 138300 loss: 0.0013 lr: 0.02
2019-06-28 12:48:47 iteration: 138400 loss: 0.0012 lr: 0.02
2019-06-28 12:49:02 iteration: 138500 loss: 0.0013 lr: 0.02
2019-06-28 12:49:15 iteration: 138600 loss: 0.0013 lr: 0.02
2019-06-28 12:49:28 iteration: 138700 loss: 0.0013 lr: 0.02
2019-06-28 12:49:43 iteration: 138800 loss: 0.0014 lr: 0.02
2019-06-28 12:49:58 iteration: 138900 loss: 0.0013 lr: 0.02
2019-06-28 12:50:11 iteration: 139000 loss: 0.0012 lr: 0.02
2019-06-28 12:50:29 iteration: 139100 loss: 0.0014 lr: 0.02
2019-06-28 12:50:44 iteration: 139200 loss: 0.0014 lr: 0.02
2019-06-28 12:50:58 iteration: 139300 loss: 0.0013 lr: 0.02
2019-06-28 12:51:12 iteration: 139400 loss: 0.0013 lr: 0.02
2019-06-28 12:51:26 iteration: 139500 loss: 0.0014 lr: 0.02
2019-06-28 12:51:41 iteration: 139600 loss: 0.0013 lr: 0.02
2019-06-28 12:51:55 iteration: 139700 loss: 0.0012 lr: 0.02
2019-06-28 12:52:08 iteration: 139800 loss: 0.0013 lr: 0.02
2019-06-28 12:52:24 iteration: 139900 loss: 0.0012 lr: 0.02
2019-06-28 12:52:38 iteration: 140000 loss: 0.0013 lr: 0.02
2019-06-28 12:52:56 iteration: 140100 loss: 0.0013 lr: 0.02
2019-06-28 12:53:10 iteration: 140200 loss: 0.0013 lr: 0.02
2019-06-28 12:53:26 iteration: 140300 loss: 0.0011 lr: 0.02
2019-06-28 12:53:40 iteration: 140400 loss: 0.0012 lr: 0.02
2019-06-28 12:53:54 iteration: 140500 loss: 0.0013 lr: 0.02
2019-06-28 12:54:09 iteration: 140600 loss: 0.0013 lr: 0.02
2019-06-28 12:54:23 iteration: 140700 loss: 0.0013 lr: 0.02
2019-06-28 12:54:38 iteration: 140800 loss: 0.0014 lr: 0.02
2019-06-28 12:54:53 iteration: 140900 loss: 0.0013 lr: 0.02
2019-06-28 12:55:05 iteration: 141000 loss: 0.0013 lr: 0.02
2019-06-28 12:55:25 iteration: 141100 loss: 0.0013 lr: 0.02
2019-06-28 12:55:41 iteration: 141200 loss: 0.0015 lr: 0.02
2019-06-28 12:55:54 iteration: 141300 loss: 0.0012 lr: 0.02
2019-06-28 12:56:10 iteration: 141400 loss: 0.0011 lr: 0.02
2019-06-28 12:56:24 iteration: 141500 loss: 0.0012 lr: 0.02
2019-06-28 12:56:38 iteration: 141600 loss: 0.0015 lr: 0.02
2019-06-28 12:56:52 iteration: 141700 loss: 0.0012 lr: 0.02
2019-06-28 12:57:06 iteration: 141800 loss: 0.0011 lr: 0.02
2019-06-28 12:57:22 iteration: 141900 loss: 0.0012 lr: 0.02
2019-06-28 12:57:36 iteration: 142000 loss: 0.0012 lr: 0.02
2019-06-28 12:57:55 iteration: 142100 loss: 0.0012 lr: 0.02
2019-06-28 12:58:10 iteration: 142200 loss: 0.0013 lr: 0.02
2019-06-28 12:58:22 iteration: 142300 loss: 0.0014 lr: 0.02
2019-06-28 12:58:37 iteration: 142400 loss: 0.0012 lr: 0.02
2019-06-28 12:58:50 iteration: 142500 loss: 0.0014 lr: 0.02
2019-06-28 12:59:03 iteration: 142600 loss: 0.0013 lr: 0.02
2019-06-28 12:59:17 iteration: 142700 loss: 0.0012 lr: 0.02
2019-06-28 12:59:32 iteration: 142800 loss: 0.0012 lr: 0.02
2019-06-28 12:59:47 iteration: 142900 loss: 0.0013 lr: 0.02
2019-06-28 13:00:00 iteration: 143000 loss: 0.0013 lr: 0.02
2019-06-28 13:00:17 iteration: 143100 loss: 0.0014 lr: 0.02
2019-06-28 13:00:32 iteration: 143200 loss: 0.0012 lr: 0.02
2019-06-28 13:00:46 iteration: 143300 loss: 0.0013 lr: 0.02
2019-06-28 13:01:02 iteration: 143400 loss: 0.0012 lr: 0.02
2019-06-28 13:01:16 iteration: 143500 loss: 0.0014 lr: 0.02
2019-06-28 13:01:30 iteration: 143600 loss: 0.0012 lr: 0.02
2019-06-28 13:01:45 iteration: 143700 loss: 0.0014 lr: 0.02
2019-06-28 13:01:59 iteration: 143800 loss: 0.0013 lr: 0.02
2019-06-28 13:02:13 iteration: 143900 loss: 0.0011 lr: 0.02
2019-06-28 13:02:27 iteration: 144000 loss: 0.0012 lr: 0.02
2019-06-28 13:02:46 iteration: 144100 loss: 0.0011 lr: 0.02
2019-06-28 13:03:02 iteration: 144200 loss: 0.0014 lr: 0.02
2019-06-28 13:03:14 iteration: 144300 loss: 0.0013 lr: 0.02
2019-06-28 13:03:27 iteration: 144400 loss: 0.0013 lr: 0.02
2019-06-28 13:03:43 iteration: 144500 loss: 0.0014 lr: 0.02
2019-06-28 13:03:56 iteration: 144600 loss: 0.0013 lr: 0.02
2019-06-28 13:04:12 iteration: 144700 loss: 0.0012 lr: 0.02
2019-06-28 13:04:25 iteration: 144800 loss: 0.0011 lr: 0.02
2019-06-28 13:04:39 iteration: 144900 loss: 0.0012 lr: 0.02
2019-06-28 13:04:53 iteration: 145000 loss: 0.0012 lr: 0.02
2019-06-28 13:05:10 iteration: 145100 loss: 0.0010 lr: 0.02
2019-06-28 13:05:25 iteration: 145200 loss: 0.0012 lr: 0.02
2019-06-28 13:05:38 iteration: 145300 loss: 0.0012 lr: 0.02
2019-06-28 13:05:53 iteration: 145400 loss: 0.0015 lr: 0.02
2019-06-28 13:06:08 iteration: 145500 loss: 0.0013 lr: 0.02
2019-06-28 13:06:22 iteration: 145600 loss: 0.0013 lr: 0.02
2019-06-28 13:06:37 iteration: 145700 loss: 0.0013 lr: 0.02
2019-06-28 13:06:50 iteration: 145800 loss: 0.0011 lr: 0.02
2019-06-28 13:07:04 iteration: 145900 loss: 0.0012 lr: 0.02
2019-06-28 13:07:20 iteration: 146000 loss: 0.0012 lr: 0.02
2019-06-28 13:07:36 iteration: 146100 loss: 0.0012 lr: 0.02
2019-06-28 13:07:51 iteration: 146200 loss: 0.0014 lr: 0.02
2019-06-28 13:08:04 iteration: 146300 loss: 0.0012 lr: 0.02
2019-06-28 13:08:19 iteration: 146400 loss: 0.0013 lr: 0.02
2019-06-28 13:08:32 iteration: 146500 loss: 0.0012 lr: 0.02
2019-06-28 13:08:45 iteration: 146600 loss: 0.0012 lr: 0.02
2019-06-28 13:08:59 iteration: 146700 loss: 0.0014 lr: 0.02
2019-06-28 13:09:13 iteration: 146800 loss: 0.0012 lr: 0.02
2019-06-28 13:09:28 iteration: 146900 loss: 0.0012 lr: 0.02
2019-06-28 13:09:43 iteration: 147000 loss: 0.0013 lr: 0.02
2019-06-28 13:10:00 iteration: 147100 loss: 0.0013 lr: 0.02
2019-06-28 13:10:14 iteration: 147200 loss: 0.0013 lr: 0.02
2019-06-28 13:10:28 iteration: 147300 loss: 0.0012 lr: 0.02
2019-06-28 13:10:42 iteration: 147400 loss: 0.0012 lr: 0.02
2019-06-28 13:10:56 iteration: 147500 loss: 0.0013 lr: 0.02
2019-06-28 13:11:10 iteration: 147600 loss: 0.0012 lr: 0.02
2019-06-28 13:11:25 iteration: 147700 loss: 0.0011 lr: 0.02
2019-06-28 13:11:39 iteration: 147800 loss: 0.0015 lr: 0.02
2019-06-28 13:11:55 iteration: 147900 loss: 0.0013 lr: 0.02
2019-06-28 13:12:07 iteration: 148000 loss: 0.0012 lr: 0.02
2019-06-28 13:12:24 iteration: 148100 loss: 0.0012 lr: 0.02
2019-06-28 13:12:40 iteration: 148200 loss: 0.0011 lr: 0.02
2019-06-28 13:12:54 iteration: 148300 loss: 0.0013 lr: 0.02
2019-06-28 13:13:09 iteration: 148400 loss: 0.0012 lr: 0.02
2019-06-28 13:13:23 iteration: 148500 loss: 0.0012 lr: 0.02
2019-06-28 13:13:36 iteration: 148600 loss: 0.0012 lr: 0.02
2019-06-28 13:13:50 iteration: 148700 loss: 0.0012 lr: 0.02
2019-06-28 13:14:03 iteration: 148800 loss: 0.0014 lr: 0.02
2019-06-28 13:14:17 iteration: 148900 loss: 0.0012 lr: 0.02
2019-06-28 13:14:31 iteration: 149000 loss: 0.0014 lr: 0.02
2019-06-28 13:14:49 iteration: 149100 loss: 0.0012 lr: 0.02
2019-06-28 13:15:04 iteration: 149200 loss: 0.0013 lr: 0.02
2019-06-28 13:15:20 iteration: 149300 loss: 0.0013 lr: 0.02
2019-06-28 13:15:34 iteration: 149400 loss: 0.0012 lr: 0.02
2019-06-28 13:15:48 iteration: 149500 loss: 0.0014 lr: 0.02
2019-06-28 13:16:02 iteration: 149600 loss: 0.0013 lr: 0.02
2019-06-28 13:16:16 iteration: 149700 loss: 0.0014 lr: 0.02
2019-06-28 13:16:28 iteration: 149800 loss: 0.0012 lr: 0.02
2019-06-28 13:16:41 iteration: 149900 loss: 0.0011 lr: 0.02
2019-06-28 13:16:55 iteration: 150000 loss: 0.0013 lr: 0.02
2019-06-28 14:02:24 Config:
{'all_joints': [[0], [1], [2]],
 'all_joints_names': ['Nose', 'RightHand', 'Pellet'],
 'batch_size': 1,
 'bottomheight': 400,
 'crop': True,
 'crop_pad': 0,
 'cropratio': 0.4,
 'dataset': 'training-datasets\\iteration-1\\UnaugmentedDataSet_pelletJun26\\pellet_vj90shuffle1.mat',
 'dataset_type': 'default',
 'display_iters': 1000,
 'fg_fraction': 0.25,
 'global_scale': 0.8,
 'init_weights': 'C:\\Users\\vjj14\\.conda\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\models\\pretrained\\resnet_v1_50.ckpt',
 'intermediate_supervision': False,
 'intermediate_supervision_layer': 12,
 'leftwidth': 400,
 'location_refinement': True,
 'locref_huber_loss': True,
 'locref_loss_weight': 0.05,
 'locref_stdev': 7.2801,
 'log_dir': 'log',
 'max_input_size': 1500,
 'mean_pixel': [123.68, 116.779, 103.939],
 'metadataset': 'training-datasets\\iteration-1\\UnaugmentedDataSet_pelletJun26\\Documentation_data-pellet_90shuffle1.pickle',
 'min_input_size': 64,
 'minsize': 100,
 'mirror': False,
 'multi_step': [[0.005, 10000],
                [0.02, 430000],
                [0.002, 730000],
                [0.001, 1030000]],
 'net_type': 'resnet_50',
 'num_joints': 3,
 'optimizer': 'sgd',
 'pos_dist_thresh': 17,
 'project_path': 'C:\\Users\\vjj14\\Desktop\\DeepLabCut\\pellet-vj-2019-06-26',
 'regularize': False,
 'rightwidth': 400,
 'save_iters': 50000,
 'scale_jitter_lo': 0.5,
 'scale_jitter_up': 1.25,
 'scoremap_dir': 'test',
 'shuffle': True,
 'snapshot_prefix': 'C:\\Users\\vjj14\\Desktop\\DeepLabCut\\pellet-vj-2019-06-26\\dlc-models\\iteration-1\\pelletJun26-trainset90shuffle1\\test\\snapshot',
 'stride': 8.0,
 'topheight': 400,
 'use_gt_segm': False,
 'video': False,
 'video_batch': False,
 'weigh_negatives': False,
 'weigh_only_present_joints': False,
 'weigh_part_predictions': False,
 'weight_decay': 0.0001}
2019-06-28 14:02:28 Config:
{'all_joints': [[0], [1], [2]],
 'all_joints_names': ['Nose', 'RightHand', 'Pellet'],
 'batch_size': 4,
 'bottomheight': 400,
 'crop': True,
 'crop_pad': 0,
 'cropratio': 0.4,
 'dataset': 'training-datasets\\iteration-1\\UnaugmentedDataSet_pelletJun26\\pellet_vj90shuffle1.mat',
 'dataset_type': 'default',
 'display_iters': 1000,
 'fg_fraction': 0.25,
 'global_scale': 0.8,
 'init_weights': 'C:\\Users\\vjj14\\.conda\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\models\\pretrained\\resnet_v1_50.ckpt',
 'intermediate_supervision': False,
 'intermediate_supervision_layer': 12,
 'leftwidth': 400,
 'location_refinement': True,
 'locref_huber_loss': True,
 'locref_loss_weight': 0.05,
 'locref_stdev': 7.2801,
 'log_dir': 'log',
 'max_input_size': 1500,
 'mean_pixel': [123.68, 116.779, 103.939],
 'metadataset': 'training-datasets\\iteration-1\\UnaugmentedDataSet_pelletJun26\\Documentation_data-pellet_90shuffle1.pickle',
 'min_input_size': 64,
 'minsize': 100,
 'mirror': False,
 'multi_step': [[0.005, 10000],
                [0.02, 430000],
                [0.002, 730000],
                [0.001, 1030000]],
 'net_type': 'resnet_50',
 'num_joints': 3,
 'optimizer': 'sgd',
 'pos_dist_thresh': 17,
 'project_path': 'C:\\Users\\vjj14\\Desktop\\DeepLabCut\\pellet-vj-2019-06-26',
 'regularize': False,
 'rightwidth': 400,
 'save_iters': 50000,
 'scale_jitter_lo': 0.5,
 'scale_jitter_up': 1.25,
 'scoremap_dir': 'test',
 'shuffle': True,
 'snapshot_prefix': 'C:\\Users\\vjj14\\Desktop\\DeepLabCut\\pellet-vj-2019-06-26\\dlc-models\\iteration-1\\pelletJun26-trainset90shuffle1\\test\\snapshot',
 'stride': 8.0,
 'topheight': 400,
 'use_gt_segm': False,
 'video': False,
 'video_batch': False,
 'weigh_negatives': False,
 'weigh_only_present_joints': False,
 'weigh_part_predictions': False,
 'weight_decay': 0.0001}
2019-06-28 14:02:30 Config:
{'all_joints': [[0], [1], [2]],
 'all_joints_names': ['Nose', 'RightHand', 'Pellet'],
 'batch_size': 4,
 'bottomheight': 400,
 'crop': True,
 'crop_pad': 0,
 'cropratio': 0.4,
 'dataset': 'training-datasets\\iteration-1\\UnaugmentedDataSet_pelletJun26\\pellet_vj90shuffle1.mat',
 'dataset_type': 'default',
 'display_iters': 1000,
 'fg_fraction': 0.25,
 'global_scale': 0.8,
 'init_weights': 'C:\\Users\\vjj14\\.conda\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\models\\pretrained\\resnet_v1_50.ckpt',
 'intermediate_supervision': False,
 'intermediate_supervision_layer': 12,
 'leftwidth': 400,
 'location_refinement': True,
 'locref_huber_loss': True,
 'locref_loss_weight': 0.05,
 'locref_stdev': 7.2801,
 'log_dir': 'log',
 'max_input_size': 1500,
 'mean_pixel': [123.68, 116.779, 103.939],
 'metadataset': 'training-datasets\\iteration-1\\UnaugmentedDataSet_pelletJun26\\Documentation_data-pellet_90shuffle1.pickle',
 'min_input_size': 64,
 'minsize': 100,
 'mirror': False,
 'multi_step': [[0.005, 10000],
                [0.02, 430000],
                [0.002, 730000],
                [0.001, 1030000]],
 'net_type': 'resnet_50',
 'num_joints': 3,
 'optimizer': 'sgd',
 'pos_dist_thresh': 17,
 'project_path': 'C:\\Users\\vjj14\\Desktop\\DeepLabCut\\pellet-vj-2019-06-26',
 'regularize': False,
 'rightwidth': 400,
 'save_iters': 50000,
 'scale_jitter_lo': 0.5,
 'scale_jitter_up': 1.25,
 'scoremap_dir': 'test',
 'shuffle': True,
 'snapshot_prefix': 'C:\\Users\\vjj14\\Desktop\\DeepLabCut\\pellet-vj-2019-06-26\\dlc-models\\iteration-1\\pelletJun26-trainset90shuffle1\\test\\snapshot',
 'stride': 8.0,
 'topheight': 400,
 'use_gt_segm': False,
 'video': False,
 'video_batch': False,
 'weigh_negatives': False,
 'weigh_only_present_joints': False,
 'weigh_part_predictions': False,
 'weight_decay': 0.0001}
2019-06-28 14:03:16 Config:
{'all_joints': [[0], [1], [2]],
 'all_joints_names': ['Nose', 'RightHand', 'Pellet'],
 'batch_size': 1,
 'bottomheight': 400,
 'crop': True,
 'crop_pad': 0,
 'cropratio': 0.4,
 'dataset': 'training-datasets\\iteration-1\\UnaugmentedDataSet_pelletJun26\\pellet_vj90shuffle1.mat',
 'dataset_type': 'default',
 'display_iters': 1000,
 'fg_fraction': 0.25,
 'global_scale': 0.8,
 'init_weights': 'C:\\Users\\vjj14\\.conda\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\models\\pretrained\\resnet_v1_50.ckpt',
 'intermediate_supervision': False,
 'intermediate_supervision_layer': 12,
 'leftwidth': 400,
 'location_refinement': True,
 'locref_huber_loss': True,
 'locref_loss_weight': 0.05,
 'locref_stdev': 7.2801,
 'log_dir': 'log',
 'max_input_size': 1500,
 'mean_pixel': [123.68, 116.779, 103.939],
 'metadataset': 'training-datasets\\iteration-1\\UnaugmentedDataSet_pelletJun26\\Documentation_data-pellet_90shuffle1.pickle',
 'min_input_size': 64,
 'minsize': 100,
 'mirror': False,
 'multi_step': [[0.005, 10000],
                [0.02, 430000],
                [0.002, 730000],
                [0.001, 1030000]],
 'net_type': 'resnet_50',
 'num_joints': 3,
 'optimizer': 'sgd',
 'pos_dist_thresh': 17,
 'project_path': 'C:\\Users\\vjj14\\Desktop\\DeepLabCut\\pellet-vj-2019-06-26',
 'regularize': False,
 'rightwidth': 400,
 'save_iters': 50000,
 'scale_jitter_lo': 0.5,
 'scale_jitter_up': 1.25,
 'scoremap_dir': 'test',
 'shuffle': True,
 'snapshot_prefix': 'C:\\Users\\vjj14\\Desktop\\DeepLabCut\\pellet-vj-2019-06-26\\dlc-models\\iteration-1\\pelletJun26-trainset90shuffle1\\test\\snapshot',
 'stride': 8.0,
 'topheight': 400,
 'use_gt_segm': False,
 'video': False,
 'video_batch': False,
 'weigh_negatives': False,
 'weigh_only_present_joints': False,
 'weigh_part_predictions': False,
 'weight_decay': 0.0001}
2019-06-28 14:05:24 Config:
{'all_joints': [[0], [1], [2]],
 'all_joints_names': ['Nose', 'RightHand', 'Pellet'],
 'batch_size': 4,
 'bottomheight': 400,
 'crop': True,
 'crop_pad': 0,
 'cropratio': 0.4,
 'dataset': 'training-datasets\\iteration-1\\UnaugmentedDataSet_pelletJun26\\pellet_vj90shuffle1.mat',
 'dataset_type': 'default',
 'display_iters': 1000,
 'fg_fraction': 0.25,
 'global_scale': 0.8,
 'init_weights': 'C:\\Users\\vjj14\\.conda\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\models\\pretrained\\resnet_v1_50.ckpt',
 'intermediate_supervision': False,
 'intermediate_supervision_layer': 12,
 'leftwidth': 400,
 'location_refinement': True,
 'locref_huber_loss': True,
 'locref_loss_weight': 0.05,
 'locref_stdev': 7.2801,
 'log_dir': 'log',
 'max_input_size': 1500,
 'mean_pixel': [123.68, 116.779, 103.939],
 'metadataset': 'training-datasets\\iteration-1\\UnaugmentedDataSet_pelletJun26\\Documentation_data-pellet_90shuffle1.pickle',
 'min_input_size': 64,
 'minsize': 100,
 'mirror': False,
 'multi_step': [[0.005, 10000],
                [0.02, 430000],
                [0.002, 730000],
                [0.001, 1030000]],
 'net_type': 'resnet_50',
 'num_joints': 3,
 'optimizer': 'sgd',
 'pos_dist_thresh': 17,
 'project_path': 'C:\\Users\\vjj14\\Desktop\\DeepLabCut\\pellet-vj-2019-06-26',
 'regularize': False,
 'rightwidth': 400,
 'save_iters': 50000,
 'scale_jitter_lo': 0.5,
 'scale_jitter_up': 1.25,
 'scoremap_dir': 'test',
 'shuffle': True,
 'snapshot_prefix': 'C:\\Users\\vjj14\\Desktop\\DeepLabCut\\pellet-vj-2019-06-26\\dlc-models\\iteration-1\\pelletJun26-trainset90shuffle1\\test\\snapshot',
 'stride': 8.0,
 'topheight': 400,
 'use_gt_segm': False,
 'video': False,
 'video_batch': False,
 'weigh_negatives': False,
 'weigh_only_present_joints': False,
 'weigh_part_predictions': False,
 'weight_decay': 0.0001}
2019-06-28 14:34:47 Config:
{'all_joints': [[0], [1], [2]],
 'all_joints_names': ['Nose', 'RightHand', 'Pellet'],
 'batch_size': 4,
 'bottomheight': 400,
 'crop': True,
 'crop_pad': 0,
 'cropratio': 0.4,
 'dataset': 'training-datasets\\iteration-1\\UnaugmentedDataSet_pelletJun26\\pellet_vj90shuffle1.mat',
 'dataset_type': 'default',
 'display_iters': 1000,
 'fg_fraction': 0.25,
 'global_scale': 0.8,
 'init_weights': 'C:\\Users\\vjj14\\.conda\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\models\\pretrained\\resnet_v1_50.ckpt',
 'intermediate_supervision': False,
 'intermediate_supervision_layer': 12,
 'leftwidth': 400,
 'location_refinement': True,
 'locref_huber_loss': True,
 'locref_loss_weight': 0.05,
 'locref_stdev': 7.2801,
 'log_dir': 'log',
 'max_input_size': 1500,
 'mean_pixel': [123.68, 116.779, 103.939],
 'metadataset': 'training-datasets\\iteration-1\\UnaugmentedDataSet_pelletJun26\\Documentation_data-pellet_90shuffle1.pickle',
 'min_input_size': 64,
 'minsize': 100,
 'mirror': False,
 'multi_step': [[0.005, 10000],
                [0.02, 430000],
                [0.002, 730000],
                [0.001, 1030000]],
 'net_type': 'resnet_50',
 'num_joints': 3,
 'optimizer': 'sgd',
 'pos_dist_thresh': 17,
 'project_path': 'C:\\Users\\vjj14\\Desktop\\DeepLabCut\\pellet-vj-2019-06-26',
 'regularize': False,
 'rightwidth': 400,
 'save_iters': 50000,
 'scale_jitter_lo': 0.5,
 'scale_jitter_up': 1.25,
 'scoremap_dir': 'test',
 'shuffle': True,
 'snapshot_prefix': 'C:\\Users\\vjj14\\Desktop\\DeepLabCut\\pellet-vj-2019-06-26\\dlc-models\\iteration-1\\pelletJun26-trainset90shuffle1\\test\\snapshot',
 'stride': 8.0,
 'topheight': 400,
 'use_gt_segm': False,
 'video': False,
 'video_batch': False,
 'weigh_negatives': False,
 'weigh_only_present_joints': False,
 'weigh_part_predictions': False,
 'weight_decay': 0.0001}
