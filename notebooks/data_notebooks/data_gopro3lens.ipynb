{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import datetime\n",
    "#turns seconds into a string format ffmpeg uses\n",
    "def seconds_formatter(sec):\n",
    "    x = \"0\" + str(datetime.timedelta(seconds=sec))[:-3]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier\n",
    "identify reaches, successes, failures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Variables \n",
    "### Change as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf(r\"C:\\Users\\vjj14\\Desktop\\DeepLabCut\\goprolensfront-vj-2019-06-25\\videos\\A_copiedDeepCut_resnet50_goprolensfrontJun25shuffle1_60002.h5\")\n",
    "#remove extra level \"scorer\"\n",
    "df.columns = df.columns.droplevel()\n",
    "\n",
    "\n",
    "frame_rate = 119.88\n",
    "\n",
    "total_num_frames = df.shape[0]\n",
    "\n",
    "cols = ['Nose', 'DomInside', 'Pellet', 'Index', 'OtherHand']\n",
    "\n",
    "classes = ['n', 's', 'f', 'r']\n",
    "\n",
    "frames_before = 0\n",
    "\n",
    "frames_after = 20\n",
    "\n",
    "step_size = 1\n",
    "\n",
    "seed = 74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frame_to_time(frame):\n",
    "    return round(frame/frame_rate, 3)\n",
    "def time_to_frame(time):\n",
    "    return int(round(time*frame_rate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for Creating Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# Using Skicit-learn to split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Functions to get training data\n",
    "def get_dataset(df, start_frames):\n",
    "    print(df.shape)\n",
    "    dataframe = df[cols]\n",
    "    dataset = []\n",
    "    for start_f in start_frames:\n",
    "        temp_df = dataframe.iloc[start_f - frames_before: start_f + frames_after]\n",
    "        if len(temp_df.values.flatten()) == 0:\n",
    "            print(start_f)\n",
    "            print(dataframe.shape)\n",
    "        dataset.append(temp_df.values.flatten())\n",
    "    return np.asarray(dataset)\n",
    "def get_non_reach_frames(df, num_frames, blacklist, avoidance_radius):\n",
    "    non_reaches = []\n",
    "    random.seed(seed)\n",
    "    while len(non_reaches) < num_frames:\n",
    "        #hard code 3 non-reaches\n",
    "        frame = random.randint(frames_before+10, df.shape[0] - frames_after)\n",
    "\n",
    "        too_close = False\n",
    "        for start_time in blacklist:\n",
    "            if abs(frame - start_time) < avoidance_radius:\n",
    "                print('no')\n",
    "                too_close = True\n",
    "                break\n",
    "        if not too_close:\n",
    "            non_reaches.append(frame)\n",
    "    return non_reaches\n",
    "\n",
    "#Use training features and labels to create Random Forest Classifier\n",
    "def create_classifier(features, labels, n_trees, test_proportion=0.25):\n",
    "    train_feats, test_feats, train_labs, test_labs = train_test_split(features, labels, test_size = test_proportion, random_state = seed)\n",
    "    print('Training Features Shape:', train_feats.shape)\n",
    "    print('Training Labels Shape:', train_labs.shape)\n",
    "    print('Testing Features Shape:', test_feats.shape)\n",
    "    print('Testing Labels Shape:', test_labs.shape)\n",
    "    rf = RandomForestClassifier(n_estimators = n_trees, random_state = seed)\n",
    "    # Train the model on training data\n",
    "    print(train_feats.shape)\n",
    "    print(train_labs.shape)\n",
    "    rf.fit(train_feats, train_labs)\n",
    "    # Use the forest's predict method on the test data\n",
    "    predictions = rf.predict(test_feats)\n",
    "    print(predictions)\n",
    "    print(test_labs)\n",
    "    wrong_labels = []\n",
    "#     for i in range(len(predictions)):\n",
    "#         if predictions[i] != test_labs[i]:\n",
    "#             frame = -1\n",
    "#             for key in frame_to_features.keys():\n",
    "#                 if (frame_to_features[key] == test_feats[i]).all():\n",
    "#                     frame = key\n",
    "#                     break\n",
    "#             wrong_labels.append((frame_to_time(frame), predictions[i], test_labs[i]))\n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] != test_labs[i]:\n",
    "            frame = -1\n",
    "            wrong_labels.append((predictions[i], test_labs[i]))\n",
    "    print('Wrong Labels', wrong_labels)\n",
    "    return rf, wrong_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reach_frames_temp, reach_frames, reach_labels, non_reaches_frames = None, None, None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no\n",
      "(17061, 27)\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "no\n",
      "(30598, 27)\n",
      "(25677, 27)\n",
      "(26534, 27)\n"
     ]
    }
   ],
   "source": [
    "pm = 3\n",
    "reach_frames_temp, reach_frames, reach_labels, non_reaches_frames = None, None, None, None\n",
    "#\"C:\\Users\\vjj14\\Documents\\GoProLens\\3lens\\gp2.7k3lensA1.mp4\"\n",
    "df_A = pd.read_hdf(r\"C:\\Users\\vjj14\\Desktop\\DeepLabCut\\gopro3lens-vj-2019-07-08\\videos\\gp2.7k3lensA1DeepCut_resnet50_gopro3lensJul8shuffle1_120001.h5\")\n",
    "df_A.columns = df_A.columns.droplevel()\n",
    "reach_times = [19.12, 23.752, 24.186, 24.630, 36.846, 43.652, 44.042, 46.964, 60.218, 62.897, 64.787, 72.045, 85.174, 88.196, \n",
    "           91.652, 93.248, 93.814, 106.294, 106.867, 111.344, 112.249, 113.407, 115.474, 115.918, 129.119, 136.837, 138.581]\n",
    "reach_frames_temp = [time_to_frame(x) for x in reach_times]\n",
    "reach_frames = [x - pm for x in reach_frames_temp] + reach_frames_temp[:] + [x + pm for x in reach_frames_temp]\n",
    "reach_labels = ['r', 'f', 'r', 'r', 's', 'f', 's', 'r', 's', 'r', 'r', 'r', 's', 'r', 's', 'r', 'r', 'r', 'f', 'r', 'r', \n",
    "                      'r', 'f', 'r', 's', 'r', 'r']*3\n",
    "non_reaches_frames = get_non_reach_frames(df_A, len(reach_frames)//2, reach_frames, 12)\n",
    "featuresA = get_dataset(df_A, reach_frames+non_reaches_frames)\n",
    "labelsA = np.asarray(reach_labels + ['n' for x in non_reaches_frames])\n",
    "reach_frames_temp, reach_frames, reach_labels, non_reaches_frames = None, None, None, None\n",
    "\n",
    "#\"D:\\DCIM\\100GOPRO\\2019.07.08_CC42970_N2_V3_2.7k_120FPS_Label_copy.mp4\"\n",
    "df_n2v3 = pd.read_hdf(r\"C:\\Users\\vjj14\\Desktop\\DeepLabCut\\gopro3lens-vj-2019-07-08\\videos\\2019.07.08_CC42970_N2_V3_2.7k_120FPS_Label_copyDeepCut_resnet50_gopro3lensJul8shuffle1_120001.h5\")\n",
    "df_n2v3.columns = df_n2v3.columns.droplevel()\n",
    "reach_times = [12.325, 16.568, 17.55, 18.912, 20.41, 22.1, 22.92, 24.699, 27.4, 29.754, 30.431, 31.39, 32.692, 37.731, \n",
    "           38.258, 42.86, 45.714, 56.45, 76.803, 77.86, 86.2, 86.75, 91.13, 91.649, 97.563, 98.1, 106.739, 107.292, 116.412, \n",
    "           121.49, 122.236, 124.775, 125.375, 134.324, 134.859, 142.37, 143.0, 150.0, 159.435, 160.04, 165.02, \n",
    "           165.633, 174.018, 177.129, 179.23, 183.719, 185.755, 192.041, 197.214, 198.66, 201.286, 203.34, 204.15, 206.253, \n",
    "           209.36, 213.027, 213.895, 217.676, 218.325, 218.982, 223.198, 226.56, 230.524, 233.61, 234.286, 235.838, 236.316, \n",
    "           237.091, 250.448, 251.206, 253.05]\n",
    "reach_frames_temp = [time_to_frame(x) for x in reach_times]\n",
    "reach_frames = [x - pm for x in reach_frames_temp] + reach_frames_temp[:] + [x + pm for x in reach_frames_temp]\n",
    "\n",
    "reach_labels = ['s', 'r', 'f', 'r', 'r', 'f', 'r', 'r', 'r', 'f', 'r', 'r', 'r', 'f', 'r', 'r', 's', 'r', 'f', 'r', \n",
    "                  'f', 'r', 'f', 'r', 'f', 'r', 'f', 'r', 'f', 'r', 'r', 'f', 'r', 'f', 'r', 'f', 'r', 'f', 'f', 'r', \n",
    "                  'f', 'r', 's', 'r', 's', 'f', 'r', 's', 'f', 'r', 'f', 'r', 'r', 's', 'r', 'f', 'r', 'r', 'f', 'r', 's', \n",
    "                  'r', 's', 'r', 'r', 'f', 'f', 'r', 'f', 'r', 'r']*3\n",
    "non_reaches_frames = get_non_reach_frames(df_n2v3, len(reach_frames)//2, reach_frames, 12)\n",
    "features_n2v3 = get_dataset(df_n2v3, reach_frames+non_reaches_frames)\n",
    "labels_n2v3 = np.asarray(reach_labels + ['n' for x in non_reaches_frames])\n",
    "reach_frames_temp, reach_frames, reach_labels, non_reaches_frames = None, None, None, None\n",
    "\n",
    "#\"D:\\DCIM\\100GOPRO\\2019.07.08_CC42970_N3_V3_2.7k_120FPS_Label_copy.mp4\"\n",
    "df_n3v3 = pd.read_hdf(r\"C:\\Users\\vjj14\\Desktop\\DeepLabCut\\gopro3lens-vj-2019-07-08\\videos\\2019.07.08_CC42970_N3_V3_2.7k_120FPS_Label_copyDeepCut_resnet50_gopro3lensJul8shuffle1_120001.h5\")\n",
    "df_n3v3.columns = df_n3v3.columns.droplevel()\n",
    "reach_times = ['11.589', '17.755', '18.474', '20.810', '22.457', '25.491', '37.403', '41.884', '51.558', '57.359', \n",
    "                         '64.503', '78.54', '84.611', '96.276', '108.619', '117.017', '123.131', '130.131', '157.557', \n",
    "                         '164.342', '207.559']\n",
    "reach_frames_temp = [time_to_frame(float(x)) for x in reach_times]\n",
    "reach_frames = [x - pm for x in reach_frames_temp] + reach_frames_temp[:] + [x + pm for x in reach_frames_temp]\n",
    "reach_labels = ['s', 'f', 'r', 'r', 'r', 's', 'f', 's', 'f', 's', 'f', 'f', 's', 'f', 's', 's', 'f', 'f', 's', \n",
    "                          's', 'f']*3\n",
    "non_reaches_times = [3.333, 126.886, 133.355, 205.494, 77.901, 94.947, 26.119, 73.896, 166.391, 51.277, 5.579, 16.697, 19.257, 22.71, 28.645, 31.2]\n",
    "non_reaches_frames = [time_to_frame(x) for x in non_reaches_times]\n",
    "features_n3v3 = get_dataset(df_n3v3, reach_frames+non_reaches_frames)\n",
    "labels_n3v3 = np.asarray(reach_labels + ['n' for x in non_reaches_frames])\n",
    "reach_frames_temp, reach_frames, reach_labels, non_reaches_frames = None, None, None, None\n",
    "\n",
    "#\"D:\\DCIM\\100GOPRO\\2019.07.08_CC42973_N2INJURED_V3_2.7k_120FPS_Label.MP4\"\n",
    "df_injuredn2v3 = pd.read_hdf(r\"C:\\Users\\vjj14\\Desktop\\DeepLabCut\\gopro3lens-vj-2019-07-08\\videos\\2019.07.08_CC42973_N2INJURED_V3_2.7k_120FPS_Label_copyDeepCut_resnet50_gopro3lensJul8shuffle1_120001.h5\")\n",
    "df_injuredn2v3.columns = df_injuredn2v3.columns.droplevel()\n",
    "reach_times = ['21.196', '66.492', '71.227', '88.349', '92.221', '99.692', '116.299', '127.703', '135.332', \n",
    "                                '142.429', '147.11', '151.609', '157.722', '163.4', '172.798', '183.103', '204.054', '208.735', '216.329']\n",
    "reach_frames_temp = [time_to_frame(float(x)) for x in reach_times]\n",
    "reach_frames = [x - pm for x in reach_frames_temp] + reach_frames_temp[:] + [x + pm for x in reach_frames_temp]\n",
    "reach_labels = ['f', 's', 'f', 'f', 'r', 'f', 'f', 's', 'f', 'f', 's', 's', 's', 's', 'f', 'f', 'f', 'f', 's']*3\n",
    "non_reaches_times = [157.463, 38.734, 62.743, 66.176, 88.856, 94.266, 171.907, 179.534, 184.588, 207.388, 72.36, 86.4, 88.5, 90.172]\n",
    "non_reaches_frames = [time_to_frame(x) for x in non_reaches_times]\n",
    "features_injuredn2v3 = get_dataset(df_injuredn2v3, reach_frames+non_reaches_frames)\n",
    "labels_injuredn2v3 = np.asarray(reach_labels + ['n' for x in non_reaches_frames])\n",
    "reach_frames_temp, reach_frames, reach_labels, non_reaches_frames = None, None, None, None\n",
    "\n",
    "# frame_to_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "can't use starred expression here (<ipython-input-28-f530a7ac9d38>, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-28-f530a7ac9d38>\"\u001b[1;36m, line \u001b[1;32m12\u001b[0m\n\u001b[1;33m    reach_labels = *3\u001b[0m\n\u001b[1;37m                  ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m can't use starred expression here\n"
     ]
    }
   ],
   "source": [
    "#\"D:\\DCIM\\100GOPRO\\2019.07.08_CC42973_N2INJURED_V3_2.7k_120FPS_Label.MP4\"\n",
    "# df_n2v2 = pd.read_hdf()\n",
    "# df_n2v2.columns = df_injuredn2v3.columns.droplevel()\n",
    "reach_times = ['14.711', '32.655', '42.082', '42.718', '50.958', '53.474', '54.719', '55.383', '55.788', '57.26', '58.26', \n",
    "               '62.387', '62.965', '64.111', '70.942', '77.294', '77.84', '78.877', '80.16', '81.473', '82.164', '83.054', \n",
    "               '87.903', '93.567', '94.042', '94.689', '100.837', '101.711', '102.704', '111.962', '112.742', '118.758', \n",
    "               '127.66', '128.541', '129.396', '134.4', '138.618', '139.764', '140.528', '142.385', '142.960', '143.816', \n",
    "               '145.012', '149.907', '150.44', '151.57', '152.573', '170.386', '171.026', '176.764', '177.220', '179.808', \n",
    "               '192.836', '197.232', '198.342', '198.911', '199.796']\n",
    "reach_frames_temp = [time_to_frame(float(x)) for x in reach_times]\n",
    "reach_frames = [x - pm for x in reach_frames_temp] + reach_frames_temp[:] + [x + pm for x in reach_frames_temp]\n",
    "reach_labels = ['f', 'f', 'f', 'f', 'r', 'f', 'f', 'f', 'f', 'f', 'r', 'f', 'f', 'r', 'r', 'f', 'r', 'r', 'r', 'f', 'f', \n",
    "                     'r', 's', 'f', 'f', 'r', 'f', 'r', 'r', 'f', 'r', 'f', 'f', 'r', 'r', 's', 'r', 'r', 'r', 'f', 'f', 'r', \n",
    "                     'r', 'f', 'r', 'r', 'r', 'f', 'r', 'f', 'r', 'r', 's', 'r', 'f', 'f', 'r']*3\n",
    "non_reaches_times = \n",
    "non_reaches_frames = [time_to_frame(x) for x in non_reaches_times]\n",
    "features_n2v2 = get_dataset(df_n2v2, reach_frames+non_reaches_frames)\n",
    "labels_n2v2 = np.asarray(reach_labels + ['n' for x in non_reaches_frames])\n",
    "reach_frames_temp, reach_frames, reach_labels, non_reaches_frames = None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=[]\n",
    "while True:\n",
    "    hold = input()\n",
    "    if hold == \"done\":\n",
    "        break\n",
    "    elif hold == \"back\":\n",
    "        x.pop()\n",
    "        continue\n",
    "    x.append(hold)\n",
    "print(x)\n",
    "temp = ['14.711', '32.655', '42.082', '42.718', '50.958', '53.474', '54.719', '55.383', '55.788', '57.26', '58.26', '62.387', '62.965', '64.111', '70.942', '77.294', '77.84', '78.877', '80.16', '81.473', '82.164', '83.054', '87.903', '93.567', '94.042', '94.689', '100.837', '101.711', '102.704', '111.962', '112.742', '118.758', '127.66', '128.541', '129.396', '134.4', '138.618', '139.764', '140.528', '142.385', '142.960', '143.816', '145.012', '149.907', '150.44', '151.57', '152.573', '170.386', '171.026', '176.764', '177.220', '179.808', '192.836', '197.232', '198.342', '198.911', '199.796']\n",
    "len(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.711f\n",
      "32.655f\n",
      "42.082f\n",
      "42.718f\n",
      "50.958r\n",
      "53.474f\n",
      "54.719f\n",
      "55.383f\n",
      "55.788f\n",
      "57.26f\n",
      "58.26r\n",
      "62.387f\n",
      "62.965f\n",
      "64.111r\n",
      "70.942r\n",
      "77.294f\n",
      "77.84r\n",
      "78.877r\n",
      "80.16r\n",
      "81.473f\n",
      "82.164f\n",
      "83.054r\n",
      "87.903s\n",
      "93.567f\n",
      "94.042f\n",
      "94.689r\n",
      "100.837f\n",
      "101.711r\n",
      "102.704r\n",
      "111.962f\n",
      "112.742r\n",
      "118.758f\n",
      "127.66f\n",
      "128.541r\n",
      "129.396r\n",
      "134.4s\n",
      "138.618r\n",
      "139.764r\n",
      "140.528r\n",
      "142.385f\n",
      "142.960f\n",
      "143.816r\n",
      "145.012r\n",
      "149.907f\n",
      "150.44r\n",
      "151.57r\n",
      "152.573r\n",
      "170.386f\n",
      "171.026r\n",
      "176.764f\n",
      "177.220r\n",
      "179.808r\n",
      "192.836s\n",
      "197.232r\n",
      "198.342f\n",
      "198.911f\n",
      "199.796r\n",
      "57\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=[]\n",
    "for x in temp:\n",
    "    y.append(input(x))\n",
    "print((len(y)))\n",
    "temp1 = ['f', 'f', 'f', 'f', 'r', 'f', 'f', 'f', 'f', 'f', 'r', 'f', 'f', 'r', 'r', 'f', 'r', 'r', 'r', 'f', 'f', 'r', 's', 'f', 'f', 'r', 'f', 'r', 'r', 'f', 'r', 'f', 'f', 'r', 'r', 's', 'r', 'r', 'r', 'f', 'f', 'r', 'r', 'f', 'r', 'r', 'r', 'f', 'r', 'f', 'r', 'r', 's', 'r', 'f', 'f', 'r']\n",
    "y == temp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['f', 'f', 'f', 'f', 'r', 'f', 'f', 'f', 'f', 'f', 'r', 'f', 'f', 'r', 'r', 'f', 'r', 'r', 'r', 'f', 'f', 'r', 's', 'f', 'f', 'r', 'f', 'r', 'r', 'f', 'r', 'f', 'f', 'r', 'r', 's', 'r', 'r', 'r', 'f', 'f', 'r', 'r', 'f', 'r', 'r', 'r', 'f', 'r', 'f', 'r', 'r', 's', 'r', 'f', 'f', 'r']\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Variables \n",
    "### Change as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "590\n",
      "590\n",
      "180\n",
      "144\n",
      "90\n",
      "176\n",
      "Training Features Shape: (584, 300)\n",
      "Training Labels Shape: (584,)\n",
      "Testing Features Shape: (6, 300)\n",
      "Testing Labels Shape: (6,)\n",
      "(584, 300)\n",
      "(584,)\n",
      "['r' 'f' 's' 's' 'r' 'n']\n",
      "['r' 'f' 's' 's' 'r' 'n']\n",
      "Wrong Labels []\n"
     ]
    }
   ],
   "source": [
    "compiled_features = np.concatenate((featuresA, features_n2v3, features_n3v3, features_injuredn2v3))\n",
    "compiled_labels = np.concatenate((labelsA, labels_n2v3, labels_n3v3, labels_injuredn2v3))\n",
    "print(len(compiled_features))\n",
    "print(len(compiled_labels))\n",
    "print(list(compiled_labels).count('r'))\n",
    "print(list(compiled_labels).count('f'))\n",
    "print(list(compiled_labels).count('s'))\n",
    "print(list(compiled_labels).count('n'))\n",
    "attempt_classifier = create_classifier(compiled_features, compiled_labels, 1000, test_proportion=0.01)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# wrong_ones = []\n",
    "# for i in range(100, 200):\n",
    "#     print(i)\n",
    "#     seed = i\n",
    "#     wrong_ones.extend(create_classifier(compiled_features, compiled_labels, 1000, test_proportion=0.25)[1])\n",
    "# wrong_ones.sort(key= lambda x: x[0])\n",
    "# wrong_df = pd.DataFrame(wrong_ones, columns = ['guess', 'actual'])\n",
    "# wrong_df.groupby(wrong_df.columns.tolist(),as_index=False).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find Success, Fails, and Reaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mode, StatisticsError\n",
    "#Helper Functions\n",
    "def get_predicted_times(classifier, df):\n",
    "    dataframe = df[cols]\n",
    "    inputs = []\n",
    "    num_frames = frames_before + frames_after\n",
    "    for index in range(num_frames, dataframe.shape[0] - num_frames, step_size):\n",
    "        temp_df = dataframe.iloc[index - frames_before: index + frames_after]\n",
    "        inputs.append(temp_df.values.flatten())\n",
    "    inputs = np.asarray(inputs)\n",
    "    predictions = classifier.predict(inputs)\n",
    "    return predictions, list(range(num_frames, dataframe.shape[0] - num_frames, step_size))\n",
    "def get_starts(lst):\n",
    "    def most_common(l):\n",
    "        try:\n",
    "            return [mode(l)]\n",
    "        except StatisticsError as e:\n",
    "            # will only return the first element if no unique mode found\n",
    "            if 'no unique mode' in e.args[0]:\n",
    "                print(\"TIE: \", l)\n",
    "                return [l[0]]\n",
    "            # this is for \"StatisticsError: no mode for empty data\"\n",
    "            # after calling mode([])\n",
    "        raise\n",
    "    lst = [(frame_to_time(x[0]), x[1]) for x in lst if x[1] != 'n']\n",
    "    print(lst[0])\n",
    "    lst.insert(0, (-999, 'sentinel'))\n",
    "    starts = []\n",
    "    run = 0\n",
    "    classes_list = []\n",
    "    for i in range(0, len(lst)):\n",
    "        run += 1\n",
    "        if lst[i][1] != 'sentinel':\n",
    "            classes_list.append(lst[i][1])\n",
    "        if lst[i][0] - lst[i-1][0] > .2:\n",
    "            starts.append((lst[i][0], most_common(classes_list), classes_list))\n",
    "            classes_list = []\n",
    "            run = 0\n",
    "    return starts\n",
    "\n",
    "#Find Reaches, \n",
    "def get_classified_starts(classifier, df):\n",
    "    predictions2, start_frames = get_predicted_times(classifier, df)\n",
    "    class_to_predictions = {}\n",
    "    return get_starts(list(zip(start_frames, predictions2)))\n",
    "#     for start, prediction in zip(start_frames, predictions2):\n",
    "#         for c in classes:\n",
    "#             if prediction == c:\n",
    "#                 if c in class_to_predictions.keys():\n",
    "#                     class_to_predictions[c].append(frame_to_time(start))\n",
    "#                 else:\n",
    "#                     class_to_predictions[c] = [frame_to_time(start)]\n",
    "#     for c in classes:\n",
    "#         hold = get_starts(class_to_predictions[c])\n",
    "#         class_to_predictions[c] = hold\n",
    "#     return class_to_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.969, 'r')\n",
      "TIE:  ['f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 'r']\n",
      "[(1.969, ['r'], ['r']), (2.878, ['r'], ['r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r']), (3.829, ['r'], ['r', 'r', 'r', 'f']), (4.596, ['r'], ['f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r']), (5.981, ['r'], ['r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r']), (10.552, ['r'], ['r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f']), (11.028, ['f'], ['f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'r']), (15.057, ['r'], ['f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r']), (15.657, ['r'], ['r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r']), (17.86, ['r'], ['r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r']), (18.544, ['r'], ['r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'f', 'f', 'f', 'f', 'f', 'r']), (19.578, ['f'], ['r', 'r', 'r', 'r', 'r', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'r']), (20.921, ['r'], ['r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r']), (26.034, ['f'], ['r', 'r', 'r', 'r', 'r', 'r', 'f', 'f', 'f', 'f', 'f', 'f', 'f']), (26.76, ['f'], ['f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'r']), (28.312, ['r'], ['r', 'r', 'r', 'r', 'r', 'r']), (30.581, ['r'], ['r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'f']), (37.171, ['f'], ['f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 'f', 'f', 'f', 'f', 'f', 'f', 'r']), (38.272, ['r'], ['r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r']), (39.806, ['r'], ['r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r']), (41.742, ['r'], ['r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r']), (43.477, ['r'], ['r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r']), (45.646, ['r'], ['r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r']), (46.58, ['r'], ['r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r']), (48.373, ['r'], ['r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'f']), (48.891, ['f'], ['f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'r']), (50.367, ['r'], ['r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r']), (51.476, ['r'], ['r', 'r', 'r', 'r']), (52.319, ['r'], ['r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'f']), (52.736, ['f'], ['f', 'f', 'f', 'f', 'f', 'f', 'f', 'f']), (58.617, ['f'], ['f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'r', 'r', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'r']), (60.385, ['r'], ['r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r']), (60.886, ['r'], ['r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r']), (64.014, ['r'], ['r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'f']), (68.118, ['f'], ['f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 'r']), (69.228, ['r'], ['r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r'])]\n",
      "36\n",
      "[(1.969, 'r'), (2.878, 'r'), (3.829, 'f'), (4.596, 'r'), (5.981, 'r'), (10.552, 'f'), (11.028, 'r'), (15.057, 'r'), (15.657, 'r'), (17.86, 'r'), (18.544, 'r'), (19.578, 'r'), (20.921, 'r'), (26.034, 'f'), (26.76, 'r'), (28.312, 'r'), (30.581, 'f'), (37.171, 'r'), (38.272, 'r'), (39.806, 'r'), (41.742, 'r'), (43.477, 'r'), (45.646, 'r'), (46.58, 'r'), (48.373, 'f'), (48.891, 'r'), (50.367, 'r'), (51.476, 'r'), (52.319, 'f'), (52.736, 'f'), (58.617, 'r'), (60.385, 'r'), (60.886, 'r'), (64.014, 'f'), (68.118, 'r'), (69.228, 'r')]\n",
      "[11.028, 19.578, 26.034, 26.76, 37.171, 48.891, 52.736, 58.617, 68.118]\n",
      "[1.969, 2.878, 3.829, 4.596, 5.981, 10.552, 15.057, 15.657, 17.86, 18.544, 20.921, 28.312, 30.581, 38.272, 39.806, 41.742, 43.477, 45.646, 46.58, 48.373, 50.367, 51.476, 52.319, 60.385, 60.886, 64.014, 69.228]\n",
      "[]\n",
      "24.0\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_hdf(r\"C:\\Users\\vjj14\\Desktop\\DeepLabCut\\gopro3lens-vj-2019-07-08\\videos\\2019.07.08_CC42970_N3_V2_2.7k_120FPS_analyze_trimDeepCut_resnet50_gopro3lensJul8shuffle1_120003.h5\")\n",
    "test_df.columns = test_df.columns.droplevel()\n",
    "starts = get_classified_starts(attempt_classifier, test_df)\n",
    "print(starts)\n",
    "print(len(starts))\n",
    "print([(x[0], x[2][-1]) for x in starts])\n",
    "predicted_fails = [x[0] for x in starts if 'f' in x[1]]\n",
    "predicted_reaches = [x[0] for x in starts if 'r' in x[1]]\n",
    "predicted_successes = [x[0] for x in starts if 's' in x[1]]\n",
    "print(predicted_fails)\n",
    "print(predicted_reaches)\n",
    "print(predicted_successes)\n",
    "summ = 0\n",
    "for x in starts:\n",
    "    summ = summ + len(x[2])\n",
    "print(summ/len(starts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2.08, 'r'), (3.9, 'f'), (4.7, 'r'), (6.09, 'r'), (10.66, 'f'), (11.1, 'f'), (15.1, 'r'), (15.77, 'r'), (17.9, 'r'), (18.6, 'f'), (19.6, 'r'), (26, 'f'), (28.4, 'r'), (30.6, 's'), (37.2, 'r'), (39.9, 'r'), (41.8, 'r'), (43.5, 'r'), (45.7, 'r'), (46.67, 'r'), (48.4, 'f'), (49, 'r'), (49.25, 'r'), (51.566, 'r'), (52.7, 's'), (58.7, 'r'), (60.5, 'r'), (60.9, 'r'), (64.15, 's'), (69.1, 'r')]\n",
      "6\n",
      "21\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "test_labels = ['r', 'f', 'r', 'r', 'f', 'f', 'r', 'r', 'r', 'f', 'r', 'f', 'r', 's', 'r', 'r', 'r', 'r', 'r', 'r', 'f', 'r', \n",
    "               'r', 'r', 's', 'r', 'r', 'r', 's', 'r']\n",
    "test_times = [2.08, 3.9, 4.7, 6.09, 10.66, 11.1, 15.1, 15.77, 17.9, 18.6, 19.6, 26, 28.4, 30.6, 37.2, 39.9, 41.8, 43.5, 45.7, \n",
    "              46.67, 48.4, 49, 49.25, 51.566, 52.7, 58.7, 60.5, 60.9, 64.15, 69.1]\n",
    "solutions = list(zip(test_times, test_labels))\n",
    "print(list(zip(test_times, test_labels)))\n",
    "print(test_labels.count('f'))\n",
    "print(test_labels.count('r'))\n",
    "print(test_labels.count('s'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-639-c515fd999aae>, line 36)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-639-c515fd999aae>\"\u001b[1;36m, line \u001b[1;32m36\u001b[0m\n\u001b[1;33m    grouped_labels.groupby(grouped_labels.columns.tolist(),as_index=False).size()\u001b[0m\n\u001b[1;37m                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def find_differences(predicted, solutions, epsilon):\n",
    "    index = 0\n",
    "    while index < len(predicted) and index < len(solutions):\n",
    "        diff = predicted[index][0] - solutions[index][0]\n",
    "        if abs(diff) < epsilon:\n",
    "            index += 1\n",
    "            continue\n",
    "        elif diff > 0:\n",
    "            predicted.insert(index, (9999, ['x'], ['x']))\n",
    "        elif diff < 0:\n",
    "            solutions.insert(index, (9999, 'x'))\n",
    "        index += 1\n",
    "    while len(predicted) < len(solutions):\n",
    "        predicted.append((9999, ['x'], ['x']))\n",
    "    while len(solutions) < len(predicted):\n",
    "        solutions.append((9999, 'x'))\n",
    "    false_positives = [predicted[i] for i in range(len(predicted)) if solutions[i][0] == 9999]\n",
    "    false_negatives = [solutions[i] for i in range(len(predicted)) if predicted[i][0] == 9999]\n",
    "    print(\"false positives: \", false_positives, \"count: \", len(false_positives))\n",
    "    print(\"false negatives: \", false_negatives, \"count: \", len(false_negatives))\n",
    "    for i in range(len(predicted)-1, -1, -1):\n",
    "        if predicted[i][0] == 9999 or solutions[i][0] == 9999:\n",
    "            predicted.pop(i)\n",
    "            solutions.pop(i)\n",
    "    return (predicted, solutions)\n",
    "correct_times = find_differences(starts[:], solutions[:], 0.3)\n",
    "pred_label_for_correct_times = [x[1][0] for x in correct_times[0]]\n",
    "true_label_for_correct_times = [x[1] for x in correct_times[1]]\n",
    "print(([x[1][0] for x in correct_times[0]]))\n",
    "print(([x[1] for x in correct_times[1]]))\n",
    "print(len(correct_times[0]))\n",
    "print()\n",
    "guessed_labels = [x[1][0] for x in correct_times[0]]\n",
    "true_labels = [x[1] for x in correct_times[1]]\n",
    "grouped_labels = pd.DataFrame(list(zip(guessed_labels, true_labels), columns = ['guess', 'actual'])\n",
    "grouped_labels.groupby(grouped_labels.columns.tolist(),as_index=False).size()\n",
    "\n",
    "wrong_ones = [correct_times[0][i][1][0] for i in range(len(correct_times[0])) if correct_times[0][i][1][0] != correct_times[1][i][1]]\n",
    "wrong_ones_correct = [correct_times[1][i][1] for i in range(len(correct_times[0])) if correct_times[0][i][1][0] != correct_times[1][i][1]]\n",
    "print(wrong_ones)\n",
    "print(wrong_ones_correct)\n",
    "wrong_df = pd.DataFrame(list(zip(wrong_ones, wrong_ones_correct)), columns = ['guess', 'actual'])\n",
    "wrong_df.groupby(wrong_df.columns.tolist(),as_index=False).size()\n",
    "\n",
    "# wrong_ones = [(correct_times[0][i][0], correct_times[0][i][1][0]) for i in range(len(correct_times[0])) if correct_times[0][i][1][0] != correct_times[1][i][1]]\n",
    "# wrong_ones_correct = [correct_times[1][i] for i in range(len(correct_times[0])) if correct_times[0][i][1][0] != correct_times[1][i][1]]\n",
    "# print([(correct_times[0][i][0], correct_times[0][i][2]) for i in range(len(correct_times[0])) if correct_times[0][i][1][0] != correct_times[1][i][1]])\n",
    "# print(list(zip(wrong_ones, wrong_ones_correct)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.504 4.238\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1ebb778cd30>"
      ]
     },
     "execution_count": 636,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAADxCAYAAAA6LpuYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XmcHHWd//HXp3t6jiSTcxISMgnDEUDDJY6ARlyO5QoQVEDABYENZldRUXa51P3hD3/swmNdAUHRyC3KsSgQkQUjIcJymkSOYDjCkQMSQk5yzNVdn98fVZN0kpnpDl09Pd3zfj4e9eiqb1V1f6sh8+nvbe6OiIhITxKlzoCIiPR9ChYiIpKTgoWIiOSkYCEiIjkpWIiISE4KFiIikpOChYiI5KRgISIiOSlYiIhITlWlzkAxNDQ0eFNTU6mzISJlYO7cuSvdfWQh73HM4QN91epMfp/3Utuj7n5sIZ9XChUZLJqampgzZ06psyEiZcDMFhX6HqtWZ3j+0fF5XZsc80ZDoZ9XChUZLEREepMDAUGps1FUChYiIgVynA7PrxqqXClYiIjEQCULERHpkeNkKny5BwULEZEYBChYiBRsVdt6Hn//ZQICPjdyIqPrhpU6SyKxcSCjYCFSmOUtazj32etoDTpwd3658I/84qCvs9ug0aXOmkhsKr1koRHcUnQ3vzmTDelW2oM0HZ6hJdPGDa//odTZEomNAx3ueW3lSiULKbrV7Ru2+tXlwNr2jaXLkEjMHK/4aiiVLKToPjdqIrWJ1Obj2kSKz42aWMIcicTMIZPnVq5UspCimzL2IFa2fcjdi54k8IATxx7EWbseXupsicQmHMFd2RQspOjMjKm7H8XU3Y8qdVZEisTIYKXORFGpGkpEpEBhA7flteXDzN4xs5fN7AUzmxOlDTezmWb2RvQ6LEo3M/uJmS00s5fM7MBiPKOChYhIgcJxFpbXtgMOd/cD3L05Or4UeMzdJwCPRccAxwETom0acGM8T7U1BQsRkRgEbnltBTgJuD3avx34fFb6HR56FhhqZmMK+aCuKFiIiBSoCCULB/5oZnPNbFqUtpO7LwOIXkdF6WOBJVn3Lo3SYqUGbhGRAjlGJv/f3g2d7RCR6e4+fZtrJrn7e2Y2CphpZq/28H5dRaDYO+kqWIiIxGAHqphWZrVDdMnd34teV5jZ/cBBwPtmNsbdl0XVTCuiy5cC47JubwTe26HM50HVUCIiBXKMdk/mteViZgPNrL5zHzgamA/MAM6OLjsbeDDanwF8JeoVdQiwrrO6Kk4qWUi/FnjAsyvfYFXbBvYZOo5dB43KfZPINsJBebH99t4JuN/MIPwb/Rt3f8TM/gLca2ZTgcXAqdH1DwOTgYXAJuDcuDKSTcFC+q3AA/5l3q+Yt/rt6Nj5wb6ncOSYfUucMylHcQ3Kc/e3gP27SF8FHNlFugPnx/LhPVA1lPRbT3/wOvNWv01Lpp2WTDttQQdXzP8tXsYzg0ppuBsZT+S1lSuVLKTfWtW+YbvA0JrpIO0ZUqZ/GrJjggqf7kP/IqTf2mdI41b9CxMYTQNHkkron4XsmLCBu7L/v6nsp5Oys75jE6va1vHh+ukEHc/RYvvzbqaBIdWjOajheIZUD43ts3avH8339/kiV87/He1Bml0GjuTa5nNie3/pP2Ju4O6TFCykz3hw6ZP88s37uXX3hxiXdEhBwOvsTBvr0s5ry77H4+uP56KJ15OweP5hHrPz/hw9Zj/agzQ1yVTuG0S6kSlsKo8+r7JDoZSNdzYu45dv/Z5v7PwUw5OOmWFmJDDGVFVTZVBraQ6v/wO3vX1HrJ9tZgoUUpDOEdz5bOVKJQvpExZtXE7SEkyoXk/UvxwI/5AnPEESyBhUk2HRxhdLl1GRbgRl3NMpH5X9dFI2dq5rIOMBb7fXb9VDyd0JCOjIurY+FfuEmiIFCScSrOySRdFybma3mNkKM5vfxbl/NTM3s4bouNvFO8zs7GixjzfM7Oxt30sqw4T6cZzceBjXLZvEusBw93ADlqbbSbuRceOJ9XszbfevlTq7IltxjA5P5rWVq2JWQ90G3ABsVcFsZuOAowiHq3fKXrzjYMLFOw42s+HA5UAzYfCea2Yz3H1NEfMtJXLubpM5avSnWNL6Nd5suQnS8/ggGM3qjhU4TnXqML6694XUJWtLnVWRrbhT1gPu8lG0YOHuT5hZUxenrgEuZsskWJC1eAfwrJl1Lt5xGDDT3VcDmNlM4FjgrmLlW0qrccBIGgeMBK4udVZEdoBpUF6czGwK8K67v5jdiEn3i3f0yqIeIiKFcFSyiI2ZDQC+Rzjd7nanu0jzHtK7ev9phOvPMn78+I+YSxGRj6acG6/z0ZtPtzuwK/Cimb1DuEDHPDMbTfeLd+S9qIe7T3f3ZndvHjlyZBGyLyLSNSe/9bcLXIO7pHotWLj7y+4+yt2b3L2JMBAc6O7L6X7xjkeBo81smJkNIyyVPNpbeRYRyYcDHV6V11auipZzM7uLsIG6wcyWApe7+83dXN7l4h3uvtrMfgj8Jbruis7GbhGRvsNiW8+irypmb6gzcpxvytrvdvEOd78FuCXWzImIxMiJdwS3mSWBOYQdgk4wsyOAHwHVwFxgqrunLewpdB3hj+1NwDnuPi+2jGSp7BYZEZFekolKF7m2PF0ALAAwswRwO3C6u+8DLGLLWtzZY9SmEY5RKwoFCxGRArkbgSfy2nIxs0bgeOCmKGkE0Obur0fHM4GTo/3NY9Tc/Vmgc4xa7BQsREQKFDZwxzbdx7WEA5eD6HglkDKz5uj4FLb0Eu21sWgKFiIiBduhNbgbzGxO1jZt87uYnQCscPe5nWlRm+7pwDVm9jywHkhv/uDtFWUR+fLtxyUi0keEDdx5t0esdPfmbs5NAqaY2WSgFhhsZne6+5nAoQBmdjSwZ3R93mPRCqWShYhIDOKYotzdL3P3xqi36OnALHc/08xGAZhZDXAJ8PPolu7GqMVOJQsRkQJ1juAuoouiKqoEcKO7z4rSuxyjVgwKFiIiMQhirqhx99nA7Gj/IuCiLq7pdoxa3BQsREQK5A4dQWXX6itYiIgUKKyGUrAQEZEcNDeUSB/Snknz+PsLWJ9u4VPDd2OXQQ2lzpLIjnadLUsKFlI22jIdnPPMdBZvXIV7AGZc88l/4OCGPUqdNen3Kr8aqrKfTirKQ+++wKINK2nJtNMapGnNdPB/X7q/1NkSASCI1uHOtZUrlSykbKxu20BbkN4qbV3HphLlRmSLsDdUXvM+lS2VLKRsHDiiiZrElt83VZbkE8OaSpchkYiWVRXpQz45fFcu/Nix1CZSJDD2GzaOKw84tdTZEgFUDSXSp5yyy8GcPP4gApyk6beO9A3qDSXSB5kZyTL+hSaVqdJ7QylYiIgUyN1IK1iIiEguqoYSEZEeqc1CRETyomAhIiI96oXFj0qusltkRER6SZzjLMwsaWZ/NbOHouMjzWyemb1gZv9rZntE6TVmdo+ZLTSz58ysqVjPp2AhIlIgd0gHiby2PF0ALMg6vhH4B3c/APgN8P0ofSqwxt33AK4Bro7pkbajYCEiEoO4pvsws0bgeOCmrGQHBkf7Q4D3ov2TgNuj/fuAI82sKPVharMQESlQzG0W1wIXA/VZaecBD5tZC/AhcEiUPhZYAuDuaTNbB4wAVsaVmU4qWYiIxMDd8tqABjObk7VN63wPMzsBWOHuc7d5++8Ak929EbgV+HHnLV1lpQiPp5KFiEgcdmCSwJXu3tzNuUnAFDObDNQCg83sD8De7v5cdM09wCPR/lJgHLDUzKoIq6hWf5T856KShYhIgdzjabNw98vcvdHdm4DTgVmE7RJDzGzP6LKj2NL4PQM4O9o/BZjl7ipZiIj0TUYm/55OOyRqi/gq8FszC4A1wD9Gp28GfmVmCwlLFKcXJRMoWIiIxMJjHpTn7rOB2dH+/cB2awi7eyvQK4u6KFiIiBRIc0OJiEhuHrZbVLKiNXCb2S1mtsLM5mel/aeZvWpmL5nZ/WY2NOvcZdGQ9dfM7Jis9GOjtIVmdmmx8isiUohKX1a1mL2hbgOO3SZtJrCPu+8HvA5cBmBmHydsmJkY3fOzaG6UJPBT4Djg48AZ0bUiIn2GRw3c+Wzlqmg5d/cn2Ka/r7v/0d3T0eGzQGO0fxJwt7u3ufvbwELgoGhb6O5vuXs7cHd0rYhIn+Ke31auShnm/hH4n2h/85D1yNIorbt0EZE+ZQdGcJelkjRwm9n3gDTw686kLi5zug5mXcbmaMj8NIDx48fHkEuRwgQeELhTlUiWOitSZGGpoXwDQT56PViY2dnACcCRWSMNO4esd2pky6yK3aVvxd2nA9MBmpuby7iwJ+Uu8ID/fOUR7n7neRzn6DH7cOUnvkAqoc6HlazSu872ajWUmR0LXAJMcfdNWadmAKdHC3nsCkwAngf+Akwws13NrJqwEXxGb+ZZZEfd887z/HbxXDJRyeLx5Qu4/tXHSp0tKTK1WXxEZnYX8Aywl5ktNbOpwA2E0+7OjFZ8+jmAu78C3Av8jXCCrPPdPRM1hn8DeJRwLpR7o2tF+qynViykNdOx+bgtSPPUioUlzJEUm2MEQSKvrVwVrVzs7md0kXxzD9dfCVzZRfrDwMMxZk2kqHaqG0zSEmQ8ACCBMbpucI67pNyVcaEhL+Ub5kT6qK/vdQTDqwcyIFlNXTLFwFQNF0+cXOpsSTG5ekOJyA4aUTOIBw7/Jk+8/zoZD5g0ag9G1Awqdbak2Cq8aKFgIVIE9alajm/cr9TZkF5UzqWGfChYiIgUyIEgULAQEZGeOFDhJQs1cIuIxCDOcRbRRKp/NbOHouMno+EGL5jZe2b2QJRuZvaTaFbul8zswGI9n0oWIiJxiLeB+wLCsWWDAdz90M4TZvZb4MHo8DjCQcwTgIOBG6PX2KlkISJSsPy6zebTCG5mjcDxwE1dnKsHjgAeiJJOAu7w0LPAUDMbE99zbaFgISISB89zy+1a4GIg6OLcF4DH3P3D6LjXZuZWsBARKZSDB5bXBjSY2ZysbVrn25jZCcAKd5/bzSedAdyVddzdjN2xU5uFiEgs8u4NtdLdm7s5NwmYYmaTgVpgsJnd6e5nmtkIwgXhvpB1fU8zdsdKJQsRkTjEUA3l7pe5e6O7NxHOsj3L3c+MTp8KPOTurVm3zAC+EvWKOgRY5+7LYnumLCpZiIjEofjTfZwOXLVN2sPAZMKlqDcB5xbrwxUsREQKVYRBee4+G5iddXxYF9c4cP6OvK+Z1W5TOsHMGtx9ZU/3qRpKRCQGZbT40V+iKisAzOxk4OlcN6lkISISh/KZG+rLwC1mNhvYGRhBOHajRwoWIiIxsL5RasjJ3V82syuBXwHrgc+5+9Jc9ylYiIgUKv8BdyVnZjcDuwP7AXsCvzezG9z9pz3dpzYLEZGCWdjAnc9WevOBw939bXd/FDgEyDkBoYKFiEgc4pvuo6jc/Rqg1sz2io7XufvUXPcpWEi/8s6GVUx/7QlufuMplresK3V2pJIEeW4lZmYnAi8Aj0THB5jZjFz3qc1C+o2/rX2Ps568lfYggwHTX3uC+w7/J8YNHF7qrEm5K6/Fj35AOG3IbAB3f8HMds11k0oW0m/86JWZtGQ6yHhA2gM2pNv42at/LnW2pEKY57f1AWl337ZYnTNnOYOFmX3DzIZ95GyJ9BHr2lu2OnZgbfum0mRGKk+ZtFkA883sy0DSzCaY2fXkMSgvn5LFaMIRf/ea2bFmVjZlLZFsx46dSF0ytfm4Lpni2LETS5gjkZL4JjARaCOc7vxD4Nu5bsrZZuHu3zezfwOOJpyk6gYzuxe42d3fLCjLIr1o6oRJrO9o5d535pIwY+qEzzJl3P6lzpZUiD5SxZSTu28Cvhdtecurgdvd3cyWA8uBNDAMuM/MZrr7xTuaWZFSSFiCCycexYUTjyp1VqTSOH1+ug8z+z09VIS5+5Se7s8ZLMzsW8DZwErCNWEvcvcOM0sAbxAu/yci0r/1/ZLFj6LXLxI2L9wZHZ8BvJPr5nxKFg3AF919UXaiuwfREoAiIv1eX6+Gcvc/A5jZD939c1mnfm9mT+S6P582i//Tw7kFeeVSRKTS9fFgkWWkme3m7m8BRGMsRua6SeMsRETiEGPXWTNLmtlfzeyh6NjM7Eoze93MFkTNA53pPzGzhWb2kpnlnOMJ+A4w28xmR9OUP04cvaFERKRnRRhwdwGwABgcHZ8DjAP2jpoARkXpxwETou1g4MbotVvu/oiZTQD2jpJedfe2XBlSyUJEJA6B5bflYGaNwPGEHYo6fQ24wt0DAHdfEaWfBNzhoWeBoWY2Jo/cfpJwrMX+wGlm9pVcN6hkISISgxhLFtcS9jKtz0rbnfCP+heAD4BvufsbwFhgSdZ1S6O0Zd3m0+xX0fu9AGSiZAfu6ClTChYiInHIP1g0mNmcrOPp7j4dIOphusLd55rZYVnX1ACt7t5sZl8EbgEOBboqquTKSTPwcfcdWxFcwUJEpFA71max0t2buzk3CZhiZpOBWmCwmd1JWGL4bXTN/cCt0f5SwraMTo3Aezk+fz7hOItuSx9dKVqbhZndYmYrzGx+VtpwM5tpZm9Er8Oi9G5b9M3s7Oj6N8zs7GLlV0SkIDH0hnL3y9y90d2bgNOBWe5+JvAAcER02d8Br0f7M4CvRH9DDwHWuXuuINAA/M3MHjWzGZ1brscrZsniNuAGtq4HuxR4zN2vMrNLo+NL6KZF38yGA5cTFpscmGtmM9x9TRHzLSKyw6y4CxtdBfzazL4DbADOi9IfBiYDC4FNhPP35fKDj5KBogULd3/CzJq2ST4JOCzav51w8Y1LyGrRB541s84W/cOAme6+GsDMZgLHEs6UKCJSsdx9NlsWKFpL2ENq22scOH8H3/cjLeLS220WO3UWkdx9WVZf4e5a9LtLFxHpW/r4CG4z+193/6yZrWfr3Bph3Bncza1A32ng7q5FP++WfjObBkwDGD9+fHw5ExHJpe+sgtctd/9s9Fqf69qu9PagvPc7B4xEr50DS7pr0c+7pd/dp7t7s7s3jxyZc5oTEZF4lc9KeR9JbweLGYTTnRO9PpiV3lWL/qPA0WY2LOo5dXSUJiLSt1R4sChaNZSZ3UXYQN1gZksJezVdBdxrZlOBxcCp0eVdtui7+2oz+yHwl+i6Kzobu0VE+gqj6L2hSq6YvaHO6ObUkV1c222LvrvfQjhaUUSkbyqDNotC9ZUGbhGR8qZgISIiOSlYiIhILqqGEhGR3BQsRESkR67eUCIikg+VLEREJBe1WYiISG4KFiIi0qMyn8ojHwoWIiIFMiq/Gqq3JxIUEalI5vlteb2XWdLM/mpmD0XHt5nZ22b2QrQdEKV3uyR13FSyEBGJQ7wliwuABUD2gkQXuft921zX5ZLUseYkopKFiEgcYpqi3MwaCZdQvSmPT928JLW7Pwt0LkkdOwULEZFC5VkFlWc11LXAxcC2w/yujKqarjGzmiit15aeVrAQEYlD/iWLBjObk7VN63wLMzsBWOHuc7d598uAvYFPAcOBSzpv6SYnsVObhYhIDHZguo+V7t7czblJwBQzmwzUAoPN7E53PzM632ZmtwL/Gh3nvfR0oVSyEBGJQRzVUO5+mbs3unsTcDowy93P7GyHMDMDPg/Mj27pbknq2KlkISJSqOIPyvu1mY0krHZ6AfjnKL3LJamLQcFCpBetadvED+b9D6+sXc5u9Q1c8cnjGF03OPeN0vfFHCzcfTYwO9o/optrul2SOm6qhhLpJYE7Z/35Tma+9xqLNqzhiWUL+dJjt9Ga6Sh11qRAnSO44xqU1xcpWIj0kiUb17B4wxo6grAlNIOzvqOVV9YsL3HOJA4WeF5buVI1lEgvSSWSBL71H4vAnVQiWaIcSWz6wUSCKlmI9JIxdYM5dPRu1CbD32g1iSr2GjqKicNGlzhnEodKr4ZSyUKkl5gZ13/6FG5/43leWv0eew4ZyXl7fZqk6TdbRSjjQJAPBQuRXlSVSDB1r0NKnQ0pgnIuNeRDwUJEJA4KFiIi0iPfoek+ypKChYhIgfrDSnkKFiIicfDKjhYKFiIF6ggyLNmwlkGpakbV1Zc6O1IiKlmISLfe27iO02bdwdq2FtIecHLTfvyw+TjCyUGl39CgPBHpyQXP3M/7LevZlOmgPcjwwKL5PLxkQamzJSVgQX5buVKwECnAGx+uJJNVV92S6WDB2vdLmCMpFQULEenWuIFDt1rXsi6ZYtf6ESXLj5SIEzZw57OVKQULkQJc8+nPM7S6jkGpGuqSKT6zUxOf32WfUmdLSkBzQ4lIt/YY3MDjJ5zPgjXvMyhVzceG7lTyxu2WdLg+Rl1VqqT56HdiDARmlgTmAO+6+wlZ6dcD57r7oOi4BrgD+CSwCjjN3d+JLydblCRYmNl3gPMIv96XCZcCHAPcDQwH5gFnuXt7b34ZIh9FfaqGg0aNL3U26AgyfOepB3l06WsAHDfuY/zXZ07UFOi9oAiD8i4AFgCbl1E0s2Zg6DbXTQXWuPseZnY6cDVwWqw5ifR6NZSZjQW+BTS7+z5AknBh8quBa9x9ArCG8EuArC8DuCa6TkS28ZOXn2TWewvJuJNx50/vvs7P5j9d6mz1D57fwkf5LH5kZo3A8cBNWWlJ4D+Bi7e5/CTg9mj/PuBIK1LRtlRtFlVAnZlVAQOAZcARhA8L4cN/PtrvtS9DpJw98/4iWjPpzcetmTTPvP9O6TLU33ieW27XEgaF7L5T3wBmuPuyba4dCywBcPc0sA4oSg+LXq+Gcvd3zexHwGKgBfgjMBdYGz0swFLCLwG2+TLMrPPLWJn9vmY2DZgGMH586asEpHwtmL+UH//7Q6xds5H9D9yFC797IgMG1mx1TVsmzdXzZvPom6+ydslaBszbSN1ap/2InVg1LEOGDGSc1DpnpwfWMvCdDXzi7/Zmn69+mtYUjO2oZu1baxg6YhB/f+IBJKvCqqIPW1t59u0lvLjwXX7/6gI2JTMctttu/PuJx1Cd7Lo6KXDn5hfm8taqteEfo+inVAJj3KBtay2kWHagGqrBzOZkHU939+kAZnYCsMLd55rZYVHazsCpwGFdfWwXaUVpRu/1YGFmwwhLC7sCa4H/Bo7r4tLOB87ry4i+7OkAzc3NZdznQEpp+bK1XPKtO2ltCRuJn3nyda747n1cdd0/bHXdvz79B/646HXaPAM7VbHxuCF4m0GiA5Lh/36WMtpqjMVfHQ4bGng1aCP11J9JdIT/Sw95pZWhr2/kuh/cz/V3fY26sfWc/MvfsKGtnY116fBfp8H9by7g/Xs38KszvtRlnr8/+0/c99ortAdpbDCb/3Vk3BkbDCvK9yTbcCD/9bVXuntzN+cmAVPMbDJQS9hm8QrQBiyMKlUGmNnCqGp+KTAOWBrV1AwBVn/k5+hBKaqh/h54290/cPcO4HfAZ4Ch0cMCNALvRfudXwbF/jJEXpjzzlZd4Ts6Mrww520y6S01AoE7/7PotTBQwJafM1Vs/nm5uaLUoq0GvAbaRzhBVXhi3cdraRtaTRA43/7yL7jykdmsa2ml1dJb7gM8aTy9fCntmcx2+U0HAfcseDk854avq8Y3VuEbq2BtNTfNmxfbdyM5xFAN5e6XuXujuzcRtuXOcvdh7j7a3Zui9E1RoACYAZwd7Z8SXV+UH8ulCBaLgUPMbEDU9nAk8DfgccKHhfDhH4z2e+3LEKmtS23X9TWZTJBIbkkzIPFRm80MglrfHAw+3GMAAB3taZasXrfVaPAubt3O9v8UDDqS0J4EjHRQxkOGy0yJxlncDIwws4XAhcClsX9CpNeDhbs/R9hQPY+w22yCsProEuDC6KFHEH4JUOQv46kPXuHnbzzE/Uueoj1I575BKtqnP7snI0cNJlUdtg/U1Kb4ylcP2yqAmBnTJh5MjUVtCJ1/ANKAG2QN1PXOX5Odf7Ozf2EGhldted9DdhtHbVUVlmarX6GWdo7YaRdSXbRZpJJJJu+xJ6lEYuu8RPuTdh73Eb8J2VFx9Ybq5O6zs8dYZKUPytpvdfdT3X0Pdz/I3d+K6XG2U5JxFu5+OXD5NslvAQd1cW0rYeNO7G5764/cvehxWoMOahIpHln2F37a/E2q1C+936qpTXHDrVN56HdzWfXBej7xqV05eNKE7a77l/0Ppal+GLfPeY6XP1wJnsAyhrUbngogEbY0W0BYJ2W2OQAkW8L9ZKtTu7IdMgHHfP5Avn7kZ1myZh1/Xvg2iY1OKmHUeoJj9t6TK04+pts8/9eRx9FYP5gHXl3ABxs3ksk4CWDS6F2Y/sUvFOurkmz9YNZZq8QanebmZp8zZ06P13QEaY6d/V0yvqWYXpes5vJ9zuKQho8VO4tSQVrbOrjmjlnMeXExi5Mb2TDcCQwSG50gBZmBTlDjJDqganWCRNpIBDCsNcHfpQfx2aP25dgvbfmdtKm9g4QZtSlNsNAbzGxuDw3OeRk8uNGbD/5GXtc+/qfLCv68Uui3/zd2dFHlZBgtmbYS5EbKWW1Nisu+uv0v/w/WbmDFmg3sPHIINVVJWto6GFBbzZvLVlGTqmKPnUd0OTXIgGpN01GWKrx5qN8GiwFVtUyoH8vC9e+R9i29TPYdumsJcyWVZOTQQYwcurl6mQG11QDs0zS6VFmSIrIKrKXJ1q9nnb36gPNoHr4n9VUDaBq4Ez8+8J9pqBlS6myJSLnJt9tsGceTfluyABiSGshVB0zNfaGI9Hn3LH6UexbPJOMZDh35CS7Y88ukEr31J27HejqVo35dshCRyjD7/bncs3gmbUE7ac/w1MoXufXtGb2bCS1+JCLStz2/ej5tQfvm4/agg+dXze+9DHjlL6var6uhRKQyDKseTNISW3WFH1pd37uZKONSQz5UshCRsnfquL9nSGoQNYkU1ZaiNlHDP+9+Su4b46QGbhGRvm1odT0/++R3eXrlC3R4mk8Nn8hOtUVZ1qFbVuHzcClYiEhFqE8N4JgxnynNh2fP/1WhFCxERApkeMUPylOwEBGJg4KFiIjkpGAhIiI96gdtFuo6KyISAwuCvLa83sssaWZ/NbOHouObzexFM3vCBwK3AAAHdUlEQVTJzO4zs0FReo2Z3WNmC83sOTNrKtbzKViIiBQsz6k+8q+qugBYkHX8HXff3933I1yaunPxjKnAmmhN7muAq+N6om0pWIiIFMqJLViYWSNwPHDT5rd3/zA6Z0AdW4b3nQTcHu3fBxxpXS2SEgMFCxGROAR5brldC1y87dVmdiuwHNgbuD5KHgssAXD3NLAOKMpoRAULEZEYmHteG9BgZnOytmmb38PsBGCFu8/d9v3d/VxgZ8LqqdM6b+kiK0XplqXeUCIicci/PWJlD2twTwKmmNlkoBYYbGZ3uvuZ4Ud4xszuAS4CbgWWAuOApWZWBQwBVhfwFN1SyUJEuvTWhrf5zaJ7+e3SB1ndVpS/P5XDHTJBfluPb+OXuXujuzcBpwOzgLPMbA/Y3GZxIvBqdMsM4Oxo/xRglntxBnyoZCEi23lp7Xyue+OntAcdJEgwc/lj/L99L6ehpncn5ysrxRuUZ8DtZjY42n8R+Fp07mbgV2a2kLBEcXqxMqFgISLbuWvxf9MedAAQENCSaWHm8lmcscupJc5ZHxZzsHD32cDs6HBSN9e0Ar3yH0XBQkS20xa0bXUc4GzKbCpRbsqAA1qDW0T6m0+POJjqRPXm4+pENYeMOKiEOerrHDzIbytTKlmIyHZObjyJwAP+d+XTpBIpTm38IhOHfKzU2eq7nJyN1+VOwUKkwmUyK+noWEAyOYpUaq+87klYgtPGn8xp408ucu4qiGadFZFy0NbyKBvXX4kHrdQOOJUB9f/Cug2/YP2H/wEkMWDAwNMYNuQ/KNKMEP2bgoWI9HXtbc/y4ZrzgRYANm34BZvanqGl/ZloiG8HDmza9N8MqDuBmupJeOYtCDZgqT0xqwNg5aYneWvtjbh3MG7wWexcP6VET1RudmiSwLKkYCFSAdpaHqQzUIRayLQ/F9alZxUi3DOkO94kuelugtZZYFVgNaRG3Mvajg94ccW3CLwVgAWrfgA4O9ef1HsPUq4cyHP68XKl3lAiFcBsIJDs8tzWP3idlK8iaHscaAXfAMFq0mu/zdIP79ocKAACb2Hxh3cUM9uVJd4pyvscBQuRClA38FywAZv/FmUc1gdGW1SscA9//NYP+joJz4Bnl0IcT7+D2fbBxroJQLKteKb76MsULEQqQLJqLO0D/43lmXqWp2t4tX0wCzuG0BJU0W61BIlGGkbcw9Ahl5BI7Qk2IOvuBFa1G+OHnEPCarekWi27Dfva9h8m23NwD/LaypXaLEQqRCI5hqWZoWR8y0jrxekRTB73PAlLbbmudgqJ1icJWv8QtVkMIjX0OqqrxtM85g4WrbuVwDsYN/h0RtR1OcuEdKXCR3CXJFiY2VDCVaD2ISwd/yPwGnAP0AS8A3zJ3ddEsyxeB0wGNgHnuPu8EmRbpE8bVfcZapMNbEovw+kgaXWMqz9pq0ABYGakhv0IT38b9/VY1W6Y1QAwpGZf9hv141Jkv/yVcXtEPkpVsrgOeMTdTzGzamAA8F3gMXe/yswuBS4FLgGOAyZE28HAjdGriGRJJmo5dOxvWLj2Fjam36Wh9iB2GXxKt9dbVWOXK+fIR+Be8b2hej1YRNPsfg44B8Dd24F2MzsJOCy67HbC2RYvIVxj9o5ojvZnzWyomY1x92W9nHWRPi+VHMzHRny71Nnonyq8ZFGKBu7dgA+AW83sr2Z2k4X9/nbqDADR66jo+s1rzEaWRmkiIn2E45lMXlu5KkWwqAIOBG50908AGwmrnLqT1xqzZjatc03bDz74IJ6ciojko3OK8ny2MlWKYLEUWOruz0XH9xEGj/fNbAxA9Loi6/pxWfc3Au9t+6buPt3dm929eeTIkUXLvIhIl2KcotzMklHNy0PR8a/N7DUzm29mt5iFvRYs9BMzW2hmL5nZgcV6vF4PFu6+HFhiZp3TXx4J/I2t15I9G3gw2p8BfCX6Ug4B1qm9QkT6Egc88Ly2PF0ALMg6/jWwN7AvUAecF6VndwCaRtgBqChK1Rvqm8Cvo55QbwHnEgaue81sKrCYLUsFPkzYbXYhYdfZc3s/uyIiPXCPbWEjM2sEjgeuBC4M394fzjr/PGENC/RiB6CSBAt3fwFo7uLUkV1c68D5Rc+UiEgBYmy8vha4GKjf9kRU/XQWYckDuu8AVBnBotjmzp270swWlTofMRlPWNLqb/Tc/Uspn3uXQt9gPWse/ZPf15Dn5bVmNifreLq7TwcwsxOAFe4+18wO6+LenwFPuPuT0XFeHYDiUJHBwt0rpoXbzD5w965KYRVNz92/lPtzu/uxMb3VJGCKmU0GaoHBZnanu59pZpcDI4F/yro+rw5AcdBEgn3f2lJnoET03P1Lf33urbj7Ze7e6O5NwOnArChQnAccA5zhW89G2GsdgCqyZFFh1pU6AyWi5+5f+utz5+vnwCLgmWhJ3N+5+xX0YgcgBYu+b3qpM1Aieu7+pb8+d7fcfTbhtEe4e5d/q3uzA5B5hc9nIiIihVObhYiI5KRgISIiOSlYiIhITgoWIiKSk4KFiIjkpGAhIiI5KViIiEhO/x9j5W+aFej2dgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(frame_to_time(420), frame_to_time(508))\n",
    "test_df.iloc[420:508]['Pellet'].reset_index().plot(kind='scatter', x='x', y='y', c='index', colormap='viridis')\n",
    "# plt.xticks([600, 800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.935, 2.87, 3.762, 4.588, 5.973, 10.46, 14.882, 15.616, 17.809, 18.527, 19.561, 20.913, 25.876, 26.76, 28.303, 30.547, 37.171, 38.255, 39.798, 41.725, 43.493, 45.654, 46.588, 48.365, 48.841, 51.476, 52.711, 58.634, 60.385, 60.886, 63.897, 68.093]\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "x = sorted(predicted_fails + predicted_reaches + predicted_successes)\n",
    "print(x)\n",
    "print(len(x))\n",
    "import numpy as np\n",
    "np.savetxt(\"file_name.csv\", x, delimiter=\",\", fmt='%s', header='times')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14.364, 'f')\n",
      "TIE:  ['r', 'f']\n",
      "[(14.364, ['f'], ['f']), (15.157, ['f'], ['f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f']), (32.533, ['f'], ['f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f']), (41.875, ['f'], ['f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f']), (42.543, ['f'], ['f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 's']), (50.859, ['s'], ['s', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 'r']), (52.327, ['r'], ['r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r']), (53.27, ['r'], ['r', 'f']), (54.663, ['f'], ['f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'r', 'f', 'f', 'f', 'f', 'r', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f']), (55.272, ['f'], ['f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f']), (56.448, ['f'], ['f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f']), (57.14, ['f'], ['f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f']), (58.141, ['f'], ['f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'r']), (62.179, ['r'], ['r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'f']), (62.813, ['f'], ['f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'r']), (63.964, ['f'], ['r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'r']), (64.615, ['r'], ['r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r']), (70.596, ['r'], ['r']), (72.014, ['r'], ['r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r']), (77.085, ['r'], ['r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'f']), (78.795, ['f'], ['f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r']), (80.013, ['r'], ['r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r']), (81.331, ['r'], ['r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'f', 'f', 'f', 'f', 'f', 'f']), (81.999, ['f'], ['f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f']), (82.916, ['f'], ['f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'r']), (84.343, ['r'], ['r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r']), (87.704, ['r'], ['r', 'r', 'r', 'r', 'r', 'r', 's']), (93.36, ['s'], ['s', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 'f']), (94.595, ['f'], ['f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'r']), (96.813, ['r'], ['r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r']), (98.874, ['r'], ['r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r']), (99.183, ['r'], ['r', 'r', 'r', 'r']), (100.634, ['f'], ['f']), (101.527, ['f'], ['f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'r']), (102.578, ['r'], ['r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r']), (111.845, ['r'], ['r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'f', 'f', 'r', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f']), (112.646, ['f'], ['f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'r']), (118.652, ['r'], ['r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'f']), (122.523, ['f'], ['f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 's', 'f', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 'r']), (127.519, ['r'], ['r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'f']), (128.303, ['f'], ['f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'r', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'r']), (129.271, ['r'], ['r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r']), (133.133, ['r'], ['r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'f']), (138.514, ['f'], ['f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 'r']), (139.615, ['r'], ['r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r']), (140.44, ['r'], ['r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r']), (142.117, ['r'], ['r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'f']), (142.835, ['f'], ['f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f']), (143.71, ['f'], ['f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'r']), (144.87, ['r'], ['r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r']), (149.633, ['r'], ['r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'f']), (150.275, ['f'], ['f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'r']), (151.468, ['r'], ['r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r']), (152.477, ['r'], ['r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r']), (170.112, ['r'], ['r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'f']), (170.913, ['f'], ['f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'r']), (176.627, ['r'], ['r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'f']), (179.68, ['f'], ['f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r']), (192.584, ['r'], ['r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 's']), (197.097, ['s'], ['s', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 's', 'r']), (198.165, ['r'], ['r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'r', 'f']), (198.774, ['f'], ['f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f']), (199.675, ['f'], ['f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'f', 'r'])]\n",
      "63\n",
      "[(14.364, 'f'), (15.157, 'f'), (32.533, 'f'), (41.875, 'f'), (42.543, 's'), (50.859, 'r'), (52.327, 'r'), (53.27, 'f'), (54.663, 'f'), (55.272, 'f'), (56.448, 'f'), (57.14, 'f'), (58.141, 'r'), (62.179, 'f'), (62.813, 'r'), (63.964, 'r'), (64.615, 'r'), (70.596, 'r'), (72.014, 'r'), (77.085, 'f'), (78.795, 'r'), (80.013, 'r'), (81.331, 'f'), (81.999, 'f'), (82.916, 'r'), (84.343, 'r'), (87.704, 's'), (93.36, 'f'), (94.595, 'r'), (96.813, 'r'), (98.874, 'r'), (99.183, 'r'), (100.634, 'f'), (101.527, 'r'), (102.578, 'r'), (111.845, 'f'), (112.646, 'r'), (118.652, 'f'), (122.523, 'r'), (127.519, 'f'), (128.303, 'r'), (129.271, 'r'), (133.133, 'f'), (138.514, 'r'), (139.615, 'r'), (140.44, 'r'), (142.117, 'f'), (142.835, 'f'), (143.71, 'r'), (144.87, 'r'), (149.633, 'f'), (150.275, 'r'), (151.468, 'r'), (152.477, 'r'), (170.112, 'f'), (170.913, 'r'), (176.627, 'f'), (179.68, 'r'), (192.584, 's'), (197.097, 'r'), (198.165, 'f'), (198.774, 'f'), (199.675, 'r')]\n",
      "[14.364, 15.157, 32.533, 41.875, 42.543, 54.663, 55.272, 56.448, 57.14, 58.141, 62.813, 63.964, 78.795, 81.999, 82.916, 94.595, 100.634, 101.527, 112.646, 122.523, 128.303, 138.514, 142.835, 143.71, 150.275, 170.913, 179.68, 198.774, 199.675]\n",
      "[52.327, 53.27, 62.179, 64.615, 70.596, 72.014, 77.085, 80.013, 81.331, 84.343, 87.704, 96.813, 98.874, 99.183, 102.578, 111.845, 118.652, 127.519, 129.271, 133.133, 139.615, 140.44, 142.117, 144.87, 149.633, 151.468, 152.477, 170.112, 176.627, 192.584, 198.165]\n",
      "[50.859, 93.36, 197.097]\n",
      "[14.364, 15.157, 32.533, 41.875, 42.543, 50.859, 52.327, 53.27, 54.663, 55.272, 56.448, 57.14, 58.141, 62.179, 62.813, 63.964, 64.615, 70.596, 72.014, 77.085, 78.795, 80.013, 81.331, 81.999, 82.916, 84.343, 87.704, 93.36, 94.595, 96.813, 98.874, 99.183, 100.634, 101.527, 102.578, 111.845, 112.646, 118.652, 122.523, 127.519, 128.303, 129.271, 133.133, 138.514, 139.615, 140.44, 142.117, 142.835, 143.71, 144.87, 149.633, 150.275, 151.468, 152.477, 170.112, 170.913, 176.627, 179.68, 192.584, 197.097, 198.165, 198.774, 199.675]\n",
      "63\n"
     ]
    }
   ],
   "source": [
    "test_df2 = pd.read_hdf(r\"C:\\Users\\vjj14\\Desktop\\DeepLabCut\\gopro3lens-vj-2019-07-08\\videos\\2019.07.08_CC42970_N2_V2_2.7k_120FPS_copyDeepCut_resnet50_gopro3lensJul8shuffle1_120001.h5\")\n",
    "test_df2.columns = test_df2.columns.droplevel()\n",
    "starts = get_classified_starts(attempt_classifier, test_df2)\n",
    "print(starts)\n",
    "print(len(starts))\n",
    "print([(x[0], x[2][-1]) for x in starts])\n",
    "predicted_fails = [x[0] for x in starts if 'f' in x[1]]\n",
    "predicted_reaches = [x[0] for x in starts if 'r' in x[1]]\n",
    "predicted_successes = [x[0] for x in starts if 's' in x[1]]\n",
    "print(predicted_fails)\n",
    "print(predicted_reaches)\n",
    "print(predicted_successes)\n",
    "x = sorted(predicted_fails + predicted_reaches + predicted_successes)\n",
    "print(x)\n",
    "print(len(x))\n",
    "import numpy as np\n",
    "np.savetxt(\"file_name.csv\", x, delimiter=\",\", fmt='%s', header='times')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm, tree\n",
    "import xgboost\n",
    "def create_classifierXGB(features, labels, n_trees, test_proportion=0.25):\n",
    "    train_feats, test_feats, train_labs, test_labs = train_test_split(features, labels, test_size = test_proportion, random_state = seed)\n",
    "    print('Training Features Shape:', train_feats.shape)\n",
    "    print('Training Labels Shape:', train_labs.shape)\n",
    "    print('Testing Features Shape:', test_feats.shape)\n",
    "    print('Testing Labels Shape:', test_labs.shape)\n",
    "    rf = xgboost.XGBClassifier()\n",
    "    # Train the model on training data\n",
    "    print(train_feats.shape)\n",
    "    print(train_labs.shape)\n",
    "    rf.fit(train_feats, train_labs)\n",
    "    # Use the forest's predict method on the test data\n",
    "    predictions = rf.predict(test_feats)\n",
    "    print(predictions)\n",
    "    print(test_labs)\n",
    "    wrong_labels = []\n",
    "#     for i in range(len(predictions)):\n",
    "#         if predictions[i] != test_labs[i]:\n",
    "#             frame = -1\n",
    "#             for key in frame_to_features.keys():\n",
    "#                 if (frame_to_features[key] == test_feats[i]).all():\n",
    "#                     frame = key\n",
    "#                     break\n",
    "#             wrong_labels.append((frame_to_time(frame), predictions[i], test_labs[i]))\n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] != test_labs[i]:\n",
    "            frame = -1\n",
    "            wrong_labels.append((predictions[i], test_labs[i]))\n",
    "    print('Wrong Labels', wrong_labels)\n",
    "    return rf, wrong_labels\n",
    "def create_classifierSVC(features, labels, n_trees, test_proportion=0.25):\n",
    "    train_feats, test_feats, train_labs, test_labs = train_test_split(features, labels, test_size = test_proportion, random_state = seed)\n",
    "    print('Training Features Shape:', train_feats.shape)\n",
    "    print('Training Labels Shape:', train_labs.shape)\n",
    "    print('Testing Features Shape:', test_feats.shape)\n",
    "    print('Testing Labels Shape:', test_labs.shape)\n",
    "    rf = svm.SVC()\n",
    "    # Train the model on training data\n",
    "    print(train_feats.shape)\n",
    "    print(train_labs.shape)\n",
    "    rf.fit(train_feats, train_labs)\n",
    "    # Use the forest's predict method on the test data\n",
    "    predictions = rf.predict(test_feats)\n",
    "    print(predictions)\n",
    "    print(test_labs)\n",
    "    wrong_labels = []\n",
    "#     for i in range(len(predictions)):\n",
    "#         if predictions[i] != test_labs[i]:\n",
    "#             frame = -1\n",
    "#             for key in frame_to_features.keys():\n",
    "#                 if (frame_to_features[key] == test_feats[i]).all():\n",
    "#                     frame = key\n",
    "#                     break\n",
    "#             wrong_labels.append((frame_to_time(frame), predictions[i], test_labs[i]))\n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] != test_labs[i]:\n",
    "            frame = -1\n",
    "            wrong_labels.append((predictions[i], test_labs[i]))\n",
    "    print('Wrong Labels', wrong_labels)\n",
    "    return rf, wrong_labels\n",
    "def create_classifier_tree(features, labels, n_trees, test_proportion=0.25):\n",
    "    train_feats, test_feats, train_labs, test_labs = train_test_split(features, labels, test_size = test_proportion, random_state = seed)\n",
    "    print('Training Features Shape:', train_feats.shape)\n",
    "    print('Training Labels Shape:', train_labs.shape)\n",
    "    print('Testing Features Shape:', test_feats.shape)\n",
    "    print('Testing Labels Shape:', test_labs.shape)\n",
    "    rf = tree.DecisionTreeClassifier()\n",
    "    # Train the model on training data\n",
    "    print(train_feats.shape)\n",
    "    print(train_labs.shape)\n",
    "    rf.fit(train_feats, train_labs)\n",
    "    # Use the forest's predict method on the test data\n",
    "    predictions = rf.predict(test_feats)\n",
    "    print(predictions)\n",
    "    print(test_labs)\n",
    "    wrong_labels = []\n",
    "#     for i in range(len(predictions)):\n",
    "#         if predictions[i] != test_labs[i]:\n",
    "#             frame = -1\n",
    "#             for key in frame_to_features.keys():\n",
    "#                 if (frame_to_features[key] == test_feats[i]).all():\n",
    "#                     frame = key\n",
    "#                     break\n",
    "#             wrong_labels.append((frame_to_time(frame), predictions[i], test_labs[i]))\n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] != test_labs[i]:\n",
    "            frame = -1\n",
    "            wrong_labels.append((predictions[i], test_labs[i]))\n",
    "    print('Wrong Labels', wrong_labels)\n",
    "    return rf, wrong_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features Shape: (162, 1728)\n",
      "Training Labels Shape: (162,)\n",
      "Testing Features Shape: (54, 1728)\n",
      "Testing Labels Shape: (54,)\n",
      "(162, 1728)\n",
      "(162,)\n",
      "['f' 's' 's' 'r' 'r' 'n' 'f' 'n' 's' 'r' 'n' 'f' 'r' 'f' 'n' 'n' 'r' 's'\n",
      " 'n' 'r' 'n' 's' 'r' 'f' 'r' 'r' 'n' 'r' 's' 'r' 's' 'f' 'f' 'n' 's' 'n'\n",
      " 'n' 'f' 'r' 'n' 'f' 'r' 's' 'n' 'f' 'f' 'n' 'n' 'n' 'n' 'r' 'r' 'n' 's']\n",
      "['f' 's' 's' 'r' 'r' 'n' 'f' 'n' 's' 'r' 'n' 'n' 'r' 'f' 'n' 'n' 'r' 's'\n",
      " 'n' 'r' 'n' 's' 'n' 'f' 'r' 'r' 'n' 'r' 's' 'r' 's' 'f' 'f' 'f' 's' 'n'\n",
      " 'n' 'f' 'r' 'n' 'f' 'r' 's' 'n' 'r' 'f' 'n' 'n' 'n' 'n' 'f' 'r' 'f' 's']\n",
      "Wrong Labels [('f', 'n'), ('r', 'n'), ('n', 'f'), ('f', 'r'), ('r', 'f'), ('n', 'f')]\n"
     ]
    }
   ],
   "source": [
    "forest_classifier = create_classifier(compiled_features, compiled_labels, 1000, test_proportion=0.25)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features Shape: (162, 1728)\n",
      "Training Labels Shape: (162,)\n",
      "Testing Features Shape: (54, 1728)\n",
      "Testing Labels Shape: (54,)\n",
      "(162, 1728)\n",
      "(162,)\n",
      "['f' 'f' 's' 'r' 'r' 'n' 'f' 'n' 's' 'r' 'n' 'n' 'r' 'f' 'n' 'n' 'r' 'f'\n",
      " 'f' 'r' 'n' 'f' 'r' 'f' 'r' 'r' 'n' 'r' 's' 'r' 's' 'f' 'f' 'n' 's' 'n'\n",
      " 'n' 'f' 'r' 'n' 'f' 'r' 's' 'n' 'f' 's' 'n' 'n' 'n' 'n' 'r' 'r' 'n' 's']\n",
      "['f' 's' 's' 'r' 'r' 'n' 'f' 'n' 's' 'r' 'n' 'n' 'r' 'f' 'n' 'n' 'r' 's'\n",
      " 'n' 'r' 'n' 's' 'n' 'f' 'r' 'r' 'n' 'r' 's' 'r' 's' 'f' 'f' 'f' 's' 'n'\n",
      " 'n' 'f' 'r' 'n' 'f' 'r' 's' 'n' 'r' 'f' 'n' 'n' 'n' 'n' 'f' 'r' 'f' 's']\n",
      "Wrong Labels [('f', 's'), ('f', 's'), ('f', 'n'), ('f', 's'), ('r', 'n'), ('n', 'f'), ('f', 'r'), ('s', 'f'), ('r', 'f'), ('n', 'f')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vjj14\\.conda\\envs\\dlc-windowsGPU\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "XGB_classifier = create_classifierXGB(compiled_features, compiled_labels, 1000, test_proportion=0.25)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features Shape: (162, 1728)\n",
      "Training Labels Shape: (162,)\n",
      "Testing Features Shape: (54, 1728)\n",
      "Testing Labels Shape: (54,)\n",
      "(162, 1728)\n",
      "(162,)\n",
      "['n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n'\n",
      " 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n'\n",
      " 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n' 'n']\n",
      "['f' 's' 's' 'r' 'r' 'n' 'f' 'n' 's' 'r' 'n' 'n' 'r' 'f' 'n' 'n' 'r' 's'\n",
      " 'n' 'r' 'n' 's' 'n' 'f' 'r' 'r' 'n' 'r' 's' 'r' 's' 'f' 'f' 'f' 's' 'n'\n",
      " 'n' 'f' 'r' 'n' 'f' 'r' 's' 'n' 'r' 'f' 'n' 'n' 'n' 'n' 'f' 'r' 'f' 's']\n",
      "Wrong Labels [('n', 'f'), ('n', 's'), ('n', 's'), ('n', 'r'), ('n', 'r'), ('n', 'f'), ('n', 's'), ('n', 'r'), ('n', 'r'), ('n', 'f'), ('n', 'r'), ('n', 's'), ('n', 'r'), ('n', 's'), ('n', 'f'), ('n', 'r'), ('n', 'r'), ('n', 'r'), ('n', 's'), ('n', 'r'), ('n', 's'), ('n', 'f'), ('n', 'f'), ('n', 'f'), ('n', 's'), ('n', 'f'), ('n', 'r'), ('n', 'f'), ('n', 'r'), ('n', 's'), ('n', 'r'), ('n', 'f'), ('n', 'f'), ('n', 'r'), ('n', 'f'), ('n', 's')]\n"
     ]
    }
   ],
   "source": [
    "SVC_classifier = create_classifierSVC(compiled_features, compiled_labels, 1000, test_proportion=0.25)[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
