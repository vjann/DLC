{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RK255E7YoEIt"
   },
   "source": [
    "# PROJECT NAME\n",
    "https://github.com/vjann/DLC\n",
    "\n",
    "### Description:\n",
    "INSERT DESCRIPTION HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Uoz9mdPoEIy"
   },
   "source": [
    "## Create a new project\n",
    "\n",
    "Keep the projects separate. This function creates a new project with subdirectories and a basic configuration file under DeepLabCut directory.\n",
    "You can add new videos to the project at any stage of the project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jqLZhp7EoEI0"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import deeplabcut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c9DjG55FoEI7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created \"C:\\Users\\vjj14\\Desktop\\DeepLabCut\\frontslowmo-vj-2019-06-06\\videos\"\n",
      "Created \"C:\\Users\\vjj14\\Desktop\\DeepLabCut\\frontslowmo-vj-2019-06-06\\labeled-data\"\n",
      "Created \"C:\\Users\\vjj14\\Desktop\\DeepLabCut\\frontslowmo-vj-2019-06-06\\training-datasets\"\n",
      "Created \"C:\\Users\\vjj14\\Desktop\\DeepLabCut\\frontslowmo-vj-2019-06-06\\dlc-models\"\n",
      "Copying the videos\n",
      "C:\\Users\\vjj14\\Desktop\\DeepLabCut\\frontslowmo-vj-2019-06-06\\videos\\1080p.MOV\n",
      "Generated \"C:\\Users\\vjj14\\Desktop\\DeepLabCut\\frontslowmo-vj-2019-06-06\\config.yaml\"\n",
      "\n",
      "A new project with name frontslowmo-vj-2019-06-06 is created at C:\\Users\\vjj14\\Desktop\\DeepLabCut and a configurable file (config.yaml) is stored there. Change the parameters in this file to adapt to your project's needs.\n",
      " Once you have changed the configuration file, use the function 'extract_frames' to select frames for labeling.\n",
      ". [OPTIONAL] Use the function 'add_new_videos' to add new videos to your project (at any stage).\n"
     ]
    }
   ],
   "source": [
    "task='TEMPLATE_NAME' # Enter the name of your experiment Task\n",
    "experimenter='LABELER' # Enter the name of the experimenter\n",
    "video=[r\"VIDEOFILEPATH\"] # Enter the paths of your videos you want to grab frames from.\n",
    "path_config_file=deeplabcut.create_new_project(task,experimenter,video, working_directory= r'C:\\Users\\vjj14\\Desktop\\DeepLabCut',copy_videos=True) #change the working directory to where you want the folders created.\n",
    "# The function returns the path, where your project is. \n",
    "time_log= open(\"{0}log{1}.txt\".format(path_config_file[:-11], project_name),\"a+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_config_file='C:\\\\Users\\\\vjj14\\\\Desktop\\\\DeepLabCut\\\\frontslowmo-vj-2019-06-05\\\\config.yaml'\n",
    "project_name=task\n",
    "def write_log(text, new_line=True):\n",
    "    time_log= open(\"{0}log{1}.txt\".format(path_config_file[:-11], project_name),\"a+\")\n",
    "    if new_line:\n",
    "        time_log.write(\"\\n\")\n",
    "    time_log.write(text)\n",
    "    time_log.close()\n",
    "    print(\"log written\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "def prompt_with_timeout(prompt_message):\n",
    "  print('Waiting... please press Ctrl-C when you wish to proceed.')\n",
    "  try:\n",
    "    for i in range(0, 2*60): # 2 minutes\n",
    "      sleep(1)\n",
    "    return \"No Input Received\"\n",
    "  except KeyboardInterrupt:\n",
    "    return input(prompt_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0yXW0bx1oEJA"
   },
   "source": [
    "## Extract frames from videos \n",
    "Select diverse frames, which are typical for the behavior you study that should be labeled.\n",
    "(algo=='uniform') selects N frames either uniformly sampled from a particular video (or folder) . Note: this might not yield diverse frames, if the behavior is sparsely distributed (consider using kmeans), and/or select frames manually etc.\n",
    "Individual images should not be too big (i.e. < 850 x 850 pixel). Although this can be taken care of later, crop the frames to remove unnecessary parts.\n",
    "Always check the output of cropping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t1ulumCuoEJC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config file read successfully.\n",
      "Do you want to extract (perhaps additional) frames for video: C:\\Users\\vjj14\\Desktop\\DeepLabCut\\frontslowmo-vj-2019-06-05\\videos\\1080p.MOV ?\n",
      "yes/nono\n",
      "\n",
      "Frames were selected.\n",
      "You can now label the frames using the function 'label_frames' (if you extracted enough frames for all videos).\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "write_log(str(start) + \"***extract_frames start\")\n",
    "\n",
    "%matplotlib inline\n",
    "deeplabcut.extract_frames(path_config_file,'automatic','uniform',crop=False) #there are other ways to grab frames, such as by clustering 'kmeans'; please see the paper. \n",
    "\n",
    "end = datetime.datetime.now()\n",
    "write_log(str(end) + \"***extract_frames end\")\n",
    "write_log(\"   time elapsed:\" + str(end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Gjn6ZDonoEJH"
   },
   "source": [
    "## Label the extracted frames\n",
    "Only videos in the config file can be used to extract the frames. Extracted labels for each video are stored in the project directory under the subdirectory **'labeled-data'**. Each subdirectory is named after the name of the video. The toolbox has a labeling toolbox which could be used for labeling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iyROSOiEoEJI"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Cannot activate multiple GUI eventloops\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Cannot load backend 'TkAgg' which requires the 'tk' interactive framework, as 'wx' is currently running",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-6005a6684cbf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'gui wx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdeeplabcut\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_config_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\vjj14\\.conda\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\generate_training_dataset\\trainingsetmanipulation.py\u001b[0m in \u001b[0;36mlabel_frames\u001b[1;34m(config)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[1;31m# labeling_toolbox.show(config,Screens,scale_w,scale_h, winHack, img_scale)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m     \u001b[0mlabeling_toolbox\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    215\u001b[0m     \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstartpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\vjj14\\.conda\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\generate_training_dataset\\labeling_toolbox.py\u001b[0m in \u001b[0;36mshow\u001b[1;34m(config)\u001b[0m\n\u001b[0;32m    648\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    649\u001b[0m     \u001b[0mapp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mApp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 650\u001b[1;33m     \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMainFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mShow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    651\u001b[0m     \u001b[0mapp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMainLoop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    652\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\vjj14\\.conda\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\generate_training_dataset\\labeling_toolbox.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, parent, config)\u001b[0m\n\u001b[0;32m    148\u001b[0m         \u001b[0mvSplitter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSplitterWindow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtopSplitter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_panel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImagePanel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvSplitter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgui_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice_panel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mScrollPanel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvSplitter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[0mvSplitter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSplitVertically\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_panel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice_panel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msashPosition\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgui_size\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\vjj14\\.conda\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\generate_training_dataset\\labeling_toolbox.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, parent, config, gui_size, **kwargs)\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFigureCanvas\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morig_xlim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morig_ylim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\vjj14\\.conda\\envs\\dlc-windowsGPU\\lib\\site-packages\\matplotlib\\backends\\backend_wx.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, parent, id, figure)\u001b[0m\n\u001b[0;32m    589\u001b[0m         \"\"\"\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m         \u001b[0mFigureCanvasBase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    592\u001b[0m         \u001b[1;31m# Set preferred window size hint - helps the sizer (if one is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m         \u001b[1;31m# connected)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\vjj14\\.conda\\envs\\dlc-windowsGPU\\lib\\site-packages\\matplotlib\\backend_bases.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, figure)\u001b[0m\n\u001b[0;32m   1580\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1581\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfigure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1582\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fix_ipython_backend2gui\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1583\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_idle_drawing\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1584\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_saving\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\vjj14\\.conda\\envs\\dlc-windowsGPU\\lib\\site-packages\\matplotlib\\backend_bases.py\u001b[0m in \u001b[0;36m_fix_ipython_backend2gui\u001b[1;34m(cls)\u001b[0m\n\u001b[0;32m   1627\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1628\u001b[0m                 \u001b[0mmpl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrcParamsOrig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"backend\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmpl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"backend\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1629\u001b[1;33m                 \u001b[0mip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_matplotlib\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1630\u001b[0m             \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1631\u001b[0m                 \u001b[0mmpl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrcParamsOrig\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"backend\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0morig_origbackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\vjj14\\.conda\\envs\\dlc-windowsGPU\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36menable_matplotlib\u001b[1;34m(self, gui)\u001b[0m\n\u001b[0;32m   2913\u001b[0m                 \u001b[0mgui\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_gui_and_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpylab_gui_select\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2914\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2915\u001b[1;33m         \u001b[0mpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivate_matplotlib\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbackend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2916\u001b[0m         \u001b[0mpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfigure_inline_support\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2917\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\vjj14\\.conda\\envs\\dlc-windowsGPU\\lib\\site-packages\\IPython\\core\\pylabtools.py\u001b[0m in \u001b[0;36mactivate_matplotlib\u001b[1;34m(backend)\u001b[0m\n\u001b[0;32m    307\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 309\u001b[1;33m     \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mswitch_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbackend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    310\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m     \u001b[1;31m# This must be imported last in the matplotlib series, after\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\vjj14\\.conda\\envs\\dlc-windowsGPU\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mswitch_backend\u001b[1;34m(newbackend)\u001b[0m\n\u001b[0;32m    228\u001b[0m                 \u001b[1;34m\"Cannot load backend {!r} which requires the {!r} interactive \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m                 \"framework, as {!r} is currently running\".format(\n\u001b[1;32m--> 230\u001b[1;33m                     newbackend, required_framework, current_framework))\n\u001b[0m\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m     \u001b[0mrcParams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'backend'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrcParamsDefault\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'backend'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnewbackend\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: Cannot load backend 'TkAgg' which requires the 'tk' interactive framework, as 'wx' is currently running"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "write_log(str(start) + \"***label_frames start\")\n",
    "\n",
    "%gui wx\n",
    "deeplabcut.label_frames(path_config_file)\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "write_log(str(end) + \"***label_frames end\")\n",
    "write_log(\"   time elapsed:\" + str(end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vim95ZvkPSeN"
   },
   "source": [
    "**Check the labels**\n",
    "\n",
    "Checking if the labels were created and stored correctly is beneficial for training, since labeling is one of the most critical parts for creating the training dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NwvgPJouPP2O"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating images with labels by vj.\n",
      "C:\\Users\\vjj14\\Desktop\\DeepLabCut\\frontslowmo-vj-2019-06-05\\labeled-data\\1080p_labeled  already exists!\n",
      "They are stored in the following folder: C:\\Users\\vjj14\\Desktop\\DeepLabCut\\frontslowmo-vj-2019-06-05\\labeled-data\\1080p_labeled.\n",
      "Attention: C:\\Users\\vjj14\\Desktop\\DeepLabCut\\frontslowmo-vj-2019-06-05\\labeled-data\\1080p does not appear to have labeled data!\n",
      "If all the labels are ok, then use the function 'create_training_dataset' to create the training dataset!\n"
     ]
    }
   ],
   "source": [
    "deeplabcut.check_labels(path_config_file) #this creates a subdirectory with the frames + your labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "of87fOjgPqzH"
   },
   "source": [
    "If the labels need adjusted, you can use the refinement GUI to move them around! Check that out below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xNi9s1dboEJN"
   },
   "source": [
    "## Create a training dataset\n",
    "This function generates the training data information for DeepCut (which requires a mat file) based on the pandas dataframes that hold label information. The user can set the fraction of the training set size (from all labeled image in the hd5 file) in the config.yaml file. While creating the dataset, the user can create multiple shuffles. \n",
    "\n",
    "After running this script the training dataset is created and saved in the project directory under the subdirectory **'training-datasets'**\n",
    "\n",
    "This function also creates new subdirectories under **dlc-models** and appends the project config.yaml file with the correct path to the training and testing pose configuration file. These files hold the parameters for training the network. Such an example file is provided with the toolbox and named as **pose_cfg.yaml**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eMeUwgxPoEJP",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vjj14\\Desktop\\DeepLabCut\\frontslowmo-vj-2019-06-05\\training-datasets\\iteration-0\\UnaugmentedDataSet_frontslowmoJun5  already exists!\n",
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "write_log(str(start) + \"***create_training_dataset start\")\n",
    "\n",
    "deeplabcut.create_training_dataset(path_config_file)\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "write_log(str(end) + \"***create_training_dataset end\")\n",
    "write_log(\"   time elapsed:\" + str(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "?deeplabcut.create_training_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c4FczXGDoEJU"
   },
   "source": [
    "## Start training - If you want to use a CPU, continue. \n",
    "### If you want to use your GPU, you need to exit here and either work from the Docker container, your own TensorFlow installation in an Anaconda env\n",
    "\n",
    "This function trains the network for a specific shuffle of the training dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_pOvDq_2oEJW",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log written\n",
      "Waiting... please press Ctrl-C when you wish to proceed.\n",
      "Training description(Network, Iterations, etc) first network, lots of iterations, maybe training includes clock time\n",
      "log written\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3]],\n",
      " 'all_joints_names': ['LeftHand', 'RightHand', 'Nose', 'Pellet'],\n",
      " 'batch_size': 1,\n",
      " 'bottomheight': 400,\n",
      " 'crop': True,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets\\\\iteration-1\\\\UnaugmentedDataSet_frontslowmoJun5\\\\frontslowmo_vj95shuffle1.mat',\n",
      " 'dataset_type': 'default',\n",
      " 'display_iters': 1000,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'C:\\\\Users\\\\vjj14\\\\Desktop\\\\DeepLabCut\\\\frontslowmo-vj-2019-06-05\\\\dlc-models\\\\iteration-1\\\\frontslowmoJun5-trainset95shuffle1\\\\train\\\\snapshot-30000',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'leftwidth': 400,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets\\\\iteration-1\\\\UnaugmentedDataSet_frontslowmoJun5\\\\Documentation_data-frontslowmo_95shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'minsize': 100,\n",
      " 'mirror': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 4,\n",
      " 'optimizer': 'sgd',\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': 'C:\\\\Users\\\\vjj14\\\\Desktop\\\\DeepLabCut\\\\frontslowmo-vj-2019-06-05',\n",
      " 'regularize': False,\n",
      " 'rightwidth': 400,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'C:\\\\Users\\\\vjj14\\\\Desktop\\\\DeepLabCut\\\\frontslowmo-vj-2019-06-05\\\\dlc-models\\\\iteration-1\\\\frontslowmoJun5-trainset95shuffle1\\\\train\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'topheight': 400,\n",
      " 'use_gt_segm': False,\n",
      " 'video': False,\n",
      " 'video_batch': False,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\vjj14\\Desktop\\DeepLabCut\\frontslowmo-vj-2019-06-05\\dlc-models\\iteration-1\\frontslowmoJun5-trainset95shuffle1\\train\\snapshot-30000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\vjj14\\Desktop\\DeepLabCut\\frontslowmo-vj-2019-06-05\\dlc-models\\iteration-1\\frontslowmoJun5-trainset95shuffle1\\train\\snapshot-30000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max_iters overwritten as 300001\n",
      "Display_iters overwritten as 100\n",
      "Save_iters overwritten as 1000\n",
      "Training parameter:\n",
      "{'stride': 8.0, 'weigh_part_predictions': False, 'weigh_negatives': False, 'fg_fraction': 0.25, 'weigh_only_present_joints': False, 'mean_pixel': [123.68, 116.779, 103.939], 'shuffle': True, 'snapshot_prefix': 'C:\\\\Users\\\\vjj14\\\\Desktop\\\\DeepLabCut\\\\frontslowmo-vj-2019-06-05\\\\dlc-models\\\\iteration-1\\\\frontslowmoJun5-trainset95shuffle1\\\\train\\\\snapshot', 'log_dir': 'log', 'global_scale': 0.8, 'location_refinement': True, 'locref_stdev': 7.2801, 'locref_loss_weight': 0.05, 'locref_huber_loss': True, 'optimizer': 'sgd', 'intermediate_supervision': False, 'intermediate_supervision_layer': 12, 'regularize': False, 'weight_decay': 0.0001, 'mirror': False, 'crop_pad': 0, 'scoremap_dir': 'test', 'dataset_type': 'default', 'use_gt_segm': False, 'batch_size': 1, 'video': False, 'video_batch': False, 'crop': True, 'cropratio': 0.4, 'minsize': 100, 'leftwidth': 400, 'rightwidth': 400, 'topheight': 400, 'bottomheight': 400, 'all_joints': [[0], [1], [2], [3]], 'all_joints_names': ['LeftHand', 'RightHand', 'Nose', 'Pellet'], 'dataset': 'training-datasets\\\\iteration-1\\\\UnaugmentedDataSet_frontslowmoJun5\\\\frontslowmo_vj95shuffle1.mat', 'init_weights': 'C:\\\\Users\\\\vjj14\\\\Desktop\\\\DeepLabCut\\\\frontslowmo-vj-2019-06-05\\\\dlc-models\\\\iteration-1\\\\frontslowmoJun5-trainset95shuffle1\\\\train\\\\snapshot-30000', 'net_type': 'resnet_50', 'num_joints': 4, 'display_iters': 1000, 'max_input_size': 1500, 'metadataset': 'training-datasets\\\\iteration-1\\\\UnaugmentedDataSet_frontslowmoJun5\\\\Documentation_data-frontslowmo_95shuffle1.pickle', 'min_input_size': 64, 'multi_step': [[0.005, 10000], [0.02, 430000], [0.002, 730000], [0.001, 1030000]], 'pos_dist_thresh': 17, 'project_path': 'C:\\\\Users\\\\vjj14\\\\Desktop\\\\DeepLabCut\\\\frontslowmo-vj-2019-06-05', 'save_iters': 50000, 'scale_jitter_lo': 0.5, 'scale_jitter_up': 1.25}\n",
      "Starting training....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 100 loss: 0.0356 lr: 0.005\n",
      "iteration: 200 loss: 0.0084 lr: 0.005\n",
      "iteration: 300 loss: 0.0059 lr: 0.005\n",
      "iteration: 400 loss: 0.0065 lr: 0.005\n",
      "iteration: 500 loss: 0.0055 lr: 0.005\n",
      "iteration: 600 loss: 0.0051 lr: 0.005\n",
      "iteration: 700 loss: 0.0045 lr: 0.005\n",
      "iteration: 800 loss: 0.0050 lr: 0.005\n",
      "iteration: 900 loss: 0.0046 lr: 0.005\n",
      "iteration: 1000 loss: 0.0036 lr: 0.005\n",
      "iteration: 1100 loss: 0.0045 lr: 0.005\n",
      "iteration: 1200 loss: 0.0035 lr: 0.005\n",
      "iteration: 1300 loss: 0.0044 lr: 0.005\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-c796e1806e5d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mwrite_log\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"   DESCRIPTION:\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mprompt_with_timeout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Training description(Network, Iterations, etc) \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdeeplabcut\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_config_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaveiters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdisplayiters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxiters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m300001\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\vjj14\\.conda\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\training.py\u001b[0m in \u001b[0;36mtrain_network\u001b[1;34m(config, shuffle, trainingsetindex, gputouse, max_snapshots_to_keep, autotune, displayiters, saveiters, maxiters)\u001b[0m\n\u001b[0;32m     87\u001b[0m           \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mposeconfigfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdisplayiters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msaveiters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmaxiters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_to_keep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_snapshots_to_keep\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#pass on path and file name for pose_cfg.yaml!\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 89\u001b[1;33m           \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m       \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m           \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\vjj14\\.conda\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\training.py\u001b[0m in \u001b[0;36mtrain_network\u001b[1;34m(config, shuffle, trainingsetindex, gputouse, max_snapshots_to_keep, autotune, displayiters, saveiters, maxiters)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m           \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mposeconfigfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdisplayiters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msaveiters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmaxiters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_to_keep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_snapshots_to_keep\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#pass on path and file name for pose_cfg.yaml!\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m           \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\vjj14\\.conda\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(config_yaml, displayiters, saveiters, maxiters, max_to_keep)\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[0mcurrent_lr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr_gen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_lr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m         [_, loss_val, summary] = sess.run([train_op, total_loss, merged_summaries],\n\u001b[1;32m--> 142\u001b[1;33m                                           feed_dict={learning_rate: current_lr})\n\u001b[0m\u001b[0;32m    143\u001b[0m         \u001b[0mcum_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss_val\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m         \u001b[0mtrain_writer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\vjj14\\.conda\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    927\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 929\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    930\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\vjj14\\.conda\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1150\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1152\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1153\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\vjj14\\.conda\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1326\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1328\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1329\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1330\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\vjj14\\.conda\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1332\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1333\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1334\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1335\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\vjj14\\.conda\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1319\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1320\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\vjj14\\.conda\\envs\\dlc-windowsGPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "write_log(str(start) + \"***train_network start\")\n",
    "write_log(\"   DESCRIPTION:\" + prompt_with_timeout(\"Training description(Network, Iterations, etc) \"))\n",
    "\n",
    "deeplabcut.train_network(path_config_file, saveiters=1000, displayiters=100, maxiters=300001)\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "write_log(str(end) + \"***train_network end\")\n",
    "write_log(\"   time elapsed:\" + str(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "?deeplabcut.train_network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xZygsb2DoEJc"
   },
   "source": [
    "## Start evaluating\n",
    "This funtion evaluates a trained model for a specific shuffle/shuffles at a particular state or all the states on the data set (images)\n",
    "and stores the results as .csv file in a subdirectory under **evaluation-results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nv4zlbrnoEJg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vjj14\\Desktop\\DeepLabCut\\frontslowmo-vj-2019-06-05/evaluation-results/  already exists!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3]],\n",
      " 'all_joints_names': ['LeftHand', 'RightHand', 'Nose', 'Pellet'],\n",
      " 'batch_size': 1,\n",
      " 'bottomheight': 400,\n",
      " 'crop': True,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets\\\\iteration-2\\\\UnaugmentedDataSet_frontslowmoJun5\\\\frontslowmo_vj95shuffle1.mat',\n",
      " 'dataset_type': 'default',\n",
      " 'display_iters': 1000,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'C:\\\\Users\\\\vjj14\\\\.conda\\\\envs\\\\dlc-windowsGPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'leftwidth': 400,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets\\\\iteration-2\\\\UnaugmentedDataSet_frontslowmoJun5\\\\Documentation_data-frontslowmo_95shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'minsize': 100,\n",
      " 'mirror': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 4,\n",
      " 'optimizer': 'sgd',\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': 'C:\\\\Users\\\\vjj14\\\\Desktop\\\\DeepLabCut\\\\frontslowmo-vj-2019-06-05',\n",
      " 'regularize': False,\n",
      " 'rightwidth': 400,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'C:\\\\Users\\\\vjj14\\\\Desktop\\\\DeepLabCut\\\\frontslowmo-vj-2019-06-05\\\\dlc-models\\\\iteration-2\\\\frontslowmoJun5-trainset95shuffle1\\\\test\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'topheight': 400,\n",
      " 'use_gt_segm': False,\n",
      " 'video': False,\n",
      " 'video_batch': False,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running  DeepCut_resnet50_frontslowmoJun5shuffle1_26000  with # of trainingiterations: 26000\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\vjj14\\Desktop\\DeepLabCut\\frontslowmo-vj-2019-06-05\\dlc-models\\iteration-2\\frontslowmoJun5-trainset95shuffle1\\train\\snapshot-26000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\vjj14\\Desktop\\DeepLabCut\\frontslowmo-vj-2019-06-05\\dlc-models\\iteration-2\\frontslowmoJun5-trainset95shuffle1\\train\\snapshot-26000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "253it [00:44,  5.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done and results stored for snapshot:  snapshot-26000\n",
      "Results for 26000  training iterations: 95 1 train error: 12.5 pixels. Test error: 32.18  pixels.\n",
      "With pcutoff of 0.1  train error: 12.5 pixels. Test error: 32.18 pixels\n",
      "Thereby, the errors are given by the average distances between the labels by DLC and the scorer.\n",
      "The network is evaluated and the results are stored in the subdirectory 'evaluation_results'.\n",
      "If it generalizes well, choose the best model for prediction and update the config file with the appropriate index for the 'snapshotindex'.\n",
      "Use the function 'analyze_video' to make predictions on new videos.\n",
      "Otherwise consider retraining the network (see DeepLabCut workflow Fig 2)\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "write_log(str(start) + \"***evaluate_network start\")\n",
    "\n",
    "deeplabcut.evaluate_network(path_config_file)\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "write_log(str(end) + \"***evalaute_network end\")\n",
    "write_log(\"   time elapsed:\" + str(end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OVFLSKKfoEJk"
   },
   "source": [
    "## Start Analyzing videos\n",
    "This function analyzes the new video. The user can choose the best model from the evaluation results and specify the correct snapshot index for the variable **snapshotindex** in the **config.yaml** file. Otherwise, by default the most recent snapshot is used to analyse the video.\n",
    "\n",
    "The results are stored in hd5 file in the same directory where the video resides. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y_LZiS_0oEJl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log written\n",
      "log written\n",
      "Using snapshot-28000 for model C:\\Users\\vjj14\\Desktop\\DeepLabCut\\frontslowmo-vj-2019-06-05\\dlc-models\\iteration-1\\frontslowmoJun5-trainset95shuffle1\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\vjj14\\Desktop\\DeepLabCut\\frontslowmo-vj-2019-06-05\\dlc-models\\iteration-1\\frontslowmoJun5-trainset95shuffle1\\train\\snapshot-28000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\vjj14\\Desktop\\DeepLabCut\\frontslowmo-vj-2019-06-05\\dlc-models\\iteration-1\\frontslowmoJun5-trainset95shuffle1\\train\\snapshot-28000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  C:\\Users\\vjj14\\Downloads\\frontslowmoCOMPRESSED\\compressed50.mp4\n",
      "Loading  C:\\Users\\vjj14\\Downloads\\frontslowmoCOMPRESSED\\compressed50.mp4\n",
      "Duration of video [s]:  518.7 , recorded with  30.0 fps!\n",
      "Overall # of frames:  15561  found with (before cropping) frame dimensions:  1920 1080\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15655it [21:36, 11.89it/s]                                                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  15561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\Users\\vjj14\\Downloads\\frontslowmoCOMPRESSED...\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'.\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract any outlier frames!\n",
      "log written\n",
      "log written\n",
      "log written\n",
      "log written\n",
      "Using snapshot-28000 for model C:\\Users\\vjj14\\Desktop\\DeepLabCut\\frontslowmo-vj-2019-06-05\\dlc-models\\iteration-1\\frontslowmoJun5-trainset95shuffle1\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\vjj14\\Desktop\\DeepLabCut\\frontslowmo-vj-2019-06-05\\dlc-models\\iteration-1\\frontslowmoJun5-trainset95shuffle1\\train\\snapshot-28000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\vjj14\\Desktop\\DeepLabCut\\frontslowmo-vj-2019-06-05\\dlc-models\\iteration-1\\frontslowmoJun5-trainset95shuffle1\\train\\snapshot-28000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  C:\\Users\\vjj14\\Downloads\\frontslowmoCOMPRESSED\\compressed30.mp4\n",
      "Loading  C:\\Users\\vjj14\\Downloads\\frontslowmoCOMPRESSED\\compressed30.mp4\n",
      "Duration of video [s]:  518.7 , recorded with  30.0 fps!\n",
      "Overall # of frames:  15561  found with (before cropping) frame dimensions:  1920 1080\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15655it [20:52, 12.26it/s]                                                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  15561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\Users\\vjj14\\Downloads\\frontslowmoCOMPRESSED...\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'.\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract any outlier frames!\n",
      "log written\n",
      "log written\n",
      "log written\n",
      "log written\n",
      "Using snapshot-28000 for model C:\\Users\\vjj14\\Desktop\\DeepLabCut\\frontslowmo-vj-2019-06-05\\dlc-models\\iteration-1\\frontslowmoJun5-trainset95shuffle1\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\vjj14\\Desktop\\DeepLabCut\\frontslowmo-vj-2019-06-05\\dlc-models\\iteration-1\\frontslowmoJun5-trainset95shuffle1\\train\\snapshot-28000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\vjj14\\Desktop\\DeepLabCut\\frontslowmo-vj-2019-06-05\\dlc-models\\iteration-1\\frontslowmoJun5-trainset95shuffle1\\train\\snapshot-28000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  C:\\Users\\vjj14\\Downloads\\frontslowmoCOMPRESSED\\compressed27.mp4\n",
      "Loading  C:\\Users\\vjj14\\Downloads\\frontslowmoCOMPRESSED\\compressed27.mp4\n",
      "Duration of video [s]:  518.7 , recorded with  30.0 fps!\n",
      "Overall # of frames:  15561  found with (before cropping) frame dimensions:  1920 1080\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15655it [21:29, 11.96it/s]                                                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  15561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\Users\\vjj14\\Downloads\\frontslowmoCOMPRESSED...\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'.\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract any outlier frames!\n",
      "log written\n",
      "log written\n",
      "log written\n",
      "log written\n",
      "Using snapshot-28000 for model C:\\Users\\vjj14\\Desktop\\DeepLabCut\\frontslowmo-vj-2019-06-05\\dlc-models\\iteration-1\\frontslowmoJun5-trainset95shuffle1\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\vjj14\\Desktop\\DeepLabCut\\frontslowmo-vj-2019-06-05\\dlc-models\\iteration-1\\frontslowmoJun5-trainset95shuffle1\\train\\snapshot-28000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\vjj14\\Desktop\\DeepLabCut\\frontslowmo-vj-2019-06-05\\dlc-models\\iteration-1\\frontslowmoJun5-trainset95shuffle1\\train\\snapshot-28000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  C:\\Users\\vjj14\\Downloads\\frontslowmoCOMPRESSED\\compressed25.mp4\n",
      "Video already analyzed! C:\\Users\\vjj14\\Downloads\\frontslowmoCOMPRESSED\\compressed25DeepCut_resnet50_frontslowmoJun5shuffle1_28000.h5\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'.\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract any outlier frames!\n",
      "log written\n",
      "log written\n",
      "log written\n",
      "log written\n",
      "Using snapshot-28000 for model C:\\Users\\vjj14\\Desktop\\DeepLabCut\\frontslowmo-vj-2019-06-05\\dlc-models\\iteration-1\\frontslowmoJun5-trainset95shuffle1\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\vjj14\\Desktop\\DeepLabCut\\frontslowmo-vj-2019-06-05\\dlc-models\\iteration-1\\frontslowmoJun5-trainset95shuffle1\\train\\snapshot-28000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\vjj14\\Desktop\\DeepLabCut\\frontslowmo-vj-2019-06-05\\dlc-models\\iteration-1\\frontslowmoJun5-trainset95shuffle1\\train\\snapshot-28000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  C:\\Users\\vjj14\\Downloads\\frontslowmoCOMPRESSED\\compressed20.mp4\n",
      "Loading  C:\\Users\\vjj14\\Downloads\\frontslowmoCOMPRESSED\\compressed20.mp4\n",
      "Duration of video [s]:  518.7 , recorded with  30.0 fps!\n",
      "Overall # of frames:  15561  found with (before cropping) frame dimensions:  1920 1080\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15655it [20:58, 12.41it/s]                                                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  15561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in C:\\Users\\vjj14\\Downloads\\frontslowmoCOMPRESSED...\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'.\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract any outlier frames!\n",
      "log written\n",
      "log written\n"
     ]
    }
   ],
   "source": [
    "# videofile_path = [r\"C:\\Users\\vjj14\\Downloads\\compressed25.mp4\"] #Enter the list of videos to analyze.\n",
    "videos=[LIST OF VIDEOS]\n",
    "for videofile_path in videos:\n",
    "    start = datetime.datetime.now()\n",
    "    write_log(str(start) + \"***analyze_videos start\")\n",
    "    write_log(\"   VIDEO: \" + str(videofile_path))\n",
    "\n",
    "    deeplabcut.analyze_videos(path_config_file,videofile_path)\n",
    "\n",
    "    end = datetime.datetime.now()\n",
    "    write_log(str(end) + \"***analyze_videos end\")\n",
    "    write_log(\"   time elapsed:\" + str(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|                                                                | 2480/15561 [03:30<17:57, 12.14it/s]"
     ]
    }
   ],
   "source": [
    "?deeplabcut.analyze_videos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iGu_PdTWoEJr"
   },
   "source": [
    "## Extract outlier frames [optional step]\n",
    "This is an optional step and is used only when the evaluation results are poor i.e. the labels are incorrectly predicted. In such a case, the user can use the following function to extract frames where the labels are incorrectly predicted. Make sure to provide the correct value of the \"iterations\" as it will be used to create the unique directory where the extracted frames will be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gkbaBOJVoEJs"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "network parameters: DeepCut_resnet50_frontslowmoJun5shuffle1_28000\n",
      "Method  uncertain  found  12  putative outlier frames.\n",
      "Do you want to proceed with extracting  200  of those?\n",
      "If this list is very large, perhaps consider changing the paramters (start, stop, p_bound, comparisonbodyparts) or use a different method.\n",
      "yes/noyes\n",
      "Frames from video 1080p  already extracted (more will be added)!\n",
      "Loading video...\n",
      "Duration of video [s]:  518.6666666666666 , recorded @  30.0 fps!\n",
      "Overall # of frames:  15560 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 518.7  seconds.\n",
      "Let's select frames indices: [113, 154, 155, 156, 157, 158, 160, 161, 162, 13116, 13117, 13126]\n",
      "New video was added to the project! Use the function 'extract_frames' to select frames for labeling.\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\1080p.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n"
     ]
    }
   ],
   "source": [
    "alg = 'uncertain'\n",
    "param = 0.0002 #epsilon or p_bound\n",
    "\n",
    "start = datetime.datetime.now()\n",
    "write_log(str(start) + \"***extract_outlier_frames start\")\n",
    "\n",
    "deeplabcut.extract_outlier_frames(path_config_file, videofile_path, outlieralgorithm=alg, p_bound=param)\n",
    "num_frames = prompt_with_timeout(\"number of frames selected?\")\n",
    "write_log(\"   VIDEOS: {0}, ALGORITHM: {1}, PARAMETER: {2}, NUM FRAMES: {3}\".format(str(videofile_path), alg, param, num_frames))\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "write_log(str(end) + \"***analyze_videos end\")\n",
    "write_log(\"   time elapsed:\" + str(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "?deeplabcut.extract_outlier_frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8ib0uvhaoEJx"
   },
   "source": [
    "## Refine Labels [optional step]\n",
    "Following the extraction of outlier frames, the user can use the following function to move the predicted labels to the correct location. Thus augmenting the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n_FpEXtyoEJy"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Cannot activate multiple GUI eventloops\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Windows\n",
      "Checking labels if they are outside the image\n",
      "A training dataset file is already found for this video. The refined machine labels are merged to this data!\n",
      "Closing... The refined labels are stored in a subdirectory under labeled-data. Use the function 'merge_datasets' to augment the training dataset, and then re-train a network using create_training_dataset followed by train_network!\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "write_log(str(start) + \"***refine_frames start\")\n",
    "\n",
    "%gui wx\n",
    "deeplabcut.refine_labels(path_config_file)\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "write_log(str(end) + \"***refine_frames end\")\n",
    "write_log(\"   time elapsed:\" + str(end-start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CHzstWr8oEJ2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data sets and updated refinement iteration to 2.\n",
      "Now you can create a new training set for the expanded annotated images (use create_training_dataset).\n"
     ]
    }
   ],
   "source": [
    "#Once all folders are relabeled, check them and advance. See how to check labels, above!\n",
    "start = datetime.datetime.now()\n",
    "write_log(str(start) + \"***refine_frames start\")\n",
    "\n",
    "deeplabcut.merge_datasets(path_config_file)\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "write_log(str(end) + \"***refine_frames end\")\n",
    "write_log(\"   time elapsed:\" + str(end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QCHj7qyboEJ6"
   },
   "source": [
    "## Create a new iteration of training dataset [optional step]\n",
    "Following the refine labels, append these frames to the original dataset to create a new iteration of training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ytQoxIldoEJ7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training dataset is successfully created. Use the function 'train_network' to start training. Happy training!\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "write_log(str(start) + \"***create_training_dataset start\")\n",
    "\n",
    "deeplabcut.create_training_dataset(path_config_file)\n",
    "\n",
    "end = datetime.datetime.now()\n",
    "write_log(str(end) + \"***create_training_dataset end\")\n",
    "write_log(\"   time elapsed:\" + str(end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pCrUvQIvoEKD"
   },
   "source": [
    "## Create labeled video\n",
    "This funtion is for visualiztion purpose and can be used to create a video in .mp4 format with labels predicted by the network. This video is saved in the same directory where the original video resides. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6aDF7Q7KoEKE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log written\n",
      "log written\n",
      "Starting %  C:\\Users\\vjj14\\Downloads\\frontslowmoCOMPRESSED ['C:\\\\Users\\\\vjj14\\\\Downloads\\\\frontslowmoCOMPRESSED\\\\compressed50.mp4']\n",
      "Loading  C:\\Users\\vjj14\\Downloads\\frontslowmoCOMPRESSED\\compressed50.mp4 and data.\n",
      "False 0 1920 0 1080\n",
      "15561\n",
      "Duration of video [s]:  518.7 , recorded with  30.0 fps!\n",
      "Overall # of frames:  15561 with cropped frame dimensions:  1920 1080\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 15561/15561 [03:14<00:00, 80.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log written\n",
      "log written\n",
      "log written\n",
      "log written\n",
      "Starting %  C:\\Users\\vjj14\\Downloads\\frontslowmoCOMPRESSED ['C:\\\\Users\\\\vjj14\\\\Downloads\\\\frontslowmoCOMPRESSED\\\\compressed30.mp4']\n",
      "Loading  C:\\Users\\vjj14\\Downloads\\frontslowmoCOMPRESSED\\compressed30.mp4 and data.\n",
      "False 0 1920 0 1080\n",
      "15561\n",
      "Duration of video [s]:  518.7 , recorded with  30.0 fps!\n",
      "Overall # of frames:  15561 with cropped frame dimensions:  1920 1080\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 15561/15561 [03:31<00:00, 73.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log written\n",
      "log written\n",
      "log written\n",
      "log written\n",
      "Starting %  C:\\Users\\vjj14\\Downloads\\frontslowmoCOMPRESSED ['C:\\\\Users\\\\vjj14\\\\Downloads\\\\frontslowmoCOMPRESSED\\\\compressed27.mp4']\n",
      "Loading  C:\\Users\\vjj14\\Downloads\\frontslowmoCOMPRESSED\\compressed27.mp4 and data.\n",
      "False 0 1920 0 1080\n",
      "15561\n",
      "Duration of video [s]:  518.7 , recorded with  30.0 fps!\n",
      "Overall # of frames:  15561 with cropped frame dimensions:  1920 1080\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 15561/15561 [03:36<00:00, 72.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log written\n",
      "log written\n",
      "log written\n",
      "log written\n",
      "Starting %  C:\\Users\\vjj14\\Downloads\\frontslowmoCOMPRESSED ['C:\\\\Users\\\\vjj14\\\\Downloads\\\\frontslowmoCOMPRESSED\\\\compressed25.mp4']\n",
      "Labeled video already created.\n",
      "log written\n",
      "log written\n",
      "log written\n",
      "log written\n",
      "Starting %  C:\\Users\\vjj14\\Downloads\\frontslowmoCOMPRESSED ['C:\\\\Users\\\\vjj14\\\\Downloads\\\\frontslowmoCOMPRESSED\\\\compressed20.mp4']\n",
      "Loading  C:\\Users\\vjj14\\Downloads\\frontslowmoCOMPRESSED\\compressed20.mp4 and data.\n",
      "False 0 1920 0 1080\n",
      "15561\n",
      "Duration of video [s]:  518.7 , recorded with  30.0 fps!\n",
      "Overall # of frames:  15561 with cropped frame dimensions:  1920 1080\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 15561/15561 [03:55<00:00, 66.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log written\n",
      "log written\n"
     ]
    }
   ],
   "source": [
    "videos=[LIST OF VIDEOS]\n",
    "for videofile_path in videos:\n",
    "    start = datetime.datetime.now()\n",
    "    write_log(str(start) + \"***create_labeled_video start\")\n",
    "    write_log(\"   VIDEOS: {}\".format(str(videofile_path)))\n",
    "\n",
    "    deeplabcut.create_labeled_video(path_config_file,videofile_path)\n",
    "\n",
    "    end = datetime.datetime.now()\n",
    "    write_log(str(end) + \"***create_labeled_video end\")\n",
    "    write_log(\"   time elapsed:\" + str(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "?deeplabcut.create_labeled_video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8GTiuJESoEKH"
   },
   "source": [
    "## Plot the trajectories of the analyzed videos\n",
    "This function plots the trajectories of all the body parts across the entire video. Each body part is identified by a unique color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\vjj14\\\\Desktop\\\\DeepLabCut\\\\frontslowmo-vj-2019-06-05\\\\videos\\\\1080p.MOV']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videofile_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gX21zZbXoEKJ",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook \n",
    "#for making interactive plots.\n",
    "deeplabcut.plot_trajectories(path_config_file,videofile_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "?deeplabcut.plot_trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas analysis of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>scorer</th>\n",
       "      <th colspan=\"12\" halign=\"left\">DeepCut_resnet50_frontslowmoJun5shuffle1_30000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bodyparts</th>\n",
       "      <th colspan=\"3\" halign=\"left\">LeftHand</th>\n",
       "      <th colspan=\"3\" halign=\"left\">RightHand</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Nose</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Pellet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coords</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>likelihood</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>likelihood</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>likelihood</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>likelihood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15560.000000</td>\n",
       "      <td>15560.000000</td>\n",
       "      <td>15560.000000</td>\n",
       "      <td>15560.000000</td>\n",
       "      <td>15560.000000</td>\n",
       "      <td>15560.000000</td>\n",
       "      <td>15560.000000</td>\n",
       "      <td>15560.000000</td>\n",
       "      <td>15560.000000</td>\n",
       "      <td>15560.000000</td>\n",
       "      <td>15560.000000</td>\n",
       "      <td>15560.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>971.243753</td>\n",
       "      <td>725.853752</td>\n",
       "      <td>0.699717</td>\n",
       "      <td>906.089441</td>\n",
       "      <td>738.766505</td>\n",
       "      <td>0.503567</td>\n",
       "      <td>931.766309</td>\n",
       "      <td>656.488581</td>\n",
       "      <td>0.671245</td>\n",
       "      <td>957.103689</td>\n",
       "      <td>811.306070</td>\n",
       "      <td>0.322458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>171.896374</td>\n",
       "      <td>139.390499</td>\n",
       "      <td>0.357561</td>\n",
       "      <td>156.673818</td>\n",
       "      <td>166.830793</td>\n",
       "      <td>0.400728</td>\n",
       "      <td>169.306891</td>\n",
       "      <td>191.976523</td>\n",
       "      <td>0.363396</td>\n",
       "      <td>159.386299</td>\n",
       "      <td>177.523694</td>\n",
       "      <td>0.418997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.870381</td>\n",
       "      <td>0.415488</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>319.477097</td>\n",
       "      <td>1.081914</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>298.748627</td>\n",
       "      <td>-0.059892</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>-5.040360</td>\n",
       "      <td>0.012989</td>\n",
       "      <td>0.000098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>914.894261</td>\n",
       "      <td>649.265245</td>\n",
       "      <td>0.397388</td>\n",
       "      <td>850.580156</td>\n",
       "      <td>651.611459</td>\n",
       "      <td>0.060324</td>\n",
       "      <td>909.805872</td>\n",
       "      <td>595.394240</td>\n",
       "      <td>0.306699</td>\n",
       "      <td>922.235798</td>\n",
       "      <td>671.503496</td>\n",
       "      <td>0.027885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1024.541650</td>\n",
       "      <td>783.569860</td>\n",
       "      <td>0.910440</td>\n",
       "      <td>905.468754</td>\n",
       "      <td>778.514918</td>\n",
       "      <td>0.466857</td>\n",
       "      <td>918.396317</td>\n",
       "      <td>703.317179</td>\n",
       "      <td>0.875269</td>\n",
       "      <td>939.903313</td>\n",
       "      <td>847.006353</td>\n",
       "      <td>0.048265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1064.598903</td>\n",
       "      <td>821.210082</td>\n",
       "      <td>0.986921</td>\n",
       "      <td>940.134475</td>\n",
       "      <td>858.174915</td>\n",
       "      <td>0.949224</td>\n",
       "      <td>928.343641</td>\n",
       "      <td>794.728728</td>\n",
       "      <td>0.960582</td>\n",
       "      <td>953.739810</td>\n",
       "      <td>940.497040</td>\n",
       "      <td>0.954270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1611.307688</td>\n",
       "      <td>1088.421771</td>\n",
       "      <td>0.999329</td>\n",
       "      <td>1609.412701</td>\n",
       "      <td>1092.391703</td>\n",
       "      <td>0.999041</td>\n",
       "      <td>1623.930874</td>\n",
       "      <td>1088.734671</td>\n",
       "      <td>0.998151</td>\n",
       "      <td>1613.409633</td>\n",
       "      <td>1089.468144</td>\n",
       "      <td>0.997180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "scorer    DeepCut_resnet50_frontslowmoJun5shuffle1_30000                \\\n",
       "bodyparts                                       LeftHand                 \n",
       "coords                                                 x             y   \n",
       "count                                       15560.000000  15560.000000   \n",
       "mean                                          971.243753    725.853752   \n",
       "std                                           171.896374    139.390499   \n",
       "min                                            -3.870381      0.415488   \n",
       "25%                                           914.894261    649.265245   \n",
       "50%                                          1024.541650    783.569860   \n",
       "75%                                          1064.598903    821.210082   \n",
       "max                                          1611.307688   1088.421771   \n",
       "\n",
       "scorer                                                             \\\n",
       "bodyparts                   RightHand                               \n",
       "coords       likelihood             x             y    likelihood   \n",
       "count      15560.000000  15560.000000  15560.000000  15560.000000   \n",
       "mean           0.699717    906.089441    738.766505      0.503567   \n",
       "std            0.357561    156.673818    166.830793      0.400728   \n",
       "min            0.000027    319.477097      1.081914      0.000040   \n",
       "25%            0.397388    850.580156    651.611459      0.060324   \n",
       "50%            0.910440    905.468754    778.514918      0.466857   \n",
       "75%            0.986921    940.134475    858.174915      0.949224   \n",
       "max            0.999329   1609.412701   1092.391703      0.999041   \n",
       "\n",
       "scorer                                                             \\\n",
       "bodyparts          Nose                                    Pellet   \n",
       "coords                x             y    likelihood             x   \n",
       "count      15560.000000  15560.000000  15560.000000  15560.000000   \n",
       "mean         931.766309    656.488581      0.671245    957.103689   \n",
       "std          169.306891    191.976523      0.363396    159.386299   \n",
       "min          298.748627     -0.059892      0.000104     -5.040360   \n",
       "25%          909.805872    595.394240      0.306699    922.235798   \n",
       "50%          918.396317    703.317179      0.875269    939.903313   \n",
       "75%          928.343641    794.728728      0.960582    953.739810   \n",
       "max         1623.930874   1088.734671      0.998151   1613.409633   \n",
       "\n",
       "scorer                                 \n",
       "bodyparts                              \n",
       "coords                y    likelihood  \n",
       "count      15560.000000  15560.000000  \n",
       "mean         811.306070      0.322458  \n",
       "std          177.523694      0.418997  \n",
       "min            0.012989      0.000098  \n",
       "25%          671.503496      0.027885  \n",
       "50%          847.006353      0.048265  \n",
       "75%          940.497040      0.954270  \n",
       "max         1089.468144      0.997180  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_hdf(r\"PATH TO .h5 FILE\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>scorer</th>\n",
       "      <th colspan=\"12\" halign=\"left\">DeepCut_resnet50_front4k60fpszoom3.0_TrimJun3shuffle1_286000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bodyparts</th>\n",
       "      <th colspan=\"3\" halign=\"left\">LeftHand</th>\n",
       "      <th colspan=\"3\" halign=\"left\">RightHand</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Nose</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Pellet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coords</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>likelihood</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>likelihood</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>likelihood</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>likelihood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>612.000000</td>\n",
       "      <td>612.000000</td>\n",
       "      <td>612.000000</td>\n",
       "      <td>612.000000</td>\n",
       "      <td>612.000000</td>\n",
       "      <td>612.000000</td>\n",
       "      <td>612.000000</td>\n",
       "      <td>612.000000</td>\n",
       "      <td>612.000000</td>\n",
       "      <td>612.000000</td>\n",
       "      <td>612.000000</td>\n",
       "      <td>612.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1294.587569</td>\n",
       "      <td>2455.822662</td>\n",
       "      <td>0.042246</td>\n",
       "      <td>609.627308</td>\n",
       "      <td>2811.817150</td>\n",
       "      <td>0.078364</td>\n",
       "      <td>1000.140640</td>\n",
       "      <td>2138.825481</td>\n",
       "      <td>0.222379</td>\n",
       "      <td>1161.420468</td>\n",
       "      <td>3607.459208</td>\n",
       "      <td>0.364173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>566.489027</td>\n",
       "      <td>890.589556</td>\n",
       "      <td>0.138305</td>\n",
       "      <td>523.969844</td>\n",
       "      <td>763.555947</td>\n",
       "      <td>0.202453</td>\n",
       "      <td>249.147238</td>\n",
       "      <td>615.631056</td>\n",
       "      <td>0.313997</td>\n",
       "      <td>635.214989</td>\n",
       "      <td>435.197877</td>\n",
       "      <td>0.308807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.173059</td>\n",
       "      <td>1.988913</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.665848</td>\n",
       "      <td>76.401595</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.269251</td>\n",
       "      <td>865.347540</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>2.184450</td>\n",
       "      <td>1940.036492</td>\n",
       "      <td>0.000428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>955.338525</td>\n",
       "      <td>1989.080632</td>\n",
       "      <td>0.000861</td>\n",
       "      <td>3.883312</td>\n",
       "      <td>2168.396138</td>\n",
       "      <td>0.001087</td>\n",
       "      <td>990.724893</td>\n",
       "      <td>1820.097459</td>\n",
       "      <td>0.004228</td>\n",
       "      <td>736.731850</td>\n",
       "      <td>3637.395378</td>\n",
       "      <td>0.070970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1458.549845</td>\n",
       "      <td>2089.116435</td>\n",
       "      <td>0.002397</td>\n",
       "      <td>764.576838</td>\n",
       "      <td>2395.076544</td>\n",
       "      <td>0.003136</td>\n",
       "      <td>1030.763698</td>\n",
       "      <td>1986.446780</td>\n",
       "      <td>0.050586</td>\n",
       "      <td>963.540944</td>\n",
       "      <td>3822.212681</td>\n",
       "      <td>0.276980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1644.293059</td>\n",
       "      <td>3421.296761</td>\n",
       "      <td>0.011128</td>\n",
       "      <td>970.543810</td>\n",
       "      <td>3556.132724</td>\n",
       "      <td>0.019450</td>\n",
       "      <td>1069.846140</td>\n",
       "      <td>2166.098999</td>\n",
       "      <td>0.300523</td>\n",
       "      <td>1822.975545</td>\n",
       "      <td>3837.997508</td>\n",
       "      <td>0.658898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2161.044888</td>\n",
       "      <td>3840.645847</td>\n",
       "      <td>0.977641</td>\n",
       "      <td>2139.572770</td>\n",
       "      <td>3840.410774</td>\n",
       "      <td>0.992057</td>\n",
       "      <td>2152.967607</td>\n",
       "      <td>3841.093842</td>\n",
       "      <td>0.998524</td>\n",
       "      <td>2158.995823</td>\n",
       "      <td>3841.865475</td>\n",
       "      <td>0.989263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "scorer    DeepCut_resnet50_front4k60fpszoom3.0_TrimJun3shuffle1_286000  \\\n",
       "bodyparts                                                     LeftHand   \n",
       "coords                                                               x   \n",
       "count                                             612.000000             \n",
       "mean                                             1294.587569             \n",
       "std                                               566.489027             \n",
       "min                                                -0.173059             \n",
       "25%                                               955.338525             \n",
       "50%                                              1458.549845             \n",
       "75%                                              1644.293059             \n",
       "max                                              2161.044888             \n",
       "\n",
       "scorer                                                                    \\\n",
       "bodyparts                             RightHand                            \n",
       "coords               y  likelihood            x            y  likelihood   \n",
       "count       612.000000  612.000000   612.000000   612.000000  612.000000   \n",
       "mean       2455.822662    0.042246   609.627308  2811.817150    0.078364   \n",
       "std         890.589556    0.138305   523.969844   763.555947    0.202453   \n",
       "min           1.988913    0.000032     0.665848    76.401595    0.000153   \n",
       "25%        1989.080632    0.000861     3.883312  2168.396138    0.001087   \n",
       "50%        2089.116435    0.002397   764.576838  2395.076544    0.003136   \n",
       "75%        3421.296761    0.011128   970.543810  3556.132724    0.019450   \n",
       "max        3840.645847    0.977641  2139.572770  3840.410774    0.992057   \n",
       "\n",
       "scorer                                                                     \\\n",
       "bodyparts         Nose                                Pellet                \n",
       "coords               x            y  likelihood            x            y   \n",
       "count       612.000000   612.000000  612.000000   612.000000   612.000000   \n",
       "mean       1000.140640  2138.825481    0.222379  1161.420468  3607.459208   \n",
       "std         249.147238   615.631056    0.313997   635.214989   435.197877   \n",
       "min           0.269251   865.347540    0.000097     2.184450  1940.036492   \n",
       "25%         990.724893  1820.097459    0.004228   736.731850  3637.395378   \n",
       "50%        1030.763698  1986.446780    0.050586   963.540944  3822.212681   \n",
       "75%        1069.846140  2166.098999    0.300523  1822.975545  3837.997508   \n",
       "max        2152.967607  3841.093842    0.998524  2158.995823  3841.865475   \n",
       "\n",
       "scorer                 \n",
       "bodyparts              \n",
       "coords     likelihood  \n",
       "count      612.000000  \n",
       "mean         0.364173  \n",
       "std          0.308807  \n",
       "min          0.000428  \n",
       "25%          0.070970  \n",
       "50%          0.276980  \n",
       "75%          0.658898  \n",
       "max          0.989263  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Demo-yourowndata.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
