2019-06-03 16:38:06 Config:
{'all_joints': [[0], [1], [2], [3]],
 'all_joints_names': ['LeftHand', 'RightHand', 'Nose', 'Pellet'],
 'batch_size': 1,
 'bottomheight': 400,
 'crop': True,
 'crop_pad': 0,
 'cropratio': 0.4,
 'dataset': 'training-datasets\\iteration-0\\UnaugmentedDataSet_front4k60fpszoom3.0_TrimJun3\\front4k60fpszoom3.0_Trim_nv95shuffle1.mat',
 'dataset_type': 'default',
 'display_iters': 1000,
 'fg_fraction': 0.25,
 'global_scale': 0.8,
 'init_weights': 'C:\\Users\\vjj14\\.conda\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\models\\pretrained\\resnet_v1_50.ckpt',
 'intermediate_supervision': False,
 'intermediate_supervision_layer': 12,
 'leftwidth': 400,
 'location_refinement': True,
 'locref_huber_loss': True,
 'locref_loss_weight': 0.05,
 'locref_stdev': 7.2801,
 'log_dir': 'log',
 'max_input_size': 1500,
 'mean_pixel': [123.68, 116.779, 103.939],
 'metadataset': 'training-datasets\\iteration-0\\UnaugmentedDataSet_front4k60fpszoom3.0_TrimJun3\\Documentation_data-front4k60fpszoom3.0_Trim_95shuffle1.pickle',
 'min_input_size': 64,
 'minsize': 100,
 'mirror': False,
 'multi_step': [[0.005, 10000],
                [0.02, 430000],
                [0.002, 730000],
                [0.001, 1030000]],
 'net_type': 'resnet_50',
 'num_joints': 4,
 'optimizer': 'sgd',
 'pos_dist_thresh': 17,
 'project_path': 'C:\\Users\\vjj14\\Desktop\\DeepLabCut\\front4k60fpszoom3.0_Trim-nv-2019-06-03',
 'regularize': False,
 'rightwidth': 400,
 'save_iters': 50000,
 'scale_jitter_lo': 0.5,
 'scale_jitter_up': 1.25,
 'scoremap_dir': 'test',
 'shuffle': True,
 'snapshot_prefix': 'C:\\Users\\vjj14\\Desktop\\DeepLabCut\\front4k60fpszoom3.0_Trim-nv-2019-06-03\\dlc-models\\iteration-0\\front4k60fpszoom3.0_TrimJun3-trainset95shuffle1\\train\\snapshot',
 'stride': 8.0,
 'topheight': 400,
 'use_gt_segm': False,
 'video': False,
 'video_batch': False,
 'weigh_negatives': False,
 'weigh_only_present_joints': False,
 'weigh_part_predictions': False,
 'weight_decay': 0.0001}
2019-06-03 16:39:18 iteration: 50 loss: 0.0824 lr: 0.005
2019-06-03 16:40:00 iteration: 100 loss: 0.0162 lr: 0.005
2019-06-03 16:40:38 iteration: 150 loss: 0.0152 lr: 0.005
2019-06-03 16:41:10 iteration: 200 loss: 0.0138 lr: 0.005
2019-06-03 16:41:40 iteration: 250 loss: 0.0137 lr: 0.005
2019-06-03 16:42:10 iteration: 300 loss: 0.0136 lr: 0.005
2019-06-03 16:42:36 iteration: 350 loss: 0.0124 lr: 0.005
2019-06-03 16:43:02 iteration: 400 loss: 0.0115 lr: 0.005
2019-06-03 16:43:29 iteration: 450 loss: 0.0129 lr: 0.005
2019-06-03 16:43:52 iteration: 500 loss: 0.0121 lr: 0.005
2019-06-03 16:44:20 iteration: 550 loss: 0.0130 lr: 0.005
2019-06-03 16:44:43 iteration: 600 loss: 0.0113 lr: 0.005
2019-06-03 16:45:05 iteration: 650 loss: 0.0114 lr: 0.005
2019-06-03 16:45:24 iteration: 700 loss: 0.0109 lr: 0.005
2019-06-03 16:45:48 iteration: 750 loss: 0.0115 lr: 0.005
2019-06-03 16:46:11 iteration: 800 loss: 0.0124 lr: 0.005
2019-06-03 16:46:31 iteration: 850 loss: 0.0115 lr: 0.005
2019-06-03 16:46:54 iteration: 900 loss: 0.0110 lr: 0.005
2019-06-03 16:47:16 iteration: 950 loss: 0.0113 lr: 0.005
2019-06-03 16:47:32 iteration: 1000 loss: 0.0110 lr: 0.005
2019-06-03 16:47:57 iteration: 1050 loss: 0.0122 lr: 0.005
2019-06-03 16:48:13 iteration: 1100 loss: 0.0097 lr: 0.005
2019-06-03 16:48:31 iteration: 1150 loss: 0.0115 lr: 0.005
2019-06-03 16:48:48 iteration: 1200 loss: 0.0124 lr: 0.005
2019-06-03 16:49:05 iteration: 1250 loss: 0.0110 lr: 0.005
2019-06-03 16:49:23 iteration: 1300 loss: 0.0108 lr: 0.005
2019-06-03 16:49:41 iteration: 1350 loss: 0.0104 lr: 0.005
2019-06-03 16:50:02 iteration: 1400 loss: 0.0100 lr: 0.005
2019-06-03 16:50:18 iteration: 1450 loss: 0.0104 lr: 0.005
2019-06-03 16:50:32 iteration: 1500 loss: 0.0103 lr: 0.005
2019-06-03 16:50:48 iteration: 1550 loss: 0.0101 lr: 0.005
2019-06-03 16:51:05 iteration: 1600 loss: 0.0108 lr: 0.005
2019-06-03 16:51:25 iteration: 1650 loss: 0.0097 lr: 0.005
2019-06-03 16:51:42 iteration: 1700 loss: 0.0114 lr: 0.005
2019-06-03 16:51:57 iteration: 1750 loss: 0.0118 lr: 0.005
2019-06-03 16:52:12 iteration: 1800 loss: 0.0097 lr: 0.005
2019-06-03 16:52:29 iteration: 1850 loss: 0.0118 lr: 0.005
2019-06-03 16:52:46 iteration: 1900 loss: 0.0109 lr: 0.005
2019-06-03 16:53:03 iteration: 1950 loss: 0.0107 lr: 0.005
2019-06-03 16:53:20 iteration: 2000 loss: 0.0101 lr: 0.005
2019-06-03 16:53:40 iteration: 2050 loss: 0.0115 lr: 0.005
2019-06-03 16:53:54 iteration: 2100 loss: 0.0101 lr: 0.005
2019-06-03 16:54:09 iteration: 2150 loss: 0.0106 lr: 0.005
2019-06-03 16:54:22 iteration: 2200 loss: 0.0096 lr: 0.005
2019-06-03 16:54:36 iteration: 2250 loss: 0.0094 lr: 0.005
2019-06-03 16:54:50 iteration: 2300 loss: 0.0099 lr: 0.005
2019-06-03 16:55:07 iteration: 2350 loss: 0.0110 lr: 0.005
2019-06-03 16:55:20 iteration: 2400 loss: 0.0100 lr: 0.005
2019-06-03 16:55:37 iteration: 2450 loss: 0.0110 lr: 0.005
2019-06-03 16:55:52 iteration: 2500 loss: 0.0100 lr: 0.005
2019-06-03 16:56:08 iteration: 2550 loss: 0.0107 lr: 0.005
2019-06-03 16:56:21 iteration: 2600 loss: 0.0090 lr: 0.005
2019-06-03 16:56:35 iteration: 2650 loss: 0.0106 lr: 0.005
2019-06-03 16:56:49 iteration: 2700 loss: 0.0089 lr: 0.005
2019-06-03 16:57:07 iteration: 2750 loss: 0.0105 lr: 0.005
2019-06-03 16:57:25 iteration: 2800 loss: 0.0103 lr: 0.005
2019-06-03 16:57:41 iteration: 2850 loss: 0.0110 lr: 0.005
2019-06-03 16:57:54 iteration: 2900 loss: 0.0093 lr: 0.005
2019-06-03 16:58:09 iteration: 2950 loss: 0.0104 lr: 0.005
2019-06-03 16:58:22 iteration: 3000 loss: 0.0102 lr: 0.005
2019-06-03 16:58:39 iteration: 3050 loss: 0.0098 lr: 0.005
2019-06-03 16:58:54 iteration: 3100 loss: 0.0106 lr: 0.005
2019-06-03 16:59:08 iteration: 3150 loss: 0.0099 lr: 0.005
2019-06-03 16:59:21 iteration: 3200 loss: 0.0108 lr: 0.005
2019-06-03 16:59:36 iteration: 3250 loss: 0.0104 lr: 0.005
2019-06-03 16:59:48 iteration: 3300 loss: 0.0096 lr: 0.005
2019-06-03 17:00:00 iteration: 3350 loss: 0.0099 lr: 0.005
2019-06-03 17:00:13 iteration: 3400 loss: 0.0094 lr: 0.005
2019-06-03 17:00:26 iteration: 3450 loss: 0.0103 lr: 0.005
2019-06-03 17:00:38 iteration: 3500 loss: 0.0102 lr: 0.005
2019-06-03 17:00:54 iteration: 3550 loss: 0.0092 lr: 0.005
2019-06-03 17:01:07 iteration: 3600 loss: 0.0105 lr: 0.005
2019-06-03 17:01:20 iteration: 3650 loss: 0.0097 lr: 0.005
2019-06-03 17:01:32 iteration: 3700 loss: 0.0094 lr: 0.005
2019-06-03 17:01:48 iteration: 3750 loss: 0.0096 lr: 0.005
2019-06-03 17:02:03 iteration: 3800 loss: 0.0110 lr: 0.005
2019-06-03 17:02:17 iteration: 3850 loss: 0.0105 lr: 0.005
2019-06-03 17:02:30 iteration: 3900 loss: 0.0101 lr: 0.005
2019-06-03 17:02:45 iteration: 3950 loss: 0.0110 lr: 0.005
2019-06-03 17:02:58 iteration: 4000 loss: 0.0100 lr: 0.005
2019-06-03 17:03:15 iteration: 4050 loss: 0.0102 lr: 0.005
2019-06-03 17:03:28 iteration: 4100 loss: 0.0096 lr: 0.005
2019-06-03 17:03:41 iteration: 4150 loss: 0.0094 lr: 0.005
2019-06-03 17:03:55 iteration: 4200 loss: 0.0094 lr: 0.005
2019-06-03 17:04:08 iteration: 4250 loss: 0.0089 lr: 0.005
2019-06-03 17:04:20 iteration: 4300 loss: 0.0103 lr: 0.005
2019-06-03 17:04:33 iteration: 4350 loss: 0.0091 lr: 0.005
2019-06-03 17:04:45 iteration: 4400 loss: 0.0096 lr: 0.005
2019-06-03 17:04:56 iteration: 4450 loss: 0.0096 lr: 0.005
2019-06-03 17:05:08 iteration: 4500 loss: 0.0096 lr: 0.005
2019-06-03 17:05:26 iteration: 4550 loss: 0.0101 lr: 0.005
2019-06-03 17:05:37 iteration: 4600 loss: 0.0092 lr: 0.005
2019-06-03 17:05:50 iteration: 4650 loss: 0.0095 lr: 0.005
2019-06-03 17:06:01 iteration: 4700 loss: 0.0088 lr: 0.005
2019-06-03 17:06:13 iteration: 4750 loss: 0.0103 lr: 0.005
2019-06-03 17:06:25 iteration: 4800 loss: 0.0093 lr: 0.005
2019-06-03 17:06:36 iteration: 4850 loss: 0.0100 lr: 0.005
2019-06-03 17:06:50 iteration: 4900 loss: 0.0103 lr: 0.005
2019-06-03 17:07:02 iteration: 4950 loss: 0.0099 lr: 0.005
2019-06-03 17:07:15 iteration: 5000 loss: 0.0097 lr: 0.005
2019-06-03 17:07:29 iteration: 5050 loss: 0.0096 lr: 0.005
2019-06-03 17:07:43 iteration: 5100 loss: 0.0101 lr: 0.005
2019-06-03 17:07:54 iteration: 5150 loss: 0.0090 lr: 0.005
2019-06-03 17:08:05 iteration: 5200 loss: 0.0088 lr: 0.005
2019-06-03 17:08:21 iteration: 5250 loss: 0.0096 lr: 0.005
2019-06-03 17:08:34 iteration: 5300 loss: 0.0090 lr: 0.005
2019-06-03 17:08:45 iteration: 5350 loss: 0.0091 lr: 0.005
2019-06-03 17:08:57 iteration: 5400 loss: 0.0097 lr: 0.005
2019-06-03 17:09:08 iteration: 5450 loss: 0.0091 lr: 0.005
2019-06-03 17:09:23 iteration: 5500 loss: 0.0095 lr: 0.005
2019-06-03 17:09:36 iteration: 5550 loss: 0.0094 lr: 0.005
2019-06-03 17:09:48 iteration: 5600 loss: 0.0094 lr: 0.005
2019-06-03 17:10:00 iteration: 5650 loss: 0.0104 lr: 0.005
2019-06-03 17:10:12 iteration: 5700 loss: 0.0097 lr: 0.005
2019-06-03 17:10:23 iteration: 5750 loss: 0.0097 lr: 0.005
2019-06-03 17:10:35 iteration: 5800 loss: 0.0095 lr: 0.005
2019-06-03 17:10:47 iteration: 5850 loss: 0.0099 lr: 0.005
2019-06-03 17:11:00 iteration: 5900 loss: 0.0094 lr: 0.005
2019-06-03 17:11:11 iteration: 5950 loss: 0.0093 lr: 0.005
2019-06-03 17:11:22 iteration: 6000 loss: 0.0098 lr: 0.005
2019-06-03 17:11:37 iteration: 6050 loss: 0.0097 lr: 0.005
2019-06-03 17:11:47 iteration: 6100 loss: 0.0087 lr: 0.005
2019-06-03 17:11:59 iteration: 6150 loss: 0.0091 lr: 0.005
2019-06-03 17:12:09 iteration: 6200 loss: 0.0097 lr: 0.005
2019-06-03 17:12:21 iteration: 6250 loss: 0.0091 lr: 0.005
2019-06-03 17:12:33 iteration: 6300 loss: 0.0094 lr: 0.005
2019-06-03 17:12:44 iteration: 6350 loss: 0.0090 lr: 0.005
2019-06-03 17:12:58 iteration: 6400 loss: 0.0090 lr: 0.005
2019-06-03 17:13:09 iteration: 6450 loss: 0.0094 lr: 0.005
2019-06-03 17:13:21 iteration: 6500 loss: 0.0098 lr: 0.005
2019-06-03 17:13:37 iteration: 6550 loss: 0.0093 lr: 0.005
2019-06-03 17:13:49 iteration: 6600 loss: 0.0090 lr: 0.005
2019-06-03 17:14:01 iteration: 6650 loss: 0.0089 lr: 0.005
2019-06-03 17:14:14 iteration: 6700 loss: 0.0095 lr: 0.005
2019-06-03 17:14:26 iteration: 6750 loss: 0.0094 lr: 0.005
2019-06-03 17:14:37 iteration: 6800 loss: 0.0100 lr: 0.005
2019-06-03 17:14:50 iteration: 6850 loss: 0.0093 lr: 0.005
2019-06-03 17:15:00 iteration: 6900 loss: 0.0087 lr: 0.005
2019-06-03 17:15:12 iteration: 6950 loss: 0.0095 lr: 0.005
2019-06-03 17:15:24 iteration: 7000 loss: 0.0097 lr: 0.005
2019-06-03 17:15:38 iteration: 7050 loss: 0.0091 lr: 0.005
2019-06-03 17:15:51 iteration: 7100 loss: 0.0093 lr: 0.005
2019-06-03 17:16:02 iteration: 7150 loss: 0.0089 lr: 0.005
2019-06-03 17:16:13 iteration: 7200 loss: 0.0086 lr: 0.005
2019-06-03 17:16:23 iteration: 7250 loss: 0.0082 lr: 0.005
2019-06-03 17:16:33 iteration: 7300 loss: 0.0087 lr: 0.005
2019-06-03 17:16:45 iteration: 7350 loss: 0.0087 lr: 0.005
2019-06-03 17:16:55 iteration: 7400 loss: 0.0096 lr: 0.005
2019-06-03 17:17:06 iteration: 7450 loss: 0.0095 lr: 0.005
2019-06-03 17:17:17 iteration: 7500 loss: 0.0090 lr: 0.005
2019-06-03 17:17:33 iteration: 7550 loss: 0.0093 lr: 0.005
2019-06-03 17:17:45 iteration: 7600 loss: 0.0094 lr: 0.005
2019-06-03 17:17:56 iteration: 7650 loss: 0.0101 lr: 0.005
2019-06-03 17:18:05 iteration: 7700 loss: 0.0092 lr: 0.005
2019-06-03 17:18:16 iteration: 7750 loss: 0.0094 lr: 0.005
2019-06-03 17:18:27 iteration: 7800 loss: 0.0088 lr: 0.005
2019-06-03 17:18:37 iteration: 7850 loss: 0.0090 lr: 0.005
2019-06-03 17:18:48 iteration: 7900 loss: 0.0086 lr: 0.005
2019-06-03 17:19:00 iteration: 7950 loss: 0.0089 lr: 0.005
2019-06-03 17:19:10 iteration: 8000 loss: 0.0095 lr: 0.005
2019-06-03 17:19:23 iteration: 8050 loss: 0.0089 lr: 0.005
2019-06-03 17:19:35 iteration: 8100 loss: 0.0095 lr: 0.005
2019-06-03 17:19:48 iteration: 8150 loss: 0.0099 lr: 0.005
2019-06-03 17:19:59 iteration: 8200 loss: 0.0098 lr: 0.005
2019-06-03 17:20:10 iteration: 8250 loss: 0.0098 lr: 0.005
2019-06-03 17:20:24 iteration: 8300 loss: 0.0097 lr: 0.005
2019-06-03 17:20:35 iteration: 8350 loss: 0.0096 lr: 0.005
2019-06-03 17:20:47 iteration: 8400 loss: 0.0092 lr: 0.005
2019-06-03 17:20:58 iteration: 8450 loss: 0.0092 lr: 0.005
2019-06-03 17:21:07 iteration: 8500 loss: 0.0091 lr: 0.005
2019-06-03 17:21:21 iteration: 8550 loss: 0.0080 lr: 0.005
2019-06-03 17:21:30 iteration: 8600 loss: 0.0084 lr: 0.005
2019-06-03 17:21:41 iteration: 8650 loss: 0.0081 lr: 0.005
2019-06-03 17:21:53 iteration: 8700 loss: 0.0088 lr: 0.005
2019-06-03 17:22:03 iteration: 8750 loss: 0.0086 lr: 0.005
2019-06-03 17:22:14 iteration: 8800 loss: 0.0084 lr: 0.005
2019-06-03 17:22:25 iteration: 8850 loss: 0.0079 lr: 0.005
2019-06-03 17:22:38 iteration: 8900 loss: 0.0085 lr: 0.005
2019-06-03 17:22:48 iteration: 8950 loss: 0.0087 lr: 0.005
2019-06-03 17:22:58 iteration: 9000 loss: 0.0096 lr: 0.005
2019-06-03 17:23:12 iteration: 9050 loss: 0.0088 lr: 0.005
2019-06-03 17:23:21 iteration: 9100 loss: 0.0095 lr: 0.005
2019-06-03 17:23:33 iteration: 9150 loss: 0.0094 lr: 0.005
2019-06-03 17:23:45 iteration: 9200 loss: 0.0090 lr: 0.005
2019-06-03 17:23:54 iteration: 9250 loss: 0.0085 lr: 0.005
2019-06-03 17:24:05 iteration: 9300 loss: 0.0083 lr: 0.005
2019-06-03 17:24:16 iteration: 9350 loss: 0.0093 lr: 0.005
2019-06-03 17:24:26 iteration: 9400 loss: 0.0090 lr: 0.005
2019-06-03 17:24:37 iteration: 9450 loss: 0.0085 lr: 0.005
2019-06-03 17:24:48 iteration: 9500 loss: 0.0085 lr: 0.005
2019-06-03 17:25:02 iteration: 9550 loss: 0.0083 lr: 0.005
2019-06-03 17:25:13 iteration: 9600 loss: 0.0089 lr: 0.005
2019-06-03 17:25:25 iteration: 9650 loss: 0.0091 lr: 0.005
2019-06-03 17:25:34 iteration: 9700 loss: 0.0092 lr: 0.005
2019-06-03 17:25:46 iteration: 9750 loss: 0.0095 lr: 0.005
2019-06-03 17:25:56 iteration: 9800 loss: 0.0091 lr: 0.005
2019-06-03 17:26:07 iteration: 9850 loss: 0.0080 lr: 0.005
2019-06-03 17:26:18 iteration: 9900 loss: 0.0084 lr: 0.005
2019-06-03 17:26:30 iteration: 9950 loss: 0.0089 lr: 0.005
2019-06-03 17:26:40 iteration: 10000 loss: 0.0086 lr: 0.005
2019-06-03 17:26:55 iteration: 10050 loss: 0.0109 lr: 0.02
2019-06-03 17:27:05 iteration: 10100 loss: 0.0139 lr: 0.02
2019-06-03 17:27:14 iteration: 10150 loss: 0.0128 lr: 0.02
2019-06-03 17:27:25 iteration: 10200 loss: 0.0104 lr: 0.02
2019-06-03 17:27:36 iteration: 10250 loss: 0.0127 lr: 0.02
2019-06-03 17:27:46 iteration: 10300 loss: 0.0106 lr: 0.02
2019-06-03 17:27:57 iteration: 10350 loss: 0.0111 lr: 0.02
2019-06-03 17:28:08 iteration: 10400 loss: 0.0103 lr: 0.02
2019-06-03 17:28:18 iteration: 10450 loss: 0.0111 lr: 0.02
2019-06-03 17:28:30 iteration: 10500 loss: 0.0100 lr: 0.02
2019-06-03 17:28:44 iteration: 10550 loss: 0.0112 lr: 0.02
2019-06-03 17:28:54 iteration: 10600 loss: 0.0105 lr: 0.02
2019-06-03 17:29:05 iteration: 10650 loss: 0.0105 lr: 0.02
2019-06-03 17:29:16 iteration: 10700 loss: 0.0113 lr: 0.02
2019-06-03 17:29:26 iteration: 10750 loss: 0.0103 lr: 0.02
2019-06-03 17:29:36 iteration: 10800 loss: 0.0111 lr: 0.02
2019-06-03 17:29:48 iteration: 10850 loss: 0.0114 lr: 0.02
2019-06-03 17:29:58 iteration: 10900 loss: 0.0101 lr: 0.02
2019-06-03 17:30:08 iteration: 10950 loss: 0.0102 lr: 0.02
2019-06-03 17:30:20 iteration: 11000 loss: 0.0098 lr: 0.02
2019-06-03 17:30:34 iteration: 11050 loss: 0.0111 lr: 0.02
2019-06-03 17:30:45 iteration: 11100 loss: 0.0108 lr: 0.02
2019-06-03 17:30:56 iteration: 11150 loss: 0.0108 lr: 0.02
2019-06-03 17:31:08 iteration: 11200 loss: 0.0113 lr: 0.02
2019-06-03 17:31:18 iteration: 11250 loss: 0.0092 lr: 0.02
2019-06-03 17:31:27 iteration: 11300 loss: 0.0109 lr: 0.02
2019-06-03 17:31:39 iteration: 11350 loss: 0.0096 lr: 0.02
2019-06-03 17:31:49 iteration: 11400 loss: 0.0102 lr: 0.02
2019-06-03 17:32:00 iteration: 11450 loss: 0.0101 lr: 0.02
2019-06-03 17:32:11 iteration: 11500 loss: 0.0099 lr: 0.02
2019-06-03 17:32:25 iteration: 11550 loss: 0.0096 lr: 0.02
2019-06-03 17:32:36 iteration: 11600 loss: 0.0101 lr: 0.02
2019-06-03 17:32:46 iteration: 11650 loss: 0.0099 lr: 0.02
2019-06-03 17:32:57 iteration: 11700 loss: 0.0095 lr: 0.02
2019-06-03 17:33:07 iteration: 11750 loss: 0.0110 lr: 0.02
2019-06-03 17:33:18 iteration: 11800 loss: 0.0107 lr: 0.02
2019-06-03 17:33:28 iteration: 11850 loss: 0.0108 lr: 0.02
2019-06-03 17:33:39 iteration: 11900 loss: 0.0107 lr: 0.02
2019-06-03 17:33:50 iteration: 11950 loss: 0.0103 lr: 0.02
2019-06-03 17:34:00 iteration: 12000 loss: 0.0106 lr: 0.02
2019-06-03 17:34:14 iteration: 12050 loss: 0.0095 lr: 0.02
2019-06-03 17:34:25 iteration: 12100 loss: 0.0092 lr: 0.02
2019-06-03 17:34:35 iteration: 12150 loss: 0.0098 lr: 0.02
2019-06-03 17:34:46 iteration: 12200 loss: 0.0100 lr: 0.02
2019-06-03 17:34:57 iteration: 12250 loss: 0.0101 lr: 0.02
2019-06-03 17:35:08 iteration: 12300 loss: 0.0103 lr: 0.02
2019-06-03 17:35:18 iteration: 12350 loss: 0.0103 lr: 0.02
2019-06-03 17:35:28 iteration: 12400 loss: 0.0100 lr: 0.02
2019-06-03 17:35:38 iteration: 12450 loss: 0.0093 lr: 0.02
2019-06-03 17:35:49 iteration: 12500 loss: 0.0089 lr: 0.02
2019-06-03 17:36:03 iteration: 12550 loss: 0.0095 lr: 0.02
2019-06-03 17:36:16 iteration: 12600 loss: 0.0102 lr: 0.02
2019-06-03 17:36:26 iteration: 12650 loss: 0.0098 lr: 0.02
2019-06-03 17:36:35 iteration: 12700 loss: 0.0098 lr: 0.02
2019-06-03 17:36:46 iteration: 12750 loss: 0.0089 lr: 0.02
2019-06-03 17:36:56 iteration: 12800 loss: 0.0090 lr: 0.02
2019-06-03 17:37:07 iteration: 12850 loss: 0.0089 lr: 0.02
2019-06-03 17:37:18 iteration: 12900 loss: 0.0101 lr: 0.02
2019-06-03 17:37:29 iteration: 12950 loss: 0.0080 lr: 0.02
2019-06-03 17:37:40 iteration: 13000 loss: 0.0102 lr: 0.02
2019-06-03 17:37:54 iteration: 13050 loss: 0.0085 lr: 0.02
2019-06-03 17:38:04 iteration: 13100 loss: 0.0090 lr: 0.02
2019-06-03 17:38:15 iteration: 13150 loss: 0.0091 lr: 0.02
2019-06-03 17:38:28 iteration: 13200 loss: 0.0086 lr: 0.02
2019-06-03 17:38:37 iteration: 13250 loss: 0.0092 lr: 0.02
2019-06-03 17:38:47 iteration: 13300 loss: 0.0099 lr: 0.02
2019-06-03 17:38:58 iteration: 13350 loss: 0.0108 lr: 0.02
2019-06-03 17:39:08 iteration: 13400 loss: 0.0088 lr: 0.02
2019-06-03 17:39:21 iteration: 13450 loss: 0.0091 lr: 0.02
2019-06-03 17:39:30 iteration: 13500 loss: 0.0091 lr: 0.02
2019-06-03 17:39:43 iteration: 13550 loss: 0.0090 lr: 0.02
2019-06-03 17:39:54 iteration: 13600 loss: 0.0087 lr: 0.02
2019-06-03 17:40:05 iteration: 13650 loss: 0.0091 lr: 0.02
2019-06-03 17:40:16 iteration: 13700 loss: 0.0101 lr: 0.02
2019-06-03 17:40:26 iteration: 13750 loss: 0.0095 lr: 0.02
2019-06-03 17:40:38 iteration: 13800 loss: 0.0092 lr: 0.02
2019-06-03 17:40:48 iteration: 13850 loss: 0.0099 lr: 0.02
2019-06-03 17:40:58 iteration: 13900 loss: 0.0091 lr: 0.02
2019-06-03 17:41:09 iteration: 13950 loss: 0.0097 lr: 0.02
2019-06-03 17:41:19 iteration: 14000 loss: 0.0088 lr: 0.02
2019-06-03 17:41:33 iteration: 14050 loss: 0.0095 lr: 0.02
2019-06-03 17:41:44 iteration: 14100 loss: 0.0090 lr: 0.02
2019-06-03 17:41:55 iteration: 14150 loss: 0.0099 lr: 0.02
2019-06-03 17:42:05 iteration: 14200 loss: 0.0094 lr: 0.02
2019-06-03 17:42:15 iteration: 14250 loss: 0.0091 lr: 0.02
2019-06-03 17:42:25 iteration: 14300 loss: 0.0107 lr: 0.02
2019-06-03 17:42:36 iteration: 14350 loss: 0.0103 lr: 0.02
2019-06-03 17:42:46 iteration: 14400 loss: 0.0095 lr: 0.02
2019-06-03 17:42:57 iteration: 14450 loss: 0.0087 lr: 0.02
2019-06-03 17:43:07 iteration: 14500 loss: 0.0096 lr: 0.02
2019-06-03 17:43:20 iteration: 14550 loss: 0.0092 lr: 0.02
2019-06-03 17:43:31 iteration: 14600 loss: 0.0084 lr: 0.02
2019-06-03 17:43:42 iteration: 14650 loss: 0.0092 lr: 0.02
2019-06-03 17:43:53 iteration: 14700 loss: 0.0094 lr: 0.02
2019-06-03 17:44:03 iteration: 14750 loss: 0.0095 lr: 0.02
2019-06-03 17:44:14 iteration: 14800 loss: 0.0086 lr: 0.02
2019-06-03 17:44:25 iteration: 14850 loss: 0.0093 lr: 0.02
2019-06-03 17:44:35 iteration: 14900 loss: 0.0091 lr: 0.02
2019-06-03 17:44:46 iteration: 14950 loss: 0.0078 lr: 0.02
2019-06-03 17:44:57 iteration: 15000 loss: 0.0091 lr: 0.02
2019-06-03 17:45:10 iteration: 15050 loss: 0.0094 lr: 0.02
2019-06-03 17:45:20 iteration: 15100 loss: 0.0093 lr: 0.02
2019-06-03 17:45:31 iteration: 15150 loss: 0.0096 lr: 0.02
2019-06-03 17:45:42 iteration: 15200 loss: 0.0096 lr: 0.02
2019-06-03 17:45:53 iteration: 15250 loss: 0.0087 lr: 0.02
2019-06-03 17:46:03 iteration: 15300 loss: 0.0091 lr: 0.02
2019-06-03 17:46:13 iteration: 15350 loss: 0.0102 lr: 0.02
2019-06-03 17:46:24 iteration: 15400 loss: 0.0091 lr: 0.02
2019-06-03 17:46:35 iteration: 15450 loss: 0.0088 lr: 0.02
2019-06-03 17:46:46 iteration: 15500 loss: 0.0091 lr: 0.02
2019-06-03 17:46:59 iteration: 15550 loss: 0.0089 lr: 0.02
2019-06-03 17:47:10 iteration: 15600 loss: 0.0088 lr: 0.02
2019-06-03 17:47:21 iteration: 15650 loss: 0.0093 lr: 0.02
2019-06-03 17:47:30 iteration: 15700 loss: 0.0087 lr: 0.02
2019-06-03 17:47:41 iteration: 15750 loss: 0.0086 lr: 0.02
2019-06-03 17:47:52 iteration: 15800 loss: 0.0091 lr: 0.02
2019-06-03 17:48:03 iteration: 15850 loss: 0.0097 lr: 0.02
2019-06-03 17:48:15 iteration: 15900 loss: 0.0082 lr: 0.02
2019-06-03 17:48:24 iteration: 15950 loss: 0.0106 lr: 0.02
2019-06-03 17:48:35 iteration: 16000 loss: 0.0086 lr: 0.02
2019-06-03 17:48:48 iteration: 16050 loss: 0.0093 lr: 0.02
2019-06-03 17:48:58 iteration: 16100 loss: 0.0085 lr: 0.02
2019-06-03 17:49:09 iteration: 16150 loss: 0.0091 lr: 0.02
2019-06-03 17:49:20 iteration: 16200 loss: 0.0092 lr: 0.02
2019-06-03 17:49:34 iteration: 16250 loss: 0.0084 lr: 0.02
2019-06-03 17:49:48 iteration: 16300 loss: 0.0096 lr: 0.02
2019-06-03 17:49:58 iteration: 16350 loss: 0.0078 lr: 0.02
2019-06-03 17:50:08 iteration: 16400 loss: 0.0087 lr: 0.02
2019-06-03 17:50:19 iteration: 16450 loss: 0.0085 lr: 0.02
2019-06-03 17:50:30 iteration: 16500 loss: 0.0079 lr: 0.02
2019-06-03 17:50:44 iteration: 16550 loss: 0.0092 lr: 0.02
2019-06-03 17:50:56 iteration: 16600 loss: 0.0097 lr: 0.02
2019-06-03 17:51:07 iteration: 16650 loss: 0.0091 lr: 0.02
2019-06-03 17:51:17 iteration: 16700 loss: 0.0074 lr: 0.02
2019-06-03 17:51:27 iteration: 16750 loss: 0.0077 lr: 0.02
2019-06-03 17:51:38 iteration: 16800 loss: 0.0083 lr: 0.02
2019-06-03 17:51:51 iteration: 16850 loss: 0.0078 lr: 0.02
2019-06-03 17:52:01 iteration: 16900 loss: 0.0083 lr: 0.02
2019-06-03 17:52:12 iteration: 16950 loss: 0.0077 lr: 0.02
2019-06-03 17:52:22 iteration: 17000 loss: 0.0087 lr: 0.02
2019-06-03 17:52:37 iteration: 17050 loss: 0.0084 lr: 0.02
2019-06-03 17:52:46 iteration: 17100 loss: 0.0086 lr: 0.02
2019-06-03 17:52:56 iteration: 17150 loss: 0.0080 lr: 0.02
2019-06-03 17:53:07 iteration: 17200 loss: 0.0086 lr: 0.02
2019-06-03 17:53:17 iteration: 17250 loss: 0.0081 lr: 0.02
2019-06-03 17:53:27 iteration: 17300 loss: 0.0089 lr: 0.02
2019-06-03 17:53:38 iteration: 17350 loss: 0.0085 lr: 0.02
2019-06-03 17:53:50 iteration: 17400 loss: 0.0087 lr: 0.02
2019-06-03 17:54:00 iteration: 17450 loss: 0.0086 lr: 0.02
2019-06-03 17:54:11 iteration: 17500 loss: 0.0087 lr: 0.02
2019-06-03 17:54:26 iteration: 17550 loss: 0.0088 lr: 0.02
2019-06-03 17:54:36 iteration: 17600 loss: 0.0070 lr: 0.02
2019-06-03 17:54:47 iteration: 17650 loss: 0.0080 lr: 0.02
2019-06-03 17:54:59 iteration: 17700 loss: 0.0084 lr: 0.02
2019-06-03 17:55:11 iteration: 17750 loss: 0.0103 lr: 0.02
2019-06-03 17:55:21 iteration: 17800 loss: 0.0087 lr: 0.02
2019-06-03 17:55:34 iteration: 17850 loss: 0.0084 lr: 0.02
2019-06-03 17:55:45 iteration: 17900 loss: 0.0082 lr: 0.02
2019-06-03 17:55:55 iteration: 17950 loss: 0.0083 lr: 0.02
2019-06-03 17:56:05 iteration: 18000 loss: 0.0077 lr: 0.02
2019-06-03 17:56:21 iteration: 18050 loss: 0.0080 lr: 0.02
2019-06-03 17:56:32 iteration: 18100 loss: 0.0084 lr: 0.02
2019-06-03 17:56:44 iteration: 18150 loss: 0.0082 lr: 0.02
2019-06-03 17:56:51 iteration: 18200 loss: 0.0083 lr: 0.02
2019-06-03 17:57:01 iteration: 18250 loss: 0.0086 lr: 0.02
2019-06-03 17:57:12 iteration: 18300 loss: 0.0081 lr: 0.02
2019-06-03 17:57:23 iteration: 18350 loss: 0.0073 lr: 0.02
2019-06-03 17:57:34 iteration: 18400 loss: 0.0076 lr: 0.02
2019-06-03 17:57:45 iteration: 18450 loss: 0.0083 lr: 0.02
2019-06-03 17:57:55 iteration: 18500 loss: 0.0086 lr: 0.02
2019-06-03 17:58:09 iteration: 18550 loss: 0.0085 lr: 0.02
2019-06-03 17:58:20 iteration: 18600 loss: 0.0079 lr: 0.02
2019-06-03 17:58:31 iteration: 18650 loss: 0.0082 lr: 0.02
2019-06-03 17:58:41 iteration: 18700 loss: 0.0079 lr: 0.02
2019-06-03 17:58:53 iteration: 18750 loss: 0.0079 lr: 0.02
2019-06-03 17:59:04 iteration: 18800 loss: 0.0082 lr: 0.02
2019-06-03 17:59:14 iteration: 18850 loss: 0.0086 lr: 0.02
2019-06-03 17:59:25 iteration: 18900 loss: 0.0087 lr: 0.02
2019-06-03 17:59:37 iteration: 18950 loss: 0.0091 lr: 0.02
2019-06-03 17:59:48 iteration: 19000 loss: 0.0074 lr: 0.02
2019-06-03 18:00:02 iteration: 19050 loss: 0.0086 lr: 0.02
2019-06-03 18:00:12 iteration: 19100 loss: 0.0088 lr: 0.02
2019-06-03 18:00:22 iteration: 19150 loss: 0.0087 lr: 0.02
2019-06-03 18:00:34 iteration: 19200 loss: 0.0079 lr: 0.02
2019-06-03 18:00:44 iteration: 19250 loss: 0.0085 lr: 0.02
2019-06-03 18:00:54 iteration: 19300 loss: 0.0079 lr: 0.02
2019-06-03 18:01:06 iteration: 19350 loss: 0.0089 lr: 0.02
2019-06-03 18:01:16 iteration: 19400 loss: 0.0078 lr: 0.02
2019-06-03 18:01:27 iteration: 19450 loss: 0.0081 lr: 0.02
2019-06-03 18:01:38 iteration: 19500 loss: 0.0079 lr: 0.02
2019-06-03 18:01:51 iteration: 19550 loss: 0.0081 lr: 0.02
2019-06-03 18:02:02 iteration: 19600 loss: 0.0077 lr: 0.02
2019-06-03 18:02:13 iteration: 19650 loss: 0.0078 lr: 0.02
2019-06-03 18:02:24 iteration: 19700 loss: 0.0072 lr: 0.02
2019-06-03 18:02:35 iteration: 19750 loss: 0.0073 lr: 0.02
2019-06-03 18:02:47 iteration: 19800 loss: 0.0077 lr: 0.02
2019-06-03 18:02:56 iteration: 19850 loss: 0.0080 lr: 0.02
2019-06-03 18:03:08 iteration: 19900 loss: 0.0076 lr: 0.02
2019-06-03 18:03:18 iteration: 19950 loss: 0.0074 lr: 0.02
2019-06-03 18:03:30 iteration: 20000 loss: 0.0075 lr: 0.02
2019-06-03 18:03:44 iteration: 20050 loss: 0.0080 lr: 0.02
2019-06-03 18:03:55 iteration: 20100 loss: 0.0072 lr: 0.02
2019-06-03 18:04:05 iteration: 20150 loss: 0.0085 lr: 0.02
2019-06-03 18:04:16 iteration: 20200 loss: 0.0080 lr: 0.02
2019-06-03 18:04:28 iteration: 20250 loss: 0.0075 lr: 0.02
2019-06-03 18:04:38 iteration: 20300 loss: 0.0078 lr: 0.02
2019-06-03 18:04:49 iteration: 20350 loss: 0.0077 lr: 0.02
2019-06-03 18:04:59 iteration: 20400 loss: 0.0090 lr: 0.02
2019-06-03 18:05:10 iteration: 20450 loss: 0.0068 lr: 0.02
2019-06-03 18:05:21 iteration: 20500 loss: 0.0088 lr: 0.02
2019-06-03 18:05:35 iteration: 20550 loss: 0.0080 lr: 0.02
2019-06-03 18:05:45 iteration: 20600 loss: 0.0078 lr: 0.02
2019-06-03 18:05:56 iteration: 20650 loss: 0.0073 lr: 0.02
2019-06-03 18:06:07 iteration: 20700 loss: 0.0082 lr: 0.02
2019-06-03 18:06:16 iteration: 20750 loss: 0.0075 lr: 0.02
2019-06-03 18:06:27 iteration: 20800 loss: 0.0082 lr: 0.02
2019-06-03 18:06:38 iteration: 20850 loss: 0.0084 lr: 0.02
2019-06-03 18:06:49 iteration: 20900 loss: 0.0069 lr: 0.02
2019-06-03 18:06:59 iteration: 20950 loss: 0.0078 lr: 0.02
2019-06-03 18:07:10 iteration: 21000 loss: 0.0081 lr: 0.02
2019-06-03 18:07:24 iteration: 21050 loss: 0.0074 lr: 0.02
2019-06-03 18:07:34 iteration: 21100 loss: 0.0074 lr: 0.02
2019-06-03 18:07:45 iteration: 21150 loss: 0.0073 lr: 0.02
2019-06-03 18:07:56 iteration: 21200 loss: 0.0078 lr: 0.02
2019-06-03 18:08:07 iteration: 21250 loss: 0.0077 lr: 0.02
2019-06-03 18:08:18 iteration: 21300 loss: 0.0080 lr: 0.02
2019-06-03 18:08:30 iteration: 21350 loss: 0.0070 lr: 0.02
2019-06-03 18:08:40 iteration: 21400 loss: 0.0072 lr: 0.02
2019-06-03 18:08:51 iteration: 21450 loss: 0.0077 lr: 0.02
2019-06-03 18:09:02 iteration: 21500 loss: 0.0076 lr: 0.02
2019-06-03 18:09:16 iteration: 21550 loss: 0.0080 lr: 0.02
2019-06-03 18:09:27 iteration: 21600 loss: 0.0069 lr: 0.02
2019-06-03 18:09:38 iteration: 21650 loss: 0.0071 lr: 0.02
2019-06-03 18:09:49 iteration: 21700 loss: 0.0082 lr: 0.02
2019-06-03 18:09:59 iteration: 21750 loss: 0.0083 lr: 0.02
2019-06-03 18:10:10 iteration: 21800 loss: 0.0080 lr: 0.02
2019-06-03 18:10:20 iteration: 21850 loss: 0.0081 lr: 0.02
2019-06-03 18:10:31 iteration: 21900 loss: 0.0072 lr: 0.02
2019-06-03 18:10:41 iteration: 21950 loss: 0.0070 lr: 0.02
2019-06-03 18:10:52 iteration: 22000 loss: 0.0081 lr: 0.02
2019-06-03 18:11:06 iteration: 22050 loss: 0.0073 lr: 0.02
2019-06-03 18:11:17 iteration: 22100 loss: 0.0080 lr: 0.02
2019-06-03 18:11:28 iteration: 22150 loss: 0.0069 lr: 0.02
2019-06-03 18:11:39 iteration: 22200 loss: 0.0075 lr: 0.02
2019-06-03 18:11:50 iteration: 22250 loss: 0.0070 lr: 0.02
2019-06-03 18:12:00 iteration: 22300 loss: 0.0073 lr: 0.02
2019-06-03 18:12:11 iteration: 22350 loss: 0.0078 lr: 0.02
2019-06-03 18:12:22 iteration: 22400 loss: 0.0082 lr: 0.02
2019-06-03 18:12:32 iteration: 22450 loss: 0.0090 lr: 0.02
2019-06-03 18:12:43 iteration: 22500 loss: 0.0078 lr: 0.02
2019-06-03 18:12:56 iteration: 22550 loss: 0.0072 lr: 0.02
2019-06-03 18:13:07 iteration: 22600 loss: 0.0075 lr: 0.02
2019-06-03 18:13:17 iteration: 22650 loss: 0.0073 lr: 0.02
2019-06-03 18:13:28 iteration: 22700 loss: 0.0070 lr: 0.02
2019-06-03 18:13:39 iteration: 22750 loss: 0.0075 lr: 0.02
2019-06-03 18:13:49 iteration: 22800 loss: 0.0075 lr: 0.02
2019-06-03 18:14:01 iteration: 22850 loss: 0.0074 lr: 0.02
2019-06-03 18:14:10 iteration: 22900 loss: 0.0078 lr: 0.02
2019-06-03 18:14:21 iteration: 22950 loss: 0.0080 lr: 0.02
2019-06-03 18:14:32 iteration: 23000 loss: 0.0076 lr: 0.02
2019-06-03 18:14:46 iteration: 23050 loss: 0.0075 lr: 0.02
2019-06-03 18:14:56 iteration: 23100 loss: 0.0077 lr: 0.02
2019-06-03 18:15:06 iteration: 23150 loss: 0.0076 lr: 0.02
2019-06-03 18:15:16 iteration: 23200 loss: 0.0080 lr: 0.02
2019-06-03 18:15:27 iteration: 23250 loss: 0.0070 lr: 0.02
2019-06-03 18:15:38 iteration: 23300 loss: 0.0073 lr: 0.02
2019-06-03 18:15:49 iteration: 23350 loss: 0.0079 lr: 0.02
2019-06-03 18:16:00 iteration: 23400 loss: 0.0072 lr: 0.02
2019-06-03 18:16:10 iteration: 23450 loss: 0.0071 lr: 0.02
2019-06-03 18:16:22 iteration: 23500 loss: 0.0066 lr: 0.02
2019-06-03 18:16:36 iteration: 23550 loss: 0.0073 lr: 0.02
2019-06-03 18:16:46 iteration: 23600 loss: 0.0088 lr: 0.02
2019-06-03 18:16:57 iteration: 23650 loss: 0.0071 lr: 0.02
2019-06-03 18:17:08 iteration: 23700 loss: 0.0072 lr: 0.02
2019-06-03 18:17:19 iteration: 23750 loss: 0.0071 lr: 0.02
2019-06-03 18:17:28 iteration: 23800 loss: 0.0066 lr: 0.02
2019-06-03 18:17:40 iteration: 23850 loss: 0.0073 lr: 0.02
2019-06-03 18:17:52 iteration: 23900 loss: 0.0061 lr: 0.02
2019-06-03 18:18:03 iteration: 23950 loss: 0.0066 lr: 0.02
2019-06-03 18:18:13 iteration: 24000 loss: 0.0062 lr: 0.02
2019-06-03 18:18:26 iteration: 24050 loss: 0.0069 lr: 0.02
2019-06-03 18:18:37 iteration: 24100 loss: 0.0074 lr: 0.02
2019-06-03 18:18:49 iteration: 24150 loss: 0.0069 lr: 0.02
2019-06-03 18:18:58 iteration: 24200 loss: 0.0064 lr: 0.02
2019-06-03 18:19:09 iteration: 24250 loss: 0.0066 lr: 0.02
2019-06-03 18:19:20 iteration: 24300 loss: 0.0063 lr: 0.02
2019-06-03 18:19:32 iteration: 24350 loss: 0.0070 lr: 0.02
2019-06-03 18:19:42 iteration: 24400 loss: 0.0071 lr: 0.02
2019-06-03 18:19:55 iteration: 24450 loss: 0.0063 lr: 0.02
2019-06-03 18:20:05 iteration: 24500 loss: 0.0065 lr: 0.02
2019-06-03 18:20:18 iteration: 24550 loss: 0.0068 lr: 0.02
2019-06-03 18:20:28 iteration: 24600 loss: 0.0069 lr: 0.02
2019-06-03 18:20:38 iteration: 24650 loss: 0.0072 lr: 0.02
2019-06-03 18:20:48 iteration: 24700 loss: 0.0070 lr: 0.02
2019-06-03 18:20:58 iteration: 24750 loss: 0.0070 lr: 0.02
2019-06-03 18:21:09 iteration: 24800 loss: 0.0062 lr: 0.02
2019-06-03 18:21:19 iteration: 24850 loss: 0.0062 lr: 0.02
2019-06-03 18:21:30 iteration: 24900 loss: 0.0070 lr: 0.02
2019-06-03 18:21:41 iteration: 24950 loss: 0.0078 lr: 0.02
2019-06-03 18:21:52 iteration: 25000 loss: 0.0063 lr: 0.02
2019-06-03 18:22:09 iteration: 25050 loss: 0.0072 lr: 0.02
2019-06-03 18:22:19 iteration: 25100 loss: 0.0072 lr: 0.02
2019-06-03 18:22:29 iteration: 25150 loss: 0.0082 lr: 0.02
2019-06-03 18:22:41 iteration: 25200 loss: 0.0070 lr: 0.02
2019-06-03 18:22:51 iteration: 25250 loss: 0.0074 lr: 0.02
2019-06-03 18:23:01 iteration: 25300 loss: 0.0066 lr: 0.02
2019-06-03 18:23:10 iteration: 25350 loss: 0.0073 lr: 0.02
2019-06-03 18:23:20 iteration: 25400 loss: 0.0077 lr: 0.02
2019-06-03 18:23:29 iteration: 25450 loss: 0.0085 lr: 0.02
2019-06-03 18:23:41 iteration: 25500 loss: 0.0075 lr: 0.02
2019-06-03 18:23:54 iteration: 25550 loss: 0.0068 lr: 0.02
2019-06-03 18:24:04 iteration: 25600 loss: 0.0076 lr: 0.02
2019-06-03 18:24:15 iteration: 25650 loss: 0.0080 lr: 0.02
2019-06-03 18:24:26 iteration: 25700 loss: 0.0064 lr: 0.02
2019-06-03 18:24:36 iteration: 25750 loss: 0.0066 lr: 0.02
2019-06-03 18:24:47 iteration: 25800 loss: 0.0063 lr: 0.02
2019-06-03 18:24:59 iteration: 25850 loss: 0.0060 lr: 0.02
2019-06-03 18:25:09 iteration: 25900 loss: 0.0063 lr: 0.02
2019-06-03 18:25:19 iteration: 25950 loss: 0.0061 lr: 0.02
2019-06-03 18:25:29 iteration: 26000 loss: 0.0069 lr: 0.02
2019-06-03 18:25:42 iteration: 26050 loss: 0.0072 lr: 0.02
2019-06-03 18:25:53 iteration: 26100 loss: 0.0064 lr: 0.02
2019-06-03 18:26:03 iteration: 26150 loss: 0.0056 lr: 0.02
2019-06-03 18:26:13 iteration: 26200 loss: 0.0072 lr: 0.02
2019-06-03 18:26:24 iteration: 26250 loss: 0.0058 lr: 0.02
2019-06-03 18:26:35 iteration: 26300 loss: 0.0068 lr: 0.02
2019-06-03 18:26:45 iteration: 26350 loss: 0.0067 lr: 0.02
2019-06-03 18:26:56 iteration: 26400 loss: 0.0062 lr: 0.02
2019-06-03 18:27:07 iteration: 26450 loss: 0.0061 lr: 0.02
2019-06-03 18:27:17 iteration: 26500 loss: 0.0066 lr: 0.02
2019-06-03 18:27:31 iteration: 26550 loss: 0.0060 lr: 0.02
2019-06-03 18:27:42 iteration: 26600 loss: 0.0065 lr: 0.02
2019-06-03 18:27:53 iteration: 26650 loss: 0.0070 lr: 0.02
2019-06-03 18:28:03 iteration: 26700 loss: 0.0069 lr: 0.02
2019-06-03 18:28:13 iteration: 26750 loss: 0.0064 lr: 0.02
2019-06-03 18:28:24 iteration: 26800 loss: 0.0068 lr: 0.02
2019-06-03 18:28:34 iteration: 26850 loss: 0.0056 lr: 0.02
2019-06-03 18:28:44 iteration: 26900 loss: 0.0072 lr: 0.02
2019-06-03 18:28:56 iteration: 26950 loss: 0.0071 lr: 0.02
2019-06-03 18:29:06 iteration: 27000 loss: 0.0068 lr: 0.02
2019-06-03 18:29:21 iteration: 27050 loss: 0.0076 lr: 0.02
2019-06-03 18:29:30 iteration: 27100 loss: 0.0068 lr: 0.02
2019-06-03 18:29:39 iteration: 27150 loss: 0.0063 lr: 0.02
2019-06-03 18:29:50 iteration: 27200 loss: 0.0068 lr: 0.02
2019-06-03 18:30:00 iteration: 27250 loss: 0.0069 lr: 0.02
2019-06-03 18:30:11 iteration: 27300 loss: 0.0078 lr: 0.02
2019-06-03 18:30:20 iteration: 27350 loss: 0.0077 lr: 0.02
2019-06-03 18:30:32 iteration: 27400 loss: 0.0059 lr: 0.02
2019-06-03 18:30:41 iteration: 27450 loss: 0.0073 lr: 0.02
2019-06-03 18:30:52 iteration: 27500 loss: 0.0068 lr: 0.02
2019-06-03 18:31:07 iteration: 27550 loss: 0.0071 lr: 0.02
2019-06-03 18:31:16 iteration: 27600 loss: 0.0064 lr: 0.02
2019-06-03 18:31:26 iteration: 27650 loss: 0.0062 lr: 0.02
2019-06-03 18:31:38 iteration: 27700 loss: 0.0062 lr: 0.02
2019-06-03 18:31:47 iteration: 27750 loss: 0.0066 lr: 0.02
2019-06-03 18:31:58 iteration: 27800 loss: 0.0060 lr: 0.02
2019-06-03 18:32:08 iteration: 27850 loss: 0.0066 lr: 0.02
2019-06-03 18:32:19 iteration: 27900 loss: 0.0072 lr: 0.02
2019-06-03 18:32:30 iteration: 27950 loss: 0.0060 lr: 0.02
2019-06-03 18:32:40 iteration: 28000 loss: 0.0058 lr: 0.02
2019-06-03 18:32:54 iteration: 28050 loss: 0.0075 lr: 0.02
2019-06-03 18:33:04 iteration: 28100 loss: 0.0057 lr: 0.02
2019-06-03 18:33:15 iteration: 28150 loss: 0.0063 lr: 0.02
2019-06-03 18:33:26 iteration: 28200 loss: 0.0070 lr: 0.02
2019-06-03 18:33:36 iteration: 28250 loss: 0.0076 lr: 0.02
2019-06-03 18:33:47 iteration: 28300 loss: 0.0065 lr: 0.02
2019-06-03 18:33:58 iteration: 28350 loss: 0.0060 lr: 0.02
2019-06-03 18:34:08 iteration: 28400 loss: 0.0053 lr: 0.02
2019-06-03 18:34:18 iteration: 28450 loss: 0.0062 lr: 0.02
2019-06-03 18:34:30 iteration: 28500 loss: 0.0073 lr: 0.02
2019-06-03 18:34:43 iteration: 28550 loss: 0.0063 lr: 0.02
2019-06-03 18:34:53 iteration: 28600 loss: 0.0061 lr: 0.02
2019-06-03 18:35:04 iteration: 28650 loss: 0.0066 lr: 0.02
2019-06-03 18:35:15 iteration: 28700 loss: 0.0062 lr: 0.02
2019-06-03 18:35:24 iteration: 28750 loss: 0.0064 lr: 0.02
2019-06-03 18:35:35 iteration: 28800 loss: 0.0064 lr: 0.02
2019-06-03 18:35:44 iteration: 28850 loss: 0.0058 lr: 0.02
2019-06-03 18:35:55 iteration: 28900 loss: 0.0059 lr: 0.02
2019-06-03 18:36:06 iteration: 28950 loss: 0.0061 lr: 0.02
2019-06-03 18:36:18 iteration: 29000 loss: 0.0063 lr: 0.02
2019-06-03 18:36:30 iteration: 29050 loss: 0.0051 lr: 0.02
2019-06-03 18:36:41 iteration: 29100 loss: 0.0053 lr: 0.02
2019-06-03 18:36:53 iteration: 29150 loss: 0.0060 lr: 0.02
2019-06-03 18:37:01 iteration: 29200 loss: 0.0056 lr: 0.02
2019-06-03 18:37:12 iteration: 29250 loss: 0.0055 lr: 0.02
2019-06-03 18:37:23 iteration: 29300 loss: 0.0058 lr: 0.02
2019-06-03 18:37:34 iteration: 29350 loss: 0.0061 lr: 0.02
2019-06-03 18:37:44 iteration: 29400 loss: 0.0057 lr: 0.02
2019-06-03 18:37:55 iteration: 29450 loss: 0.0062 lr: 0.02
2019-06-03 18:38:07 iteration: 29500 loss: 0.0053 lr: 0.02
2019-06-03 18:38:21 iteration: 29550 loss: 0.0054 lr: 0.02
2019-06-03 18:38:31 iteration: 29600 loss: 0.0057 lr: 0.02
2019-06-03 18:38:41 iteration: 29650 loss: 0.0064 lr: 0.02
2019-06-03 18:38:52 iteration: 29700 loss: 0.0060 lr: 0.02
2019-06-03 18:39:01 iteration: 29750 loss: 0.0057 lr: 0.02
2019-06-03 18:39:12 iteration: 29800 loss: 0.0064 lr: 0.02
2019-06-03 18:39:23 iteration: 29850 loss: 0.0059 lr: 0.02
2019-06-03 18:39:33 iteration: 29900 loss: 0.0056 lr: 0.02
2019-06-03 18:39:44 iteration: 29950 loss: 0.0063 lr: 0.02
2019-06-03 18:39:55 iteration: 30000 loss: 0.0063 lr: 0.02
2019-06-03 18:40:08 iteration: 30050 loss: 0.0057 lr: 0.02
2019-06-03 18:40:19 iteration: 30100 loss: 0.0064 lr: 0.02
2019-06-03 18:40:29 iteration: 30150 loss: 0.0055 lr: 0.02
2019-06-03 18:40:40 iteration: 30200 loss: 0.0060 lr: 0.02
2019-06-03 18:40:49 iteration: 30250 loss: 0.0060 lr: 0.02
2019-06-03 18:41:01 iteration: 30300 loss: 0.0064 lr: 0.02
2019-06-03 18:41:11 iteration: 30350 loss: 0.0054 lr: 0.02
2019-06-03 18:41:22 iteration: 30400 loss: 0.0059 lr: 0.02
2019-06-03 18:41:33 iteration: 30450 loss: 0.0053 lr: 0.02
2019-06-03 18:41:43 iteration: 30500 loss: 0.0051 lr: 0.02
2019-06-03 18:41:56 iteration: 30550 loss: 0.0066 lr: 0.02
2019-06-03 18:42:06 iteration: 30600 loss: 0.0055 lr: 0.02
2019-06-03 18:42:17 iteration: 30650 loss: 0.0053 lr: 0.02
2019-06-03 18:42:27 iteration: 30700 loss: 0.0060 lr: 0.02
2019-06-03 18:42:37 iteration: 30750 loss: 0.0068 lr: 0.02
2019-06-03 18:42:48 iteration: 30800 loss: 0.0056 lr: 0.02
2019-06-03 18:42:58 iteration: 30850 loss: 0.0065 lr: 0.02
2019-06-03 18:43:08 iteration: 30900 loss: 0.0059 lr: 0.02
2019-06-03 18:43:19 iteration: 30950 loss: 0.0059 lr: 0.02
2019-06-03 18:43:29 iteration: 31000 loss: 0.0055 lr: 0.02
2019-06-03 18:43:42 iteration: 31050 loss: 0.0059 lr: 0.02
2019-06-03 18:43:54 iteration: 31100 loss: 0.0053 lr: 0.02
2019-06-03 18:44:04 iteration: 31150 loss: 0.0049 lr: 0.02
2019-06-03 18:44:14 iteration: 31200 loss: 0.0051 lr: 0.02
2019-06-03 18:44:25 iteration: 31250 loss: 0.0065 lr: 0.02
2019-06-03 18:44:36 iteration: 31300 loss: 0.0060 lr: 0.02
2019-06-03 18:44:46 iteration: 31350 loss: 0.0062 lr: 0.02
2019-06-03 18:44:58 iteration: 31400 loss: 0.0064 lr: 0.02
2019-06-03 18:45:07 iteration: 31450 loss: 0.0066 lr: 0.02
2019-06-03 18:45:18 iteration: 31500 loss: 0.0060 lr: 0.02
2019-06-03 18:45:32 iteration: 31550 loss: 0.0054 lr: 0.02
2019-06-03 18:45:43 iteration: 31600 loss: 0.0056 lr: 0.02
2019-06-03 18:45:53 iteration: 31650 loss: 0.0052 lr: 0.02
2019-06-03 18:46:04 iteration: 31700 loss: 0.0051 lr: 0.02
2019-06-03 18:46:14 iteration: 31750 loss: 0.0058 lr: 0.02
2019-06-03 18:46:25 iteration: 31800 loss: 0.0052 lr: 0.02
2019-06-03 18:46:36 iteration: 31850 loss: 0.0054 lr: 0.02
2019-06-03 18:46:46 iteration: 31900 loss: 0.0059 lr: 0.02
2019-06-03 18:46:57 iteration: 31950 loss: 0.0067 lr: 0.02
2019-06-03 18:47:07 iteration: 32000 loss: 0.0070 lr: 0.02
2019-06-03 18:47:20 iteration: 32050 loss: 0.0056 lr: 0.02
2019-06-03 18:47:30 iteration: 32100 loss: 0.0065 lr: 0.02
2019-06-03 18:47:41 iteration: 32150 loss: 0.0051 lr: 0.02
2019-06-03 18:47:52 iteration: 32200 loss: 0.0051 lr: 0.02
2019-06-03 18:48:02 iteration: 32250 loss: 0.0054 lr: 0.02
2019-06-03 18:48:13 iteration: 32300 loss: 0.0058 lr: 0.02
2019-06-03 18:48:24 iteration: 32350 loss: 0.0052 lr: 0.02
2019-06-03 18:48:33 iteration: 32400 loss: 0.0066 lr: 0.02
2019-06-03 18:48:44 iteration: 32450 loss: 0.0050 lr: 0.02
2019-06-03 18:48:55 iteration: 32500 loss: 0.0054 lr: 0.02
2019-06-03 18:49:09 iteration: 32550 loss: 0.0054 lr: 0.02
2019-06-03 18:49:18 iteration: 32600 loss: 0.0061 lr: 0.02
2019-06-03 18:49:29 iteration: 32650 loss: 0.0056 lr: 0.02
2019-06-03 18:49:39 iteration: 32700 loss: 0.0057 lr: 0.02
2019-06-03 18:49:50 iteration: 32750 loss: 0.0057 lr: 0.02
2019-06-03 18:50:01 iteration: 32800 loss: 0.0056 lr: 0.02
2019-06-03 18:50:11 iteration: 32850 loss: 0.0053 lr: 0.02
2019-06-03 18:50:21 iteration: 32900 loss: 0.0050 lr: 0.02
2019-06-03 18:50:31 iteration: 32950 loss: 0.0054 lr: 0.02
2019-06-03 18:50:42 iteration: 33000 loss: 0.0052 lr: 0.02
2019-06-03 18:50:56 iteration: 33050 loss: 0.0059 lr: 0.02
2019-06-03 18:51:05 iteration: 33100 loss: 0.0049 lr: 0.02
2019-06-03 18:51:16 iteration: 33150 loss: 0.0049 lr: 0.02
2019-06-03 18:51:27 iteration: 33200 loss: 0.0045 lr: 0.02
2019-06-03 18:51:37 iteration: 33250 loss: 0.0058 lr: 0.02
2019-06-03 18:51:47 iteration: 33300 loss: 0.0062 lr: 0.02
2019-06-03 18:51:58 iteration: 33350 loss: 0.0053 lr: 0.02
2019-06-03 18:52:08 iteration: 33400 loss: 0.0059 lr: 0.02
2019-06-03 18:52:19 iteration: 33450 loss: 0.0057 lr: 0.02
2019-06-03 18:52:29 iteration: 33500 loss: 0.0052 lr: 0.02
2019-06-03 18:52:43 iteration: 33550 loss: 0.0051 lr: 0.02
2019-06-03 18:52:53 iteration: 33600 loss: 0.0063 lr: 0.02
2019-06-03 18:53:04 iteration: 33650 loss: 0.0063 lr: 0.02
2019-06-03 18:53:15 iteration: 33700 loss: 0.0044 lr: 0.02
2019-06-03 18:53:26 iteration: 33750 loss: 0.0050 lr: 0.02
2019-06-03 18:53:37 iteration: 33800 loss: 0.0049 lr: 0.02
2019-06-03 18:53:47 iteration: 33850 loss: 0.0053 lr: 0.02
2019-06-03 18:53:58 iteration: 33900 loss: 0.0047 lr: 0.02
2019-06-03 18:54:09 iteration: 33950 loss: 0.0057 lr: 0.02
2019-06-03 18:54:19 iteration: 34000 loss: 0.0053 lr: 0.02
2019-06-03 18:54:33 iteration: 34050 loss: 0.0048 lr: 0.02
2019-06-03 18:54:44 iteration: 34100 loss: 0.0046 lr: 0.02
2019-06-03 18:54:54 iteration: 34150 loss: 0.0046 lr: 0.02
2019-06-03 18:55:05 iteration: 34200 loss: 0.0060 lr: 0.02
2019-06-03 18:55:15 iteration: 34250 loss: 0.0044 lr: 0.02
2019-06-03 18:55:26 iteration: 34300 loss: 0.0054 lr: 0.02
2019-06-03 18:55:37 iteration: 34350 loss: 0.0054 lr: 0.02
2019-06-03 18:55:47 iteration: 34400 loss: 0.0056 lr: 0.02
2019-06-03 18:55:57 iteration: 34450 loss: 0.0059 lr: 0.02
2019-06-03 18:56:08 iteration: 34500 loss: 0.0055 lr: 0.02
2019-06-03 18:56:21 iteration: 34550 loss: 0.0053 lr: 0.02
2019-06-03 18:56:32 iteration: 34600 loss: 0.0056 lr: 0.02
2019-06-03 18:56:42 iteration: 34650 loss: 0.0055 lr: 0.02
2019-06-03 18:56:52 iteration: 34700 loss: 0.0056 lr: 0.02
2019-06-03 18:57:03 iteration: 34750 loss: 0.0055 lr: 0.02
2019-06-03 18:57:14 iteration: 34800 loss: 0.0049 lr: 0.02
2019-06-03 18:57:24 iteration: 34850 loss: 0.0048 lr: 0.02
2019-06-03 18:57:35 iteration: 34900 loss: 0.0051 lr: 0.02
2019-06-03 18:57:46 iteration: 34950 loss: 0.0043 lr: 0.02
2019-06-03 18:57:56 iteration: 35000 loss: 0.0050 lr: 0.02
2019-06-03 18:58:09 iteration: 35050 loss: 0.0050 lr: 0.02
2019-06-03 18:58:20 iteration: 35100 loss: 0.0049 lr: 0.02
2019-06-03 18:58:30 iteration: 35150 loss: 0.0047 lr: 0.02
2019-06-03 18:58:42 iteration: 35200 loss: 0.0048 lr: 0.02
2019-06-03 18:58:52 iteration: 35250 loss: 0.0052 lr: 0.02
2019-06-03 18:59:03 iteration: 35300 loss: 0.0050 lr: 0.02
2019-06-03 18:59:13 iteration: 35350 loss: 0.0049 lr: 0.02
2019-06-03 18:59:24 iteration: 35400 loss: 0.0052 lr: 0.02
2019-06-03 18:59:34 iteration: 35450 loss: 0.0044 lr: 0.02
2019-06-03 18:59:45 iteration: 35500 loss: 0.0047 lr: 0.02
2019-06-03 18:59:58 iteration: 35550 loss: 0.0048 lr: 0.02
2019-06-03 19:00:08 iteration: 35600 loss: 0.0051 lr: 0.02
2019-06-03 19:00:19 iteration: 35650 loss: 0.0050 lr: 0.02
2019-06-03 19:00:30 iteration: 35700 loss: 0.0047 lr: 0.02
2019-06-03 19:00:40 iteration: 35750 loss: 0.0060 lr: 0.02
2019-06-03 19:00:52 iteration: 35800 loss: 0.0046 lr: 0.02
2019-06-03 19:01:02 iteration: 35850 loss: 0.0044 lr: 0.02
2019-06-03 19:01:13 iteration: 35900 loss: 0.0049 lr: 0.02
2019-06-03 19:01:24 iteration: 35950 loss: 0.0051 lr: 0.02
2019-06-03 19:01:34 iteration: 36000 loss: 0.0055 lr: 0.02
2019-06-03 19:01:48 iteration: 36050 loss: 0.0059 lr: 0.02
2019-06-03 19:01:59 iteration: 36100 loss: 0.0049 lr: 0.02
2019-06-03 19:02:10 iteration: 36150 loss: 0.0046 lr: 0.02
2019-06-03 19:02:20 iteration: 36200 loss: 0.0063 lr: 0.02
2019-06-03 19:02:30 iteration: 36250 loss: 0.0048 lr: 0.02
2019-06-03 19:02:40 iteration: 36300 loss: 0.0047 lr: 0.02
2019-06-03 19:02:51 iteration: 36350 loss: 0.0050 lr: 0.02
2019-06-03 19:03:02 iteration: 36400 loss: 0.0046 lr: 0.02
2019-06-03 19:03:12 iteration: 36450 loss: 0.0053 lr: 0.02
2019-06-03 19:03:23 iteration: 36500 loss: 0.0047 lr: 0.02
2019-06-03 19:03:37 iteration: 36550 loss: 0.0041 lr: 0.02
2019-06-03 19:03:47 iteration: 36600 loss: 0.0051 lr: 0.02
2019-06-03 19:03:58 iteration: 36650 loss: 0.0052 lr: 0.02
2019-06-03 19:04:08 iteration: 36700 loss: 0.0054 lr: 0.02
2019-06-03 19:04:18 iteration: 36750 loss: 0.0045 lr: 0.02
2019-06-03 19:04:29 iteration: 36800 loss: 0.0053 lr: 0.02
2019-06-03 19:04:39 iteration: 36850 loss: 0.0052 lr: 0.02
2019-06-03 19:04:49 iteration: 36900 loss: 0.0047 lr: 0.02
2019-06-03 19:05:01 iteration: 36950 loss: 0.0047 lr: 0.02
2019-06-03 19:05:11 iteration: 37000 loss: 0.0051 lr: 0.02
2019-06-03 19:05:24 iteration: 37050 loss: 0.0050 lr: 0.02
2019-06-03 19:05:34 iteration: 37100 loss: 0.0052 lr: 0.02
2019-06-03 19:05:45 iteration: 37150 loss: 0.0050 lr: 0.02
2019-06-03 19:05:55 iteration: 37200 loss: 0.0043 lr: 0.02
2019-06-03 19:06:06 iteration: 37250 loss: 0.0047 lr: 0.02
2019-06-03 19:06:17 iteration: 37300 loss: 0.0039 lr: 0.02
2019-06-03 19:06:28 iteration: 37350 loss: 0.0042 lr: 0.02
2019-06-03 19:06:38 iteration: 37400 loss: 0.0049 lr: 0.02
2019-06-03 19:06:48 iteration: 37450 loss: 0.0049 lr: 0.02
2019-06-03 19:06:59 iteration: 37500 loss: 0.0045 lr: 0.02
2019-06-03 19:07:12 iteration: 37550 loss: 0.0043 lr: 0.02
2019-06-03 19:07:23 iteration: 37600 loss: 0.0047 lr: 0.02
2019-06-03 19:07:34 iteration: 37650 loss: 0.0049 lr: 0.02
2019-06-03 19:07:45 iteration: 37700 loss: 0.0046 lr: 0.02
2019-06-03 19:07:55 iteration: 37750 loss: 0.0047 lr: 0.02
2019-06-03 19:08:05 iteration: 37800 loss: 0.0052 lr: 0.02
2019-06-03 19:08:16 iteration: 37850 loss: 0.0045 lr: 0.02
2019-06-03 19:08:26 iteration: 37900 loss: 0.0045 lr: 0.02
2019-06-03 19:08:37 iteration: 37950 loss: 0.0046 lr: 0.02
2019-06-03 19:08:48 iteration: 38000 loss: 0.0049 lr: 0.02
2019-06-03 19:09:00 iteration: 38050 loss: 0.0051 lr: 0.02
2019-06-03 19:09:11 iteration: 38100 loss: 0.0043 lr: 0.02
2019-06-03 19:09:22 iteration: 38150 loss: 0.0048 lr: 0.02
2019-06-03 19:09:32 iteration: 38200 loss: 0.0041 lr: 0.02
2019-06-03 19:09:43 iteration: 38250 loss: 0.0047 lr: 0.02
2019-06-03 19:09:53 iteration: 38300 loss: 0.0043 lr: 0.02
2019-06-03 19:10:04 iteration: 38350 loss: 0.0048 lr: 0.02
2019-06-03 19:10:14 iteration: 38400 loss: 0.0054 lr: 0.02
2019-06-03 19:10:25 iteration: 38450 loss: 0.0047 lr: 0.02
2019-06-03 19:10:35 iteration: 38500 loss: 0.0049 lr: 0.02
2019-06-03 19:10:48 iteration: 38550 loss: 0.0053 lr: 0.02
2019-06-03 19:10:59 iteration: 38600 loss: 0.0046 lr: 0.02
2019-06-03 19:11:10 iteration: 38650 loss: 0.0045 lr: 0.02
2019-06-03 19:11:19 iteration: 38700 loss: 0.0049 lr: 0.02
2019-06-03 19:11:29 iteration: 38750 loss: 0.0051 lr: 0.02
2019-06-03 19:11:40 iteration: 38800 loss: 0.0045 lr: 0.02
2019-06-03 19:11:51 iteration: 38850 loss: 0.0041 lr: 0.02
2019-06-03 19:12:02 iteration: 38900 loss: 0.0046 lr: 0.02
2019-06-03 19:12:13 iteration: 38950 loss: 0.0044 lr: 0.02
2019-06-03 19:12:23 iteration: 39000 loss: 0.0042 lr: 0.02
2019-06-03 19:12:36 iteration: 39050 loss: 0.0050 lr: 0.02
2019-06-03 19:12:47 iteration: 39100 loss: 0.0044 lr: 0.02
2019-06-03 19:12:58 iteration: 39150 loss: 0.0040 lr: 0.02
2019-06-03 19:13:08 iteration: 39200 loss: 0.0051 lr: 0.02
2019-06-03 19:13:19 iteration: 39250 loss: 0.0049 lr: 0.02
2019-06-03 19:13:30 iteration: 39300 loss: 0.0044 lr: 0.02
2019-06-03 19:13:40 iteration: 39350 loss: 0.0047 lr: 0.02
2019-06-03 19:13:51 iteration: 39400 loss: 0.0045 lr: 0.02
2019-06-03 19:14:02 iteration: 39450 loss: 0.0045 lr: 0.02
2019-06-03 19:14:12 iteration: 39500 loss: 0.0046 lr: 0.02
2019-06-03 19:14:26 iteration: 39550 loss: 0.0050 lr: 0.02
2019-06-03 19:14:36 iteration: 39600 loss: 0.0041 lr: 0.02
2019-06-03 19:14:48 iteration: 39650 loss: 0.0042 lr: 0.02
2019-06-03 19:14:57 iteration: 39700 loss: 0.0039 lr: 0.02
2019-06-03 19:15:07 iteration: 39750 loss: 0.0048 lr: 0.02
2019-06-03 19:15:18 iteration: 39800 loss: 0.0039 lr: 0.02
2019-06-03 19:15:29 iteration: 39850 loss: 0.0044 lr: 0.02
2019-06-03 19:15:39 iteration: 39900 loss: 0.0044 lr: 0.02
2019-06-03 19:15:50 iteration: 39950 loss: 0.0040 lr: 0.02
2019-06-03 19:16:00 iteration: 40000 loss: 0.0045 lr: 0.02
2019-06-03 19:16:14 iteration: 40050 loss: 0.0038 lr: 0.02
2019-06-03 19:16:23 iteration: 40100 loss: 0.0047 lr: 0.02
2019-06-03 19:16:34 iteration: 40150 loss: 0.0045 lr: 0.02
2019-06-03 19:16:45 iteration: 40200 loss: 0.0041 lr: 0.02
2019-06-03 19:16:55 iteration: 40250 loss: 0.0049 lr: 0.02
2019-06-03 19:17:06 iteration: 40300 loss: 0.0039 lr: 0.02
2019-06-03 19:17:17 iteration: 40350 loss: 0.0046 lr: 0.02
2019-06-03 19:17:27 iteration: 40400 loss: 0.0046 lr: 0.02
2019-06-03 19:17:37 iteration: 40450 loss: 0.0041 lr: 0.02
2019-06-03 19:17:47 iteration: 40500 loss: 0.0043 lr: 0.02
2019-06-03 19:18:00 iteration: 40550 loss: 0.0045 lr: 0.02
2019-06-03 19:18:11 iteration: 40600 loss: 0.0041 lr: 0.02
2019-06-03 19:18:22 iteration: 40650 loss: 0.0039 lr: 0.02
2019-06-03 19:18:32 iteration: 40700 loss: 0.0047 lr: 0.02
2019-06-03 19:18:42 iteration: 40750 loss: 0.0039 lr: 0.02
2019-06-03 19:18:53 iteration: 40800 loss: 0.0043 lr: 0.02
2019-06-03 19:19:04 iteration: 40850 loss: 0.0047 lr: 0.02
2019-06-03 19:19:14 iteration: 40900 loss: 0.0049 lr: 0.02
2019-06-03 19:19:24 iteration: 40950 loss: 0.0044 lr: 0.02
2019-06-03 19:19:35 iteration: 41000 loss: 0.0043 lr: 0.02
2019-06-03 19:19:48 iteration: 41050 loss: 0.0044 lr: 0.02
2019-06-03 19:19:59 iteration: 41100 loss: 0.0041 lr: 0.02
2019-06-03 19:20:08 iteration: 41150 loss: 0.0043 lr: 0.02
2019-06-03 19:20:19 iteration: 41200 loss: 0.0040 lr: 0.02
2019-06-03 19:20:30 iteration: 41250 loss: 0.0047 lr: 0.02
2019-06-03 19:20:40 iteration: 41300 loss: 0.0046 lr: 0.02
2019-06-03 19:20:51 iteration: 41350 loss: 0.0038 lr: 0.02
2019-06-03 19:21:02 iteration: 41400 loss: 0.0042 lr: 0.02
2019-06-03 19:21:13 iteration: 41450 loss: 0.0040 lr: 0.02
2019-06-03 19:21:23 iteration: 41500 loss: 0.0045 lr: 0.02
2019-06-03 19:21:36 iteration: 41550 loss: 0.0042 lr: 0.02
2019-06-03 19:21:47 iteration: 41600 loss: 0.0052 lr: 0.02
2019-06-03 19:21:57 iteration: 41650 loss: 0.0052 lr: 0.02
2019-06-03 19:22:07 iteration: 41700 loss: 0.0042 lr: 0.02
2019-06-03 19:22:18 iteration: 41750 loss: 0.0048 lr: 0.02
2019-06-03 19:22:28 iteration: 41800 loss: 0.0047 lr: 0.02
2019-06-03 19:22:40 iteration: 41850 loss: 0.0044 lr: 0.02
2019-06-03 19:22:51 iteration: 41900 loss: 0.0044 lr: 0.02
2019-06-03 19:23:01 iteration: 41950 loss: 0.0042 lr: 0.02
2019-06-03 19:23:12 iteration: 42000 loss: 0.0037 lr: 0.02
2019-06-03 19:23:25 iteration: 42050 loss: 0.0048 lr: 0.02
2019-06-03 19:23:35 iteration: 42100 loss: 0.0042 lr: 0.02
2019-06-03 19:23:46 iteration: 42150 loss: 0.0046 lr: 0.02
2019-06-03 19:23:56 iteration: 42200 loss: 0.0044 lr: 0.02
2019-06-03 19:24:07 iteration: 42250 loss: 0.0044 lr: 0.02
2019-06-03 19:24:18 iteration: 42300 loss: 0.0037 lr: 0.02
2019-06-03 19:24:28 iteration: 42350 loss: 0.0045 lr: 0.02
2019-06-03 19:24:39 iteration: 42400 loss: 0.0041 lr: 0.02
2019-06-03 19:24:48 iteration: 42450 loss: 0.0047 lr: 0.02
2019-06-03 19:24:59 iteration: 42500 loss: 0.0037 lr: 0.02
2019-06-03 19:25:13 iteration: 42550 loss: 0.0036 lr: 0.02
2019-06-03 19:25:23 iteration: 42600 loss: 0.0039 lr: 0.02
2019-06-03 19:25:34 iteration: 42650 loss: 0.0035 lr: 0.02
2019-06-03 19:25:45 iteration: 42700 loss: 0.0043 lr: 0.02
2019-06-03 19:25:55 iteration: 42750 loss: 0.0049 lr: 0.02
2019-06-03 19:26:05 iteration: 42800 loss: 0.0043 lr: 0.02
2019-06-03 19:26:15 iteration: 42850 loss: 0.0045 lr: 0.02
2019-06-03 19:26:26 iteration: 42900 loss: 0.0044 lr: 0.02
2019-06-03 19:26:37 iteration: 42950 loss: 0.0037 lr: 0.02
2019-06-03 19:26:46 iteration: 43000 loss: 0.0038 lr: 0.02
2019-06-03 19:26:59 iteration: 43050 loss: 0.0042 lr: 0.02
2019-06-03 19:27:10 iteration: 43100 loss: 0.0038 lr: 0.02
2019-06-03 19:27:20 iteration: 43150 loss: 0.0040 lr: 0.02
2019-06-03 19:27:31 iteration: 43200 loss: 0.0034 lr: 0.02
2019-06-03 19:27:42 iteration: 43250 loss: 0.0046 lr: 0.02
2019-06-03 19:27:52 iteration: 43300 loss: 0.0036 lr: 0.02
2019-06-03 19:28:03 iteration: 43350 loss: 0.0040 lr: 0.02
2019-06-03 19:28:14 iteration: 43400 loss: 0.0034 lr: 0.02
2019-06-03 19:28:23 iteration: 43450 loss: 0.0039 lr: 0.02
2019-06-03 19:28:34 iteration: 43500 loss: 0.0039 lr: 0.02
2019-06-03 19:28:47 iteration: 43550 loss: 0.0041 lr: 0.02
2019-06-03 19:28:58 iteration: 43600 loss: 0.0035 lr: 0.02
2019-06-03 19:29:08 iteration: 43650 loss: 0.0043 lr: 0.02
2019-06-03 19:29:18 iteration: 43700 loss: 0.0040 lr: 0.02
2019-06-03 19:29:29 iteration: 43750 loss: 0.0033 lr: 0.02
2019-06-03 19:29:41 iteration: 43800 loss: 0.0037 lr: 0.02
2019-06-03 19:29:52 iteration: 43850 loss: 0.0037 lr: 0.02
2019-06-03 19:30:04 iteration: 43900 loss: 0.0038 lr: 0.02
2019-06-03 19:30:14 iteration: 43950 loss: 0.0036 lr: 0.02
2019-06-03 19:30:24 iteration: 44000 loss: 0.0037 lr: 0.02
2019-06-03 19:30:38 iteration: 44050 loss: 0.0044 lr: 0.02
2019-06-03 19:30:48 iteration: 44100 loss: 0.0037 lr: 0.02
2019-06-03 19:30:59 iteration: 44150 loss: 0.0038 lr: 0.02
2019-06-03 19:31:09 iteration: 44200 loss: 0.0040 lr: 0.02
2019-06-03 19:31:20 iteration: 44250 loss: 0.0029 lr: 0.02
2019-06-03 19:31:31 iteration: 44300 loss: 0.0035 lr: 0.02
2019-06-03 19:31:42 iteration: 44350 loss: 0.0038 lr: 0.02
2019-06-03 19:31:52 iteration: 44400 loss: 0.0034 lr: 0.02
2019-06-03 19:32:03 iteration: 44450 loss: 0.0036 lr: 0.02
2019-06-03 19:32:14 iteration: 44500 loss: 0.0039 lr: 0.02
2019-06-03 19:32:27 iteration: 44550 loss: 0.0045 lr: 0.02
2019-06-03 19:32:38 iteration: 44600 loss: 0.0035 lr: 0.02
2019-06-03 19:32:49 iteration: 44650 loss: 0.0041 lr: 0.02
2019-06-03 19:32:59 iteration: 44700 loss: 0.0042 lr: 0.02
2019-06-03 19:33:10 iteration: 44750 loss: 0.0044 lr: 0.02
2019-06-03 19:33:21 iteration: 44800 loss: 0.0039 lr: 0.02
2019-06-03 19:33:31 iteration: 44850 loss: 0.0040 lr: 0.02
2019-06-03 19:33:42 iteration: 44900 loss: 0.0035 lr: 0.02
2019-06-03 19:33:53 iteration: 44950 loss: 0.0034 lr: 0.02
2019-06-03 19:34:04 iteration: 45000 loss: 0.0037 lr: 0.02
2019-06-03 19:34:17 iteration: 45050 loss: 0.0038 lr: 0.02
2019-06-03 19:34:29 iteration: 45100 loss: 0.0035 lr: 0.02
2019-06-03 19:34:39 iteration: 45150 loss: 0.0037 lr: 0.02
2019-06-03 19:34:49 iteration: 45200 loss: 0.0035 lr: 0.02
2019-06-03 19:35:00 iteration: 45250 loss: 0.0036 lr: 0.02
2019-06-03 19:35:09 iteration: 45300 loss: 0.0035 lr: 0.02
2019-06-03 19:35:20 iteration: 45350 loss: 0.0038 lr: 0.02
2019-06-03 19:35:31 iteration: 45400 loss: 0.0035 lr: 0.02
2019-06-03 19:35:42 iteration: 45450 loss: 0.0043 lr: 0.02
2019-06-03 19:35:52 iteration: 45500 loss: 0.0040 lr: 0.02
2019-06-03 19:36:05 iteration: 45550 loss: 0.0036 lr: 0.02
2019-06-03 19:36:16 iteration: 45600 loss: 0.0038 lr: 0.02
2019-06-03 19:36:26 iteration: 45650 loss: 0.0039 lr: 0.02
2019-06-03 19:36:37 iteration: 45700 loss: 0.0036 lr: 0.02
2019-06-03 19:36:47 iteration: 45750 loss: 0.0045 lr: 0.02
2019-06-03 19:36:57 iteration: 45800 loss: 0.0041 lr: 0.02
2019-06-03 19:37:08 iteration: 45850 loss: 0.0038 lr: 0.02
2019-06-03 19:37:18 iteration: 45900 loss: 0.0051 lr: 0.02
2019-06-03 19:37:28 iteration: 45950 loss: 0.0040 lr: 0.02
2019-06-03 19:37:39 iteration: 46000 loss: 0.0039 lr: 0.02
2019-06-03 19:37:53 iteration: 46050 loss: 0.0041 lr: 0.02
2019-06-03 19:38:04 iteration: 46100 loss: 0.0036 lr: 0.02
2019-06-03 19:38:14 iteration: 46150 loss: 0.0034 lr: 0.02
2019-06-03 19:38:25 iteration: 46200 loss: 0.0035 lr: 0.02
2019-06-03 19:38:36 iteration: 46250 loss: 0.0040 lr: 0.02
2019-06-03 19:38:47 iteration: 46300 loss: 0.0041 lr: 0.02
2019-06-03 19:38:58 iteration: 46350 loss: 0.0037 lr: 0.02
2019-06-03 19:39:08 iteration: 46400 loss: 0.0037 lr: 0.02
2019-06-03 19:39:19 iteration: 46450 loss: 0.0032 lr: 0.02
2019-06-03 19:39:28 iteration: 46500 loss: 0.0048 lr: 0.02
2019-06-03 19:39:42 iteration: 46550 loss: 0.0040 lr: 0.02
2019-06-03 19:39:53 iteration: 46600 loss: 0.0036 lr: 0.02
2019-06-03 19:40:03 iteration: 46650 loss: 0.0031 lr: 0.02
2019-06-03 19:40:15 iteration: 46700 loss: 0.0040 lr: 0.02
2019-06-03 19:40:25 iteration: 46750 loss: 0.0039 lr: 0.02
2019-06-03 19:40:36 iteration: 46800 loss: 0.0036 lr: 0.02
2019-06-03 19:40:47 iteration: 46850 loss: 0.0033 lr: 0.02
2019-06-03 19:40:58 iteration: 46900 loss: 0.0039 lr: 0.02
2019-06-03 19:41:08 iteration: 46950 loss: 0.0035 lr: 0.02
2019-06-03 19:41:19 iteration: 47000 loss: 0.0037 lr: 0.02
2019-06-03 19:41:31 iteration: 47050 loss: 0.0043 lr: 0.02
2019-06-03 19:41:41 iteration: 47100 loss: 0.0040 lr: 0.02
2019-06-03 19:41:52 iteration: 47150 loss: 0.0037 lr: 0.02
2019-06-03 19:42:02 iteration: 47200 loss: 0.0039 lr: 0.02
2019-06-03 19:42:13 iteration: 47250 loss: 0.0041 lr: 0.02
2019-06-03 19:42:23 iteration: 47300 loss: 0.0034 lr: 0.02
2019-06-03 19:42:34 iteration: 47350 loss: 0.0038 lr: 0.02
2019-06-03 19:42:45 iteration: 47400 loss: 0.0036 lr: 0.02
2019-06-03 19:42:56 iteration: 47450 loss: 0.0035 lr: 0.02
2019-06-03 19:43:07 iteration: 47500 loss: 0.0032 lr: 0.02
2019-06-03 19:43:20 iteration: 47550 loss: 0.0031 lr: 0.02
2019-06-03 19:43:30 iteration: 47600 loss: 0.0041 lr: 0.02
2019-06-03 19:43:40 iteration: 47650 loss: 0.0040 lr: 0.02
2019-06-03 19:43:51 iteration: 47700 loss: 0.0039 lr: 0.02
2019-06-03 19:44:02 iteration: 47750 loss: 0.0038 lr: 0.02
2019-06-03 19:44:12 iteration: 47800 loss: 0.0037 lr: 0.02
2019-06-03 19:44:22 iteration: 47850 loss: 0.0041 lr: 0.02
2019-06-03 19:44:33 iteration: 47900 loss: 0.0032 lr: 0.02
2019-06-03 19:44:44 iteration: 47950 loss: 0.0027 lr: 0.02
2019-06-03 19:44:55 iteration: 48000 loss: 0.0031 lr: 0.02
2019-06-03 19:45:08 iteration: 48050 loss: 0.0036 lr: 0.02
2019-06-03 19:45:19 iteration: 48100 loss: 0.0031 lr: 0.02
2019-06-03 19:45:30 iteration: 48150 loss: 0.0031 lr: 0.02
2019-06-03 19:45:41 iteration: 48200 loss: 0.0027 lr: 0.02
2019-06-03 19:45:52 iteration: 48250 loss: 0.0031 lr: 0.02
2019-06-03 19:46:02 iteration: 48300 loss: 0.0035 lr: 0.02
2019-06-03 19:46:12 iteration: 48350 loss: 0.0037 lr: 0.02
2019-06-03 19:46:22 iteration: 48400 loss: 0.0035 lr: 0.02
2019-06-03 19:46:33 iteration: 48450 loss: 0.0037 lr: 0.02
2019-06-03 19:46:43 iteration: 48500 loss: 0.0041 lr: 0.02
2019-06-03 19:46:57 iteration: 48550 loss: 0.0036 lr: 0.02
2019-06-03 19:47:08 iteration: 48600 loss: 0.0032 lr: 0.02
2019-06-03 19:47:19 iteration: 48650 loss: 0.0035 lr: 0.02
2019-06-03 19:47:30 iteration: 48700 loss: 0.0026 lr: 0.02
2019-06-03 19:47:40 iteration: 48750 loss: 0.0034 lr: 0.02
2019-06-03 19:47:51 iteration: 48800 loss: 0.0037 lr: 0.02
2019-06-03 19:48:01 iteration: 48850 loss: 0.0036 lr: 0.02
2019-06-03 19:48:12 iteration: 48900 loss: 0.0034 lr: 0.02
2019-06-03 19:48:22 iteration: 48950 loss: 0.0037 lr: 0.02
2019-06-03 19:48:33 iteration: 49000 loss: 0.0038 lr: 0.02
2019-06-03 19:48:47 iteration: 49050 loss: 0.0033 lr: 0.02
2019-06-03 19:48:57 iteration: 49100 loss: 0.0032 lr: 0.02
2019-06-03 19:49:07 iteration: 49150 loss: 0.0035 lr: 0.02
2019-06-03 19:49:18 iteration: 49200 loss: 0.0032 lr: 0.02
2019-06-03 19:49:29 iteration: 49250 loss: 0.0032 lr: 0.02
2019-06-03 19:49:39 iteration: 49300 loss: 0.0039 lr: 0.02
2019-06-03 19:49:50 iteration: 49350 loss: 0.0036 lr: 0.02
2019-06-03 19:50:00 iteration: 49400 loss: 0.0034 lr: 0.02
2019-06-03 19:50:10 iteration: 49450 loss: 0.0038 lr: 0.02
2019-06-03 19:50:21 iteration: 49500 loss: 0.0035 lr: 0.02
2019-06-03 19:50:34 iteration: 49550 loss: 0.0036 lr: 0.02
2019-06-03 19:50:45 iteration: 49600 loss: 0.0034 lr: 0.02
2019-06-03 19:50:55 iteration: 49650 loss: 0.0039 lr: 0.02
2019-06-03 19:51:05 iteration: 49700 loss: 0.0035 lr: 0.02
2019-06-03 19:51:16 iteration: 49750 loss: 0.0033 lr: 0.02
2019-06-03 19:51:27 iteration: 49800 loss: 0.0036 lr: 0.02
2019-06-03 19:51:38 iteration: 49850 loss: 0.0034 lr: 0.02
2019-06-03 19:51:48 iteration: 49900 loss: 0.0042 lr: 0.02
2019-06-03 19:51:58 iteration: 49950 loss: 0.0034 lr: 0.02
2019-06-03 19:52:09 iteration: 50000 loss: 0.0032 lr: 0.02
2019-06-03 19:52:22 iteration: 50050 loss: 0.0029 lr: 0.02
2019-06-03 19:52:33 iteration: 50100 loss: 0.0034 lr: 0.02
2019-06-03 19:52:44 iteration: 50150 loss: 0.0032 lr: 0.02
2019-06-03 19:52:54 iteration: 50200 loss: 0.0040 lr: 0.02
2019-06-03 19:53:05 iteration: 50250 loss: 0.0033 lr: 0.02
2019-06-03 19:53:16 iteration: 50300 loss: 0.0033 lr: 0.02
2019-06-03 19:53:26 iteration: 50350 loss: 0.0036 lr: 0.02
2019-06-03 19:53:37 iteration: 50400 loss: 0.0034 lr: 0.02
2019-06-03 19:53:47 iteration: 50450 loss: 0.0040 lr: 0.02
2019-06-03 19:53:57 iteration: 50500 loss: 0.0040 lr: 0.02
2019-06-03 19:54:11 iteration: 50550 loss: 0.0033 lr: 0.02
2019-06-03 19:54:22 iteration: 50600 loss: 0.0028 lr: 0.02
2019-06-03 19:54:33 iteration: 50650 loss: 0.0029 lr: 0.02
2019-06-03 19:54:43 iteration: 50700 loss: 0.0030 lr: 0.02
2019-06-03 19:54:54 iteration: 50750 loss: 0.0030 lr: 0.02
2019-06-03 19:55:05 iteration: 50800 loss: 0.0035 lr: 0.02
2019-06-03 19:55:16 iteration: 50850 loss: 0.0034 lr: 0.02
2019-06-03 19:55:27 iteration: 50900 loss: 0.0035 lr: 0.02
2019-06-03 19:55:36 iteration: 50950 loss: 0.0035 lr: 0.02
2019-06-03 19:55:46 iteration: 51000 loss: 0.0032 lr: 0.02
2019-06-03 19:56:00 iteration: 51050 loss: 0.0033 lr: 0.02
2019-06-03 19:56:11 iteration: 51100 loss: 0.0033 lr: 0.02
2019-06-03 19:56:22 iteration: 51150 loss: 0.0031 lr: 0.02
2019-06-03 19:56:32 iteration: 51200 loss: 0.0029 lr: 0.02
2019-06-03 19:56:43 iteration: 51250 loss: 0.0034 lr: 0.02
2019-06-03 19:56:54 iteration: 51300 loss: 0.0035 lr: 0.02
2019-06-03 19:57:03 iteration: 51350 loss: 0.0033 lr: 0.02
2019-06-03 19:57:14 iteration: 51400 loss: 0.0033 lr: 0.02
2019-06-03 19:57:25 iteration: 51450 loss: 0.0033 lr: 0.02
2019-06-03 19:57:35 iteration: 51500 loss: 0.0032 lr: 0.02
2019-06-03 19:57:49 iteration: 51550 loss: 0.0043 lr: 0.02
2019-06-03 19:57:59 iteration: 51600 loss: 0.0040 lr: 0.02
2019-06-03 19:58:09 iteration: 51650 loss: 0.0032 lr: 0.02
2019-06-03 19:58:20 iteration: 51700 loss: 0.0024 lr: 0.02
2019-06-03 19:58:30 iteration: 51750 loss: 0.0034 lr: 0.02
2019-06-03 19:58:41 iteration: 51800 loss: 0.0035 lr: 0.02
2019-06-03 19:58:52 iteration: 51850 loss: 0.0032 lr: 0.02
2019-06-03 19:59:03 iteration: 51900 loss: 0.0030 lr: 0.02
2019-06-03 19:59:13 iteration: 51950 loss: 0.0037 lr: 0.02
2019-06-03 19:59:24 iteration: 52000 loss: 0.0034 lr: 0.02
2019-06-03 19:59:37 iteration: 52050 loss: 0.0030 lr: 0.02
2019-06-03 19:59:48 iteration: 52100 loss: 0.0027 lr: 0.02
2019-06-03 20:00:00 iteration: 52150 loss: 0.0030 lr: 0.02
2019-06-03 20:00:10 iteration: 52200 loss: 0.0033 lr: 0.02
2019-06-03 20:00:20 iteration: 52250 loss: 0.0033 lr: 0.02
2019-06-03 20:00:31 iteration: 52300 loss: 0.0040 lr: 0.02
2019-06-03 20:00:41 iteration: 52350 loss: 0.0031 lr: 0.02
2019-06-03 20:00:51 iteration: 52400 loss: 0.0031 lr: 0.02
2019-06-03 20:01:02 iteration: 52450 loss: 0.0027 lr: 0.02
2019-06-03 20:01:13 iteration: 52500 loss: 0.0031 lr: 0.02
2019-06-03 20:01:26 iteration: 52550 loss: 0.0035 lr: 0.02
2019-06-03 20:01:37 iteration: 52600 loss: 0.0030 lr: 0.02
2019-06-03 20:01:47 iteration: 52650 loss: 0.0032 lr: 0.02
2019-06-03 20:01:58 iteration: 52700 loss: 0.0035 lr: 0.02
2019-06-03 20:02:09 iteration: 52750 loss: 0.0031 lr: 0.02
2019-06-03 20:02:20 iteration: 52800 loss: 0.0030 lr: 0.02
2019-06-03 20:02:31 iteration: 52850 loss: 0.0038 lr: 0.02
2019-06-03 20:02:40 iteration: 52900 loss: 0.0033 lr: 0.02
2019-06-03 20:02:50 iteration: 52950 loss: 0.0037 lr: 0.02
2019-06-03 20:03:00 iteration: 53000 loss: 0.0039 lr: 0.02
2019-06-03 20:03:14 iteration: 53050 loss: 0.0031 lr: 0.02
2019-06-03 20:03:24 iteration: 53100 loss: 0.0032 lr: 0.02
2019-06-03 20:03:35 iteration: 53150 loss: 0.0038 lr: 0.02
2019-06-03 20:03:46 iteration: 53200 loss: 0.0032 lr: 0.02
2019-06-03 20:03:56 iteration: 53250 loss: 0.0031 lr: 0.02
2019-06-03 20:04:07 iteration: 53300 loss: 0.0029 lr: 0.02
2019-06-03 20:04:18 iteration: 53350 loss: 0.0030 lr: 0.02
2019-06-03 20:04:28 iteration: 53400 loss: 0.0030 lr: 0.02
2019-06-03 20:04:39 iteration: 53450 loss: 0.0026 lr: 0.02
2019-06-03 20:04:50 iteration: 53500 loss: 0.0033 lr: 0.02
2019-06-03 20:05:03 iteration: 53550 loss: 0.0034 lr: 0.02
2019-06-03 20:05:13 iteration: 53600 loss: 0.0031 lr: 0.02
2019-06-03 20:05:24 iteration: 53650 loss: 0.0036 lr: 0.02
2019-06-03 20:05:34 iteration: 53700 loss: 0.0036 lr: 0.02
2019-06-03 20:05:44 iteration: 53750 loss: 0.0034 lr: 0.02
2019-06-03 20:05:55 iteration: 53800 loss: 0.0029 lr: 0.02
2019-06-03 20:06:06 iteration: 53850 loss: 0.0034 lr: 0.02
2019-06-03 20:06:16 iteration: 53900 loss: 0.0031 lr: 0.02
2019-06-03 20:06:27 iteration: 53950 loss: 0.0029 lr: 0.02
2019-06-03 20:06:38 iteration: 54000 loss: 0.0032 lr: 0.02
2019-06-03 20:06:51 iteration: 54050 loss: 0.0033 lr: 0.02
2019-06-03 20:07:01 iteration: 54100 loss: 0.0034 lr: 0.02
2019-06-03 20:07:13 iteration: 54150 loss: 0.0028 lr: 0.02
2019-06-03 20:07:24 iteration: 54200 loss: 0.0027 lr: 0.02
2019-06-03 20:07:34 iteration: 54250 loss: 0.0035 lr: 0.02
2019-06-03 20:07:45 iteration: 54300 loss: 0.0032 lr: 0.02
2019-06-03 20:07:55 iteration: 54350 loss: 0.0035 lr: 0.02
2019-06-03 20:08:05 iteration: 54400 loss: 0.0032 lr: 0.02
2019-06-03 20:08:16 iteration: 54450 loss: 0.0037 lr: 0.02
2019-06-03 20:08:27 iteration: 54500 loss: 0.0033 lr: 0.02
2019-06-03 20:08:40 iteration: 54550 loss: 0.0029 lr: 0.02
2019-06-03 20:08:51 iteration: 54600 loss: 0.0031 lr: 0.02
2019-06-03 20:09:02 iteration: 54650 loss: 0.0030 lr: 0.02
2019-06-03 20:09:13 iteration: 54700 loss: 0.0031 lr: 0.02
2019-06-03 20:09:22 iteration: 54750 loss: 0.0037 lr: 0.02
2019-06-03 20:09:33 iteration: 54800 loss: 0.0035 lr: 0.02
2019-06-03 20:09:43 iteration: 54850 loss: 0.0032 lr: 0.02
2019-06-03 20:09:53 iteration: 54900 loss: 0.0029 lr: 0.02
2019-06-03 20:10:04 iteration: 54950 loss: 0.0029 lr: 0.02
2019-06-03 20:10:14 iteration: 55000 loss: 0.0034 lr: 0.02
2019-06-03 20:10:28 iteration: 55050 loss: 0.0030 lr: 0.02
2019-06-03 20:10:39 iteration: 55100 loss: 0.0025 lr: 0.02
2019-06-03 20:10:50 iteration: 55150 loss: 0.0026 lr: 0.02
2019-06-03 20:11:02 iteration: 55200 loss: 0.0030 lr: 0.02
2019-06-03 20:11:11 iteration: 55250 loss: 0.0028 lr: 0.02
2019-06-03 20:11:22 iteration: 55300 loss: 0.0032 lr: 0.02
2019-06-03 20:11:32 iteration: 55350 loss: 0.0026 lr: 0.02
2019-06-03 20:11:43 iteration: 55400 loss: 0.0029 lr: 0.02
2019-06-03 20:11:53 iteration: 55450 loss: 0.0031 lr: 0.02
2019-06-03 20:12:03 iteration: 55500 loss: 0.0030 lr: 0.02
2019-06-03 20:12:17 iteration: 55550 loss: 0.0030 lr: 0.02
2019-06-03 20:12:27 iteration: 55600 loss: 0.0035 lr: 0.02
2019-06-03 20:12:38 iteration: 55650 loss: 0.0029 lr: 0.02
2019-06-03 20:12:48 iteration: 55700 loss: 0.0032 lr: 0.02
2019-06-03 20:12:59 iteration: 55750 loss: 0.0026 lr: 0.02
2019-06-03 20:13:10 iteration: 55800 loss: 0.0038 lr: 0.02
2019-06-03 20:13:20 iteration: 55850 loss: 0.0033 lr: 0.02
2019-06-03 20:13:31 iteration: 55900 loss: 0.0033 lr: 0.02
2019-06-03 20:13:42 iteration: 55950 loss: 0.0029 lr: 0.02
2019-06-03 20:13:52 iteration: 56000 loss: 0.0038 lr: 0.02
2019-06-03 20:14:06 iteration: 56050 loss: 0.0036 lr: 0.02
2019-06-03 20:14:17 iteration: 56100 loss: 0.0031 lr: 0.02
2019-06-03 20:14:27 iteration: 56150 loss: 0.0024 lr: 0.02
2019-06-03 20:14:37 iteration: 56200 loss: 0.0030 lr: 0.02
2019-06-03 20:14:48 iteration: 56250 loss: 0.0030 lr: 0.02
2019-06-03 20:14:58 iteration: 56300 loss: 0.0028 lr: 0.02
2019-06-03 20:15:09 iteration: 56350 loss: 0.0032 lr: 0.02
2019-06-03 20:15:21 iteration: 56400 loss: 0.0025 lr: 0.02
2019-06-03 20:15:31 iteration: 56450 loss: 0.0026 lr: 0.02
2019-06-03 20:15:41 iteration: 56500 loss: 0.0026 lr: 0.02
2019-06-03 20:15:55 iteration: 56550 loss: 0.0031 lr: 0.02
2019-06-03 20:16:06 iteration: 56600 loss: 0.0032 lr: 0.02
2019-06-03 20:16:16 iteration: 56650 loss: 0.0029 lr: 0.02
2019-06-03 20:16:27 iteration: 56700 loss: 0.0030 lr: 0.02
2019-06-03 20:16:38 iteration: 56750 loss: 0.0030 lr: 0.02
2019-06-03 20:16:48 iteration: 56800 loss: 0.0028 lr: 0.02
2019-06-03 20:17:00 iteration: 56850 loss: 0.0028 lr: 0.02
2019-06-03 20:17:10 iteration: 56900 loss: 0.0028 lr: 0.02
2019-06-03 20:17:20 iteration: 56950 loss: 0.0028 lr: 0.02
2019-06-03 20:17:31 iteration: 57000 loss: 0.0025 lr: 0.02
2019-06-03 20:17:44 iteration: 57050 loss: 0.0022 lr: 0.02
2019-06-03 20:17:55 iteration: 57100 loss: 0.0027 lr: 0.02
2019-06-03 20:18:06 iteration: 57150 loss: 0.0024 lr: 0.02
2019-06-03 20:18:17 iteration: 57200 loss: 0.0030 lr: 0.02
2019-06-03 20:18:27 iteration: 57250 loss: 0.0026 lr: 0.02
2019-06-03 20:18:38 iteration: 57300 loss: 0.0027 lr: 0.02
2019-06-03 20:18:49 iteration: 57350 loss: 0.0030 lr: 0.02
2019-06-03 20:18:59 iteration: 57400 loss: 0.0030 lr: 0.02
2019-06-03 20:19:10 iteration: 57450 loss: 0.0028 lr: 0.02
2019-06-03 20:19:20 iteration: 57500 loss: 0.0030 lr: 0.02
2019-06-03 20:19:34 iteration: 57550 loss: 0.0029 lr: 0.02
2019-06-03 20:19:44 iteration: 57600 loss: 0.0028 lr: 0.02
2019-06-03 20:19:55 iteration: 57650 loss: 0.0029 lr: 0.02
2019-06-03 20:20:06 iteration: 57700 loss: 0.0035 lr: 0.02
2019-06-03 20:20:17 iteration: 57750 loss: 0.0027 lr: 0.02
2019-06-03 20:20:27 iteration: 57800 loss: 0.0028 lr: 0.02
2019-06-03 20:20:38 iteration: 57850 loss: 0.0034 lr: 0.02
2019-06-03 20:20:48 iteration: 57900 loss: 0.0026 lr: 0.02
2019-06-03 20:20:59 iteration: 57950 loss: 0.0027 lr: 0.02
2019-06-03 20:21:10 iteration: 58000 loss: 0.0027 lr: 0.02
2019-06-03 20:21:23 iteration: 58050 loss: 0.0030 lr: 0.02
2019-06-03 20:21:34 iteration: 58100 loss: 0.0027 lr: 0.02
2019-06-03 20:21:45 iteration: 58150 loss: 0.0022 lr: 0.02
2019-06-03 20:21:55 iteration: 58200 loss: 0.0028 lr: 0.02
2019-06-03 20:22:05 iteration: 58250 loss: 0.0034 lr: 0.02
2019-06-03 20:22:16 iteration: 58300 loss: 0.0028 lr: 0.02
2019-06-03 20:22:26 iteration: 58350 loss: 0.0034 lr: 0.02
2019-06-03 20:22:37 iteration: 58400 loss: 0.0030 lr: 0.02
2019-06-03 20:22:47 iteration: 58450 loss: 0.0027 lr: 0.02
2019-06-03 20:22:57 iteration: 58500 loss: 0.0032 lr: 0.02
2019-06-03 20:23:11 iteration: 58550 loss: 0.0035 lr: 0.02
2019-06-03 20:23:21 iteration: 58600 loss: 0.0030 lr: 0.02
2019-06-03 20:23:32 iteration: 58650 loss: 0.0031 lr: 0.02
2019-06-03 20:23:42 iteration: 58700 loss: 0.0031 lr: 0.02
2019-06-03 20:23:53 iteration: 58750 loss: 0.0037 lr: 0.02
2019-06-03 20:24:04 iteration: 58800 loss: 0.0025 lr: 0.02
2019-06-03 20:24:16 iteration: 58850 loss: 0.0022 lr: 0.02
2019-06-03 20:24:26 iteration: 58900 loss: 0.0030 lr: 0.02
2019-06-03 20:24:36 iteration: 58950 loss: 0.0033 lr: 0.02
2019-06-03 20:24:46 iteration: 59000 loss: 0.0034 lr: 0.02
2019-06-03 20:24:59 iteration: 59050 loss: 0.0024 lr: 0.02
2019-06-03 20:25:10 iteration: 59100 loss: 0.0029 lr: 0.02
2019-06-03 20:25:21 iteration: 59150 loss: 0.0032 lr: 0.02
2019-06-03 20:25:31 iteration: 59200 loss: 0.0028 lr: 0.02
2019-06-03 20:25:41 iteration: 59250 loss: 0.0030 lr: 0.02
2019-06-03 20:25:52 iteration: 59300 loss: 0.0030 lr: 0.02
2019-06-03 20:26:03 iteration: 59350 loss: 0.0031 lr: 0.02
2019-06-03 20:26:13 iteration: 59400 loss: 0.0025 lr: 0.02
2019-06-03 20:26:24 iteration: 59450 loss: 0.0029 lr: 0.02
2019-06-03 20:26:34 iteration: 59500 loss: 0.0028 lr: 0.02
2019-06-03 20:26:48 iteration: 59550 loss: 0.0028 lr: 0.02
2019-06-03 20:26:59 iteration: 59600 loss: 0.0030 lr: 0.02
2019-06-03 20:27:09 iteration: 59650 loss: 0.0028 lr: 0.02
2019-06-03 20:27:20 iteration: 59700 loss: 0.0026 lr: 0.02
2019-06-03 20:27:31 iteration: 59750 loss: 0.0025 lr: 0.02
2019-06-03 20:27:41 iteration: 59800 loss: 0.0037 lr: 0.02
2019-06-03 20:27:52 iteration: 59850 loss: 0.0028 lr: 0.02
2019-06-03 20:28:03 iteration: 59900 loss: 0.0025 lr: 0.02
2019-06-03 20:28:13 iteration: 59950 loss: 0.0024 lr: 0.02
2019-06-03 20:28:24 iteration: 60000 loss: 0.0024 lr: 0.02
2019-06-03 20:28:37 iteration: 60050 loss: 0.0026 lr: 0.02
2019-06-03 20:28:48 iteration: 60100 loss: 0.0029 lr: 0.02
2019-06-03 20:28:59 iteration: 60150 loss: 0.0032 lr: 0.02
2019-06-03 20:29:09 iteration: 60200 loss: 0.0032 lr: 0.02
2019-06-03 20:29:20 iteration: 60250 loss: 0.0029 lr: 0.02
2019-06-03 20:29:30 iteration: 60300 loss: 0.0024 lr: 0.02
2019-06-03 20:29:41 iteration: 60350 loss: 0.0024 lr: 0.02
2019-06-03 20:29:52 iteration: 60400 loss: 0.0026 lr: 0.02
2019-06-03 20:30:03 iteration: 60450 loss: 0.0028 lr: 0.02
2019-06-03 20:30:13 iteration: 60500 loss: 0.0030 lr: 0.02
2019-06-03 20:30:27 iteration: 60550 loss: 0.0033 lr: 0.02
2019-06-03 20:30:37 iteration: 60600 loss: 0.0033 lr: 0.02
2019-06-03 20:30:47 iteration: 60650 loss: 0.0023 lr: 0.02
2019-06-03 20:30:58 iteration: 60700 loss: 0.0029 lr: 0.02
2019-06-03 20:31:08 iteration: 60750 loss: 0.0023 lr: 0.02
2019-06-03 20:31:19 iteration: 60800 loss: 0.0026 lr: 0.02
2019-06-03 20:31:29 iteration: 60850 loss: 0.0030 lr: 0.02
2019-06-03 20:31:41 iteration: 60900 loss: 0.0030 lr: 0.02
2019-06-03 20:31:51 iteration: 60950 loss: 0.0031 lr: 0.02
2019-06-03 20:32:02 iteration: 61000 loss: 0.0030 lr: 0.02
2019-06-03 20:32:16 iteration: 61050 loss: 0.0029 lr: 0.02
2019-06-03 20:32:27 iteration: 61100 loss: 0.0025 lr: 0.02
2019-06-03 20:32:38 iteration: 61150 loss: 0.0024 lr: 0.02
2019-06-03 20:32:49 iteration: 61200 loss: 0.0023 lr: 0.02
2019-06-03 20:33:00 iteration: 61250 loss: 0.0028 lr: 0.02
2019-06-03 20:33:11 iteration: 61300 loss: 0.0029 lr: 0.02
2019-06-03 20:33:21 iteration: 61350 loss: 0.0033 lr: 0.02
2019-06-03 20:33:32 iteration: 61400 loss: 0.0025 lr: 0.02
2019-06-03 20:33:42 iteration: 61450 loss: 0.0028 lr: 0.02
2019-06-03 20:33:53 iteration: 61500 loss: 0.0029 lr: 0.02
2019-06-03 20:34:07 iteration: 61550 loss: 0.0024 lr: 0.02
2019-06-03 20:34:18 iteration: 61600 loss: 0.0030 lr: 0.02
2019-06-03 20:34:28 iteration: 61650 loss: 0.0024 lr: 0.02
2019-06-03 20:34:39 iteration: 61700 loss: 0.0032 lr: 0.02
2019-06-03 20:34:50 iteration: 61750 loss: 0.0026 lr: 0.02
2019-06-03 20:35:01 iteration: 61800 loss: 0.0025 lr: 0.02
2019-06-03 20:35:12 iteration: 61850 loss: 0.0027 lr: 0.02
2019-06-03 20:35:24 iteration: 61900 loss: 0.0027 lr: 0.02
2019-06-03 20:35:35 iteration: 61950 loss: 0.0024 lr: 0.02
2019-06-03 20:35:46 iteration: 62000 loss: 0.0023 lr: 0.02
2019-06-03 20:36:00 iteration: 62050 loss: 0.0023 lr: 0.02
2019-06-03 20:36:11 iteration: 62100 loss: 0.0022 lr: 0.02
2019-06-03 20:36:22 iteration: 62150 loss: 0.0026 lr: 0.02
2019-06-03 20:36:32 iteration: 62200 loss: 0.0027 lr: 0.02
2019-06-03 20:36:43 iteration: 62250 loss: 0.0035 lr: 0.02
2019-06-03 20:36:54 iteration: 62300 loss: 0.0031 lr: 0.02
2019-06-03 20:37:04 iteration: 62350 loss: 0.0026 lr: 0.02
2019-06-03 20:37:15 iteration: 62400 loss: 0.0026 lr: 0.02
2019-06-03 20:37:26 iteration: 62450 loss: 0.0028 lr: 0.02
2019-06-03 20:37:36 iteration: 62500 loss: 0.0027 lr: 0.02
2019-06-03 20:37:51 iteration: 62550 loss: 0.0025 lr: 0.02
2019-06-03 20:38:02 iteration: 62600 loss: 0.0028 lr: 0.02
2019-06-03 20:38:13 iteration: 62650 loss: 0.0024 lr: 0.02
2019-06-03 20:38:24 iteration: 62700 loss: 0.0028 lr: 0.02
2019-06-03 20:38:34 iteration: 62750 loss: 0.0026 lr: 0.02
2019-06-03 20:38:45 iteration: 62800 loss: 0.0026 lr: 0.02
2019-06-03 20:38:56 iteration: 62850 loss: 0.0025 lr: 0.02
2019-06-03 20:39:07 iteration: 62900 loss: 0.0029 lr: 0.02
2019-06-03 20:39:18 iteration: 62950 loss: 0.0031 lr: 0.02
2019-06-03 20:39:29 iteration: 63000 loss: 0.0025 lr: 0.02
2019-06-03 20:39:43 iteration: 63050 loss: 0.0020 lr: 0.02
2019-06-03 20:39:54 iteration: 63100 loss: 0.0024 lr: 0.02
2019-06-03 20:40:06 iteration: 63150 loss: 0.0021 lr: 0.02
2019-06-03 20:40:16 iteration: 63200 loss: 0.0028 lr: 0.02
2019-06-03 20:40:27 iteration: 63250 loss: 0.0029 lr: 0.02
2019-06-03 20:40:37 iteration: 63300 loss: 0.0026 lr: 0.02
2019-06-03 20:40:48 iteration: 63350 loss: 0.0026 lr: 0.02
2019-06-03 20:40:58 iteration: 63400 loss: 0.0026 lr: 0.02
2019-06-03 20:41:10 iteration: 63450 loss: 0.0024 lr: 0.02
2019-06-03 20:41:20 iteration: 63500 loss: 0.0028 lr: 0.02
2019-06-03 20:41:34 iteration: 63550 loss: 0.0031 lr: 0.02
2019-06-03 20:41:44 iteration: 63600 loss: 0.0027 lr: 0.02
2019-06-03 20:41:55 iteration: 63650 loss: 0.0022 lr: 0.02
2019-06-03 20:42:06 iteration: 63700 loss: 0.0023 lr: 0.02
2019-06-03 20:42:16 iteration: 63750 loss: 0.0036 lr: 0.02
2019-06-03 20:42:28 iteration: 63800 loss: 0.0028 lr: 0.02
2019-06-03 20:42:38 iteration: 63850 loss: 0.0023 lr: 0.02
2019-06-03 20:42:48 iteration: 63900 loss: 0.0029 lr: 0.02
2019-06-03 20:42:59 iteration: 63950 loss: 0.0027 lr: 0.02
2019-06-03 20:43:10 iteration: 64000 loss: 0.0028 lr: 0.02
2019-06-03 20:43:24 iteration: 64050 loss: 0.0024 lr: 0.02
2019-06-03 20:43:35 iteration: 64100 loss: 0.0026 lr: 0.02
2019-06-03 20:43:46 iteration: 64150 loss: 0.0027 lr: 0.02
2019-06-03 20:43:56 iteration: 64200 loss: 0.0026 lr: 0.02
2019-06-03 20:44:06 iteration: 64250 loss: 0.0025 lr: 0.02
2019-06-03 20:44:17 iteration: 64300 loss: 0.0024 lr: 0.02
2019-06-03 20:44:28 iteration: 64350 loss: 0.0023 lr: 0.02
2019-06-03 20:44:40 iteration: 64400 loss: 0.0024 lr: 0.02
2019-06-03 20:44:50 iteration: 64450 loss: 0.0025 lr: 0.02
2019-06-03 20:45:01 iteration: 64500 loss: 0.0024 lr: 0.02
2019-06-03 20:45:14 iteration: 64550 loss: 0.0024 lr: 0.02
2019-06-03 20:45:25 iteration: 64600 loss: 0.0028 lr: 0.02
2019-06-03 20:45:37 iteration: 64650 loss: 0.0022 lr: 0.02
2019-06-03 20:45:47 iteration: 64700 loss: 0.0029 lr: 0.02
2019-06-03 20:45:58 iteration: 64750 loss: 0.0027 lr: 0.02
2019-06-03 20:46:08 iteration: 64800 loss: 0.0025 lr: 0.02
2019-06-03 20:46:19 iteration: 64850 loss: 0.0025 lr: 0.02
2019-06-03 20:46:30 iteration: 64900 loss: 0.0031 lr: 0.02
2019-06-03 20:46:41 iteration: 64950 loss: 0.0023 lr: 0.02
2019-06-03 20:46:51 iteration: 65000 loss: 0.0022 lr: 0.02
2019-06-03 20:47:04 iteration: 65050 loss: 0.0028 lr: 0.02
2019-06-03 20:47:15 iteration: 65100 loss: 0.0030 lr: 0.02
2019-06-03 20:47:26 iteration: 65150 loss: 0.0030 lr: 0.02
2019-06-03 20:47:37 iteration: 65200 loss: 0.0023 lr: 0.02
2019-06-03 20:47:48 iteration: 65250 loss: 0.0025 lr: 0.02
2019-06-03 20:47:58 iteration: 65300 loss: 0.0026 lr: 0.02
2019-06-03 20:48:09 iteration: 65350 loss: 0.0031 lr: 0.02
2019-06-03 20:48:20 iteration: 65400 loss: 0.0028 lr: 0.02
2019-06-03 20:48:31 iteration: 65450 loss: 0.0024 lr: 0.02
2019-06-03 20:48:42 iteration: 65500 loss: 0.0022 lr: 0.02
2019-06-03 20:48:56 iteration: 65550 loss: 0.0028 lr: 0.02
2019-06-03 20:49:06 iteration: 65600 loss: 0.0026 lr: 0.02
2019-06-03 20:49:17 iteration: 65650 loss: 0.0025 lr: 0.02
2019-06-03 20:49:28 iteration: 65700 loss: 0.0032 lr: 0.02
2019-06-03 20:49:39 iteration: 65750 loss: 0.0027 lr: 0.02
2019-06-03 20:49:50 iteration: 65800 loss: 0.0025 lr: 0.02
2019-06-03 20:50:01 iteration: 65850 loss: 0.0029 lr: 0.02
2019-06-03 20:50:12 iteration: 65900 loss: 0.0023 lr: 0.02
2019-06-03 20:50:22 iteration: 65950 loss: 0.0022 lr: 0.02
2019-06-03 20:50:32 iteration: 66000 loss: 0.0024 lr: 0.02
2019-06-03 20:50:45 iteration: 66050 loss: 0.0028 lr: 0.02
2019-06-03 20:50:57 iteration: 66100 loss: 0.0027 lr: 0.02
2019-06-03 20:51:07 iteration: 66150 loss: 0.0025 lr: 0.02
2019-06-03 20:51:17 iteration: 66200 loss: 0.0027 lr: 0.02
2019-06-03 20:51:28 iteration: 66250 loss: 0.0026 lr: 0.02
2019-06-03 20:51:39 iteration: 66300 loss: 0.0026 lr: 0.02
2019-06-03 20:51:51 iteration: 66350 loss: 0.0023 lr: 0.02
2019-06-03 20:52:01 iteration: 66400 loss: 0.0027 lr: 0.02
2019-06-03 20:52:11 iteration: 66450 loss: 0.0031 lr: 0.02
2019-06-03 20:52:22 iteration: 66500 loss: 0.0025 lr: 0.02
2019-06-03 20:52:36 iteration: 66550 loss: 0.0029 lr: 0.02
2019-06-03 20:52:47 iteration: 66600 loss: 0.0028 lr: 0.02
2019-06-03 20:52:58 iteration: 66650 loss: 0.0022 lr: 0.02
2019-06-03 20:53:09 iteration: 66700 loss: 0.0023 lr: 0.02
2019-06-03 20:53:20 iteration: 66750 loss: 0.0028 lr: 0.02
2019-06-03 20:53:30 iteration: 66800 loss: 0.0031 lr: 0.02
2019-06-03 20:53:41 iteration: 66850 loss: 0.0029 lr: 0.02
2019-06-03 20:53:51 iteration: 66900 loss: 0.0026 lr: 0.02
2019-06-03 20:54:02 iteration: 66950 loss: 0.0021 lr: 0.02
2019-06-03 20:54:13 iteration: 67000 loss: 0.0023 lr: 0.02
2019-06-03 20:54:27 iteration: 67050 loss: 0.0025 lr: 0.02
2019-06-03 20:54:38 iteration: 67100 loss: 0.0023 lr: 0.02
2019-06-03 20:54:49 iteration: 67150 loss: 0.0023 lr: 0.02
2019-06-03 20:54:59 iteration: 67200 loss: 0.0024 lr: 0.02
2019-06-03 20:55:10 iteration: 67250 loss: 0.0024 lr: 0.02
2019-06-03 20:55:20 iteration: 67300 loss: 0.0024 lr: 0.02
2019-06-03 20:55:31 iteration: 67350 loss: 0.0020 lr: 0.02
2019-06-03 20:55:42 iteration: 67400 loss: 0.0023 lr: 0.02
2019-06-03 20:55:53 iteration: 67450 loss: 0.0027 lr: 0.02
2019-06-03 20:56:03 iteration: 67500 loss: 0.0027 lr: 0.02
2019-06-03 20:56:18 iteration: 67550 loss: 0.0024 lr: 0.02
2019-06-03 20:56:29 iteration: 67600 loss: 0.0024 lr: 0.02
2019-06-03 20:56:40 iteration: 67650 loss: 0.0025 lr: 0.02
2019-06-03 20:56:50 iteration: 67700 loss: 0.0028 lr: 0.02
2019-06-03 20:57:02 iteration: 67750 loss: 0.0024 lr: 0.02
2019-06-03 20:57:13 iteration: 67800 loss: 0.0027 lr: 0.02
2019-06-03 20:57:24 iteration: 67850 loss: 0.0027 lr: 0.02
2019-06-03 20:57:35 iteration: 67900 loss: 0.0028 lr: 0.02
2019-06-03 20:57:45 iteration: 67950 loss: 0.0028 lr: 0.02
2019-06-03 20:57:56 iteration: 68000 loss: 0.0026 lr: 0.02
2019-06-03 20:58:10 iteration: 68050 loss: 0.0026 lr: 0.02
2019-06-03 20:58:21 iteration: 68100 loss: 0.0022 lr: 0.02
2019-06-03 20:58:32 iteration: 68150 loss: 0.0022 lr: 0.02
2019-06-03 20:58:43 iteration: 68200 loss: 0.0022 lr: 0.02
2019-06-03 20:58:54 iteration: 68250 loss: 0.0023 lr: 0.02
2019-06-03 20:59:05 iteration: 68300 loss: 0.0026 lr: 0.02
2019-06-03 20:59:16 iteration: 68350 loss: 0.0023 lr: 0.02
2019-06-03 20:59:27 iteration: 68400 loss: 0.0026 lr: 0.02
2019-06-03 20:59:39 iteration: 68450 loss: 0.0021 lr: 0.02
2019-06-03 20:59:49 iteration: 68500 loss: 0.0026 lr: 0.02
2019-06-03 21:00:04 iteration: 68550 loss: 0.0021 lr: 0.02
2019-06-03 21:00:14 iteration: 68600 loss: 0.0021 lr: 0.02
2019-06-03 21:00:24 iteration: 68650 loss: 0.0023 lr: 0.02
2019-06-03 21:00:36 iteration: 68700 loss: 0.0025 lr: 0.02
2019-06-03 21:00:46 iteration: 68750 loss: 0.0024 lr: 0.02
2019-06-03 21:00:57 iteration: 68800 loss: 0.0027 lr: 0.02
2019-06-03 21:01:08 iteration: 68850 loss: 0.0026 lr: 0.02
2019-06-03 21:01:18 iteration: 68900 loss: 0.0030 lr: 0.02
2019-06-03 21:01:30 iteration: 68950 loss: 0.0025 lr: 0.02
2019-06-03 21:01:41 iteration: 69000 loss: 0.0020 lr: 0.02
2019-06-03 21:01:55 iteration: 69050 loss: 0.0028 lr: 0.02
2019-06-03 21:02:06 iteration: 69100 loss: 0.0027 lr: 0.02
2019-06-03 21:02:17 iteration: 69150 loss: 0.0027 lr: 0.02
2019-06-03 21:02:28 iteration: 69200 loss: 0.0029 lr: 0.02
2019-06-03 21:02:38 iteration: 69250 loss: 0.0023 lr: 0.02
2019-06-03 21:02:50 iteration: 69300 loss: 0.0024 lr: 0.02
2019-06-03 21:03:01 iteration: 69350 loss: 0.0027 lr: 0.02
2019-06-03 21:03:13 iteration: 69400 loss: 0.0020 lr: 0.02
2019-06-03 21:03:25 iteration: 69450 loss: 0.0023 lr: 0.02
2019-06-03 21:03:36 iteration: 69500 loss: 0.0021 lr: 0.02
2019-06-03 21:03:51 iteration: 69550 loss: 0.0021 lr: 0.02
2019-06-03 21:04:01 iteration: 69600 loss: 0.0022 lr: 0.02
2019-06-03 21:04:12 iteration: 69650 loss: 0.0028 lr: 0.02
2019-06-03 21:04:24 iteration: 69700 loss: 0.0024 lr: 0.02
2019-06-03 21:04:35 iteration: 69750 loss: 0.0026 lr: 0.02
2019-06-03 21:04:46 iteration: 69800 loss: 0.0026 lr: 0.02
2019-06-03 21:04:57 iteration: 69850 loss: 0.0025 lr: 0.02
2019-06-03 21:05:09 iteration: 69900 loss: 0.0027 lr: 0.02
2019-06-03 21:05:19 iteration: 69950 loss: 0.0023 lr: 0.02
2019-06-03 21:05:31 iteration: 70000 loss: 0.0021 lr: 0.02
2019-06-03 21:05:45 iteration: 70050 loss: 0.0023 lr: 0.02
2019-06-03 21:05:55 iteration: 70100 loss: 0.0027 lr: 0.02
2019-06-03 21:06:06 iteration: 70150 loss: 0.0024 lr: 0.02
2019-06-03 21:06:17 iteration: 70200 loss: 0.0023 lr: 0.02
2019-06-03 21:06:28 iteration: 70250 loss: 0.0024 lr: 0.02
2019-06-03 21:06:39 iteration: 70300 loss: 0.0022 lr: 0.02
2019-06-03 21:06:50 iteration: 70350 loss: 0.0022 lr: 0.02
2019-06-03 21:07:02 iteration: 70400 loss: 0.0022 lr: 0.02
2019-06-03 21:07:14 iteration: 70450 loss: 0.0023 lr: 0.02
2019-06-03 21:07:25 iteration: 70500 loss: 0.0026 lr: 0.02
2019-06-03 21:07:40 iteration: 70550 loss: 0.0028 lr: 0.02
2019-06-03 21:07:50 iteration: 70600 loss: 0.0024 lr: 0.02
2019-06-03 21:08:02 iteration: 70650 loss: 0.0024 lr: 0.02
2019-06-03 21:08:13 iteration: 70700 loss: 0.0024 lr: 0.02
2019-06-03 21:08:24 iteration: 70750 loss: 0.0024 lr: 0.02
2019-06-03 21:08:35 iteration: 70800 loss: 0.0027 lr: 0.02
2019-06-03 21:08:47 iteration: 70850 loss: 0.0021 lr: 0.02
2019-06-03 21:08:58 iteration: 70900 loss: 0.0024 lr: 0.02
2019-06-03 21:09:09 iteration: 70950 loss: 0.0023 lr: 0.02
2019-06-03 21:09:18 iteration: 71000 loss: 0.0027 lr: 0.02
2019-06-03 21:09:32 iteration: 71050 loss: 0.0025 lr: 0.02
2019-06-03 21:09:44 iteration: 71100 loss: 0.0024 lr: 0.02
2019-06-03 21:09:55 iteration: 71150 loss: 0.0022 lr: 0.02
2019-06-03 21:10:06 iteration: 71200 loss: 0.0019 lr: 0.02
2019-06-03 21:10:16 iteration: 71250 loss: 0.0024 lr: 0.02
2019-06-03 21:10:27 iteration: 71300 loss: 0.0027 lr: 0.02
2019-06-03 21:10:38 iteration: 71350 loss: 0.0026 lr: 0.02
2019-06-03 21:10:48 iteration: 71400 loss: 0.0026 lr: 0.02
2019-06-03 21:11:00 iteration: 71450 loss: 0.0022 lr: 0.02
2019-06-03 21:11:10 iteration: 71500 loss: 0.0020 lr: 0.02
2019-06-03 21:11:25 iteration: 71550 loss: 0.0021 lr: 0.02
2019-06-03 21:11:35 iteration: 71600 loss: 0.0022 lr: 0.02
2019-06-03 21:11:46 iteration: 71650 loss: 0.0021 lr: 0.02
2019-06-03 21:11:57 iteration: 71700 loss: 0.0021 lr: 0.02
2019-06-03 21:12:08 iteration: 71750 loss: 0.0022 lr: 0.02
2019-06-03 21:12:18 iteration: 71800 loss: 0.0021 lr: 0.02
2019-06-03 21:12:29 iteration: 71850 loss: 0.0030 lr: 0.02
2019-06-03 21:12:40 iteration: 71900 loss: 0.0024 lr: 0.02
2019-06-03 21:12:51 iteration: 71950 loss: 0.0026 lr: 0.02
2019-06-03 21:13:02 iteration: 72000 loss: 0.0024 lr: 0.02
2019-06-03 21:13:16 iteration: 72050 loss: 0.0032 lr: 0.02
2019-06-03 21:13:27 iteration: 72100 loss: 0.0029 lr: 0.02
2019-06-03 21:13:37 iteration: 72150 loss: 0.0023 lr: 0.02
2019-06-03 21:13:48 iteration: 72200 loss: 0.0025 lr: 0.02
2019-06-03 21:13:59 iteration: 72250 loss: 0.0027 lr: 0.02
2019-06-03 21:14:10 iteration: 72300 loss: 0.0024 lr: 0.02
2019-06-03 21:14:21 iteration: 72350 loss: 0.0022 lr: 0.02
2019-06-03 21:14:33 iteration: 72400 loss: 0.0024 lr: 0.02
2019-06-03 21:14:43 iteration: 72450 loss: 0.0022 lr: 0.02
2019-06-03 21:14:54 iteration: 72500 loss: 0.0024 lr: 0.02
2019-06-03 21:15:09 iteration: 72550 loss: 0.0021 lr: 0.02
2019-06-03 21:15:20 iteration: 72600 loss: 0.0021 lr: 0.02
2019-06-03 21:15:31 iteration: 72650 loss: 0.0023 lr: 0.02
2019-06-03 21:15:42 iteration: 72700 loss: 0.0019 lr: 0.02
2019-06-03 21:15:53 iteration: 72750 loss: 0.0025 lr: 0.02
2019-06-03 21:16:04 iteration: 72800 loss: 0.0023 lr: 0.02
2019-06-03 21:16:14 iteration: 72850 loss: 0.0022 lr: 0.02
2019-06-03 21:16:25 iteration: 72900 loss: 0.0024 lr: 0.02
2019-06-03 21:16:36 iteration: 72950 loss: 0.0023 lr: 0.02
2019-06-03 21:16:47 iteration: 73000 loss: 0.0023 lr: 0.02
2019-06-03 21:17:02 iteration: 73050 loss: 0.0027 lr: 0.02
2019-06-03 21:17:13 iteration: 73100 loss: 0.0025 lr: 0.02
2019-06-03 21:17:25 iteration: 73150 loss: 0.0021 lr: 0.02
2019-06-03 21:17:37 iteration: 73200 loss: 0.0024 lr: 0.02
2019-06-03 21:17:48 iteration: 73250 loss: 0.0020 lr: 0.02
2019-06-03 21:17:59 iteration: 73300 loss: 0.0025 lr: 0.02
2019-06-03 21:18:10 iteration: 73350 loss: 0.0026 lr: 0.02
2019-06-03 21:18:22 iteration: 73400 loss: 0.0021 lr: 0.02
2019-06-03 21:18:33 iteration: 73450 loss: 0.0024 lr: 0.02
2019-06-03 21:18:43 iteration: 73500 loss: 0.0023 lr: 0.02
2019-06-03 21:18:57 iteration: 73550 loss: 0.0022 lr: 0.02
2019-06-03 21:19:07 iteration: 73600 loss: 0.0027 lr: 0.02
2019-06-03 21:19:18 iteration: 73650 loss: 0.0029 lr: 0.02
2019-06-03 21:19:29 iteration: 73700 loss: 0.0022 lr: 0.02
2019-06-03 21:19:40 iteration: 73750 loss: 0.0024 lr: 0.02
2019-06-03 21:19:50 iteration: 73800 loss: 0.0021 lr: 0.02
2019-06-03 21:20:01 iteration: 73850 loss: 0.0022 lr: 0.02
2019-06-03 21:20:12 iteration: 73900 loss: 0.0019 lr: 0.02
2019-06-03 21:20:24 iteration: 73950 loss: 0.0022 lr: 0.02
2019-06-03 21:20:35 iteration: 74000 loss: 0.0019 lr: 0.02
2019-06-03 21:20:51 iteration: 74050 loss: 0.0025 lr: 0.02
2019-06-03 21:21:02 iteration: 74100 loss: 0.0022 lr: 0.02
2019-06-03 21:21:14 iteration: 74150 loss: 0.0022 lr: 0.02
2019-06-03 21:21:26 iteration: 74200 loss: 0.0018 lr: 0.02
2019-06-03 21:21:36 iteration: 74250 loss: 0.0025 lr: 0.02
2019-06-03 21:21:47 iteration: 74300 loss: 0.0020 lr: 0.02
2019-06-03 21:21:58 iteration: 74350 loss: 0.0020 lr: 0.02
2019-06-03 21:22:09 iteration: 74400 loss: 0.0022 lr: 0.02
2019-06-03 21:22:20 iteration: 74450 loss: 0.0022 lr: 0.02
2019-06-03 21:22:31 iteration: 74500 loss: 0.0022 lr: 0.02
2019-06-03 21:22:45 iteration: 74550 loss: 0.0024 lr: 0.02
2019-06-03 21:22:56 iteration: 74600 loss: 0.0023 lr: 0.02
2019-06-03 21:23:07 iteration: 74650 loss: 0.0021 lr: 0.02
2019-06-03 21:23:18 iteration: 74700 loss: 0.0024 lr: 0.02
2019-06-03 21:23:28 iteration: 74750 loss: 0.0026 lr: 0.02
2019-06-03 21:23:39 iteration: 74800 loss: 0.0023 lr: 0.02
2019-06-03 21:23:51 iteration: 74850 loss: 0.0027 lr: 0.02
2019-06-03 21:24:01 iteration: 74900 loss: 0.0020 lr: 0.02
2019-06-03 21:24:12 iteration: 74950 loss: 0.0029 lr: 0.02
2019-06-03 21:24:23 iteration: 75000 loss: 0.0021 lr: 0.02
2019-06-03 21:24:36 iteration: 75050 loss: 0.0022 lr: 0.02
2019-06-03 21:24:47 iteration: 75100 loss: 0.0020 lr: 0.02
2019-06-03 21:24:58 iteration: 75150 loss: 0.0024 lr: 0.02
2019-06-03 21:25:08 iteration: 75200 loss: 0.0023 lr: 0.02
2019-06-03 21:25:19 iteration: 75250 loss: 0.0022 lr: 0.02
2019-06-03 21:25:30 iteration: 75300 loss: 0.0025 lr: 0.02
2019-06-03 21:25:41 iteration: 75350 loss: 0.0019 lr: 0.02
2019-06-03 21:25:52 iteration: 75400 loss: 0.0021 lr: 0.02
2019-06-03 21:26:03 iteration: 75450 loss: 0.0029 lr: 0.02
2019-06-03 21:26:14 iteration: 75500 loss: 0.0025 lr: 0.02
2019-06-03 21:26:27 iteration: 75550 loss: 0.0022 lr: 0.02
2019-06-03 21:26:38 iteration: 75600 loss: 0.0021 lr: 0.02
2019-06-03 21:26:50 iteration: 75650 loss: 0.0023 lr: 0.02
2019-06-03 21:27:02 iteration: 75700 loss: 0.0024 lr: 0.02
2019-06-03 21:27:12 iteration: 75750 loss: 0.0023 lr: 0.02
2019-06-03 21:27:22 iteration: 75800 loss: 0.0026 lr: 0.02
2019-06-03 21:27:33 iteration: 75850 loss: 0.0027 lr: 0.02
2019-06-03 21:27:44 iteration: 75900 loss: 0.0026 lr: 0.02
2019-06-03 21:27:56 iteration: 75950 loss: 0.0025 lr: 0.02
2019-06-03 21:28:06 iteration: 76000 loss: 0.0020 lr: 0.02
2019-06-03 21:28:20 iteration: 76050 loss: 0.0021 lr: 0.02
2019-06-03 21:28:30 iteration: 76100 loss: 0.0024 lr: 0.02
2019-06-03 21:28:42 iteration: 76150 loss: 0.0021 lr: 0.02
2019-06-03 21:28:53 iteration: 76200 loss: 0.0021 lr: 0.02
2019-06-03 21:29:03 iteration: 76250 loss: 0.0022 lr: 0.02
2019-06-03 21:29:14 iteration: 76300 loss: 0.0023 lr: 0.02
2019-06-03 21:29:25 iteration: 76350 loss: 0.0021 lr: 0.02
2019-06-03 21:29:36 iteration: 76400 loss: 0.0025 lr: 0.02
2019-06-03 21:29:47 iteration: 76450 loss: 0.0023 lr: 0.02
2019-06-03 21:29:58 iteration: 76500 loss: 0.0022 lr: 0.02
2019-06-03 21:30:12 iteration: 76550 loss: 0.0021 lr: 0.02
2019-06-03 21:30:22 iteration: 76600 loss: 0.0027 lr: 0.02
2019-06-03 21:30:33 iteration: 76650 loss: 0.0025 lr: 0.02
2019-06-03 21:30:43 iteration: 76700 loss: 0.0023 lr: 0.02
2019-06-03 21:30:54 iteration: 76750 loss: 0.0022 lr: 0.02
2019-06-03 21:31:05 iteration: 76800 loss: 0.0023 lr: 0.02
2019-06-03 21:31:15 iteration: 76850 loss: 0.0023 lr: 0.02
2019-06-03 21:31:26 iteration: 76900 loss: 0.0022 lr: 0.02
2019-06-03 21:31:36 iteration: 76950 loss: 0.0025 lr: 0.02
2019-06-03 21:31:47 iteration: 77000 loss: 0.0022 lr: 0.02
2019-06-03 21:32:01 iteration: 77050 loss: 0.0023 lr: 0.02
2019-06-03 21:32:11 iteration: 77100 loss: 0.0024 lr: 0.02
2019-06-03 21:32:22 iteration: 77150 loss: 0.0022 lr: 0.02
2019-06-03 21:32:33 iteration: 77200 loss: 0.0022 lr: 0.02
2019-06-03 21:32:44 iteration: 77250 loss: 0.0022 lr: 0.02
2019-06-03 21:32:54 iteration: 77300 loss: 0.0024 lr: 0.02
2019-06-03 21:33:04 iteration: 77350 loss: 0.0018 lr: 0.02
2019-06-03 21:33:15 iteration: 77400 loss: 0.0022 lr: 0.02
2019-06-03 21:33:26 iteration: 77450 loss: 0.0022 lr: 0.02
2019-06-03 21:33:36 iteration: 77500 loss: 0.0023 lr: 0.02
2019-06-03 21:33:50 iteration: 77550 loss: 0.0024 lr: 0.02
2019-06-03 21:34:00 iteration: 77600 loss: 0.0027 lr: 0.02
2019-06-03 21:34:11 iteration: 77650 loss: 0.0022 lr: 0.02
2019-06-03 21:34:23 iteration: 77700 loss: 0.0022 lr: 0.02
2019-06-03 21:34:33 iteration: 77750 loss: 0.0025 lr: 0.02
2019-06-03 21:34:44 iteration: 77800 loss: 0.0019 lr: 0.02
2019-06-03 21:34:55 iteration: 77850 loss: 0.0023 lr: 0.02
2019-06-03 21:35:05 iteration: 77900 loss: 0.0024 lr: 0.02
2019-06-03 21:35:15 iteration: 77950 loss: 0.0026 lr: 0.02
2019-06-03 21:35:26 iteration: 78000 loss: 0.0021 lr: 0.02
2019-06-03 21:35:39 iteration: 78050 loss: 0.0025 lr: 0.02
2019-06-03 21:35:51 iteration: 78100 loss: 0.0028 lr: 0.02
2019-06-03 21:36:02 iteration: 78150 loss: 0.0020 lr: 0.02
2019-06-03 21:36:12 iteration: 78200 loss: 0.0022 lr: 0.02
2019-06-03 21:36:23 iteration: 78250 loss: 0.0024 lr: 0.02
2019-06-03 21:36:33 iteration: 78300 loss: 0.0022 lr: 0.02
2019-06-03 21:36:44 iteration: 78350 loss: 0.0027 lr: 0.02
2019-06-03 21:36:55 iteration: 78400 loss: 0.0026 lr: 0.02
2019-06-03 21:37:05 iteration: 78450 loss: 0.0025 lr: 0.02
2019-06-03 21:37:17 iteration: 78500 loss: 0.0022 lr: 0.02
2019-06-03 21:37:31 iteration: 78550 loss: 0.0018 lr: 0.02
2019-06-03 21:37:42 iteration: 78600 loss: 0.0020 lr: 0.02
2019-06-03 21:37:53 iteration: 78650 loss: 0.0024 lr: 0.02
2019-06-03 21:38:04 iteration: 78700 loss: 0.0022 lr: 0.02
2019-06-03 21:38:15 iteration: 78750 loss: 0.0023 lr: 0.02
2019-06-03 21:38:25 iteration: 78800 loss: 0.0023 lr: 0.02
2019-06-03 21:38:36 iteration: 78850 loss: 0.0026 lr: 0.02
2019-06-03 21:38:47 iteration: 78900 loss: 0.0024 lr: 0.02
2019-06-03 21:38:58 iteration: 78950 loss: 0.0026 lr: 0.02
2019-06-03 21:39:09 iteration: 79000 loss: 0.0019 lr: 0.02
2019-06-03 21:39:23 iteration: 79050 loss: 0.0022 lr: 0.02
2019-06-03 21:39:33 iteration: 79100 loss: 0.0025 lr: 0.02
2019-06-03 21:39:44 iteration: 79150 loss: 0.0022 lr: 0.02
2019-06-03 21:39:55 iteration: 79200 loss: 0.0018 lr: 0.02
2019-06-03 21:40:06 iteration: 79250 loss: 0.0019 lr: 0.02
2019-06-03 21:40:17 iteration: 79300 loss: 0.0021 lr: 0.02
2019-06-03 21:40:28 iteration: 79350 loss: 0.0025 lr: 0.02
2019-06-03 21:40:39 iteration: 79400 loss: 0.0023 lr: 0.02
2019-06-03 21:40:49 iteration: 79450 loss: 0.0021 lr: 0.02
2019-06-03 21:41:00 iteration: 79500 loss: 0.0027 lr: 0.02
2019-06-03 21:41:13 iteration: 79550 loss: 0.0024 lr: 0.02
2019-06-03 21:41:24 iteration: 79600 loss: 0.0022 lr: 0.02
2019-06-03 21:41:35 iteration: 79650 loss: 0.0019 lr: 0.02
2019-06-03 21:41:45 iteration: 79700 loss: 0.0018 lr: 0.02
2019-06-03 21:41:56 iteration: 79750 loss: 0.0027 lr: 0.02
2019-06-03 21:42:06 iteration: 79800 loss: 0.0024 lr: 0.02
2019-06-03 21:42:17 iteration: 79850 loss: 0.0021 lr: 0.02
2019-06-03 21:42:28 iteration: 79900 loss: 0.0026 lr: 0.02
2019-06-03 21:42:38 iteration: 79950 loss: 0.0024 lr: 0.02
2019-06-03 21:42:50 iteration: 80000 loss: 0.0020 lr: 0.02
2019-06-03 21:43:03 iteration: 80050 loss: 0.0020 lr: 0.02
2019-06-03 21:43:15 iteration: 80100 loss: 0.0021 lr: 0.02
2019-06-03 21:43:25 iteration: 80150 loss: 0.0022 lr: 0.02
2019-06-03 21:43:36 iteration: 80200 loss: 0.0022 lr: 0.02
2019-06-03 21:43:47 iteration: 80250 loss: 0.0021 lr: 0.02
2019-06-03 21:43:58 iteration: 80300 loss: 0.0024 lr: 0.02
2019-06-03 21:44:09 iteration: 80350 loss: 0.0023 lr: 0.02
2019-06-03 21:44:20 iteration: 80400 loss: 0.0021 lr: 0.02
2019-06-03 21:44:30 iteration: 80450 loss: 0.0026 lr: 0.02
2019-06-03 21:44:41 iteration: 80500 loss: 0.0022 lr: 0.02
2019-06-03 21:44:53 iteration: 80550 loss: 0.0022 lr: 0.02
2019-06-03 21:45:04 iteration: 80600 loss: 0.0025 lr: 0.02
2019-06-03 21:45:14 iteration: 80650 loss: 0.0024 lr: 0.02
2019-06-03 21:45:25 iteration: 80700 loss: 0.0018 lr: 0.02
2019-06-03 21:45:36 iteration: 80750 loss: 0.0022 lr: 0.02
2019-06-03 21:45:47 iteration: 80800 loss: 0.0021 lr: 0.02
2019-06-03 21:45:57 iteration: 80850 loss: 0.0020 lr: 0.02
2019-06-03 21:46:07 iteration: 80900 loss: 0.0020 lr: 0.02
2019-06-03 21:46:17 iteration: 80950 loss: 0.0024 lr: 0.02
2019-06-03 21:46:28 iteration: 81000 loss: 0.0024 lr: 0.02
2019-06-03 21:46:41 iteration: 81050 loss: 0.0022 lr: 0.02
2019-06-03 21:46:51 iteration: 81100 loss: 0.0024 lr: 0.02
2019-06-03 21:47:02 iteration: 81150 loss: 0.0022 lr: 0.02
2019-06-03 21:47:12 iteration: 81200 loss: 0.0020 lr: 0.02
2019-06-03 21:47:22 iteration: 81250 loss: 0.0024 lr: 0.02
2019-06-03 21:47:33 iteration: 81300 loss: 0.0024 lr: 0.02
2019-06-03 21:47:43 iteration: 81350 loss: 0.0022 lr: 0.02
2019-06-03 21:47:53 iteration: 81400 loss: 0.0023 lr: 0.02
2019-06-03 21:48:04 iteration: 81450 loss: 0.0023 lr: 0.02
2019-06-03 21:48:15 iteration: 81500 loss: 0.0020 lr: 0.02
2019-06-03 21:48:28 iteration: 81550 loss: 0.0023 lr: 0.02
2019-06-03 21:48:38 iteration: 81600 loss: 0.0023 lr: 0.02
2019-06-03 21:48:49 iteration: 81650 loss: 0.0024 lr: 0.02
2019-06-03 21:48:59 iteration: 81700 loss: 0.0020 lr: 0.02
2019-06-03 21:49:10 iteration: 81750 loss: 0.0019 lr: 0.02
2019-06-03 21:49:20 iteration: 81800 loss: 0.0018 lr: 0.02
2019-06-03 21:49:31 iteration: 81850 loss: 0.0019 lr: 0.02
2019-06-03 21:49:42 iteration: 81900 loss: 0.0019 lr: 0.02
2019-06-03 21:49:53 iteration: 81950 loss: 0.0021 lr: 0.02
2019-06-03 21:50:03 iteration: 82000 loss: 0.0020 lr: 0.02
2019-06-03 21:50:16 iteration: 82050 loss: 0.0021 lr: 0.02
2019-06-03 21:50:27 iteration: 82100 loss: 0.0019 lr: 0.02
2019-06-03 21:50:38 iteration: 82150 loss: 0.0024 lr: 0.02
2019-06-03 21:50:49 iteration: 82200 loss: 0.0021 lr: 0.02
2019-06-03 21:51:00 iteration: 82250 loss: 0.0021 lr: 0.02
2019-06-03 21:51:10 iteration: 82300 loss: 0.0022 lr: 0.02
2019-06-03 21:51:20 iteration: 82350 loss: 0.0024 lr: 0.02
2019-06-03 21:51:31 iteration: 82400 loss: 0.0020 lr: 0.02
2019-06-03 21:51:42 iteration: 82450 loss: 0.0022 lr: 0.02
2019-06-03 21:51:52 iteration: 82500 loss: 0.0019 lr: 0.02
2019-06-03 21:52:06 iteration: 82550 loss: 0.0022 lr: 0.02
2019-06-03 21:52:15 iteration: 82600 loss: 0.0028 lr: 0.02
2019-06-03 21:52:26 iteration: 82650 loss: 0.0019 lr: 0.02
2019-06-03 21:52:36 iteration: 82700 loss: 0.0027 lr: 0.02
2019-06-03 21:52:46 iteration: 82750 loss: 0.0026 lr: 0.02
2019-06-03 21:52:57 iteration: 82800 loss: 0.0021 lr: 0.02
2019-06-03 21:53:07 iteration: 82850 loss: 0.0022 lr: 0.02
2019-06-03 21:53:17 iteration: 82900 loss: 0.0023 lr: 0.02
2019-06-03 21:53:28 iteration: 82950 loss: 0.0021 lr: 0.02
2019-06-03 21:53:38 iteration: 83000 loss: 0.0022 lr: 0.02
2019-06-03 21:53:51 iteration: 83050 loss: 0.0026 lr: 0.02
2019-06-03 21:54:01 iteration: 83100 loss: 0.0018 lr: 0.02
2019-06-03 21:54:12 iteration: 83150 loss: 0.0019 lr: 0.02
2019-06-03 21:54:21 iteration: 83200 loss: 0.0021 lr: 0.02
2019-06-03 21:54:32 iteration: 83250 loss: 0.0020 lr: 0.02
2019-06-03 21:54:42 iteration: 83300 loss: 0.0019 lr: 0.02
2019-06-03 21:54:53 iteration: 83350 loss: 0.0021 lr: 0.02
2019-06-03 21:55:04 iteration: 83400 loss: 0.0019 lr: 0.02
2019-06-03 21:55:15 iteration: 83450 loss: 0.0019 lr: 0.02
2019-06-03 21:55:25 iteration: 83500 loss: 0.0021 lr: 0.02
2019-06-03 21:55:39 iteration: 83550 loss: 0.0017 lr: 0.02
2019-06-03 21:55:49 iteration: 83600 loss: 0.0018 lr: 0.02
2019-06-03 21:55:59 iteration: 83650 loss: 0.0022 lr: 0.02
2019-06-03 21:56:10 iteration: 83700 loss: 0.0020 lr: 0.02
2019-06-03 21:56:20 iteration: 83750 loss: 0.0023 lr: 0.02
2019-06-03 21:56:30 iteration: 83800 loss: 0.0022 lr: 0.02
2019-06-03 21:56:41 iteration: 83850 loss: 0.0022 lr: 0.02
2019-06-03 21:56:50 iteration: 83900 loss: 0.0023 lr: 0.02
2019-06-03 21:57:01 iteration: 83950 loss: 0.0024 lr: 0.02
2019-06-03 21:57:11 iteration: 84000 loss: 0.0026 lr: 0.02
2019-06-03 21:57:24 iteration: 84050 loss: 0.0021 lr: 0.02
2019-06-03 21:57:35 iteration: 84100 loss: 0.0017 lr: 0.02
2019-06-03 21:57:46 iteration: 84150 loss: 0.0021 lr: 0.02
2019-06-03 21:57:56 iteration: 84200 loss: 0.0021 lr: 0.02
2019-06-03 21:58:06 iteration: 84250 loss: 0.0022 lr: 0.02
2019-06-03 21:58:18 iteration: 84300 loss: 0.0024 lr: 0.02
2019-06-03 21:58:28 iteration: 84350 loss: 0.0019 lr: 0.02
2019-06-03 21:58:38 iteration: 84400 loss: 0.0023 lr: 0.02
2019-06-03 21:58:49 iteration: 84450 loss: 0.0022 lr: 0.02
2019-06-03 21:58:59 iteration: 84500 loss: 0.0018 lr: 0.02
2019-06-03 21:59:12 iteration: 84550 loss: 0.0023 lr: 0.02
2019-06-03 21:59:23 iteration: 84600 loss: 0.0023 lr: 0.02
2019-06-03 21:59:33 iteration: 84650 loss: 0.0020 lr: 0.02
2019-06-03 21:59:43 iteration: 84700 loss: 0.0025 lr: 0.02
2019-06-03 21:59:54 iteration: 84750 loss: 0.0022 lr: 0.02
2019-06-03 22:00:04 iteration: 84800 loss: 0.0021 lr: 0.02
2019-06-03 22:00:15 iteration: 84850 loss: 0.0018 lr: 0.02
2019-06-03 22:00:25 iteration: 84900 loss: 0.0021 lr: 0.02
2019-06-03 22:00:37 iteration: 84950 loss: 0.0019 lr: 0.02
2019-06-03 22:00:48 iteration: 85000 loss: 0.0021 lr: 0.02
2019-06-03 22:01:01 iteration: 85050 loss: 0.0019 lr: 0.02
2019-06-03 22:01:11 iteration: 85100 loss: 0.0021 lr: 0.02
2019-06-03 22:01:22 iteration: 85150 loss: 0.0023 lr: 0.02
2019-06-03 22:01:33 iteration: 85200 loss: 0.0016 lr: 0.02
2019-06-03 22:01:44 iteration: 85250 loss: 0.0021 lr: 0.02
2019-06-03 22:01:54 iteration: 85300 loss: 0.0020 lr: 0.02
2019-06-03 22:02:05 iteration: 85350 loss: 0.0021 lr: 0.02
2019-06-03 22:02:16 iteration: 85400 loss: 0.0019 lr: 0.02
2019-06-03 22:02:27 iteration: 85450 loss: 0.0018 lr: 0.02
2019-06-03 22:02:37 iteration: 85500 loss: 0.0022 lr: 0.02
2019-06-03 22:02:51 iteration: 85550 loss: 0.0019 lr: 0.02
2019-06-03 22:03:01 iteration: 85600 loss: 0.0019 lr: 0.02
2019-06-03 22:03:12 iteration: 85650 loss: 0.0021 lr: 0.02
2019-06-03 22:03:22 iteration: 85700 loss: 0.0019 lr: 0.02
2019-06-03 22:03:33 iteration: 85750 loss: 0.0019 lr: 0.02
2019-06-03 22:03:44 iteration: 85800 loss: 0.0023 lr: 0.02
2019-06-03 22:03:54 iteration: 85850 loss: 0.0018 lr: 0.02
2019-06-03 22:04:04 iteration: 85900 loss: 0.0019 lr: 0.02
2019-06-03 22:04:14 iteration: 85950 loss: 0.0021 lr: 0.02
2019-06-03 22:04:26 iteration: 86000 loss: 0.0017 lr: 0.02
2019-06-03 22:04:39 iteration: 86050 loss: 0.0020 lr: 0.02
2019-06-03 22:04:50 iteration: 86100 loss: 0.0017 lr: 0.02
2019-06-03 22:05:00 iteration: 86150 loss: 0.0023 lr: 0.02
2019-06-03 22:05:11 iteration: 86200 loss: 0.0019 lr: 0.02
2019-06-03 22:05:21 iteration: 86250 loss: 0.0020 lr: 0.02
2019-06-03 22:05:31 iteration: 86300 loss: 0.0022 lr: 0.02
2019-06-03 22:05:41 iteration: 86350 loss: 0.0021 lr: 0.02
2019-06-03 22:05:52 iteration: 86400 loss: 0.0019 lr: 0.02
2019-06-03 22:06:02 iteration: 86450 loss: 0.0018 lr: 0.02
2019-06-03 22:06:13 iteration: 86500 loss: 0.0025 lr: 0.02
2019-06-03 22:06:26 iteration: 86550 loss: 0.0019 lr: 0.02
2019-06-03 22:06:37 iteration: 86600 loss: 0.0019 lr: 0.02
2019-06-03 22:06:48 iteration: 86650 loss: 0.0021 lr: 0.02
2019-06-03 22:06:58 iteration: 86700 loss: 0.0023 lr: 0.02
2019-06-03 22:07:08 iteration: 86750 loss: 0.0022 lr: 0.02
2019-06-03 22:07:19 iteration: 86800 loss: 0.0020 lr: 0.02
2019-06-03 22:07:30 iteration: 86850 loss: 0.0023 lr: 0.02
2019-06-03 22:07:41 iteration: 86900 loss: 0.0018 lr: 0.02
2019-06-03 22:07:51 iteration: 86950 loss: 0.0019 lr: 0.02
2019-06-03 22:08:02 iteration: 87000 loss: 0.0020 lr: 0.02
2019-06-03 22:08:15 iteration: 87050 loss: 0.0022 lr: 0.02
2019-06-03 22:08:26 iteration: 87100 loss: 0.0018 lr: 0.02
2019-06-03 22:08:36 iteration: 87150 loss: 0.0018 lr: 0.02
2019-06-03 22:08:47 iteration: 87200 loss: 0.0019 lr: 0.02
2019-06-03 22:08:57 iteration: 87250 loss: 0.0020 lr: 0.02
2019-06-03 22:09:08 iteration: 87300 loss: 0.0018 lr: 0.02
2019-06-03 22:09:18 iteration: 87350 loss: 0.0019 lr: 0.02
2019-06-03 22:09:28 iteration: 87400 loss: 0.0023 lr: 0.02
2019-06-03 22:09:38 iteration: 87450 loss: 0.0019 lr: 0.02
2019-06-03 22:09:50 iteration: 87500 loss: 0.0023 lr: 0.02
2019-06-03 22:10:03 iteration: 87550 loss: 0.0022 lr: 0.02
2019-06-03 22:10:14 iteration: 87600 loss: 0.0020 lr: 0.02
2019-06-03 22:10:24 iteration: 87650 loss: 0.0023 lr: 0.02
2019-06-03 22:10:34 iteration: 87700 loss: 0.0023 lr: 0.02
2019-06-03 22:10:45 iteration: 87750 loss: 0.0020 lr: 0.02
2019-06-03 22:10:55 iteration: 87800 loss: 0.0018 lr: 0.02
2019-06-03 22:11:06 iteration: 87850 loss: 0.0019 lr: 0.02
2019-06-03 22:11:16 iteration: 87900 loss: 0.0020 lr: 0.02
2019-06-03 22:11:27 iteration: 87950 loss: 0.0019 lr: 0.02
2019-06-03 22:11:37 iteration: 88000 loss: 0.0019 lr: 0.02
2019-06-03 22:11:51 iteration: 88050 loss: 0.0020 lr: 0.02
2019-06-03 22:12:01 iteration: 88100 loss: 0.0022 lr: 0.02
2019-06-03 22:12:11 iteration: 88150 loss: 0.0021 lr: 0.02
2019-06-03 22:12:22 iteration: 88200 loss: 0.0013 lr: 0.02
2019-06-03 22:12:32 iteration: 88250 loss: 0.0022 lr: 0.02
2019-06-03 22:12:43 iteration: 88300 loss: 0.0023 lr: 0.02
2019-06-03 22:12:54 iteration: 88350 loss: 0.0016 lr: 0.02
2019-06-03 22:13:04 iteration: 88400 loss: 0.0026 lr: 0.02
2019-06-03 22:13:14 iteration: 88450 loss: 0.0023 lr: 0.02
2019-06-03 22:13:24 iteration: 88500 loss: 0.0020 lr: 0.02
2019-06-03 22:13:37 iteration: 88550 loss: 0.0022 lr: 0.02
2019-06-03 22:13:48 iteration: 88600 loss: 0.0021 lr: 0.02
2019-06-03 22:13:59 iteration: 88650 loss: 0.0020 lr: 0.02
2019-06-03 22:14:09 iteration: 88700 loss: 0.0024 lr: 0.02
2019-06-03 22:14:19 iteration: 88750 loss: 0.0017 lr: 0.02
2019-06-03 22:14:29 iteration: 88800 loss: 0.0021 lr: 0.02
2019-06-03 22:14:40 iteration: 88850 loss: 0.0017 lr: 0.02
2019-06-03 22:14:51 iteration: 88900 loss: 0.0021 lr: 0.02
2019-06-03 22:15:01 iteration: 88950 loss: 0.0018 lr: 0.02
2019-06-03 22:15:12 iteration: 89000 loss: 0.0016 lr: 0.02
2019-06-03 22:15:26 iteration: 89050 loss: 0.0017 lr: 0.02
2019-06-03 22:15:36 iteration: 89100 loss: 0.0028 lr: 0.02
2019-06-03 22:15:47 iteration: 89150 loss: 0.0017 lr: 0.02
2019-06-03 22:15:57 iteration: 89200 loss: 0.0019 lr: 0.02
2019-06-03 22:16:08 iteration: 89250 loss: 0.0020 lr: 0.02
2019-06-03 22:16:19 iteration: 89300 loss: 0.0023 lr: 0.02
2019-06-03 22:16:29 iteration: 89350 loss: 0.0017 lr: 0.02
2019-06-03 22:16:40 iteration: 89400 loss: 0.0018 lr: 0.02
2019-06-03 22:16:50 iteration: 89450 loss: 0.0016 lr: 0.02
2019-06-03 22:17:00 iteration: 89500 loss: 0.0018 lr: 0.02
2019-06-03 22:17:14 iteration: 89550 loss: 0.0018 lr: 0.02
2019-06-03 22:17:24 iteration: 89600 loss: 0.0022 lr: 0.02
2019-06-03 22:17:34 iteration: 89650 loss: 0.0021 lr: 0.02
2019-06-03 22:17:45 iteration: 89700 loss: 0.0021 lr: 0.02
2019-06-03 22:17:55 iteration: 89750 loss: 0.0023 lr: 0.02
2019-06-03 22:18:06 iteration: 89800 loss: 0.0020 lr: 0.02
2019-06-03 22:18:16 iteration: 89850 loss: 0.0021 lr: 0.02
2019-06-03 22:18:26 iteration: 89900 loss: 0.0019 lr: 0.02
2019-06-03 22:18:36 iteration: 89950 loss: 0.0017 lr: 0.02
2019-06-03 22:18:48 iteration: 90000 loss: 0.0019 lr: 0.02
2019-06-03 22:19:01 iteration: 90050 loss: 0.0019 lr: 0.02
2019-06-03 22:19:12 iteration: 90100 loss: 0.0023 lr: 0.02
2019-06-03 22:19:22 iteration: 90150 loss: 0.0021 lr: 0.02
2019-06-03 22:19:32 iteration: 90200 loss: 0.0021 lr: 0.02
2019-06-03 22:19:43 iteration: 90250 loss: 0.0019 lr: 0.02
2019-06-03 22:19:54 iteration: 90300 loss: 0.0020 lr: 0.02
2019-06-03 22:20:04 iteration: 90350 loss: 0.0018 lr: 0.02
2019-06-03 22:20:15 iteration: 90400 loss: 0.0018 lr: 0.02
2019-06-03 22:20:25 iteration: 90450 loss: 0.0021 lr: 0.02
2019-06-03 22:20:36 iteration: 90500 loss: 0.0021 lr: 0.02
2019-06-03 22:20:50 iteration: 90550 loss: 0.0021 lr: 0.02
2019-06-03 22:21:01 iteration: 90600 loss: 0.0022 lr: 0.02
2019-06-03 22:21:11 iteration: 90650 loss: 0.0022 lr: 0.02
2019-06-03 22:21:21 iteration: 90700 loss: 0.0022 lr: 0.02
2019-06-03 22:21:32 iteration: 90750 loss: 0.0017 lr: 0.02
2019-06-03 22:21:42 iteration: 90800 loss: 0.0019 lr: 0.02
2019-06-03 22:21:53 iteration: 90850 loss: 0.0022 lr: 0.02
2019-06-03 22:22:03 iteration: 90900 loss: 0.0021 lr: 0.02
2019-06-03 22:22:14 iteration: 90950 loss: 0.0020 lr: 0.02
2019-06-03 22:22:25 iteration: 91000 loss: 0.0023 lr: 0.02
2019-06-03 22:22:38 iteration: 91050 loss: 0.0017 lr: 0.02
2019-06-03 22:22:49 iteration: 91100 loss: 0.0021 lr: 0.02
2019-06-03 22:23:00 iteration: 91150 loss: 0.0019 lr: 0.02
2019-06-03 22:23:11 iteration: 91200 loss: 0.0018 lr: 0.02
2019-06-03 22:23:21 iteration: 91250 loss: 0.0022 lr: 0.02
2019-06-03 22:23:32 iteration: 91300 loss: 0.0021 lr: 0.02
2019-06-03 22:23:43 iteration: 91350 loss: 0.0019 lr: 0.02
2019-06-03 22:23:54 iteration: 91400 loss: 0.0017 lr: 0.02
2019-06-03 22:24:04 iteration: 91450 loss: 0.0019 lr: 0.02
2019-06-03 22:24:15 iteration: 91500 loss: 0.0021 lr: 0.02
2019-06-03 22:24:28 iteration: 91550 loss: 0.0024 lr: 0.02
2019-06-03 22:24:39 iteration: 91600 loss: 0.0022 lr: 0.02
2019-06-03 22:24:49 iteration: 91650 loss: 0.0017 lr: 0.02
2019-06-03 22:25:00 iteration: 91700 loss: 0.0022 lr: 0.02
2019-06-03 22:25:11 iteration: 91750 loss: 0.0020 lr: 0.02
2019-06-03 22:25:21 iteration: 91800 loss: 0.0021 lr: 0.02
2019-06-03 22:25:32 iteration: 91850 loss: 0.0015 lr: 0.02
2019-06-03 22:25:43 iteration: 91900 loss: 0.0016 lr: 0.02
2019-06-03 22:25:53 iteration: 91950 loss: 0.0019 lr: 0.02
2019-06-03 22:26:04 iteration: 92000 loss: 0.0018 lr: 0.02
2019-06-03 22:26:18 iteration: 92050 loss: 0.0018 lr: 0.02
2019-06-03 22:26:28 iteration: 92100 loss: 0.0023 lr: 0.02
2019-06-03 22:26:38 iteration: 92150 loss: 0.0021 lr: 0.02
2019-06-03 22:26:48 iteration: 92200 loss: 0.0019 lr: 0.02
2019-06-03 22:26:59 iteration: 92250 loss: 0.0021 lr: 0.02
2019-06-03 22:27:09 iteration: 92300 loss: 0.0023 lr: 0.02
2019-06-03 22:27:20 iteration: 92350 loss: 0.0021 lr: 0.02
2019-06-03 22:27:30 iteration: 92400 loss: 0.0020 lr: 0.02
2019-06-03 22:27:41 iteration: 92450 loss: 0.0020 lr: 0.02
2019-06-03 22:27:52 iteration: 92500 loss: 0.0019 lr: 0.02
2019-06-03 22:28:05 iteration: 92550 loss: 0.0020 lr: 0.02
2019-06-03 22:28:16 iteration: 92600 loss: 0.0017 lr: 0.02
2019-06-03 22:28:26 iteration: 92650 loss: 0.0018 lr: 0.02
2019-06-03 22:28:37 iteration: 92700 loss: 0.0017 lr: 0.02
2019-06-03 22:28:49 iteration: 92750 loss: 0.0017 lr: 0.02
2019-06-03 22:28:59 iteration: 92800 loss: 0.0021 lr: 0.02
2019-06-03 22:29:09 iteration: 92850 loss: 0.0017 lr: 0.02
2019-06-03 22:29:20 iteration: 92900 loss: 0.0019 lr: 0.02
2019-06-03 22:29:31 iteration: 92950 loss: 0.0018 lr: 0.02
2019-06-03 22:29:42 iteration: 93000 loss: 0.0022 lr: 0.02
2019-06-03 22:29:56 iteration: 93050 loss: 0.0020 lr: 0.02
2019-06-03 22:30:07 iteration: 93100 loss: 0.0018 lr: 0.02
2019-06-03 22:30:17 iteration: 93150 loss: 0.0018 lr: 0.02
2019-06-03 22:30:28 iteration: 93200 loss: 0.0016 lr: 0.02
2019-06-03 22:30:39 iteration: 93250 loss: 0.0017 lr: 0.02
2019-06-03 22:30:49 iteration: 93300 loss: 0.0024 lr: 0.02
2019-06-03 22:30:59 iteration: 93350 loss: 0.0020 lr: 0.02
2019-06-03 22:31:10 iteration: 93400 loss: 0.0019 lr: 0.02
2019-06-03 22:31:20 iteration: 93450 loss: 0.0020 lr: 0.02
2019-06-03 22:31:31 iteration: 93500 loss: 0.0021 lr: 0.02
2019-06-03 22:31:44 iteration: 93550 loss: 0.0022 lr: 0.02
2019-06-03 22:31:54 iteration: 93600 loss: 0.0018 lr: 0.02
2019-06-03 22:32:05 iteration: 93650 loss: 0.0022 lr: 0.02
2019-06-03 22:32:15 iteration: 93700 loss: 0.0019 lr: 0.02
2019-06-03 22:32:25 iteration: 93750 loss: 0.0023 lr: 0.02
2019-06-03 22:32:36 iteration: 93800 loss: 0.0018 lr: 0.02
2019-06-03 22:32:47 iteration: 93850 loss: 0.0018 lr: 0.02
2019-06-03 22:32:57 iteration: 93900 loss: 0.0017 lr: 0.02
2019-06-03 22:33:08 iteration: 93950 loss: 0.0017 lr: 0.02
2019-06-03 22:33:18 iteration: 94000 loss: 0.0018 lr: 0.02
2019-06-03 22:33:32 iteration: 94050 loss: 0.0020 lr: 0.02
2019-06-03 22:33:42 iteration: 94100 loss: 0.0018 lr: 0.02
2019-06-03 22:33:53 iteration: 94150 loss: 0.0014 lr: 0.02
2019-06-03 22:34:04 iteration: 94200 loss: 0.0016 lr: 0.02
2019-06-03 22:34:15 iteration: 94250 loss: 0.0019 lr: 0.02
2019-06-03 22:34:25 iteration: 94300 loss: 0.0017 lr: 0.02
2019-06-03 22:34:36 iteration: 94350 loss: 0.0017 lr: 0.02
2019-06-03 22:34:46 iteration: 94400 loss: 0.0019 lr: 0.02
2019-06-03 22:34:56 iteration: 94450 loss: 0.0018 lr: 0.02
2019-06-03 22:35:07 iteration: 94500 loss: 0.0018 lr: 0.02
2019-06-03 22:35:20 iteration: 94550 loss: 0.0020 lr: 0.02
2019-06-03 22:35:31 iteration: 94600 loss: 0.0024 lr: 0.02
2019-06-03 22:35:41 iteration: 94650 loss: 0.0024 lr: 0.02
2019-06-03 22:35:51 iteration: 94700 loss: 0.0020 lr: 0.02
2019-06-03 22:36:02 iteration: 94750 loss: 0.0018 lr: 0.02
2019-06-03 22:36:12 iteration: 94800 loss: 0.0023 lr: 0.02
2019-06-03 22:36:22 iteration: 94850 loss: 0.0019 lr: 0.02
2019-06-03 22:36:32 iteration: 94900 loss: 0.0023 lr: 0.02
2019-06-03 22:36:43 iteration: 94950 loss: 0.0018 lr: 0.02
2019-06-03 22:36:54 iteration: 95000 loss: 0.0021 lr: 0.02
2019-06-03 22:37:07 iteration: 95050 loss: 0.0019 lr: 0.02
2019-06-03 22:37:18 iteration: 95100 loss: 0.0016 lr: 0.02
2019-06-03 22:37:29 iteration: 95150 loss: 0.0018 lr: 0.02
2019-06-03 22:37:40 iteration: 95200 loss: 0.0017 lr: 0.02
2019-06-03 22:37:50 iteration: 95250 loss: 0.0017 lr: 0.02
2019-06-03 22:38:01 iteration: 95300 loss: 0.0020 lr: 0.02
2019-06-03 22:38:12 iteration: 95350 loss: 0.0019 lr: 0.02
2019-06-03 22:38:22 iteration: 95400 loss: 0.0019 lr: 0.02
2019-06-03 22:38:32 iteration: 95450 loss: 0.0018 lr: 0.02
2019-06-03 22:38:43 iteration: 95500 loss: 0.0020 lr: 0.02
2019-06-03 22:38:55 iteration: 95550 loss: 0.0020 lr: 0.02
2019-06-03 22:39:06 iteration: 95600 loss: 0.0020 lr: 0.02
2019-06-03 22:39:16 iteration: 95650 loss: 0.0020 lr: 0.02
2019-06-03 22:39:27 iteration: 95700 loss: 0.0016 lr: 0.02
2019-06-03 22:39:37 iteration: 95750 loss: 0.0022 lr: 0.02
2019-06-03 22:39:48 iteration: 95800 loss: 0.0019 lr: 0.02
2019-06-03 22:39:58 iteration: 95850 loss: 0.0019 lr: 0.02
2019-06-03 22:40:09 iteration: 95900 loss: 0.0016 lr: 0.02
2019-06-03 22:40:19 iteration: 95950 loss: 0.0017 lr: 0.02
2019-06-03 22:40:30 iteration: 96000 loss: 0.0023 lr: 0.02
2019-06-03 22:40:43 iteration: 96050 loss: 0.0018 lr: 0.02
2019-06-03 22:40:53 iteration: 96100 loss: 0.0018 lr: 0.02
2019-06-03 22:41:04 iteration: 96150 loss: 0.0020 lr: 0.02
2019-06-03 22:41:14 iteration: 96200 loss: 0.0020 lr: 0.02
2019-06-03 22:41:25 iteration: 96250 loss: 0.0015 lr: 0.02
2019-06-03 22:41:35 iteration: 96300 loss: 0.0024 lr: 0.02
2019-06-03 22:41:45 iteration: 96350 loss: 0.0021 lr: 0.02
2019-06-03 22:41:56 iteration: 96400 loss: 0.0020 lr: 0.02
2019-06-03 22:42:07 iteration: 96450 loss: 0.0021 lr: 0.02
2019-06-03 22:42:17 iteration: 96500 loss: 0.0021 lr: 0.02
2019-06-03 22:42:31 iteration: 96550 loss: 0.0018 lr: 0.02
2019-06-03 22:42:41 iteration: 96600 loss: 0.0018 lr: 0.02
2019-06-03 22:42:51 iteration: 96650 loss: 0.0021 lr: 0.02
2019-06-03 22:43:02 iteration: 96700 loss: 0.0019 lr: 0.02
2019-06-03 22:43:14 iteration: 96750 loss: 0.0016 lr: 0.02
2019-06-03 22:43:24 iteration: 96800 loss: 0.0017 lr: 0.02
2019-06-03 22:43:34 iteration: 96850 loss: 0.0022 lr: 0.02
2019-06-03 22:43:45 iteration: 96900 loss: 0.0018 lr: 0.02
2019-06-03 22:43:55 iteration: 96950 loss: 0.0020 lr: 0.02
2019-06-03 22:44:06 iteration: 97000 loss: 0.0021 lr: 0.02
2019-06-03 22:44:20 iteration: 97050 loss: 0.0016 lr: 0.02
2019-06-03 22:44:31 iteration: 97100 loss: 0.0022 lr: 0.02
2019-06-03 22:44:41 iteration: 97150 loss: 0.0020 lr: 0.02
2019-06-03 22:44:52 iteration: 97200 loss: 0.0023 lr: 0.02
2019-06-03 22:45:02 iteration: 97250 loss: 0.0019 lr: 0.02
2019-06-03 22:45:12 iteration: 97300 loss: 0.0020 lr: 0.02
2019-06-03 22:45:23 iteration: 97350 loss: 0.0018 lr: 0.02
2019-06-03 22:45:33 iteration: 97400 loss: 0.0018 lr: 0.02
2019-06-03 22:45:44 iteration: 97450 loss: 0.0018 lr: 0.02
2019-06-03 22:45:54 iteration: 97500 loss: 0.0020 lr: 0.02
2019-06-03 22:46:08 iteration: 97550 loss: 0.0018 lr: 0.02
2019-06-03 22:46:19 iteration: 97600 loss: 0.0019 lr: 0.02
2019-06-03 22:46:30 iteration: 97650 loss: 0.0017 lr: 0.02
2019-06-03 22:46:40 iteration: 97700 loss: 0.0017 lr: 0.02
2019-06-03 22:46:52 iteration: 97750 loss: 0.0020 lr: 0.02
2019-06-03 22:47:01 iteration: 97800 loss: 0.0020 lr: 0.02
2019-06-03 22:47:12 iteration: 97850 loss: 0.0022 lr: 0.02
2019-06-03 22:47:22 iteration: 97900 loss: 0.0021 lr: 0.02
2019-06-03 22:47:33 iteration: 97950 loss: 0.0017 lr: 0.02
2019-06-03 22:47:44 iteration: 98000 loss: 0.0019 lr: 0.02
2019-06-03 22:47:57 iteration: 98050 loss: 0.0021 lr: 0.02
2019-06-03 22:48:08 iteration: 98100 loss: 0.0017 lr: 0.02
2019-06-03 22:48:18 iteration: 98150 loss: 0.0024 lr: 0.02
2019-06-03 22:48:29 iteration: 98200 loss: 0.0020 lr: 0.02
2019-06-03 22:48:39 iteration: 98250 loss: 0.0020 lr: 0.02
2019-06-03 22:48:49 iteration: 98300 loss: 0.0021 lr: 0.02
2019-06-03 22:48:59 iteration: 98350 loss: 0.0017 lr: 0.02
2019-06-03 22:49:10 iteration: 98400 loss: 0.0018 lr: 0.02
2019-06-03 22:49:21 iteration: 98450 loss: 0.0018 lr: 0.02
2019-06-03 22:49:31 iteration: 98500 loss: 0.0019 lr: 0.02
2019-06-03 22:49:45 iteration: 98550 loss: 0.0020 lr: 0.02
2019-06-03 22:49:56 iteration: 98600 loss: 0.0016 lr: 0.02
2019-06-03 22:50:06 iteration: 98650 loss: 0.0020 lr: 0.02
2019-06-03 22:50:17 iteration: 98700 loss: 0.0019 lr: 0.02
2019-06-03 22:50:28 iteration: 98750 loss: 0.0021 lr: 0.02
2019-06-03 22:50:38 iteration: 98800 loss: 0.0020 lr: 0.02
2019-06-03 22:50:48 iteration: 98850 loss: 0.0020 lr: 0.02
2019-06-03 22:50:59 iteration: 98900 loss: 0.0016 lr: 0.02
2019-06-03 22:51:10 iteration: 98950 loss: 0.0017 lr: 0.02
2019-06-03 22:51:20 iteration: 99000 loss: 0.0018 lr: 0.02
2019-06-03 22:51:34 iteration: 99050 loss: 0.0019 lr: 0.02
2019-06-03 22:51:44 iteration: 99100 loss: 0.0018 lr: 0.02
2019-06-03 22:51:54 iteration: 99150 loss: 0.0021 lr: 0.02
2019-06-03 22:52:05 iteration: 99200 loss: 0.0017 lr: 0.02
2019-06-03 22:52:16 iteration: 99250 loss: 0.0018 lr: 0.02
2019-06-03 22:52:27 iteration: 99300 loss: 0.0017 lr: 0.02
2019-06-03 22:52:38 iteration: 99350 loss: 0.0018 lr: 0.02
2019-06-03 22:52:48 iteration: 99400 loss: 0.0016 lr: 0.02
2019-06-03 22:52:59 iteration: 99450 loss: 0.0018 lr: 0.02
2019-06-03 22:53:09 iteration: 99500 loss: 0.0021 lr: 0.02
2019-06-03 22:53:23 iteration: 99550 loss: 0.0018 lr: 0.02
2019-06-03 22:53:33 iteration: 99600 loss: 0.0018 lr: 0.02
2019-06-03 22:53:43 iteration: 99650 loss: 0.0019 lr: 0.02
2019-06-03 22:53:53 iteration: 99700 loss: 0.0019 lr: 0.02
2019-06-03 22:54:04 iteration: 99750 loss: 0.0017 lr: 0.02
2019-06-03 22:54:15 iteration: 99800 loss: 0.0014 lr: 0.02
2019-06-03 22:54:26 iteration: 99850 loss: 0.0017 lr: 0.02
2019-06-03 22:54:36 iteration: 99900 loss: 0.0021 lr: 0.02
2019-06-03 22:54:47 iteration: 99950 loss: 0.0015 lr: 0.02
2019-06-03 22:54:57 iteration: 100000 loss: 0.0018 lr: 0.02
2019-06-03 22:55:10 iteration: 100050 loss: 0.0020 lr: 0.02
2019-06-03 22:55:21 iteration: 100100 loss: 0.0019 lr: 0.02
2019-06-03 22:55:32 iteration: 100150 loss: 0.0017 lr: 0.02
2019-06-03 22:55:43 iteration: 100200 loss: 0.0017 lr: 0.02
2019-06-03 22:55:53 iteration: 100250 loss: 0.0015 lr: 0.02
2019-06-03 22:56:04 iteration: 100300 loss: 0.0019 lr: 0.02
2019-06-03 22:56:15 iteration: 100350 loss: 0.0015 lr: 0.02
2019-06-03 22:56:26 iteration: 100400 loss: 0.0016 lr: 0.02
2019-06-03 22:56:37 iteration: 100450 loss: 0.0016 lr: 0.02
2019-06-03 22:56:48 iteration: 100500 loss: 0.0018 lr: 0.02
2019-06-03 22:57:01 iteration: 100550 loss: 0.0014 lr: 0.02
2019-06-03 22:57:12 iteration: 100600 loss: 0.0019 lr: 0.02
2019-06-03 22:57:22 iteration: 100650 loss: 0.0019 lr: 0.02
2019-06-03 22:57:33 iteration: 100700 loss: 0.0017 lr: 0.02
2019-06-03 22:57:43 iteration: 100750 loss: 0.0022 lr: 0.02
2019-06-03 22:57:53 iteration: 100800 loss: 0.0018 lr: 0.02
2019-06-03 22:58:04 iteration: 100850 loss: 0.0016 lr: 0.02
2019-06-03 22:58:14 iteration: 100900 loss: 0.0019 lr: 0.02
2019-06-03 22:58:25 iteration: 100950 loss: 0.0022 lr: 0.02
2019-06-03 22:58:36 iteration: 101000 loss: 0.0019 lr: 0.02
2019-06-03 22:58:49 iteration: 101050 loss: 0.0017 lr: 0.02
2019-06-03 22:59:00 iteration: 101100 loss: 0.0016 lr: 0.02
2019-06-03 22:59:11 iteration: 101150 loss: 0.0019 lr: 0.02
2019-06-03 22:59:21 iteration: 101200 loss: 0.0021 lr: 0.02
2019-06-03 22:59:32 iteration: 101250 loss: 0.0019 lr: 0.02
2019-06-03 22:59:43 iteration: 101300 loss: 0.0020 lr: 0.02
2019-06-03 22:59:53 iteration: 101350 loss: 0.0020 lr: 0.02
2019-06-03 23:00:03 iteration: 101400 loss: 0.0020 lr: 0.02
2019-06-03 23:00:14 iteration: 101450 loss: 0.0017 lr: 0.02
2019-06-03 23:00:25 iteration: 101500 loss: 0.0016 lr: 0.02
2019-06-03 23:00:38 iteration: 101550 loss: 0.0016 lr: 0.02
2019-06-03 23:00:49 iteration: 101600 loss: 0.0016 lr: 0.02
2019-06-03 23:01:00 iteration: 101650 loss: 0.0018 lr: 0.02
2019-06-03 23:01:11 iteration: 101700 loss: 0.0015 lr: 0.02
2019-06-03 23:01:21 iteration: 101750 loss: 0.0020 lr: 0.02
2019-06-03 23:01:31 iteration: 101800 loss: 0.0017 lr: 0.02
2019-06-03 23:01:42 iteration: 101850 loss: 0.0016 lr: 0.02
2019-06-03 23:01:53 iteration: 101900 loss: 0.0019 lr: 0.02
2019-06-03 23:02:04 iteration: 101950 loss: 0.0017 lr: 0.02
2019-06-03 23:02:15 iteration: 102000 loss: 0.0018 lr: 0.02
2019-06-03 23:02:28 iteration: 102050 loss: 0.0019 lr: 0.02
2019-06-03 23:02:39 iteration: 102100 loss: 0.0016 lr: 0.02
2019-06-03 23:02:49 iteration: 102150 loss: 0.0018 lr: 0.02
2019-06-03 23:02:59 iteration: 102200 loss: 0.0017 lr: 0.02
2019-06-03 23:03:10 iteration: 102250 loss: 0.0017 lr: 0.02
2019-06-03 23:03:20 iteration: 102300 loss: 0.0019 lr: 0.02
2019-06-03 23:03:30 iteration: 102350 loss: 0.0016 lr: 0.02
2019-06-03 23:03:41 iteration: 102400 loss: 0.0020 lr: 0.02
2019-06-03 23:03:50 iteration: 102450 loss: 0.0023 lr: 0.02
2019-06-03 23:04:01 iteration: 102500 loss: 0.0017 lr: 0.02
2019-06-03 23:04:14 iteration: 102550 loss: 0.0020 lr: 0.02
2019-06-03 23:04:25 iteration: 102600 loss: 0.0019 lr: 0.02
2019-06-03 23:04:36 iteration: 102650 loss: 0.0017 lr: 0.02
2019-06-03 23:04:45 iteration: 102700 loss: 0.0022 lr: 0.02
2019-06-03 23:04:56 iteration: 102750 loss: 0.0020 lr: 0.02
2019-06-03 23:05:06 iteration: 102800 loss: 0.0019 lr: 0.02
2019-06-03 23:05:17 iteration: 102850 loss: 0.0017 lr: 0.02
2019-06-03 23:05:27 iteration: 102900 loss: 0.0018 lr: 0.02
2019-06-03 23:05:37 iteration: 102950 loss: 0.0020 lr: 0.02
2019-06-03 23:05:48 iteration: 103000 loss: 0.0019 lr: 0.02
2019-06-03 23:06:01 iteration: 103050 loss: 0.0022 lr: 0.02
2019-06-03 23:06:12 iteration: 103100 loss: 0.0020 lr: 0.02
2019-06-03 23:06:22 iteration: 103150 loss: 0.0019 lr: 0.02
2019-06-03 23:06:32 iteration: 103200 loss: 0.0017 lr: 0.02
2019-06-03 23:06:43 iteration: 103250 loss: 0.0016 lr: 0.02
2019-06-03 23:06:54 iteration: 103300 loss: 0.0015 lr: 0.02
2019-06-03 23:07:04 iteration: 103350 loss: 0.0015 lr: 0.02
2019-06-03 23:07:15 iteration: 103400 loss: 0.0015 lr: 0.02
2019-06-03 23:07:25 iteration: 103450 loss: 0.0019 lr: 0.02
2019-06-03 23:07:36 iteration: 103500 loss: 0.0017 lr: 0.02
2019-06-03 23:07:49 iteration: 103550 loss: 0.0018 lr: 0.02
2019-06-03 23:08:00 iteration: 103600 loss: 0.0017 lr: 0.02
2019-06-03 23:08:12 iteration: 103650 loss: 0.0016 lr: 0.02
2019-06-03 23:08:22 iteration: 103700 loss: 0.0018 lr: 0.02
2019-06-03 23:08:33 iteration: 103750 loss: 0.0018 lr: 0.02
2019-06-03 23:08:44 iteration: 103800 loss: 0.0017 lr: 0.02
2019-06-03 23:08:53 iteration: 103850 loss: 0.0018 lr: 0.02
2019-06-03 23:09:04 iteration: 103900 loss: 0.0015 lr: 0.02
2019-06-03 23:09:14 iteration: 103950 loss: 0.0018 lr: 0.02
2019-06-03 23:09:25 iteration: 104000 loss: 0.0019 lr: 0.02
2019-06-03 23:09:39 iteration: 104050 loss: 0.0014 lr: 0.02
2019-06-03 23:09:50 iteration: 104100 loss: 0.0019 lr: 0.02
2019-06-03 23:10:00 iteration: 104150 loss: 0.0018 lr: 0.02
2019-06-03 23:10:10 iteration: 104200 loss: 0.0018 lr: 0.02
2019-06-03 23:10:21 iteration: 104250 loss: 0.0018 lr: 0.02
2019-06-03 23:10:32 iteration: 104300 loss: 0.0017 lr: 0.02
2019-06-03 23:10:43 iteration: 104350 loss: 0.0015 lr: 0.02
2019-06-03 23:10:53 iteration: 104400 loss: 0.0018 lr: 0.02
2019-06-03 23:11:04 iteration: 104450 loss: 0.0017 lr: 0.02
2019-06-03 23:11:14 iteration: 104500 loss: 0.0019 lr: 0.02
2019-06-03 23:11:26 iteration: 104550 loss: 0.0019 lr: 0.02
2019-06-03 23:11:37 iteration: 104600 loss: 0.0018 lr: 0.02
2019-06-03 23:11:47 iteration: 104650 loss: 0.0024 lr: 0.02
2019-06-03 23:11:58 iteration: 104700 loss: 0.0019 lr: 0.02
2019-06-03 23:12:09 iteration: 104750 loss: 0.0019 lr: 0.02
2019-06-03 23:12:19 iteration: 104800 loss: 0.0016 lr: 0.02
2019-06-03 23:12:30 iteration: 104850 loss: 0.0017 lr: 0.02
2019-06-03 23:12:41 iteration: 104900 loss: 0.0018 lr: 0.02
2019-06-03 23:12:52 iteration: 104950 loss: 0.0020 lr: 0.02
2019-06-03 23:13:03 iteration: 105000 loss: 0.0017 lr: 0.02
2019-06-03 23:13:16 iteration: 105050 loss: 0.0018 lr: 0.02
2019-06-03 23:13:26 iteration: 105100 loss: 0.0018 lr: 0.02
2019-06-03 23:13:36 iteration: 105150 loss: 0.0017 lr: 0.02
2019-06-03 23:13:47 iteration: 105200 loss: 0.0020 lr: 0.02
2019-06-03 23:13:58 iteration: 105250 loss: 0.0017 lr: 0.02
2019-06-03 23:14:08 iteration: 105300 loss: 0.0017 lr: 0.02
2019-06-03 23:14:19 iteration: 105350 loss: 0.0018 lr: 0.02
2019-06-03 23:14:29 iteration: 105400 loss: 0.0020 lr: 0.02
2019-06-03 23:14:39 iteration: 105450 loss: 0.0019 lr: 0.02
2019-06-03 23:14:50 iteration: 105500 loss: 0.0018 lr: 0.02
2019-06-03 23:15:03 iteration: 105550 loss: 0.0019 lr: 0.02
2019-06-03 23:15:14 iteration: 105600 loss: 0.0017 lr: 0.02
2019-06-03 23:15:25 iteration: 105650 loss: 0.0016 lr: 0.02
2019-06-03 23:15:36 iteration: 105700 loss: 0.0018 lr: 0.02
2019-06-03 23:15:46 iteration: 105750 loss: 0.0020 lr: 0.02
2019-06-03 23:15:57 iteration: 105800 loss: 0.0020 lr: 0.02
2019-06-03 23:16:08 iteration: 105850 loss: 0.0014 lr: 0.02
2019-06-03 23:16:18 iteration: 105900 loss: 0.0017 lr: 0.02
2019-06-03 23:16:29 iteration: 105950 loss: 0.0017 lr: 0.02
2019-06-03 23:16:39 iteration: 106000 loss: 0.0018 lr: 0.02
2019-06-03 23:16:51 iteration: 106050 loss: 0.0021 lr: 0.02
2019-06-03 23:17:02 iteration: 106100 loss: 0.0016 lr: 0.02
2019-06-03 23:17:13 iteration: 106150 loss: 0.0020 lr: 0.02
2019-06-03 23:17:24 iteration: 106200 loss: 0.0018 lr: 0.02
2019-06-03 23:17:34 iteration: 106250 loss: 0.0022 lr: 0.02
2019-06-03 23:17:45 iteration: 106300 loss: 0.0018 lr: 0.02
2019-06-03 23:17:56 iteration: 106350 loss: 0.0018 lr: 0.02
2019-06-03 23:18:06 iteration: 106400 loss: 0.0017 lr: 0.02
2019-06-03 23:18:15 iteration: 106450 loss: 0.0022 lr: 0.02
2019-06-03 23:18:26 iteration: 106500 loss: 0.0016 lr: 0.02
2019-06-03 23:18:39 iteration: 106550 loss: 0.0018 lr: 0.02
2019-06-03 23:18:50 iteration: 106600 loss: 0.0018 lr: 0.02
2019-06-03 23:19:00 iteration: 106650 loss: 0.0016 lr: 0.02
2019-06-03 23:19:11 iteration: 106700 loss: 0.0016 lr: 0.02
2019-06-03 23:19:22 iteration: 106750 loss: 0.0013 lr: 0.02
2019-06-03 23:19:33 iteration: 106800 loss: 0.0013 lr: 0.02
2019-06-03 23:19:44 iteration: 106850 loss: 0.0016 lr: 0.02
2019-06-03 23:19:54 iteration: 106900 loss: 0.0019 lr: 0.02
2019-06-03 23:20:04 iteration: 106950 loss: 0.0018 lr: 0.02
2019-06-03 23:20:15 iteration: 107000 loss: 0.0018 lr: 0.02
2019-06-03 23:20:28 iteration: 107050 loss: 0.0019 lr: 0.02
2019-06-03 23:20:39 iteration: 107100 loss: 0.0016 lr: 0.02
2019-06-03 23:20:49 iteration: 107150 loss: 0.0015 lr: 0.02
2019-06-03 23:21:00 iteration: 107200 loss: 0.0016 lr: 0.02
2019-06-03 23:21:11 iteration: 107250 loss: 0.0020 lr: 0.02
2019-06-03 23:21:21 iteration: 107300 loss: 0.0017 lr: 0.02
2019-06-03 23:21:32 iteration: 107350 loss: 0.0019 lr: 0.02
2019-06-03 23:21:42 iteration: 107400 loss: 0.0017 lr: 0.02
2019-06-03 23:21:52 iteration: 107450 loss: 0.0020 lr: 0.02
2019-06-03 23:22:03 iteration: 107500 loss: 0.0016 lr: 0.02
2019-06-03 23:22:17 iteration: 107550 loss: 0.0018 lr: 0.02
2019-06-03 23:22:28 iteration: 107600 loss: 0.0017 lr: 0.02
2019-06-03 23:22:39 iteration: 107650 loss: 0.0017 lr: 0.02
2019-06-03 23:22:49 iteration: 107700 loss: 0.0022 lr: 0.02
2019-06-03 23:23:00 iteration: 107750 loss: 0.0016 lr: 0.02
2019-06-03 23:23:10 iteration: 107800 loss: 0.0017 lr: 0.02
2019-06-03 23:23:21 iteration: 107850 loss: 0.0019 lr: 0.02
2019-06-03 23:23:31 iteration: 107900 loss: 0.0015 lr: 0.02
2019-06-03 23:23:41 iteration: 107950 loss: 0.0019 lr: 0.02
2019-06-03 23:23:51 iteration: 108000 loss: 0.0021 lr: 0.02
2019-06-03 23:24:05 iteration: 108050 loss: 0.0016 lr: 0.02
2019-06-03 23:24:16 iteration: 108100 loss: 0.0024 lr: 0.02
2019-06-03 23:24:27 iteration: 108150 loss: 0.0017 lr: 0.02
2019-06-03 23:24:37 iteration: 108200 loss: 0.0019 lr: 0.02
2019-06-03 23:24:48 iteration: 108250 loss: 0.0016 lr: 0.02
2019-06-03 23:24:58 iteration: 108300 loss: 0.0017 lr: 0.02
2019-06-03 23:25:09 iteration: 108350 loss: 0.0016 lr: 0.02
2019-06-03 23:25:19 iteration: 108400 loss: 0.0016 lr: 0.02
2019-06-03 23:25:30 iteration: 108450 loss: 0.0015 lr: 0.02
2019-06-03 23:25:41 iteration: 108500 loss: 0.0019 lr: 0.02
2019-06-03 23:25:54 iteration: 108550 loss: 0.0019 lr: 0.02
2019-06-03 23:26:04 iteration: 108600 loss: 0.0019 lr: 0.02
2019-06-03 23:26:15 iteration: 108650 loss: 0.0018 lr: 0.02
2019-06-03 23:26:26 iteration: 108700 loss: 0.0016 lr: 0.02
2019-06-03 23:26:35 iteration: 108750 loss: 0.0019 lr: 0.02
2019-06-03 23:26:46 iteration: 108800 loss: 0.0016 lr: 0.02
2019-06-03 23:26:57 iteration: 108850 loss: 0.0016 lr: 0.02
2019-06-03 23:27:08 iteration: 108900 loss: 0.0019 lr: 0.02
2019-06-03 23:27:19 iteration: 108950 loss: 0.0016 lr: 0.02
2019-06-03 23:27:29 iteration: 109000 loss: 0.0017 lr: 0.02
2019-06-03 23:27:42 iteration: 109050 loss: 0.0018 lr: 0.02
2019-06-03 23:27:52 iteration: 109100 loss: 0.0020 lr: 0.02
2019-06-03 23:28:03 iteration: 109150 loss: 0.0020 lr: 0.02
2019-06-03 23:28:13 iteration: 109200 loss: 0.0016 lr: 0.02
2019-06-03 23:28:24 iteration: 109250 loss: 0.0015 lr: 0.02
2019-06-03 23:28:34 iteration: 109300 loss: 0.0020 lr: 0.02
2019-06-03 23:28:44 iteration: 109350 loss: 0.0020 lr: 0.02
2019-06-03 23:28:54 iteration: 109400 loss: 0.0019 lr: 0.02
2019-06-03 23:29:05 iteration: 109450 loss: 0.0015 lr: 0.02
2019-06-03 23:29:15 iteration: 109500 loss: 0.0017 lr: 0.02
2019-06-03 23:29:29 iteration: 109550 loss: 0.0018 lr: 0.02
2019-06-03 23:29:39 iteration: 109600 loss: 0.0018 lr: 0.02
2019-06-03 23:29:50 iteration: 109650 loss: 0.0019 lr: 0.02
2019-06-03 23:30:01 iteration: 109700 loss: 0.0016 lr: 0.02
2019-06-03 23:30:11 iteration: 109750 loss: 0.0017 lr: 0.02
2019-06-03 23:30:22 iteration: 109800 loss: 0.0016 lr: 0.02
2019-06-03 23:30:32 iteration: 109850 loss: 0.0019 lr: 0.02
2019-06-03 23:30:43 iteration: 109900 loss: 0.0020 lr: 0.02
2019-06-03 23:30:54 iteration: 109950 loss: 0.0015 lr: 0.02
2019-06-03 23:31:05 iteration: 110000 loss: 0.0015 lr: 0.02
2019-06-03 23:31:18 iteration: 110050 loss: 0.0017 lr: 0.02
2019-06-03 23:31:29 iteration: 110100 loss: 0.0015 lr: 0.02
2019-06-03 23:31:39 iteration: 110150 loss: 0.0016 lr: 0.02
2019-06-03 23:31:50 iteration: 110200 loss: 0.0022 lr: 0.02
2019-06-03 23:32:00 iteration: 110250 loss: 0.0020 lr: 0.02
2019-06-03 23:32:11 iteration: 110300 loss: 0.0020 lr: 0.02
2019-06-03 23:32:21 iteration: 110350 loss: 0.0016 lr: 0.02
2019-06-03 23:32:32 iteration: 110400 loss: 0.0017 lr: 0.02
2019-06-03 23:32:43 iteration: 110450 loss: 0.0012 lr: 0.02
2019-06-03 23:32:53 iteration: 110500 loss: 0.0019 lr: 0.02
2019-06-03 23:33:07 iteration: 110550 loss: 0.0018 lr: 0.02
2019-06-03 23:33:17 iteration: 110600 loss: 0.0019 lr: 0.02
2019-06-03 23:33:28 iteration: 110650 loss: 0.0022 lr: 0.02
2019-06-03 23:33:39 iteration: 110700 loss: 0.0015 lr: 0.02
2019-06-03 23:33:50 iteration: 110750 loss: 0.0019 lr: 0.02
2019-06-03 23:34:00 iteration: 110800 loss: 0.0018 lr: 0.02
2019-06-03 23:34:10 iteration: 110850 loss: 0.0018 lr: 0.02
2019-06-03 23:34:21 iteration: 110900 loss: 0.0021 lr: 0.02
2019-06-03 23:34:32 iteration: 110950 loss: 0.0019 lr: 0.02
2019-06-03 23:34:42 iteration: 111000 loss: 0.0019 lr: 0.02
2019-06-03 23:34:55 iteration: 111050 loss: 0.0018 lr: 0.02
2019-06-03 23:35:06 iteration: 111100 loss: 0.0015 lr: 0.02
2019-06-03 23:35:17 iteration: 111150 loss: 0.0018 lr: 0.02
2019-06-03 23:35:27 iteration: 111200 loss: 0.0018 lr: 0.02
2019-06-03 23:35:38 iteration: 111250 loss: 0.0014 lr: 0.02
2019-06-03 23:35:49 iteration: 111300 loss: 0.0016 lr: 0.02
2019-06-03 23:35:59 iteration: 111350 loss: 0.0018 lr: 0.02
2019-06-03 23:36:10 iteration: 111400 loss: 0.0015 lr: 0.02
2019-06-03 23:36:21 iteration: 111450 loss: 0.0016 lr: 0.02
2019-06-03 23:36:32 iteration: 111500 loss: 0.0013 lr: 0.02
2019-06-03 23:36:45 iteration: 111550 loss: 0.0015 lr: 0.02
2019-06-03 23:36:55 iteration: 111600 loss: 0.0017 lr: 0.02
2019-06-03 23:37:06 iteration: 111650 loss: 0.0016 lr: 0.02
2019-06-03 23:37:17 iteration: 111700 loss: 0.0015 lr: 0.02
2019-06-03 23:37:28 iteration: 111750 loss: 0.0017 lr: 0.02
2019-06-03 23:37:39 iteration: 111800 loss: 0.0015 lr: 0.02
2019-06-03 23:37:48 iteration: 111850 loss: 0.0018 lr: 0.02
2019-06-03 23:37:59 iteration: 111900 loss: 0.0017 lr: 0.02
2019-06-03 23:38:10 iteration: 111950 loss: 0.0021 lr: 0.02
2019-06-03 23:38:19 iteration: 112000 loss: 0.0016 lr: 0.02
2019-06-03 23:38:32 iteration: 112050 loss: 0.0016 lr: 0.02
2019-06-03 23:38:43 iteration: 112100 loss: 0.0021 lr: 0.02
2019-06-03 23:38:53 iteration: 112150 loss: 0.0020 lr: 0.02
2019-06-03 23:39:03 iteration: 112200 loss: 0.0023 lr: 0.02
2019-06-03 23:39:14 iteration: 112250 loss: 0.0016 lr: 0.02
2019-06-03 23:39:24 iteration: 112300 loss: 0.0018 lr: 0.02
2019-06-03 23:39:35 iteration: 112350 loss: 0.0017 lr: 0.02
2019-06-03 23:39:45 iteration: 112400 loss: 0.0021 lr: 0.02
2019-06-03 23:39:56 iteration: 112450 loss: 0.0016 lr: 0.02
2019-06-03 23:40:07 iteration: 112500 loss: 0.0015 lr: 0.02
2019-06-03 23:40:21 iteration: 112550 loss: 0.0019 lr: 0.02
2019-06-03 23:40:31 iteration: 112600 loss: 0.0017 lr: 0.02
2019-06-03 23:40:42 iteration: 112650 loss: 0.0015 lr: 0.02
2019-06-03 23:40:53 iteration: 112700 loss: 0.0018 lr: 0.02
2019-06-03 23:41:03 iteration: 112750 loss: 0.0016 lr: 0.02
2019-06-03 23:41:14 iteration: 112800 loss: 0.0020 lr: 0.02
2019-06-03 23:41:24 iteration: 112850 loss: 0.0018 lr: 0.02
2019-06-03 23:41:35 iteration: 112900 loss: 0.0013 lr: 0.02
2019-06-03 23:41:46 iteration: 112950 loss: 0.0015 lr: 0.02
2019-06-03 23:41:56 iteration: 113000 loss: 0.0016 lr: 0.02
2019-06-03 23:42:09 iteration: 113050 loss: 0.0017 lr: 0.02
2019-06-03 23:42:20 iteration: 113100 loss: 0.0016 lr: 0.02
2019-06-03 23:42:31 iteration: 113150 loss: 0.0013 lr: 0.02
2019-06-03 23:42:42 iteration: 113200 loss: 0.0017 lr: 0.02
2019-06-03 23:42:53 iteration: 113250 loss: 0.0016 lr: 0.02
2019-06-03 23:43:03 iteration: 113300 loss: 0.0018 lr: 0.02
2019-06-03 23:43:13 iteration: 113350 loss: 0.0019 lr: 0.02
2019-06-03 23:43:23 iteration: 113400 loss: 0.0016 lr: 0.02
2019-06-03 23:43:34 iteration: 113450 loss: 0.0014 lr: 0.02
2019-06-03 23:43:43 iteration: 113500 loss: 0.0018 lr: 0.02
2019-06-03 23:43:57 iteration: 113550 loss: 0.0017 lr: 0.02
2019-06-03 23:44:07 iteration: 113600 loss: 0.0021 lr: 0.02
2019-06-03 23:44:19 iteration: 113650 loss: 0.0017 lr: 0.02
2019-06-03 23:44:29 iteration: 113700 loss: 0.0015 lr: 0.02
2019-06-03 23:44:39 iteration: 113750 loss: 0.0021 lr: 0.02
2019-06-03 23:44:50 iteration: 113800 loss: 0.0017 lr: 0.02
2019-06-03 23:45:00 iteration: 113850 loss: 0.0017 lr: 0.02
2019-06-03 23:45:10 iteration: 113900 loss: 0.0021 lr: 0.02
2019-06-03 23:45:21 iteration: 113950 loss: 0.0019 lr: 0.02
2019-06-03 23:45:32 iteration: 114000 loss: 0.0014 lr: 0.02
2019-06-03 23:45:45 iteration: 114050 loss: 0.0017 lr: 0.02
2019-06-03 23:45:55 iteration: 114100 loss: 0.0017 lr: 0.02
2019-06-03 23:46:06 iteration: 114150 loss: 0.0017 lr: 0.02
2019-06-03 23:46:15 iteration: 114200 loss: 0.0017 lr: 0.02
2019-06-03 23:46:26 iteration: 114250 loss: 0.0017 lr: 0.02
2019-06-03 23:46:37 iteration: 114300 loss: 0.0017 lr: 0.02
2019-06-03 23:46:48 iteration: 114350 loss: 0.0017 lr: 0.02
2019-06-03 23:46:58 iteration: 114400 loss: 0.0016 lr: 0.02
2019-06-03 23:47:08 iteration: 114450 loss: 0.0015 lr: 0.02
2019-06-03 23:47:19 iteration: 114500 loss: 0.0018 lr: 0.02
2019-06-03 23:47:32 iteration: 114550 loss: 0.0015 lr: 0.02
2019-06-03 23:47:42 iteration: 114600 loss: 0.0018 lr: 0.02
2019-06-03 23:47:53 iteration: 114650 loss: 0.0018 lr: 0.02
2019-06-03 23:48:04 iteration: 114700 loss: 0.0018 lr: 0.02
2019-06-03 23:48:14 iteration: 114750 loss: 0.0016 lr: 0.02
2019-06-03 23:48:24 iteration: 114800 loss: 0.0015 lr: 0.02
2019-06-03 23:48:34 iteration: 114850 loss: 0.0017 lr: 0.02
2019-06-03 23:48:44 iteration: 114900 loss: 0.0017 lr: 0.02
2019-06-03 23:48:55 iteration: 114950 loss: 0.0018 lr: 0.02
2019-06-03 23:49:05 iteration: 115000 loss: 0.0020 lr: 0.02
2019-06-03 23:49:19 iteration: 115050 loss: 0.0015 lr: 0.02
2019-06-03 23:49:30 iteration: 115100 loss: 0.0019 lr: 0.02
2019-06-03 23:49:40 iteration: 115150 loss: 0.0017 lr: 0.02
2019-06-03 23:49:50 iteration: 115200 loss: 0.0020 lr: 0.02
2019-06-03 23:50:01 iteration: 115250 loss: 0.0016 lr: 0.02
2019-06-03 23:50:12 iteration: 115300 loss: 0.0014 lr: 0.02
2019-06-03 23:50:23 iteration: 115350 loss: 0.0015 lr: 0.02
2019-06-03 23:50:34 iteration: 115400 loss: 0.0015 lr: 0.02
2019-06-03 23:50:44 iteration: 115450 loss: 0.0016 lr: 0.02
2019-06-03 23:50:55 iteration: 115500 loss: 0.0017 lr: 0.02
2019-06-03 23:51:08 iteration: 115550 loss: 0.0015 lr: 0.02
2019-06-03 23:51:19 iteration: 115600 loss: 0.0021 lr: 0.02
2019-06-03 23:51:29 iteration: 115650 loss: 0.0019 lr: 0.02
2019-06-03 23:51:40 iteration: 115700 loss: 0.0017 lr: 0.02
2019-06-03 23:51:50 iteration: 115750 loss: 0.0017 lr: 0.02
2019-06-03 23:52:01 iteration: 115800 loss: 0.0015 lr: 0.02
2019-06-03 23:52:11 iteration: 115850 loss: 0.0021 lr: 0.02
2019-06-03 23:52:21 iteration: 115900 loss: 0.0018 lr: 0.02
2019-06-03 23:52:32 iteration: 115950 loss: 0.0015 lr: 0.02
2019-06-03 23:52:43 iteration: 116000 loss: 0.0017 lr: 0.02
2019-06-03 23:52:56 iteration: 116050 loss: 0.0018 lr: 0.02
2019-06-03 23:53:07 iteration: 116100 loss: 0.0016 lr: 0.02
2019-06-03 23:53:18 iteration: 116150 loss: 0.0016 lr: 0.02
2019-06-03 23:53:28 iteration: 116200 loss: 0.0020 lr: 0.02
2019-06-03 23:53:38 iteration: 116250 loss: 0.0016 lr: 0.02
2019-06-03 23:53:49 iteration: 116300 loss: 0.0015 lr: 0.02
2019-06-03 23:54:00 iteration: 116350 loss: 0.0016 lr: 0.02
2019-06-03 23:54:11 iteration: 116400 loss: 0.0014 lr: 0.02
2019-06-03 23:54:21 iteration: 116450 loss: 0.0015 lr: 0.02
2019-06-03 23:54:31 iteration: 116500 loss: 0.0015 lr: 0.02
2019-06-03 23:54:45 iteration: 116550 loss: 0.0014 lr: 0.02
2019-06-03 23:54:55 iteration: 116600 loss: 0.0017 lr: 0.02
2019-06-03 23:55:06 iteration: 116650 loss: 0.0014 lr: 0.02
2019-06-03 23:55:17 iteration: 116700 loss: 0.0017 lr: 0.02
2019-06-03 23:55:28 iteration: 116750 loss: 0.0016 lr: 0.02
2019-06-03 23:55:38 iteration: 116800 loss: 0.0017 lr: 0.02
2019-06-03 23:55:48 iteration: 116850 loss: 0.0018 lr: 0.02
2019-06-03 23:55:59 iteration: 116900 loss: 0.0015 lr: 0.02
2019-06-03 23:56:09 iteration: 116950 loss: 0.0017 lr: 0.02
2019-06-03 23:56:20 iteration: 117000 loss: 0.0018 lr: 0.02
2019-06-03 23:56:34 iteration: 117050 loss: 0.0015 lr: 0.02
2019-06-03 23:56:45 iteration: 117100 loss: 0.0014 lr: 0.02
2019-06-03 23:56:55 iteration: 117150 loss: 0.0020 lr: 0.02
2019-06-03 23:57:05 iteration: 117200 loss: 0.0019 lr: 0.02
2019-06-03 23:57:15 iteration: 117250 loss: 0.0018 lr: 0.02
2019-06-03 23:57:26 iteration: 117300 loss: 0.0017 lr: 0.02
2019-06-03 23:57:36 iteration: 117350 loss: 0.0018 lr: 0.02
2019-06-03 23:57:46 iteration: 117400 loss: 0.0019 lr: 0.02
2019-06-03 23:57:57 iteration: 117450 loss: 0.0013 lr: 0.02
2019-06-03 23:58:08 iteration: 117500 loss: 0.0015 lr: 0.02
2019-06-03 23:58:21 iteration: 117550 loss: 0.0014 lr: 0.02
2019-06-03 23:58:32 iteration: 117600 loss: 0.0016 lr: 0.02
2019-06-03 23:58:42 iteration: 117650 loss: 0.0017 lr: 0.02
2019-06-03 23:58:53 iteration: 117700 loss: 0.0018 lr: 0.02
2019-06-03 23:59:03 iteration: 117750 loss: 0.0018 lr: 0.02
2019-06-03 23:59:14 iteration: 117800 loss: 0.0017 lr: 0.02
2019-06-03 23:59:24 iteration: 117850 loss: 0.0019 lr: 0.02
2019-06-03 23:59:34 iteration: 117900 loss: 0.0016 lr: 0.02
2019-06-03 23:59:45 iteration: 117950 loss: 0.0016 lr: 0.02
2019-06-03 23:59:55 iteration: 118000 loss: 0.0014 lr: 0.02
2019-06-04 00:00:08 iteration: 118050 loss: 0.0016 lr: 0.02
2019-06-04 00:00:19 iteration: 118100 loss: 0.0017 lr: 0.02
2019-06-04 00:00:30 iteration: 118150 loss: 0.0015 lr: 0.02
2019-06-04 00:00:40 iteration: 118200 loss: 0.0016 lr: 0.02
2019-06-04 00:00:50 iteration: 118250 loss: 0.0016 lr: 0.02
2019-06-04 00:01:01 iteration: 118300 loss: 0.0021 lr: 0.02
2019-06-04 00:01:12 iteration: 118350 loss: 0.0018 lr: 0.02
2019-06-04 00:01:22 iteration: 118400 loss: 0.0020 lr: 0.02
2019-06-04 00:01:33 iteration: 118450 loss: 0.0018 lr: 0.02
2019-06-04 00:01:43 iteration: 118500 loss: 0.0019 lr: 0.02
2019-06-04 00:01:57 iteration: 118550 loss: 0.0016 lr: 0.02
2019-06-04 00:02:08 iteration: 118600 loss: 0.0016 lr: 0.02
2019-06-04 00:02:19 iteration: 118650 loss: 0.0017 lr: 0.02
2019-06-04 00:02:29 iteration: 118700 loss: 0.0016 lr: 0.02
2019-06-04 00:02:40 iteration: 118750 loss: 0.0015 lr: 0.02
2019-06-04 00:02:50 iteration: 118800 loss: 0.0016 lr: 0.02
2019-06-04 00:03:01 iteration: 118850 loss: 0.0015 lr: 0.02
2019-06-04 00:03:11 iteration: 118900 loss: 0.0016 lr: 0.02
2019-06-04 00:03:21 iteration: 118950 loss: 0.0019 lr: 0.02
2019-06-04 00:03:32 iteration: 119000 loss: 0.0015 lr: 0.02
2019-06-04 00:03:46 iteration: 119050 loss: 0.0016 lr: 0.02
2019-06-04 00:03:56 iteration: 119100 loss: 0.0017 lr: 0.02
2019-06-04 00:04:07 iteration: 119150 loss: 0.0014 lr: 0.02
2019-06-04 00:04:17 iteration: 119200 loss: 0.0015 lr: 0.02
2019-06-04 00:04:28 iteration: 119250 loss: 0.0019 lr: 0.02
2019-06-04 00:04:38 iteration: 119300 loss: 0.0016 lr: 0.02
2019-06-04 00:04:49 iteration: 119350 loss: 0.0017 lr: 0.02
2019-06-04 00:04:58 iteration: 119400 loss: 0.0018 lr: 0.02
2019-06-04 00:05:09 iteration: 119450 loss: 0.0021 lr: 0.02
2019-06-04 00:05:19 iteration: 119500 loss: 0.0015 lr: 0.02
2019-06-04 00:05:33 iteration: 119550 loss: 0.0018 lr: 0.02
2019-06-04 00:05:43 iteration: 119600 loss: 0.0018 lr: 0.02
2019-06-04 00:05:53 iteration: 119650 loss: 0.0019 lr: 0.02
2019-06-04 00:06:04 iteration: 119700 loss: 0.0017 lr: 0.02
2019-06-04 00:06:14 iteration: 119750 loss: 0.0016 lr: 0.02
2019-06-04 00:06:25 iteration: 119800 loss: 0.0019 lr: 0.02
2019-06-04 00:06:35 iteration: 119850 loss: 0.0018 lr: 0.02
2019-06-04 00:06:46 iteration: 119900 loss: 0.0016 lr: 0.02
2019-06-04 00:06:57 iteration: 119950 loss: 0.0015 lr: 0.02
2019-06-04 00:07:07 iteration: 120000 loss: 0.0018 lr: 0.02
2019-06-04 00:07:20 iteration: 120050 loss: 0.0016 lr: 0.02
2019-06-04 00:07:30 iteration: 120100 loss: 0.0017 lr: 0.02
2019-06-04 00:07:41 iteration: 120150 loss: 0.0017 lr: 0.02
2019-06-04 00:07:51 iteration: 120200 loss: 0.0017 lr: 0.02
2019-06-04 00:08:03 iteration: 120250 loss: 0.0015 lr: 0.02
2019-06-04 00:08:13 iteration: 120300 loss: 0.0018 lr: 0.02
2019-06-04 00:08:24 iteration: 120350 loss: 0.0014 lr: 0.02
2019-06-04 00:08:35 iteration: 120400 loss: 0.0015 lr: 0.02
2019-06-04 00:08:45 iteration: 120450 loss: 0.0018 lr: 0.02
2019-06-04 00:08:56 iteration: 120500 loss: 0.0015 lr: 0.02
2019-06-04 00:09:09 iteration: 120550 loss: 0.0015 lr: 0.02
2019-06-04 00:09:20 iteration: 120600 loss: 0.0017 lr: 0.02
2019-06-04 00:09:30 iteration: 120650 loss: 0.0019 lr: 0.02
2019-06-04 00:09:41 iteration: 120700 loss: 0.0016 lr: 0.02
2019-06-04 00:09:52 iteration: 120750 loss: 0.0013 lr: 0.02
2019-06-04 00:10:03 iteration: 120800 loss: 0.0015 lr: 0.02
2019-06-04 00:10:13 iteration: 120850 loss: 0.0017 lr: 0.02
2019-06-04 00:10:23 iteration: 120900 loss: 0.0018 lr: 0.02
2019-06-04 00:10:34 iteration: 120950 loss: 0.0016 lr: 0.02
2019-06-04 00:10:45 iteration: 121000 loss: 0.0016 lr: 0.02
2019-06-04 00:10:58 iteration: 121050 loss: 0.0014 lr: 0.02
2019-06-04 00:11:09 iteration: 121100 loss: 0.0014 lr: 0.02
2019-06-04 00:11:19 iteration: 121150 loss: 0.0017 lr: 0.02
2019-06-04 00:11:29 iteration: 121200 loss: 0.0018 lr: 0.02
2019-06-04 00:11:40 iteration: 121250 loss: 0.0015 lr: 0.02
2019-06-04 00:11:49 iteration: 121300 loss: 0.0018 lr: 0.02
2019-06-04 00:12:00 iteration: 121350 loss: 0.0017 lr: 0.02
2019-06-04 00:12:11 iteration: 121400 loss: 0.0017 lr: 0.02
2019-06-04 00:12:21 iteration: 121450 loss: 0.0017 lr: 0.02
2019-06-04 00:12:32 iteration: 121500 loss: 0.0015 lr: 0.02
2019-06-04 00:12:45 iteration: 121550 loss: 0.0018 lr: 0.02
2019-06-04 00:12:56 iteration: 121600 loss: 0.0015 lr: 0.02
2019-06-04 00:13:07 iteration: 121650 loss: 0.0016 lr: 0.02
2019-06-04 00:13:17 iteration: 121700 loss: 0.0013 lr: 0.02
2019-06-04 00:13:28 iteration: 121750 loss: 0.0016 lr: 0.02
2019-06-04 00:13:39 iteration: 121800 loss: 0.0014 lr: 0.02
2019-06-04 00:13:49 iteration: 121850 loss: 0.0015 lr: 0.02
2019-06-04 00:14:00 iteration: 121900 loss: 0.0014 lr: 0.02
2019-06-04 00:14:10 iteration: 121950 loss: 0.0015 lr: 0.02
2019-06-04 00:14:20 iteration: 122000 loss: 0.0017 lr: 0.02
2019-06-04 00:14:34 iteration: 122050 loss: 0.0015 lr: 0.02
2019-06-04 00:14:45 iteration: 122100 loss: 0.0014 lr: 0.02
2019-06-04 00:14:55 iteration: 122150 loss: 0.0022 lr: 0.02
2019-06-04 00:15:05 iteration: 122200 loss: 0.0019 lr: 0.02
2019-06-04 00:15:16 iteration: 122250 loss: 0.0014 lr: 0.02
2019-06-04 00:15:27 iteration: 122300 loss: 0.0015 lr: 0.02
2019-06-04 00:15:37 iteration: 122350 loss: 0.0018 lr: 0.02
2019-06-04 00:15:47 iteration: 122400 loss: 0.0018 lr: 0.02
2019-06-04 00:15:58 iteration: 122450 loss: 0.0015 lr: 0.02
2019-06-04 00:16:09 iteration: 122500 loss: 0.0014 lr: 0.02
2019-06-04 00:16:23 iteration: 122550 loss: 0.0015 lr: 0.02
2019-06-04 00:16:34 iteration: 122600 loss: 0.0015 lr: 0.02
2019-06-04 00:16:44 iteration: 122650 loss: 0.0018 lr: 0.02
2019-06-04 00:16:56 iteration: 122700 loss: 0.0014 lr: 0.02
2019-06-04 00:17:06 iteration: 122750 loss: 0.0015 lr: 0.02
2019-06-04 00:17:17 iteration: 122800 loss: 0.0013 lr: 0.02
2019-06-04 00:17:28 iteration: 122850 loss: 0.0013 lr: 0.02
2019-06-04 00:17:38 iteration: 122900 loss: 0.0016 lr: 0.02
2019-06-04 00:17:49 iteration: 122950 loss: 0.0016 lr: 0.02
2019-06-04 00:17:59 iteration: 123000 loss: 0.0015 lr: 0.02
2019-06-04 00:18:13 iteration: 123050 loss: 0.0017 lr: 0.02
2019-06-04 00:18:23 iteration: 123100 loss: 0.0017 lr: 0.02
2019-06-04 00:18:34 iteration: 123150 loss: 0.0016 lr: 0.02
2019-06-04 00:18:45 iteration: 123200 loss: 0.0015 lr: 0.02
2019-06-04 00:18:55 iteration: 123250 loss: 0.0021 lr: 0.02
2019-06-04 00:19:06 iteration: 123300 loss: 0.0015 lr: 0.02
2019-06-04 00:19:16 iteration: 123350 loss: 0.0016 lr: 0.02
2019-06-04 00:19:27 iteration: 123400 loss: 0.0015 lr: 0.02
2019-06-04 00:19:38 iteration: 123450 loss: 0.0016 lr: 0.02
2019-06-04 00:19:48 iteration: 123500 loss: 0.0020 lr: 0.02
2019-06-04 00:20:01 iteration: 123550 loss: 0.0019 lr: 0.02
2019-06-04 00:20:12 iteration: 123600 loss: 0.0015 lr: 0.02
2019-06-04 00:20:23 iteration: 123650 loss: 0.0015 lr: 0.02
2019-06-04 00:20:34 iteration: 123700 loss: 0.0014 lr: 0.02
2019-06-04 00:20:44 iteration: 123750 loss: 0.0016 lr: 0.02
2019-06-04 00:20:54 iteration: 123800 loss: 0.0015 lr: 0.02
2019-06-04 00:21:05 iteration: 123850 loss: 0.0017 lr: 0.02
2019-06-04 00:21:16 iteration: 123900 loss: 0.0017 lr: 0.02
2019-06-04 00:21:26 iteration: 123950 loss: 0.0017 lr: 0.02
2019-06-04 00:21:37 iteration: 124000 loss: 0.0015 lr: 0.02
2019-06-04 00:21:50 iteration: 124050 loss: 0.0016 lr: 0.02
2019-06-04 00:22:01 iteration: 124100 loss: 0.0015 lr: 0.02
2019-06-04 00:22:11 iteration: 124150 loss: 0.0019 lr: 0.02
2019-06-04 00:22:21 iteration: 124200 loss: 0.0015 lr: 0.02
2019-06-04 00:22:32 iteration: 124250 loss: 0.0014 lr: 0.02
2019-06-04 00:22:42 iteration: 124300 loss: 0.0015 lr: 0.02
2019-06-04 00:22:52 iteration: 124350 loss: 0.0016 lr: 0.02
2019-06-04 00:23:03 iteration: 124400 loss: 0.0015 lr: 0.02
2019-06-04 00:23:13 iteration: 124450 loss: 0.0016 lr: 0.02
2019-06-04 00:23:24 iteration: 124500 loss: 0.0016 lr: 0.02
2019-06-04 00:23:37 iteration: 124550 loss: 0.0016 lr: 0.02
2019-06-04 00:23:47 iteration: 124600 loss: 0.0014 lr: 0.02
2019-06-04 00:23:58 iteration: 124650 loss: 0.0015 lr: 0.02
2019-06-04 00:24:09 iteration: 124700 loss: 0.0017 lr: 0.02
2019-06-04 00:24:19 iteration: 124750 loss: 0.0014 lr: 0.02
2019-06-04 00:24:30 iteration: 124800 loss: 0.0017 lr: 0.02
2019-06-04 00:24:40 iteration: 124850 loss: 0.0015 lr: 0.02
2019-06-04 00:24:51 iteration: 124900 loss: 0.0016 lr: 0.02
2019-06-04 00:25:01 iteration: 124950 loss: 0.0020 lr: 0.02
2019-06-04 00:25:11 iteration: 125000 loss: 0.0020 lr: 0.02
2019-06-04 00:25:25 iteration: 125050 loss: 0.0016 lr: 0.02
2019-06-04 00:25:35 iteration: 125100 loss: 0.0018 lr: 0.02
2019-06-04 00:25:46 iteration: 125150 loss: 0.0016 lr: 0.02
2019-06-04 00:25:56 iteration: 125200 loss: 0.0019 lr: 0.02
2019-06-04 00:26:06 iteration: 125250 loss: 0.0018 lr: 0.02
2019-06-04 00:26:16 iteration: 125300 loss: 0.0018 lr: 0.02
2019-06-04 00:26:27 iteration: 125350 loss: 0.0016 lr: 0.02
2019-06-04 00:26:38 iteration: 125400 loss: 0.0015 lr: 0.02
2019-06-04 00:26:49 iteration: 125450 loss: 0.0017 lr: 0.02
2019-06-04 00:26:59 iteration: 125500 loss: 0.0016 lr: 0.02
2019-06-04 00:27:12 iteration: 125550 loss: 0.0018 lr: 0.02
2019-06-04 00:27:23 iteration: 125600 loss: 0.0015 lr: 0.02
2019-06-04 00:27:33 iteration: 125650 loss: 0.0015 lr: 0.02
2019-06-04 00:27:44 iteration: 125700 loss: 0.0015 lr: 0.02
2019-06-04 00:27:55 iteration: 125750 loss: 0.0015 lr: 0.02
2019-06-04 00:28:06 iteration: 125800 loss: 0.0015 lr: 0.02
2019-06-04 00:28:16 iteration: 125850 loss: 0.0015 lr: 0.02
2019-06-04 00:28:27 iteration: 125900 loss: 0.0015 lr: 0.02
2019-06-04 00:28:38 iteration: 125950 loss: 0.0018 lr: 0.02
2019-06-04 00:28:48 iteration: 126000 loss: 0.0017 lr: 0.02
2019-06-04 00:29:02 iteration: 126050 loss: 0.0018 lr: 0.02
2019-06-04 00:29:12 iteration: 126100 loss: 0.0023 lr: 0.02
2019-06-04 00:29:22 iteration: 126150 loss: 0.0019 lr: 0.02
2019-06-04 00:29:33 iteration: 126200 loss: 0.0017 lr: 0.02
2019-06-04 00:29:44 iteration: 126250 loss: 0.0017 lr: 0.02
2019-06-04 00:29:55 iteration: 126300 loss: 0.0016 lr: 0.02
2019-06-04 00:30:05 iteration: 126350 loss: 0.0015 lr: 0.02
2019-06-04 00:30:16 iteration: 126400 loss: 0.0012 lr: 0.02
2019-06-04 00:30:26 iteration: 126450 loss: 0.0015 lr: 0.02
2019-06-04 00:30:37 iteration: 126500 loss: 0.0015 lr: 0.02
2019-06-04 00:30:50 iteration: 126550 loss: 0.0017 lr: 0.02
2019-06-04 00:31:01 iteration: 126600 loss: 0.0014 lr: 0.02
2019-06-04 00:31:11 iteration: 126650 loss: 0.0015 lr: 0.02
2019-06-04 00:31:22 iteration: 126700 loss: 0.0018 lr: 0.02
2019-06-04 00:31:32 iteration: 126750 loss: 0.0015 lr: 0.02
2019-06-04 00:31:44 iteration: 126800 loss: 0.0014 lr: 0.02
2019-06-04 00:31:55 iteration: 126850 loss: 0.0014 lr: 0.02
2019-06-04 00:32:05 iteration: 126900 loss: 0.0020 lr: 0.02
2019-06-04 00:32:16 iteration: 126950 loss: 0.0017 lr: 0.02
2019-06-04 00:32:27 iteration: 127000 loss: 0.0017 lr: 0.02
2019-06-04 00:32:40 iteration: 127050 loss: 0.0016 lr: 0.02
2019-06-04 00:32:51 iteration: 127100 loss: 0.0015 lr: 0.02
2019-06-04 00:33:02 iteration: 127150 loss: 0.0013 lr: 0.02
2019-06-04 00:33:13 iteration: 127200 loss: 0.0015 lr: 0.02
2019-06-04 00:33:24 iteration: 127250 loss: 0.0015 lr: 0.02
2019-06-04 00:33:34 iteration: 127300 loss: 0.0015 lr: 0.02
2019-06-04 00:33:45 iteration: 127350 loss: 0.0012 lr: 0.02
2019-06-04 00:33:56 iteration: 127400 loss: 0.0016 lr: 0.02
2019-06-04 00:34:06 iteration: 127450 loss: 0.0018 lr: 0.02
2019-06-04 00:34:16 iteration: 127500 loss: 0.0016 lr: 0.02
2019-06-04 00:34:29 iteration: 127550 loss: 0.0015 lr: 0.02
2019-06-04 00:34:39 iteration: 127600 loss: 0.0017 lr: 0.02
2019-06-04 00:34:50 iteration: 127650 loss: 0.0016 lr: 0.02
2019-06-04 00:35:00 iteration: 127700 loss: 0.0017 lr: 0.02
2019-06-04 00:35:11 iteration: 127750 loss: 0.0014 lr: 0.02
2019-06-04 00:35:21 iteration: 127800 loss: 0.0015 lr: 0.02
2019-06-04 00:35:33 iteration: 127850 loss: 0.0015 lr: 0.02
2019-06-04 00:35:43 iteration: 127900 loss: 0.0015 lr: 0.02
2019-06-04 00:35:54 iteration: 127950 loss: 0.0015 lr: 0.02
2019-06-04 00:36:05 iteration: 128000 loss: 0.0013 lr: 0.02
2019-06-04 00:36:19 iteration: 128050 loss: 0.0012 lr: 0.02
2019-06-04 00:36:30 iteration: 128100 loss: 0.0014 lr: 0.02
2019-06-04 00:36:42 iteration: 128150 loss: 0.0014 lr: 0.02
2019-06-04 00:36:52 iteration: 128200 loss: 0.0015 lr: 0.02
2019-06-04 00:37:03 iteration: 128250 loss: 0.0016 lr: 0.02
2019-06-04 00:37:13 iteration: 128300 loss: 0.0013 lr: 0.02
2019-06-04 00:37:24 iteration: 128350 loss: 0.0014 lr: 0.02
2019-06-04 00:37:34 iteration: 128400 loss: 0.0017 lr: 0.02
2019-06-04 00:37:45 iteration: 128450 loss: 0.0016 lr: 0.02
2019-06-04 00:37:55 iteration: 128500 loss: 0.0014 lr: 0.02
2019-06-04 00:38:09 iteration: 128550 loss: 0.0014 lr: 0.02
2019-06-04 00:38:20 iteration: 128600 loss: 0.0014 lr: 0.02
2019-06-04 00:38:30 iteration: 128650 loss: 0.0016 lr: 0.02
2019-06-04 00:38:40 iteration: 128700 loss: 0.0016 lr: 0.02
2019-06-04 00:38:50 iteration: 128750 loss: 0.0019 lr: 0.02
2019-06-04 00:39:01 iteration: 128800 loss: 0.0015 lr: 0.02
2019-06-04 00:39:11 iteration: 128850 loss: 0.0018 lr: 0.02
2019-06-04 00:39:21 iteration: 128900 loss: 0.0015 lr: 0.02
2019-06-04 00:39:31 iteration: 128950 loss: 0.0017 lr: 0.02
2019-06-04 00:39:43 iteration: 129000 loss: 0.0014 lr: 0.02
2019-06-04 00:39:56 iteration: 129050 loss: 0.0021 lr: 0.02
2019-06-04 00:40:06 iteration: 129100 loss: 0.0015 lr: 0.02
2019-06-04 00:40:16 iteration: 129150 loss: 0.0015 lr: 0.02
2019-06-04 00:40:27 iteration: 129200 loss: 0.0016 lr: 0.02
2019-06-04 00:40:38 iteration: 129250 loss: 0.0014 lr: 0.02
2019-06-04 00:40:50 iteration: 129300 loss: 0.0014 lr: 0.02
2019-06-04 00:41:00 iteration: 129350 loss: 0.0014 lr: 0.02
2019-06-04 00:41:10 iteration: 129400 loss: 0.0019 lr: 0.02
2019-06-04 00:41:20 iteration: 129450 loss: 0.0017 lr: 0.02
2019-06-04 00:41:31 iteration: 129500 loss: 0.0020 lr: 0.02
2019-06-04 00:41:45 iteration: 129550 loss: 0.0017 lr: 0.02
2019-06-04 00:41:55 iteration: 129600 loss: 0.0014 lr: 0.02
2019-06-04 00:42:05 iteration: 129650 loss: 0.0019 lr: 0.02
2019-06-04 00:42:15 iteration: 129700 loss: 0.0016 lr: 0.02
2019-06-04 00:42:26 iteration: 129750 loss: 0.0017 lr: 0.02
2019-06-04 00:42:35 iteration: 129800 loss: 0.0019 lr: 0.02
2019-06-04 00:42:45 iteration: 129850 loss: 0.0016 lr: 0.02
2019-06-04 00:42:56 iteration: 129900 loss: 0.0016 lr: 0.02
2019-06-04 00:43:07 iteration: 129950 loss: 0.0016 lr: 0.02
2019-06-04 00:43:17 iteration: 130000 loss: 0.0016 lr: 0.02
2019-06-04 00:43:30 iteration: 130050 loss: 0.0015 lr: 0.02
2019-06-04 00:43:41 iteration: 130100 loss: 0.0016 lr: 0.02
2019-06-04 00:43:52 iteration: 130150 loss: 0.0014 lr: 0.02
2019-06-04 00:44:03 iteration: 130200 loss: 0.0013 lr: 0.02
2019-06-04 00:44:14 iteration: 130250 loss: 0.0014 lr: 0.02
2019-06-04 00:44:24 iteration: 130300 loss: 0.0014 lr: 0.02
2019-06-04 00:44:35 iteration: 130350 loss: 0.0017 lr: 0.02
2019-06-04 00:44:45 iteration: 130400 loss: 0.0019 lr: 0.02
2019-06-04 00:44:56 iteration: 130450 loss: 0.0017 lr: 0.02
2019-06-04 00:45:06 iteration: 130500 loss: 0.0015 lr: 0.02
2019-06-04 00:45:20 iteration: 130550 loss: 0.0016 lr: 0.02
2019-06-04 00:45:30 iteration: 130600 loss: 0.0018 lr: 0.02
2019-06-04 00:45:40 iteration: 130650 loss: 0.0014 lr: 0.02
2019-06-04 00:45:50 iteration: 130700 loss: 0.0019 lr: 0.02
2019-06-04 00:46:01 iteration: 130750 loss: 0.0014 lr: 0.02
2019-06-04 00:46:12 iteration: 130800 loss: 0.0017 lr: 0.02
2019-06-04 00:46:22 iteration: 130850 loss: 0.0016 lr: 0.02
2019-06-04 00:46:32 iteration: 130900 loss: 0.0015 lr: 0.02
2019-06-04 00:46:43 iteration: 130950 loss: 0.0017 lr: 0.02
2019-06-04 00:46:54 iteration: 131000 loss: 0.0015 lr: 0.02
2019-06-04 00:47:07 iteration: 131050 loss: 0.0014 lr: 0.02
2019-06-04 00:47:18 iteration: 131100 loss: 0.0018 lr: 0.02
2019-06-04 00:47:28 iteration: 131150 loss: 0.0017 lr: 0.02
2019-06-04 00:47:39 iteration: 131200 loss: 0.0013 lr: 0.02
2019-06-04 00:47:50 iteration: 131250 loss: 0.0018 lr: 0.02
2019-06-04 00:48:00 iteration: 131300 loss: 0.0016 lr: 0.02
2019-06-04 00:48:11 iteration: 131350 loss: 0.0018 lr: 0.02
2019-06-04 00:48:21 iteration: 131400 loss: 0.0014 lr: 0.02
2019-06-04 00:48:31 iteration: 131450 loss: 0.0018 lr: 0.02
2019-06-04 00:48:42 iteration: 131500 loss: 0.0018 lr: 0.02
2019-06-04 00:48:55 iteration: 131550 loss: 0.0013 lr: 0.02
2019-06-04 00:49:05 iteration: 131600 loss: 0.0015 lr: 0.02
2019-06-04 00:49:17 iteration: 131650 loss: 0.0014 lr: 0.02
2019-06-04 00:49:27 iteration: 131700 loss: 0.0016 lr: 0.02
2019-06-04 00:49:38 iteration: 131750 loss: 0.0013 lr: 0.02
2019-06-04 00:49:50 iteration: 131800 loss: 0.0013 lr: 0.02
2019-06-04 00:50:00 iteration: 131850 loss: 0.0016 lr: 0.02
2019-06-04 00:50:11 iteration: 131900 loss: 0.0016 lr: 0.02
2019-06-04 00:50:21 iteration: 131950 loss: 0.0018 lr: 0.02
2019-06-04 00:50:32 iteration: 132000 loss: 0.0015 lr: 0.02
2019-06-04 00:50:45 iteration: 132050 loss: 0.0018 lr: 0.02
2019-06-04 00:50:56 iteration: 132100 loss: 0.0016 lr: 0.02
2019-06-04 00:51:07 iteration: 132150 loss: 0.0016 lr: 0.02
2019-06-04 00:51:17 iteration: 132200 loss: 0.0014 lr: 0.02
2019-06-04 00:51:27 iteration: 132250 loss: 0.0015 lr: 0.02
2019-06-04 00:51:38 iteration: 132300 loss: 0.0014 lr: 0.02
2019-06-04 00:51:48 iteration: 132350 loss: 0.0015 lr: 0.02
2019-06-04 00:51:59 iteration: 132400 loss: 0.0015 lr: 0.02
2019-06-04 00:52:09 iteration: 132450 loss: 0.0016 lr: 0.02
2019-06-04 00:52:19 iteration: 132500 loss: 0.0014 lr: 0.02
2019-06-04 00:52:33 iteration: 132550 loss: 0.0015 lr: 0.02
2019-06-04 00:52:43 iteration: 132600 loss: 0.0016 lr: 0.02
2019-06-04 00:52:54 iteration: 132650 loss: 0.0018 lr: 0.02
2019-06-04 00:53:04 iteration: 132700 loss: 0.0013 lr: 0.02
2019-06-04 00:53:15 iteration: 132750 loss: 0.0013 lr: 0.02
2019-06-04 00:53:26 iteration: 132800 loss: 0.0012 lr: 0.02
2019-06-04 00:53:37 iteration: 132850 loss: 0.0014 lr: 0.02
2019-06-04 00:53:48 iteration: 132900 loss: 0.0012 lr: 0.02
2019-06-04 00:53:58 iteration: 132950 loss: 0.0016 lr: 0.02
2019-06-04 00:54:09 iteration: 133000 loss: 0.0016 lr: 0.02
2019-06-04 00:54:23 iteration: 133050 loss: 0.0014 lr: 0.02
2019-06-04 00:54:34 iteration: 133100 loss: 0.0015 lr: 0.02
2019-06-04 00:54:45 iteration: 133150 loss: 0.0014 lr: 0.02
2019-06-04 00:54:56 iteration: 133200 loss: 0.0013 lr: 0.02
2019-06-04 00:55:06 iteration: 133250 loss: 0.0016 lr: 0.02
2019-06-04 00:55:17 iteration: 133300 loss: 0.0017 lr: 0.02
2019-06-04 00:55:28 iteration: 133350 loss: 0.0016 lr: 0.02
2019-06-04 00:55:38 iteration: 133400 loss: 0.0014 lr: 0.02
2019-06-04 00:55:49 iteration: 133450 loss: 0.0015 lr: 0.02
2019-06-04 00:56:00 iteration: 133500 loss: 0.0014 lr: 0.02
2019-06-04 00:56:14 iteration: 133550 loss: 0.0018 lr: 0.02
2019-06-04 00:56:24 iteration: 133600 loss: 0.0014 lr: 0.02
2019-06-04 00:56:34 iteration: 133650 loss: 0.0019 lr: 0.02
2019-06-04 00:56:45 iteration: 133700 loss: 0.0014 lr: 0.02
2019-06-04 00:56:56 iteration: 133750 loss: 0.0018 lr: 0.02
2019-06-04 00:57:06 iteration: 133800 loss: 0.0018 lr: 0.02
2019-06-04 00:57:16 iteration: 133850 loss: 0.0015 lr: 0.02
2019-06-04 00:57:26 iteration: 133900 loss: 0.0015 lr: 0.02
2019-06-04 00:57:37 iteration: 133950 loss: 0.0016 lr: 0.02
2019-06-04 00:57:47 iteration: 134000 loss: 0.0016 lr: 0.02
2019-06-04 00:58:00 iteration: 134050 loss: 0.0016 lr: 0.02
2019-06-04 00:58:11 iteration: 134100 loss: 0.0014 lr: 0.02
2019-06-04 00:58:22 iteration: 134150 loss: 0.0016 lr: 0.02
2019-06-04 00:58:32 iteration: 134200 loss: 0.0017 lr: 0.02
2019-06-04 00:58:43 iteration: 134250 loss: 0.0015 lr: 0.02
2019-06-04 00:58:54 iteration: 134300 loss: 0.0016 lr: 0.02
2019-06-04 00:59:04 iteration: 134350 loss: 0.0018 lr: 0.02
2019-06-04 00:59:15 iteration: 134400 loss: 0.0016 lr: 0.02
2019-06-04 00:59:26 iteration: 134450 loss: 0.0016 lr: 0.02
2019-06-04 00:59:37 iteration: 134500 loss: 0.0015 lr: 0.02
2019-06-04 00:59:50 iteration: 134550 loss: 0.0015 lr: 0.02
2019-06-04 01:00:01 iteration: 134600 loss: 0.0014 lr: 0.02
2019-06-04 01:00:12 iteration: 134650 loss: 0.0017 lr: 0.02
2019-06-04 01:00:21 iteration: 134700 loss: 0.0015 lr: 0.02
2019-06-04 01:00:33 iteration: 134750 loss: 0.0015 lr: 0.02
2019-06-04 01:00:43 iteration: 134800 loss: 0.0014 lr: 0.02
2019-06-04 01:00:54 iteration: 134850 loss: 0.0015 lr: 0.02
2019-06-04 01:01:05 iteration: 134900 loss: 0.0017 lr: 0.02
2019-06-04 01:01:16 iteration: 134950 loss: 0.0016 lr: 0.02
2019-06-04 01:01:26 iteration: 135000 loss: 0.0019 lr: 0.02
2019-06-04 01:01:39 iteration: 135050 loss: 0.0019 lr: 0.02
2019-06-04 01:01:50 iteration: 135100 loss: 0.0018 lr: 0.02
2019-06-04 01:02:00 iteration: 135150 loss: 0.0014 lr: 0.02
2019-06-04 01:02:10 iteration: 135200 loss: 0.0015 lr: 0.02
2019-06-04 01:02:21 iteration: 135250 loss: 0.0019 lr: 0.02
2019-06-04 01:02:31 iteration: 135300 loss: 0.0018 lr: 0.02
2019-06-04 01:02:42 iteration: 135350 loss: 0.0016 lr: 0.02
2019-06-04 01:02:53 iteration: 135400 loss: 0.0013 lr: 0.02
2019-06-04 01:03:04 iteration: 135450 loss: 0.0016 lr: 0.02
2019-06-04 01:03:14 iteration: 135500 loss: 0.0016 lr: 0.02
2019-06-04 01:03:28 iteration: 135550 loss: 0.0016 lr: 0.02
2019-06-04 01:03:39 iteration: 135600 loss: 0.0015 lr: 0.02
2019-06-04 01:03:49 iteration: 135650 loss: 0.0012 lr: 0.02
2019-06-04 01:04:00 iteration: 135700 loss: 0.0013 lr: 0.02
2019-06-04 01:04:10 iteration: 135750 loss: 0.0019 lr: 0.02
2019-06-04 01:04:21 iteration: 135800 loss: 0.0014 lr: 0.02
2019-06-04 01:04:32 iteration: 135850 loss: 0.0017 lr: 0.02
2019-06-04 01:04:43 iteration: 135900 loss: 0.0014 lr: 0.02
2019-06-04 01:04:53 iteration: 135950 loss: 0.0017 lr: 0.02
2019-06-04 01:05:03 iteration: 136000 loss: 0.0014 lr: 0.02
2019-06-04 01:05:17 iteration: 136050 loss: 0.0016 lr: 0.02
2019-06-04 01:05:27 iteration: 136100 loss: 0.0016 lr: 0.02
2019-06-04 01:05:38 iteration: 136150 loss: 0.0013 lr: 0.02
2019-06-04 01:05:48 iteration: 136200 loss: 0.0015 lr: 0.02
2019-06-04 01:05:58 iteration: 136250 loss: 0.0018 lr: 0.02
2019-06-04 01:06:08 iteration: 136300 loss: 0.0020 lr: 0.02
2019-06-04 01:06:19 iteration: 136350 loss: 0.0018 lr: 0.02
2019-06-04 01:06:29 iteration: 136400 loss: 0.0018 lr: 0.02
2019-06-04 01:06:40 iteration: 136450 loss: 0.0014 lr: 0.02
2019-06-04 01:06:51 iteration: 136500 loss: 0.0016 lr: 0.02
2019-06-04 01:07:04 iteration: 136550 loss: 0.0017 lr: 0.02
2019-06-04 01:07:14 iteration: 136600 loss: 0.0013 lr: 0.02
2019-06-04 01:07:25 iteration: 136650 loss: 0.0016 lr: 0.02
2019-06-04 01:07:35 iteration: 136700 loss: 0.0019 lr: 0.02
2019-06-04 01:07:46 iteration: 136750 loss: 0.0016 lr: 0.02
2019-06-04 01:07:56 iteration: 136800 loss: 0.0017 lr: 0.02
2019-06-04 01:08:07 iteration: 136850 loss: 0.0015 lr: 0.02
2019-06-04 01:08:18 iteration: 136900 loss: 0.0016 lr: 0.02
2019-06-04 01:08:27 iteration: 136950 loss: 0.0016 lr: 0.02
2019-06-04 01:08:39 iteration: 137000 loss: 0.0014 lr: 0.02
2019-06-04 01:08:52 iteration: 137050 loss: 0.0013 lr: 0.02
2019-06-04 01:09:02 iteration: 137100 loss: 0.0014 lr: 0.02
2019-06-04 01:09:13 iteration: 137150 loss: 0.0014 lr: 0.02
2019-06-04 01:09:24 iteration: 137200 loss: 0.0016 lr: 0.02
2019-06-04 01:09:34 iteration: 137250 loss: 0.0014 lr: 0.02
2019-06-04 01:09:45 iteration: 137300 loss: 0.0016 lr: 0.02
2019-06-04 01:09:55 iteration: 137350 loss: 0.0016 lr: 0.02
2019-06-04 01:10:06 iteration: 137400 loss: 0.0015 lr: 0.02
2019-06-04 01:10:16 iteration: 137450 loss: 0.0015 lr: 0.02
2019-06-04 01:10:27 iteration: 137500 loss: 0.0015 lr: 0.02
2019-06-04 01:10:41 iteration: 137550 loss: 0.0015 lr: 0.02
2019-06-04 01:10:51 iteration: 137600 loss: 0.0013 lr: 0.02
2019-06-04 01:11:02 iteration: 137650 loss: 0.0014 lr: 0.02
2019-06-04 01:11:12 iteration: 137700 loss: 0.0017 lr: 0.02
2019-06-04 01:11:22 iteration: 137750 loss: 0.0016 lr: 0.02
2019-06-04 01:11:33 iteration: 137800 loss: 0.0013 lr: 0.02
2019-06-04 01:11:44 iteration: 137850 loss: 0.0014 lr: 0.02
2019-06-04 01:11:54 iteration: 137900 loss: 0.0015 lr: 0.02
2019-06-04 01:12:03 iteration: 137950 loss: 0.0017 lr: 0.02
2019-06-04 01:12:13 iteration: 138000 loss: 0.0018 lr: 0.02
2019-06-04 01:12:26 iteration: 138050 loss: 0.0016 lr: 0.02
2019-06-04 01:12:37 iteration: 138100 loss: 0.0016 lr: 0.02
2019-06-04 01:12:48 iteration: 138150 loss: 0.0013 lr: 0.02
2019-06-04 01:12:58 iteration: 138200 loss: 0.0015 lr: 0.02
2019-06-04 01:13:08 iteration: 138250 loss: 0.0017 lr: 0.02
2019-06-04 01:13:19 iteration: 138300 loss: 0.0013 lr: 0.02
2019-06-04 01:13:29 iteration: 138350 loss: 0.0014 lr: 0.02
2019-06-04 01:13:41 iteration: 138400 loss: 0.0011 lr: 0.02
2019-06-04 01:13:51 iteration: 138450 loss: 0.0017 lr: 0.02
2019-06-04 01:14:01 iteration: 138500 loss: 0.0016 lr: 0.02
2019-06-04 01:14:14 iteration: 138550 loss: 0.0014 lr: 0.02
2019-06-04 01:14:25 iteration: 138600 loss: 0.0014 lr: 0.02
2019-06-04 01:14:35 iteration: 138650 loss: 0.0014 lr: 0.02
2019-06-04 01:14:46 iteration: 138700 loss: 0.0012 lr: 0.02
2019-06-04 01:14:56 iteration: 138750 loss: 0.0016 lr: 0.02
2019-06-04 01:15:07 iteration: 138800 loss: 0.0015 lr: 0.02
2019-06-04 01:15:18 iteration: 138850 loss: 0.0014 lr: 0.02
2019-06-04 01:15:28 iteration: 138900 loss: 0.0014 lr: 0.02
2019-06-04 01:15:38 iteration: 138950 loss: 0.0014 lr: 0.02
2019-06-04 01:15:49 iteration: 139000 loss: 0.0014 lr: 0.02
2019-06-04 01:16:02 iteration: 139050 loss: 0.0015 lr: 0.02
2019-06-04 01:16:13 iteration: 139100 loss: 0.0016 lr: 0.02
2019-06-04 01:16:23 iteration: 139150 loss: 0.0016 lr: 0.02
2019-06-04 01:16:34 iteration: 139200 loss: 0.0015 lr: 0.02
2019-06-04 01:16:44 iteration: 139250 loss: 0.0017 lr: 0.02
2019-06-04 01:16:55 iteration: 139300 loss: 0.0016 lr: 0.02
2019-06-04 01:17:05 iteration: 139350 loss: 0.0016 lr: 0.02
2019-06-04 01:17:16 iteration: 139400 loss: 0.0013 lr: 0.02
2019-06-04 01:17:27 iteration: 139450 loss: 0.0014 lr: 0.02
2019-06-04 01:17:38 iteration: 139500 loss: 0.0017 lr: 0.02
2019-06-04 01:17:51 iteration: 139550 loss: 0.0016 lr: 0.02
2019-06-04 01:18:02 iteration: 139600 loss: 0.0016 lr: 0.02
2019-06-04 01:18:13 iteration: 139650 loss: 0.0016 lr: 0.02
2019-06-04 01:18:24 iteration: 139700 loss: 0.0014 lr: 0.02
2019-06-04 01:18:34 iteration: 139750 loss: 0.0014 lr: 0.02
2019-06-04 01:18:45 iteration: 139800 loss: 0.0015 lr: 0.02
2019-06-04 01:18:55 iteration: 139850 loss: 0.0016 lr: 0.02
2019-06-04 01:19:05 iteration: 139900 loss: 0.0016 lr: 0.02
2019-06-04 01:19:16 iteration: 139950 loss: 0.0015 lr: 0.02
2019-06-04 01:19:26 iteration: 140000 loss: 0.0016 lr: 0.02
2019-06-04 01:19:39 iteration: 140050 loss: 0.0016 lr: 0.02
2019-06-04 01:19:50 iteration: 140100 loss: 0.0014 lr: 0.02
2019-06-04 01:20:01 iteration: 140150 loss: 0.0012 lr: 0.02
2019-06-04 01:20:11 iteration: 140200 loss: 0.0017 lr: 0.02
2019-06-04 01:20:22 iteration: 140250 loss: 0.0015 lr: 0.02
2019-06-04 01:20:32 iteration: 140300 loss: 0.0015 lr: 0.02
2019-06-04 01:20:42 iteration: 140350 loss: 0.0017 lr: 0.02
2019-06-04 01:20:53 iteration: 140400 loss: 0.0014 lr: 0.02
2019-06-04 01:21:04 iteration: 140450 loss: 0.0016 lr: 0.02
2019-06-04 01:21:14 iteration: 140500 loss: 0.0015 lr: 0.02
2019-06-04 01:21:28 iteration: 140550 loss: 0.0015 lr: 0.02
2019-06-04 01:21:39 iteration: 140600 loss: 0.0015 lr: 0.02
2019-06-04 01:21:49 iteration: 140650 loss: 0.0015 lr: 0.02
2019-06-04 01:22:00 iteration: 140700 loss: 0.0014 lr: 0.02
2019-06-04 01:22:11 iteration: 140750 loss: 0.0015 lr: 0.02
2019-06-04 01:22:22 iteration: 140800 loss: 0.0015 lr: 0.02
2019-06-04 01:22:33 iteration: 140850 loss: 0.0018 lr: 0.02
2019-06-04 01:22:43 iteration: 140900 loss: 0.0014 lr: 0.02
2019-06-04 01:22:54 iteration: 140950 loss: 0.0014 lr: 0.02
2019-06-04 01:23:04 iteration: 141000 loss: 0.0012 lr: 0.02
2019-06-04 01:23:19 iteration: 141050 loss: 0.0012 lr: 0.02
2019-06-04 01:23:29 iteration: 141100 loss: 0.0015 lr: 0.02
2019-06-04 01:23:40 iteration: 141150 loss: 0.0016 lr: 0.02
2019-06-04 01:23:50 iteration: 141200 loss: 0.0015 lr: 0.02
2019-06-04 01:24:01 iteration: 141250 loss: 0.0016 lr: 0.02
2019-06-04 01:24:12 iteration: 141300 loss: 0.0016 lr: 0.02
2019-06-04 01:24:22 iteration: 141350 loss: 0.0014 lr: 0.02
2019-06-04 01:24:32 iteration: 141400 loss: 0.0014 lr: 0.02
2019-06-04 01:24:43 iteration: 141450 loss: 0.0015 lr: 0.02
2019-06-04 01:24:54 iteration: 141500 loss: 0.0016 lr: 0.02
2019-06-04 01:25:07 iteration: 141550 loss: 0.0016 lr: 0.02
2019-06-04 01:25:18 iteration: 141600 loss: 0.0015 lr: 0.02
2019-06-04 01:25:29 iteration: 141650 loss: 0.0013 lr: 0.02
2019-06-04 01:25:40 iteration: 141700 loss: 0.0014 lr: 0.02
2019-06-04 01:25:50 iteration: 141750 loss: 0.0014 lr: 0.02
2019-06-04 01:26:01 iteration: 141800 loss: 0.0015 lr: 0.02
2019-06-04 01:26:11 iteration: 141850 loss: 0.0017 lr: 0.02
2019-06-04 01:26:21 iteration: 141900 loss: 0.0018 lr: 0.02
2019-06-04 01:26:32 iteration: 141950 loss: 0.0014 lr: 0.02
2019-06-04 01:26:43 iteration: 142000 loss: 0.0014 lr: 0.02
2019-06-04 01:26:56 iteration: 142050 loss: 0.0018 lr: 0.02
2019-06-04 01:27:06 iteration: 142100 loss: 0.0013 lr: 0.02
2019-06-04 01:27:17 iteration: 142150 loss: 0.0016 lr: 0.02
2019-06-04 01:27:27 iteration: 142200 loss: 0.0015 lr: 0.02
2019-06-04 01:27:37 iteration: 142250 loss: 0.0018 lr: 0.02
2019-06-04 01:27:47 iteration: 142300 loss: 0.0016 lr: 0.02
2019-06-04 01:27:59 iteration: 142350 loss: 0.0014 lr: 0.02
2019-06-04 01:28:09 iteration: 142400 loss: 0.0014 lr: 0.02
2019-06-04 01:28:20 iteration: 142450 loss: 0.0016 lr: 0.02
2019-06-04 01:28:30 iteration: 142500 loss: 0.0015 lr: 0.02
2019-06-04 01:28:44 iteration: 142550 loss: 0.0014 lr: 0.02
2019-06-04 01:28:54 iteration: 142600 loss: 0.0012 lr: 0.02
2019-06-04 01:29:04 iteration: 142650 loss: 0.0019 lr: 0.02
2019-06-04 01:29:15 iteration: 142700 loss: 0.0015 lr: 0.02
2019-06-04 01:29:25 iteration: 142750 loss: 0.0016 lr: 0.02
2019-06-04 01:29:36 iteration: 142800 loss: 0.0016 lr: 0.02
2019-06-04 01:29:46 iteration: 142850 loss: 0.0014 lr: 0.02
2019-06-04 01:29:57 iteration: 142900 loss: 0.0017 lr: 0.02
2019-06-04 01:30:07 iteration: 142950 loss: 0.0013 lr: 0.02
2019-06-04 01:30:18 iteration: 143000 loss: 0.0017 lr: 0.02
2019-06-04 01:30:32 iteration: 143050 loss: 0.0013 lr: 0.02
2019-06-04 01:30:43 iteration: 143100 loss: 0.0015 lr: 0.02
2019-06-04 01:30:53 iteration: 143150 loss: 0.0016 lr: 0.02
2019-06-04 01:31:04 iteration: 143200 loss: 0.0013 lr: 0.02
2019-06-04 01:31:15 iteration: 143250 loss: 0.0015 lr: 0.02
2019-06-04 01:31:25 iteration: 143300 loss: 0.0014 lr: 0.02
2019-06-04 01:31:36 iteration: 143350 loss: 0.0016 lr: 0.02
2019-06-04 01:31:46 iteration: 143400 loss: 0.0014 lr: 0.02
2019-06-04 01:31:57 iteration: 143450 loss: 0.0015 lr: 0.02
2019-06-04 01:32:08 iteration: 143500 loss: 0.0014 lr: 0.02
2019-06-04 01:32:21 iteration: 143550 loss: 0.0017 lr: 0.02
2019-06-04 01:32:32 iteration: 143600 loss: 0.0013 lr: 0.02
2019-06-04 01:32:43 iteration: 143650 loss: 0.0014 lr: 0.02
2019-06-04 01:32:54 iteration: 143700 loss: 0.0014 lr: 0.02
2019-06-04 01:33:04 iteration: 143750 loss: 0.0015 lr: 0.02
2019-06-04 01:33:14 iteration: 143800 loss: 0.0017 lr: 0.02
2019-06-04 01:33:25 iteration: 143850 loss: 0.0015 lr: 0.02
2019-06-04 01:33:36 iteration: 143900 loss: 0.0015 lr: 0.02
2019-06-04 01:33:46 iteration: 143950 loss: 0.0018 lr: 0.02
2019-06-04 01:33:57 iteration: 144000 loss: 0.0018 lr: 0.02
2019-06-04 01:34:10 iteration: 144050 loss: 0.0017 lr: 0.02
2019-06-04 01:34:21 iteration: 144100 loss: 0.0014 lr: 0.02
2019-06-04 01:34:31 iteration: 144150 loss: 0.0014 lr: 0.02
2019-06-04 01:34:42 iteration: 144200 loss: 0.0015 lr: 0.02
2019-06-04 01:34:52 iteration: 144250 loss: 0.0016 lr: 0.02
2019-06-04 01:35:03 iteration: 144300 loss: 0.0014 lr: 0.02
2019-06-04 01:35:13 iteration: 144350 loss: 0.0019 lr: 0.02
2019-06-04 01:35:24 iteration: 144400 loss: 0.0013 lr: 0.02
2019-06-04 01:35:34 iteration: 144450 loss: 0.0014 lr: 0.02
2019-06-04 01:35:45 iteration: 144500 loss: 0.0017 lr: 0.02
2019-06-04 01:35:58 iteration: 144550 loss: 0.0015 lr: 0.02
2019-06-04 01:36:08 iteration: 144600 loss: 0.0016 lr: 0.02
2019-06-04 01:36:20 iteration: 144650 loss: 0.0013 lr: 0.02
2019-06-04 01:36:30 iteration: 144700 loss: 0.0020 lr: 0.02
2019-06-04 01:36:40 iteration: 144750 loss: 0.0016 lr: 0.02
2019-06-04 01:36:50 iteration: 144800 loss: 0.0016 lr: 0.02
2019-06-04 01:37:01 iteration: 144850 loss: 0.0016 lr: 0.02
2019-06-04 01:37:11 iteration: 144900 loss: 0.0013 lr: 0.02
2019-06-04 01:37:22 iteration: 144950 loss: 0.0014 lr: 0.02
2019-06-04 01:37:33 iteration: 145000 loss: 0.0014 lr: 0.02
2019-06-04 01:37:47 iteration: 145050 loss: 0.0014 lr: 0.02
2019-06-04 01:37:57 iteration: 145100 loss: 0.0014 lr: 0.02
2019-06-04 01:38:07 iteration: 145150 loss: 0.0017 lr: 0.02
2019-06-04 01:38:17 iteration: 145200 loss: 0.0014 lr: 0.02
2019-06-04 01:38:28 iteration: 145250 loss: 0.0017 lr: 0.02
2019-06-04 01:38:38 iteration: 145300 loss: 0.0016 lr: 0.02
2019-06-04 01:38:49 iteration: 145350 loss: 0.0016 lr: 0.02
2019-06-04 01:38:59 iteration: 145400 loss: 0.0018 lr: 0.02
2019-06-04 01:39:09 iteration: 145450 loss: 0.0017 lr: 0.02
2019-06-04 01:39:20 iteration: 145500 loss: 0.0017 lr: 0.02
2019-06-04 01:39:33 iteration: 145550 loss: 0.0014 lr: 0.02
2019-06-04 01:39:45 iteration: 145600 loss: 0.0013 lr: 0.02
2019-06-04 01:39:55 iteration: 145650 loss: 0.0013 lr: 0.02
2019-06-04 01:40:06 iteration: 145700 loss: 0.0016 lr: 0.02
2019-06-04 01:40:16 iteration: 145750 loss: 0.0015 lr: 0.02
2019-06-04 01:40:26 iteration: 145800 loss: 0.0015 lr: 0.02
2019-06-04 01:40:37 iteration: 145850 loss: 0.0014 lr: 0.02
2019-06-04 01:40:46 iteration: 145900 loss: 0.0014 lr: 0.02
2019-06-04 01:40:57 iteration: 145950 loss: 0.0017 lr: 0.02
2019-06-04 01:41:07 iteration: 146000 loss: 0.0016 lr: 0.02
2019-06-04 01:41:20 iteration: 146050 loss: 0.0015 lr: 0.02
2019-06-04 01:41:31 iteration: 146100 loss: 0.0018 lr: 0.02
2019-06-04 01:41:42 iteration: 146150 loss: 0.0016 lr: 0.02
2019-06-04 01:41:52 iteration: 146200 loss: 0.0015 lr: 0.02
2019-06-04 01:42:03 iteration: 146250 loss: 0.0013 lr: 0.02
2019-06-04 01:42:13 iteration: 146300 loss: 0.0016 lr: 0.02
2019-06-04 01:42:24 iteration: 146350 loss: 0.0016 lr: 0.02
2019-06-04 01:42:34 iteration: 146400 loss: 0.0015 lr: 0.02
2019-06-04 01:42:45 iteration: 146450 loss: 0.0015 lr: 0.02
2019-06-04 01:42:55 iteration: 146500 loss: 0.0014 lr: 0.02
2019-06-04 01:43:08 iteration: 146550 loss: 0.0015 lr: 0.02
2019-06-04 01:43:19 iteration: 146600 loss: 0.0017 lr: 0.02
2019-06-04 01:43:29 iteration: 146650 loss: 0.0015 lr: 0.02
2019-06-04 01:43:40 iteration: 146700 loss: 0.0014 lr: 0.02
2019-06-04 01:43:50 iteration: 146750 loss: 0.0015 lr: 0.02
2019-06-04 01:44:00 iteration: 146800 loss: 0.0013 lr: 0.02
2019-06-04 01:44:11 iteration: 146850 loss: 0.0013 lr: 0.02
2019-06-04 01:44:22 iteration: 146900 loss: 0.0013 lr: 0.02
2019-06-04 01:44:32 iteration: 146950 loss: 0.0016 lr: 0.02
2019-06-04 01:44:43 iteration: 147000 loss: 0.0017 lr: 0.02
2019-06-04 01:44:56 iteration: 147050 loss: 0.0014 lr: 0.02
2019-06-04 01:45:07 iteration: 147100 loss: 0.0012 lr: 0.02
2019-06-04 01:45:18 iteration: 147150 loss: 0.0015 lr: 0.02
2019-06-04 01:45:28 iteration: 147200 loss: 0.0015 lr: 0.02
2019-06-04 01:45:38 iteration: 147250 loss: 0.0014 lr: 0.02
2019-06-04 01:45:49 iteration: 147300 loss: 0.0013 lr: 0.02
2019-06-04 01:46:00 iteration: 147350 loss: 0.0014 lr: 0.02
2019-06-04 01:46:10 iteration: 147400 loss: 0.0016 lr: 0.02
2019-06-04 01:46:21 iteration: 147450 loss: 0.0019 lr: 0.02
2019-06-04 01:46:32 iteration: 147500 loss: 0.0015 lr: 0.02
2019-06-04 01:46:45 iteration: 147550 loss: 0.0017 lr: 0.02
2019-06-04 01:46:55 iteration: 147600 loss: 0.0013 lr: 0.02
2019-06-04 01:47:06 iteration: 147650 loss: 0.0015 lr: 0.02
2019-06-04 01:47:16 iteration: 147700 loss: 0.0016 lr: 0.02
2019-06-04 01:47:27 iteration: 147750 loss: 0.0014 lr: 0.02
2019-06-04 01:47:37 iteration: 147800 loss: 0.0015 lr: 0.02
2019-06-04 01:47:48 iteration: 147850 loss: 0.0017 lr: 0.02
2019-06-04 01:47:58 iteration: 147900 loss: 0.0015 lr: 0.02
2019-06-04 01:48:09 iteration: 147950 loss: 0.0013 lr: 0.02
2019-06-04 01:48:20 iteration: 148000 loss: 0.0014 lr: 0.02
2019-06-04 01:48:33 iteration: 148050 loss: 0.0014 lr: 0.02
2019-06-04 01:48:44 iteration: 148100 loss: 0.0014 lr: 0.02
2019-06-04 01:48:54 iteration: 148150 loss: 0.0014 lr: 0.02
2019-06-04 01:49:04 iteration: 148200 loss: 0.0019 lr: 0.02
2019-06-04 01:49:15 iteration: 148250 loss: 0.0015 lr: 0.02
2019-06-04 01:49:26 iteration: 148300 loss: 0.0014 lr: 0.02
2019-06-04 01:49:36 iteration: 148350 loss: 0.0017 lr: 0.02
2019-06-04 01:49:47 iteration: 148400 loss: 0.0015 lr: 0.02
2019-06-04 01:49:57 iteration: 148450 loss: 0.0014 lr: 0.02
2019-06-04 01:50:07 iteration: 148500 loss: 0.0014 lr: 0.02
2019-06-04 01:50:21 iteration: 148550 loss: 0.0013 lr: 0.02
2019-06-04 01:50:32 iteration: 148600 loss: 0.0015 lr: 0.02
2019-06-04 01:50:43 iteration: 148650 loss: 0.0014 lr: 0.02
2019-06-04 01:50:53 iteration: 148700 loss: 0.0015 lr: 0.02
2019-06-04 01:51:04 iteration: 148750 loss: 0.0014 lr: 0.02
2019-06-04 01:51:14 iteration: 148800 loss: 0.0017 lr: 0.02
2019-06-04 01:51:24 iteration: 148850 loss: 0.0014 lr: 0.02
2019-06-04 01:51:35 iteration: 148900 loss: 0.0014 lr: 0.02
2019-06-04 01:51:45 iteration: 148950 loss: 0.0016 lr: 0.02
2019-06-04 01:51:56 iteration: 149000 loss: 0.0013 lr: 0.02
2019-06-04 01:52:09 iteration: 149050 loss: 0.0016 lr: 0.02
2019-06-04 01:52:20 iteration: 149100 loss: 0.0016 lr: 0.02
2019-06-04 01:52:30 iteration: 149150 loss: 0.0014 lr: 0.02
2019-06-04 01:52:41 iteration: 149200 loss: 0.0014 lr: 0.02
2019-06-04 01:52:52 iteration: 149250 loss: 0.0011 lr: 0.02
2019-06-04 01:53:02 iteration: 149300 loss: 0.0016 lr: 0.02
2019-06-04 01:53:12 iteration: 149350 loss: 0.0012 lr: 0.02
2019-06-04 01:53:23 iteration: 149400 loss: 0.0014 lr: 0.02
2019-06-04 01:53:33 iteration: 149450 loss: 0.0014 lr: 0.02
2019-06-04 01:53:44 iteration: 149500 loss: 0.0015 lr: 0.02
2019-06-04 01:53:57 iteration: 149550 loss: 0.0014 lr: 0.02
2019-06-04 01:54:07 iteration: 149600 loss: 0.0014 lr: 0.02
2019-06-04 01:54:18 iteration: 149650 loss: 0.0014 lr: 0.02
2019-06-04 01:54:28 iteration: 149700 loss: 0.0014 lr: 0.02
2019-06-04 01:54:39 iteration: 149750 loss: 0.0014 lr: 0.02
2019-06-04 01:54:50 iteration: 149800 loss: 0.0015 lr: 0.02
2019-06-04 01:55:00 iteration: 149850 loss: 0.0015 lr: 0.02
2019-06-04 01:55:11 iteration: 149900 loss: 0.0016 lr: 0.02
2019-06-04 01:55:21 iteration: 149950 loss: 0.0018 lr: 0.02
2019-06-04 01:55:32 iteration: 150000 loss: 0.0017 lr: 0.02
2019-06-04 01:55:45 iteration: 150050 loss: 0.0015 lr: 0.02
2019-06-04 01:55:56 iteration: 150100 loss: 0.0012 lr: 0.02
2019-06-04 01:56:07 iteration: 150150 loss: 0.0016 lr: 0.02
2019-06-04 01:56:18 iteration: 150200 loss: 0.0015 lr: 0.02
2019-06-04 01:56:28 iteration: 150250 loss: 0.0014 lr: 0.02
2019-06-04 01:56:39 iteration: 150300 loss: 0.0015 lr: 0.02
2019-06-04 01:56:49 iteration: 150350 loss: 0.0014 lr: 0.02
2019-06-04 01:57:00 iteration: 150400 loss: 0.0016 lr: 0.02
2019-06-04 01:57:11 iteration: 150450 loss: 0.0012 lr: 0.02
2019-06-04 01:57:21 iteration: 150500 loss: 0.0013 lr: 0.02
2019-06-04 01:57:34 iteration: 150550 loss: 0.0014 lr: 0.02
2019-06-04 01:57:45 iteration: 150600 loss: 0.0019 lr: 0.02
2019-06-04 01:57:55 iteration: 150650 loss: 0.0015 lr: 0.02
2019-06-04 01:58:05 iteration: 150700 loss: 0.0017 lr: 0.02
2019-06-04 01:58:15 iteration: 150750 loss: 0.0017 lr: 0.02
2019-06-04 01:58:25 iteration: 150800 loss: 0.0016 lr: 0.02
2019-06-04 01:58:35 iteration: 150850 loss: 0.0014 lr: 0.02
2019-06-04 01:58:46 iteration: 150900 loss: 0.0018 lr: 0.02
2019-06-04 01:58:56 iteration: 150950 loss: 0.0019 lr: 0.02
2019-06-04 01:59:07 iteration: 151000 loss: 0.0016 lr: 0.02
2019-06-04 01:59:20 iteration: 151050 loss: 0.0014 lr: 0.02
2019-06-04 01:59:30 iteration: 151100 loss: 0.0013 lr: 0.02
2019-06-04 01:59:41 iteration: 151150 loss: 0.0014 lr: 0.02
2019-06-04 01:59:52 iteration: 151200 loss: 0.0016 lr: 0.02
2019-06-04 02:00:03 iteration: 151250 loss: 0.0016 lr: 0.02
2019-06-04 02:00:13 iteration: 151300 loss: 0.0015 lr: 0.02
2019-06-04 02:00:23 iteration: 151350 loss: 0.0014 lr: 0.02
2019-06-04 02:00:34 iteration: 151400 loss: 0.0012 lr: 0.02
2019-06-04 02:00:44 iteration: 151450 loss: 0.0016 lr: 0.02
2019-06-04 02:00:55 iteration: 151500 loss: 0.0013 lr: 0.02
2019-06-04 02:01:08 iteration: 151550 loss: 0.0015 lr: 0.02
2019-06-04 02:01:18 iteration: 151600 loss: 0.0014 lr: 0.02
2019-06-04 02:01:29 iteration: 151650 loss: 0.0015 lr: 0.02
2019-06-04 02:01:39 iteration: 151700 loss: 0.0017 lr: 0.02
2019-06-04 02:01:49 iteration: 151750 loss: 0.0013 lr: 0.02
2019-06-04 02:01:59 iteration: 151800 loss: 0.0017 lr: 0.02
2019-06-04 02:02:10 iteration: 151850 loss: 0.0014 lr: 0.02
2019-06-04 02:02:21 iteration: 151900 loss: 0.0016 lr: 0.02
2019-06-04 02:02:32 iteration: 151950 loss: 0.0016 lr: 0.02
2019-06-04 02:02:42 iteration: 152000 loss: 0.0016 lr: 0.02
2019-06-04 02:02:56 iteration: 152050 loss: 0.0015 lr: 0.02
2019-06-04 02:03:06 iteration: 152100 loss: 0.0016 lr: 0.02
2019-06-04 02:03:16 iteration: 152150 loss: 0.0018 lr: 0.02
2019-06-04 02:03:27 iteration: 152200 loss: 0.0015 lr: 0.02
2019-06-04 02:03:37 iteration: 152250 loss: 0.0015 lr: 0.02
2019-06-04 02:03:49 iteration: 152300 loss: 0.0013 lr: 0.02
2019-06-04 02:03:59 iteration: 152350 loss: 0.0017 lr: 0.02
2019-06-04 02:04:10 iteration: 152400 loss: 0.0018 lr: 0.02
2019-06-04 02:04:20 iteration: 152450 loss: 0.0015 lr: 0.02
2019-06-04 02:04:31 iteration: 152500 loss: 0.0016 lr: 0.02
2019-06-04 02:04:44 iteration: 152550 loss: 0.0017 lr: 0.02
2019-06-04 02:04:55 iteration: 152600 loss: 0.0014 lr: 0.02
2019-06-04 02:05:05 iteration: 152650 loss: 0.0014 lr: 0.02
2019-06-04 02:05:16 iteration: 152700 loss: 0.0013 lr: 0.02
2019-06-04 02:05:27 iteration: 152750 loss: 0.0014 lr: 0.02
2019-06-04 02:05:38 iteration: 152800 loss: 0.0012 lr: 0.02
2019-06-04 02:05:48 iteration: 152850 loss: 0.0015 lr: 0.02
2019-06-04 02:05:59 iteration: 152900 loss: 0.0016 lr: 0.02
2019-06-04 02:06:09 iteration: 152950 loss: 0.0016 lr: 0.02
2019-06-04 02:06:19 iteration: 153000 loss: 0.0015 lr: 0.02
2019-06-04 02:06:33 iteration: 153050 loss: 0.0014 lr: 0.02
2019-06-04 02:06:44 iteration: 153100 loss: 0.0015 lr: 0.02
2019-06-04 02:06:54 iteration: 153150 loss: 0.0017 lr: 0.02
2019-06-04 02:07:04 iteration: 153200 loss: 0.0011 lr: 0.02
2019-06-04 02:07:15 iteration: 153250 loss: 0.0013 lr: 0.02
2019-06-04 02:07:26 iteration: 153300 loss: 0.0012 lr: 0.02
2019-06-04 02:07:36 iteration: 153350 loss: 0.0012 lr: 0.02
2019-06-04 02:07:47 iteration: 153400 loss: 0.0016 lr: 0.02
2019-06-04 02:07:58 iteration: 153450 loss: 0.0015 lr: 0.02
2019-06-04 02:08:08 iteration: 153500 loss: 0.0017 lr: 0.02
2019-06-04 02:08:22 iteration: 153550 loss: 0.0014 lr: 0.02
2019-06-04 02:08:32 iteration: 153600 loss: 0.0014 lr: 0.02
2019-06-04 02:08:43 iteration: 153650 loss: 0.0014 lr: 0.02
2019-06-04 02:08:53 iteration: 153700 loss: 0.0014 lr: 0.02
2019-06-04 02:09:04 iteration: 153750 loss: 0.0015 lr: 0.02
2019-06-04 02:09:14 iteration: 153800 loss: 0.0014 lr: 0.02
2019-06-04 02:09:25 iteration: 153850 loss: 0.0012 lr: 0.02
2019-06-04 02:09:35 iteration: 153900 loss: 0.0013 lr: 0.02
2019-06-04 02:09:46 iteration: 153950 loss: 0.0015 lr: 0.02
2019-06-04 02:09:56 iteration: 154000 loss: 0.0015 lr: 0.02
2019-06-04 02:10:10 iteration: 154050 loss: 0.0018 lr: 0.02
2019-06-04 02:10:20 iteration: 154100 loss: 0.0018 lr: 0.02
2019-06-04 02:10:31 iteration: 154150 loss: 0.0012 lr: 0.02
2019-06-04 02:10:42 iteration: 154200 loss: 0.0015 lr: 0.02
2019-06-04 02:10:52 iteration: 154250 loss: 0.0011 lr: 0.02
2019-06-04 02:11:03 iteration: 154300 loss: 0.0012 lr: 0.02
2019-06-04 02:11:14 iteration: 154350 loss: 0.0014 lr: 0.02
2019-06-04 02:11:25 iteration: 154400 loss: 0.0015 lr: 0.02
2019-06-04 02:11:35 iteration: 154450 loss: 0.0014 lr: 0.02
2019-06-04 02:11:46 iteration: 154500 loss: 0.0014 lr: 0.02
2019-06-04 02:12:00 iteration: 154550 loss: 0.0017 lr: 0.02
2019-06-04 02:12:10 iteration: 154600 loss: 0.0014 lr: 0.02
2019-06-04 02:12:21 iteration: 154650 loss: 0.0015 lr: 0.02
2019-06-04 02:12:31 iteration: 154700 loss: 0.0013 lr: 0.02
2019-06-04 02:12:40 iteration: 154750 loss: 0.0018 lr: 0.02
2019-06-04 02:12:51 iteration: 154800 loss: 0.0015 lr: 0.02
2019-06-04 02:13:02 iteration: 154850 loss: 0.0014 lr: 0.02
2019-06-04 02:13:12 iteration: 154900 loss: 0.0016 lr: 0.02
2019-06-04 02:13:22 iteration: 154950 loss: 0.0014 lr: 0.02
2019-06-04 02:13:33 iteration: 155000 loss: 0.0018 lr: 0.02
2019-06-04 02:13:47 iteration: 155050 loss: 0.0016 lr: 0.02
2019-06-04 02:13:57 iteration: 155100 loss: 0.0012 lr: 0.02
2019-06-04 02:14:08 iteration: 155150 loss: 0.0013 lr: 0.02
2019-06-04 02:14:18 iteration: 155200 loss: 0.0015 lr: 0.02
2019-06-04 02:14:30 iteration: 155250 loss: 0.0013 lr: 0.02
2019-06-04 02:14:40 iteration: 155300 loss: 0.0015 lr: 0.02
2019-06-04 02:14:51 iteration: 155350 loss: 0.0014 lr: 0.02
2019-06-04 02:15:00 iteration: 155400 loss: 0.0015 lr: 0.02
2019-06-04 02:15:11 iteration: 155450 loss: 0.0012 lr: 0.02
2019-06-04 02:15:22 iteration: 155500 loss: 0.0016 lr: 0.02
2019-06-04 02:15:35 iteration: 155550 loss: 0.0015 lr: 0.02
2019-06-04 02:15:46 iteration: 155600 loss: 0.0013 lr: 0.02
2019-06-04 02:15:57 iteration: 155650 loss: 0.0014 lr: 0.02
2019-06-04 02:16:07 iteration: 155700 loss: 0.0014 lr: 0.02
2019-06-04 02:16:17 iteration: 155750 loss: 0.0014 lr: 0.02
2019-06-04 02:16:28 iteration: 155800 loss: 0.0013 lr: 0.02
2019-06-04 02:16:38 iteration: 155850 loss: 0.0016 lr: 0.02
2019-06-04 02:16:49 iteration: 155900 loss: 0.0011 lr: 0.02
2019-06-04 02:17:00 iteration: 155950 loss: 0.0013 lr: 0.02
2019-06-04 02:17:10 iteration: 156000 loss: 0.0014 lr: 0.02
2019-06-04 02:17:24 iteration: 156050 loss: 0.0013 lr: 0.02
2019-06-04 02:17:34 iteration: 156100 loss: 0.0014 lr: 0.02
2019-06-04 02:17:45 iteration: 156150 loss: 0.0014 lr: 0.02
2019-06-04 02:17:55 iteration: 156200 loss: 0.0015 lr: 0.02
2019-06-04 02:18:06 iteration: 156250 loss: 0.0012 lr: 0.02
2019-06-04 02:18:17 iteration: 156300 loss: 0.0013 lr: 0.02
2019-06-04 02:18:27 iteration: 156350 loss: 0.0014 lr: 0.02
2019-06-04 02:18:37 iteration: 156400 loss: 0.0014 lr: 0.02
2019-06-04 02:18:48 iteration: 156450 loss: 0.0014 lr: 0.02
2019-06-04 02:18:59 iteration: 156500 loss: 0.0013 lr: 0.02
2019-06-04 02:19:14 iteration: 156550 loss: 0.0013 lr: 0.02
2019-06-04 02:19:24 iteration: 156600 loss: 0.0012 lr: 0.02
2019-06-04 02:19:35 iteration: 156650 loss: 0.0017 lr: 0.02
2019-06-04 02:19:45 iteration: 156700 loss: 0.0012 lr: 0.02
2019-06-04 02:19:55 iteration: 156750 loss: 0.0013 lr: 0.02
2019-06-04 02:20:06 iteration: 156800 loss: 0.0015 lr: 0.02
2019-06-04 02:20:16 iteration: 156850 loss: 0.0015 lr: 0.02
2019-06-04 02:20:27 iteration: 156900 loss: 0.0013 lr: 0.02
2019-06-04 02:20:37 iteration: 156950 loss: 0.0014 lr: 0.02
2019-06-04 02:20:47 iteration: 157000 loss: 0.0013 lr: 0.02
2019-06-04 02:21:02 iteration: 157050 loss: 0.0015 lr: 0.02
2019-06-04 02:21:12 iteration: 157100 loss: 0.0014 lr: 0.02
2019-06-04 02:21:23 iteration: 157150 loss: 0.0015 lr: 0.02
2019-06-04 02:21:34 iteration: 157200 loss: 0.0015 lr: 0.02
2019-06-04 02:21:44 iteration: 157250 loss: 0.0012 lr: 0.02
2019-06-04 02:21:55 iteration: 157300 loss: 0.0016 lr: 0.02
2019-06-04 02:22:06 iteration: 157350 loss: 0.0016 lr: 0.02
2019-06-04 02:22:16 iteration: 157400 loss: 0.0012 lr: 0.02
2019-06-04 02:22:26 iteration: 157450 loss: 0.0014 lr: 0.02
2019-06-04 02:22:37 iteration: 157500 loss: 0.0012 lr: 0.02
2019-06-04 02:22:52 iteration: 157550 loss: 0.0013 lr: 0.02
2019-06-04 02:23:02 iteration: 157600 loss: 0.0015 lr: 0.02
2019-06-04 02:23:13 iteration: 157650 loss: 0.0013 lr: 0.02
2019-06-04 02:23:23 iteration: 157700 loss: 0.0013 lr: 0.02
2019-06-04 02:23:33 iteration: 157750 loss: 0.0016 lr: 0.02
2019-06-04 02:23:44 iteration: 157800 loss: 0.0016 lr: 0.02
2019-06-04 02:23:54 iteration: 157850 loss: 0.0017 lr: 0.02
2019-06-04 02:24:04 iteration: 157900 loss: 0.0015 lr: 0.02
2019-06-04 02:24:14 iteration: 157950 loss: 0.0015 lr: 0.02
2019-06-04 02:24:25 iteration: 158000 loss: 0.0014 lr: 0.02
2019-06-04 02:24:39 iteration: 158050 loss: 0.0014 lr: 0.02
2019-06-04 02:24:50 iteration: 158100 loss: 0.0014 lr: 0.02
2019-06-04 02:25:00 iteration: 158150 loss: 0.0015 lr: 0.02
2019-06-04 02:25:10 iteration: 158200 loss: 0.0015 lr: 0.02
2019-06-04 02:25:22 iteration: 158250 loss: 0.0013 lr: 0.02
2019-06-04 02:25:32 iteration: 158300 loss: 0.0013 lr: 0.02
2019-06-04 02:25:43 iteration: 158350 loss: 0.0012 lr: 0.02
2019-06-04 02:25:54 iteration: 158400 loss: 0.0019 lr: 0.02
2019-06-04 02:26:05 iteration: 158450 loss: 0.0013 lr: 0.02
2019-06-04 02:26:15 iteration: 158500 loss: 0.0013 lr: 0.02
2019-06-04 02:26:29 iteration: 158550 loss: 0.0015 lr: 0.02
2019-06-04 02:26:40 iteration: 158600 loss: 0.0014 lr: 0.02
2019-06-04 02:26:50 iteration: 158650 loss: 0.0013 lr: 0.02
2019-06-04 02:27:01 iteration: 158700 loss: 0.0013 lr: 0.02
2019-06-04 02:27:11 iteration: 158750 loss: 0.0015 lr: 0.02
2019-06-04 02:27:22 iteration: 158800 loss: 0.0013 lr: 0.02
2019-06-04 02:27:33 iteration: 158850 loss: 0.0012 lr: 0.02
2019-06-04 02:27:43 iteration: 158900 loss: 0.0014 lr: 0.02
2019-06-04 02:27:53 iteration: 158950 loss: 0.0014 lr: 0.02
2019-06-04 02:28:04 iteration: 159000 loss: 0.0012 lr: 0.02
2019-06-04 02:28:19 iteration: 159050 loss: 0.0014 lr: 0.02
2019-06-04 02:28:29 iteration: 159100 loss: 0.0013 lr: 0.02
2019-06-04 02:28:39 iteration: 159150 loss: 0.0013 lr: 0.02
2019-06-04 02:28:50 iteration: 159200 loss: 0.0014 lr: 0.02
2019-06-04 02:29:00 iteration: 159250 loss: 0.0012 lr: 0.02
2019-06-04 02:29:10 iteration: 159300 loss: 0.0015 lr: 0.02
2019-06-04 02:29:20 iteration: 159350 loss: 0.0017 lr: 0.02
2019-06-04 02:29:31 iteration: 159400 loss: 0.0015 lr: 0.02
2019-06-04 02:29:41 iteration: 159450 loss: 0.0014 lr: 0.02
2019-06-04 02:29:51 iteration: 159500 loss: 0.0020 lr: 0.02
2019-06-04 02:30:05 iteration: 159550 loss: 0.0014 lr: 0.02
2019-06-04 02:30:16 iteration: 159600 loss: 0.0012 lr: 0.02
2019-06-04 02:30:27 iteration: 159650 loss: 0.0014 lr: 0.02
2019-06-04 02:30:36 iteration: 159700 loss: 0.0015 lr: 0.02
2019-06-04 02:30:47 iteration: 159750 loss: 0.0013 lr: 0.02
2019-06-04 02:30:58 iteration: 159800 loss: 0.0013 lr: 0.02
2019-06-04 02:31:08 iteration: 159850 loss: 0.0013 lr: 0.02
2019-06-04 02:31:18 iteration: 159900 loss: 0.0015 lr: 0.02
2019-06-04 02:31:28 iteration: 159950 loss: 0.0014 lr: 0.02
2019-06-04 02:31:38 iteration: 160000 loss: 0.0017 lr: 0.02
2019-06-04 02:31:51 iteration: 160050 loss: 0.0015 lr: 0.02
2019-06-04 02:32:01 iteration: 160100 loss: 0.0015 lr: 0.02
2019-06-04 02:32:12 iteration: 160150 loss: 0.0016 lr: 0.02
2019-06-04 02:32:22 iteration: 160200 loss: 0.0015 lr: 0.02
2019-06-04 02:32:33 iteration: 160250 loss: 0.0014 lr: 0.02
2019-06-04 02:32:43 iteration: 160300 loss: 0.0014 lr: 0.02
2019-06-04 02:32:54 iteration: 160350 loss: 0.0012 lr: 0.02
2019-06-04 02:33:04 iteration: 160400 loss: 0.0013 lr: 0.02
2019-06-04 02:33:14 iteration: 160450 loss: 0.0014 lr: 0.02
2019-06-04 02:33:24 iteration: 160500 loss: 0.0016 lr: 0.02
2019-06-04 02:33:38 iteration: 160550 loss: 0.0016 lr: 0.02
2019-06-04 02:33:49 iteration: 160600 loss: 0.0014 lr: 0.02
2019-06-04 02:33:59 iteration: 160650 loss: 0.0013 lr: 0.02
2019-06-04 02:34:09 iteration: 160700 loss: 0.0015 lr: 0.02
2019-06-04 02:34:19 iteration: 160750 loss: 0.0015 lr: 0.02
2019-06-04 02:34:30 iteration: 160800 loss: 0.0012 lr: 0.02
2019-06-04 02:34:40 iteration: 160850 loss: 0.0016 lr: 0.02
2019-06-04 02:34:51 iteration: 160900 loss: 0.0015 lr: 0.02
2019-06-04 02:35:01 iteration: 160950 loss: 0.0012 lr: 0.02
2019-06-04 02:35:12 iteration: 161000 loss: 0.0013 lr: 0.02
2019-06-04 02:35:26 iteration: 161050 loss: 0.0012 lr: 0.02
2019-06-04 02:35:37 iteration: 161100 loss: 0.0014 lr: 0.02
2019-06-04 02:35:48 iteration: 161150 loss: 0.0014 lr: 0.02
2019-06-04 02:35:59 iteration: 161200 loss: 0.0014 lr: 0.02
2019-06-04 02:36:10 iteration: 161250 loss: 0.0014 lr: 0.02
2019-06-04 02:36:20 iteration: 161300 loss: 0.0013 lr: 0.02
2019-06-04 02:36:31 iteration: 161350 loss: 0.0013 lr: 0.02
2019-06-04 02:36:41 iteration: 161400 loss: 0.0016 lr: 0.02
2019-06-04 02:36:52 iteration: 161450 loss: 0.0013 lr: 0.02
2019-06-04 02:37:03 iteration: 161500 loss: 0.0014 lr: 0.02
2019-06-04 02:37:17 iteration: 161550 loss: 0.0015 lr: 0.02
2019-06-04 02:37:28 iteration: 161600 loss: 0.0015 lr: 0.02
2019-06-04 02:37:39 iteration: 161650 loss: 0.0012 lr: 0.02
2019-06-04 02:37:49 iteration: 161700 loss: 0.0013 lr: 0.02
2019-06-04 02:38:00 iteration: 161750 loss: 0.0012 lr: 0.02
2019-06-04 02:38:10 iteration: 161800 loss: 0.0019 lr: 0.02
2019-06-04 02:38:20 iteration: 161850 loss: 0.0013 lr: 0.02
2019-06-04 02:38:31 iteration: 161900 loss: 0.0012 lr: 0.02
2019-06-04 02:38:41 iteration: 161950 loss: 0.0017 lr: 0.02
2019-06-04 02:38:52 iteration: 162000 loss: 0.0011 lr: 0.02
2019-06-04 02:39:06 iteration: 162050 loss: 0.0013 lr: 0.02
2019-06-04 02:39:17 iteration: 162100 loss: 0.0016 lr: 0.02
2019-06-04 02:39:27 iteration: 162150 loss: 0.0013 lr: 0.02
2019-06-04 02:39:38 iteration: 162200 loss: 0.0013 lr: 0.02
2019-06-04 02:39:49 iteration: 162250 loss: 0.0012 lr: 0.02
2019-06-04 02:39:59 iteration: 162300 loss: 0.0017 lr: 0.02
2019-06-04 02:40:10 iteration: 162350 loss: 0.0015 lr: 0.02
2019-06-04 02:40:20 iteration: 162400 loss: 0.0013 lr: 0.02
2019-06-04 02:40:30 iteration: 162450 loss: 0.0013 lr: 0.02
2019-06-04 02:40:41 iteration: 162500 loss: 0.0014 lr: 0.02
2019-06-04 02:40:55 iteration: 162550 loss: 0.0018 lr: 0.02
2019-06-04 02:41:05 iteration: 162600 loss: 0.0016 lr: 0.02
2019-06-04 02:41:16 iteration: 162650 loss: 0.0015 lr: 0.02
2019-06-04 02:41:27 iteration: 162700 loss: 0.0012 lr: 0.02
2019-06-04 02:41:38 iteration: 162750 loss: 0.0014 lr: 0.02
2019-06-04 02:41:49 iteration: 162800 loss: 0.0013 lr: 0.02
2019-06-04 02:41:59 iteration: 162850 loss: 0.0014 lr: 0.02
2019-06-04 02:42:10 iteration: 162900 loss: 0.0012 lr: 0.02
2019-06-04 02:42:21 iteration: 162950 loss: 0.0014 lr: 0.02
2019-06-04 02:42:32 iteration: 163000 loss: 0.0014 lr: 0.02
2019-06-04 02:42:45 iteration: 163050 loss: 0.0015 lr: 0.02
2019-06-04 02:42:55 iteration: 163100 loss: 0.0015 lr: 0.02
2019-06-04 02:43:06 iteration: 163150 loss: 0.0017 lr: 0.02
2019-06-04 02:43:16 iteration: 163200 loss: 0.0015 lr: 0.02
2019-06-04 02:43:27 iteration: 163250 loss: 0.0015 lr: 0.02
2019-06-04 02:43:38 iteration: 163300 loss: 0.0015 lr: 0.02
2019-06-04 02:43:48 iteration: 163350 loss: 0.0013 lr: 0.02
2019-06-04 02:43:59 iteration: 163400 loss: 0.0017 lr: 0.02
2019-06-04 02:44:09 iteration: 163450 loss: 0.0014 lr: 0.02
2019-06-04 02:44:19 iteration: 163500 loss: 0.0015 lr: 0.02
2019-06-04 02:44:33 iteration: 163550 loss: 0.0013 lr: 0.02
2019-06-04 02:44:45 iteration: 163600 loss: 0.0013 lr: 0.02
2019-06-04 02:44:55 iteration: 163650 loss: 0.0014 lr: 0.02
2019-06-04 02:45:06 iteration: 163700 loss: 0.0013 lr: 0.02
2019-06-04 02:45:17 iteration: 163750 loss: 0.0014 lr: 0.02
2019-06-04 02:45:28 iteration: 163800 loss: 0.0011 lr: 0.02
2019-06-04 02:45:39 iteration: 163850 loss: 0.0015 lr: 0.02
2019-06-04 02:45:50 iteration: 163900 loss: 0.0015 lr: 0.02
2019-06-04 02:46:01 iteration: 163950 loss: 0.0014 lr: 0.02
2019-06-04 02:46:12 iteration: 164000 loss: 0.0013 lr: 0.02
2019-06-04 02:46:26 iteration: 164050 loss: 0.0013 lr: 0.02
2019-06-04 02:46:36 iteration: 164100 loss: 0.0013 lr: 0.02
2019-06-04 02:46:47 iteration: 164150 loss: 0.0013 lr: 0.02
2019-06-04 02:46:57 iteration: 164200 loss: 0.0012 lr: 0.02
2019-06-04 02:47:08 iteration: 164250 loss: 0.0016 lr: 0.02
2019-06-04 02:47:19 iteration: 164300 loss: 0.0013 lr: 0.02
2019-06-04 02:47:29 iteration: 164350 loss: 0.0014 lr: 0.02
2019-06-04 02:47:39 iteration: 164400 loss: 0.0013 lr: 0.02
2019-06-04 02:47:49 iteration: 164450 loss: 0.0017 lr: 0.02
2019-06-04 02:47:59 iteration: 164500 loss: 0.0013 lr: 0.02
2019-06-04 02:48:13 iteration: 164550 loss: 0.0014 lr: 0.02
2019-06-04 02:48:24 iteration: 164600 loss: 0.0015 lr: 0.02
2019-06-04 02:48:33 iteration: 164650 loss: 0.0020 lr: 0.02
2019-06-04 02:48:43 iteration: 164700 loss: 0.0015 lr: 0.02
2019-06-04 02:48:53 iteration: 164750 loss: 0.0016 lr: 0.02
2019-06-04 02:49:04 iteration: 164800 loss: 0.0013 lr: 0.02
2019-06-04 02:49:14 iteration: 164850 loss: 0.0014 lr: 0.02
2019-06-04 02:49:25 iteration: 164900 loss: 0.0014 lr: 0.02
2019-06-04 02:49:36 iteration: 164950 loss: 0.0014 lr: 0.02
2019-06-04 02:49:46 iteration: 165000 loss: 0.0019 lr: 0.02
2019-06-04 02:50:00 iteration: 165050 loss: 0.0012 lr: 0.02
2019-06-04 02:50:10 iteration: 165100 loss: 0.0015 lr: 0.02
2019-06-04 02:50:21 iteration: 165150 loss: 0.0014 lr: 0.02
2019-06-04 02:50:31 iteration: 165200 loss: 0.0017 lr: 0.02
2019-06-04 02:50:41 iteration: 165250 loss: 0.0015 lr: 0.02
2019-06-04 02:50:52 iteration: 165300 loss: 0.0016 lr: 0.02
2019-06-04 02:51:02 iteration: 165350 loss: 0.0014 lr: 0.02
2019-06-04 02:51:13 iteration: 165400 loss: 0.0015 lr: 0.02
2019-06-04 02:51:24 iteration: 165450 loss: 0.0012 lr: 0.02
2019-06-04 02:51:34 iteration: 165500 loss: 0.0014 lr: 0.02
2019-06-04 02:51:47 iteration: 165550 loss: 0.0018 lr: 0.02
2019-06-04 02:51:59 iteration: 165600 loss: 0.0014 lr: 0.02
2019-06-04 02:52:09 iteration: 165650 loss: 0.0014 lr: 0.02
2019-06-04 02:52:20 iteration: 165700 loss: 0.0014 lr: 0.02
2019-06-04 02:52:30 iteration: 165750 loss: 0.0015 lr: 0.02
2019-06-04 02:52:40 iteration: 165800 loss: 0.0016 lr: 0.02
2019-06-04 02:52:52 iteration: 165850 loss: 0.0014 lr: 0.02
2019-06-04 02:53:02 iteration: 165900 loss: 0.0011 lr: 0.02
2019-06-04 02:53:13 iteration: 165950 loss: 0.0014 lr: 0.02
2019-06-04 02:53:23 iteration: 166000 loss: 0.0011 lr: 0.02
2019-06-04 02:53:37 iteration: 166050 loss: 0.0012 lr: 0.02
2019-06-04 02:53:48 iteration: 166100 loss: 0.0014 lr: 0.02
2019-06-04 02:53:58 iteration: 166150 loss: 0.0014 lr: 0.02
2019-06-04 02:54:08 iteration: 166200 loss: 0.0012 lr: 0.02
2019-06-04 02:54:19 iteration: 166250 loss: 0.0014 lr: 0.02
2019-06-04 02:54:30 iteration: 166300 loss: 0.0011 lr: 0.02
2019-06-04 02:54:40 iteration: 166350 loss: 0.0014 lr: 0.02
2019-06-04 02:54:51 iteration: 166400 loss: 0.0012 lr: 0.02
2019-06-04 02:55:02 iteration: 166450 loss: 0.0013 lr: 0.02
2019-06-04 02:55:13 iteration: 166500 loss: 0.0014 lr: 0.02
2019-06-04 02:55:27 iteration: 166550 loss: 0.0016 lr: 0.02
2019-06-04 02:55:38 iteration: 166600 loss: 0.0015 lr: 0.02
2019-06-04 02:55:48 iteration: 166650 loss: 0.0016 lr: 0.02
2019-06-04 02:55:59 iteration: 166700 loss: 0.0013 lr: 0.02
2019-06-04 02:56:09 iteration: 166750 loss: 0.0015 lr: 0.02
2019-06-04 02:56:19 iteration: 166800 loss: 0.0014 lr: 0.02
2019-06-04 02:56:29 iteration: 166850 loss: 0.0015 lr: 0.02
2019-06-04 02:56:39 iteration: 166900 loss: 0.0015 lr: 0.02
2019-06-04 02:56:49 iteration: 166950 loss: 0.0016 lr: 0.02
2019-06-04 02:57:00 iteration: 167000 loss: 0.0014 lr: 0.02
2019-06-04 02:57:14 iteration: 167050 loss: 0.0012 lr: 0.02
2019-06-04 02:57:25 iteration: 167100 loss: 0.0015 lr: 0.02
2019-06-04 02:57:35 iteration: 167150 loss: 0.0015 lr: 0.02
2019-06-04 02:57:46 iteration: 167200 loss: 0.0015 lr: 0.02
2019-06-04 02:57:56 iteration: 167250 loss: 0.0015 lr: 0.02
2019-06-04 02:58:07 iteration: 167300 loss: 0.0015 lr: 0.02
2019-06-04 02:58:18 iteration: 167350 loss: 0.0012 lr: 0.02
2019-06-04 02:58:29 iteration: 167400 loss: 0.0013 lr: 0.02
2019-06-04 02:58:39 iteration: 167450 loss: 0.0013 lr: 0.02
2019-06-04 02:58:50 iteration: 167500 loss: 0.0013 lr: 0.02
2019-06-04 02:59:03 iteration: 167550 loss: 0.0015 lr: 0.02
2019-06-04 02:59:14 iteration: 167600 loss: 0.0015 lr: 0.02
2019-06-04 02:59:23 iteration: 167650 loss: 0.0015 lr: 0.02
2019-06-04 02:59:34 iteration: 167700 loss: 0.0012 lr: 0.02
2019-06-04 02:59:45 iteration: 167750 loss: 0.0014 lr: 0.02
2019-06-04 02:59:56 iteration: 167800 loss: 0.0012 lr: 0.02
2019-06-04 03:00:06 iteration: 167850 loss: 0.0011 lr: 0.02
2019-06-04 03:00:16 iteration: 167900 loss: 0.0013 lr: 0.02
2019-06-04 03:00:27 iteration: 167950 loss: 0.0013 lr: 0.02
2019-06-04 03:00:38 iteration: 168000 loss: 0.0016 lr: 0.02
2019-06-04 03:00:52 iteration: 168050 loss: 0.0013 lr: 0.02
2019-06-04 03:01:02 iteration: 168100 loss: 0.0013 lr: 0.02
2019-06-04 03:01:13 iteration: 168150 loss: 0.0013 lr: 0.02
2019-06-04 03:01:24 iteration: 168200 loss: 0.0013 lr: 0.02
2019-06-04 03:01:35 iteration: 168250 loss: 0.0014 lr: 0.02
2019-06-04 03:01:45 iteration: 168300 loss: 0.0015 lr: 0.02
2019-06-04 03:01:56 iteration: 168350 loss: 0.0013 lr: 0.02
2019-06-04 03:02:06 iteration: 168400 loss: 0.0016 lr: 0.02
2019-06-04 03:02:16 iteration: 168450 loss: 0.0014 lr: 0.02
2019-06-04 03:02:27 iteration: 168500 loss: 0.0013 lr: 0.02
2019-06-04 03:02:41 iteration: 168550 loss: 0.0012 lr: 0.02
2019-06-04 03:02:51 iteration: 168600 loss: 0.0015 lr: 0.02
2019-06-04 03:03:01 iteration: 168650 loss: 0.0016 lr: 0.02
2019-06-04 03:03:12 iteration: 168700 loss: 0.0013 lr: 0.02
2019-06-04 03:03:22 iteration: 168750 loss: 0.0015 lr: 0.02
2019-06-04 03:03:33 iteration: 168800 loss: 0.0014 lr: 0.02
2019-06-04 03:03:44 iteration: 168850 loss: 0.0013 lr: 0.02
2019-06-04 03:03:55 iteration: 168900 loss: 0.0015 lr: 0.02
2019-06-04 03:04:05 iteration: 168950 loss: 0.0014 lr: 0.02
2019-06-04 03:04:15 iteration: 169000 loss: 0.0016 lr: 0.02
2019-06-04 03:04:29 iteration: 169050 loss: 0.0014 lr: 0.02
2019-06-04 03:04:40 iteration: 169100 loss: 0.0014 lr: 0.02
2019-06-04 03:04:50 iteration: 169150 loss: 0.0015 lr: 0.02
2019-06-04 03:05:00 iteration: 169200 loss: 0.0015 lr: 0.02
2019-06-04 03:05:11 iteration: 169250 loss: 0.0014 lr: 0.02
2019-06-04 03:05:21 iteration: 169300 loss: 0.0014 lr: 0.02
2019-06-04 03:05:32 iteration: 169350 loss: 0.0012 lr: 0.02
2019-06-04 03:05:43 iteration: 169400 loss: 0.0011 lr: 0.02
2019-06-04 03:05:54 iteration: 169450 loss: 0.0013 lr: 0.02
2019-06-04 03:06:04 iteration: 169500 loss: 0.0014 lr: 0.02
2019-06-04 03:06:18 iteration: 169550 loss: 0.0018 lr: 0.02
2019-06-04 03:06:29 iteration: 169600 loss: 0.0015 lr: 0.02
2019-06-04 03:06:39 iteration: 169650 loss: 0.0014 lr: 0.02
2019-06-04 03:06:50 iteration: 169700 loss: 0.0014 lr: 0.02
2019-06-04 03:07:00 iteration: 169750 loss: 0.0015 lr: 0.02
2019-06-04 03:07:11 iteration: 169800 loss: 0.0013 lr: 0.02
2019-06-04 03:07:21 iteration: 169850 loss: 0.0012 lr: 0.02
2019-06-04 03:07:31 iteration: 169900 loss: 0.0016 lr: 0.02
2019-06-04 03:07:42 iteration: 169950 loss: 0.0014 lr: 0.02
2019-06-04 03:07:53 iteration: 170000 loss: 0.0013 lr: 0.02
2019-06-04 03:08:07 iteration: 170050 loss: 0.0013 lr: 0.02
2019-06-04 03:08:17 iteration: 170100 loss: 0.0013 lr: 0.02
2019-06-04 03:08:28 iteration: 170150 loss: 0.0015 lr: 0.02
2019-06-04 03:08:39 iteration: 170200 loss: 0.0014 lr: 0.02
2019-06-04 03:08:50 iteration: 170250 loss: 0.0013 lr: 0.02
2019-06-04 03:09:00 iteration: 170300 loss: 0.0012 lr: 0.02
2019-06-04 03:09:10 iteration: 170350 loss: 0.0017 lr: 0.02
2019-06-04 03:09:21 iteration: 170400 loss: 0.0014 lr: 0.02
2019-06-04 03:09:32 iteration: 170450 loss: 0.0012 lr: 0.02
2019-06-04 03:09:42 iteration: 170500 loss: 0.0016 lr: 0.02
2019-06-04 03:09:57 iteration: 170550 loss: 0.0013 lr: 0.02
2019-06-04 03:10:07 iteration: 170600 loss: 0.0015 lr: 0.02
2019-06-04 03:10:17 iteration: 170650 loss: 0.0011 lr: 0.02
2019-06-04 03:10:29 iteration: 170700 loss: 0.0012 lr: 0.02
2019-06-04 03:10:39 iteration: 170750 loss: 0.0013 lr: 0.02
2019-06-04 03:10:50 iteration: 170800 loss: 0.0014 lr: 0.02
2019-06-04 03:11:00 iteration: 170850 loss: 0.0015 lr: 0.02
2019-06-04 03:11:11 iteration: 170900 loss: 0.0013 lr: 0.02
2019-06-04 03:11:21 iteration: 170950 loss: 0.0014 lr: 0.02
2019-06-04 03:11:31 iteration: 171000 loss: 0.0017 lr: 0.02
2019-06-04 03:11:45 iteration: 171050 loss: 0.0015 lr: 0.02
2019-06-04 03:11:56 iteration: 171100 loss: 0.0014 lr: 0.02
2019-06-04 03:12:07 iteration: 171150 loss: 0.0013 lr: 0.02
2019-06-04 03:12:18 iteration: 171200 loss: 0.0011 lr: 0.02
2019-06-04 03:12:28 iteration: 171250 loss: 0.0017 lr: 0.02
2019-06-04 03:12:38 iteration: 171300 loss: 0.0016 lr: 0.02
2019-06-04 03:12:49 iteration: 171350 loss: 0.0013 lr: 0.02
2019-06-04 03:13:00 iteration: 171400 loss: 0.0012 lr: 0.02
2019-06-04 03:13:10 iteration: 171450 loss: 0.0017 lr: 0.02
2019-06-04 03:13:21 iteration: 171500 loss: 0.0013 lr: 0.02
2019-06-04 03:13:34 iteration: 171550 loss: 0.0015 lr: 0.02
2019-06-04 03:13:45 iteration: 171600 loss: 0.0016 lr: 0.02
2019-06-04 03:13:56 iteration: 171650 loss: 0.0013 lr: 0.02
2019-06-04 03:14:06 iteration: 171700 loss: 0.0015 lr: 0.02
2019-06-04 03:14:17 iteration: 171750 loss: 0.0013 lr: 0.02
2019-06-04 03:14:27 iteration: 171800 loss: 0.0015 lr: 0.02
2019-06-04 03:14:37 iteration: 171850 loss: 0.0014 lr: 0.02
2019-06-04 03:14:49 iteration: 171900 loss: 0.0011 lr: 0.02
2019-06-04 03:14:58 iteration: 171950 loss: 0.0015 lr: 0.02
2019-06-04 03:15:09 iteration: 172000 loss: 0.0012 lr: 0.02
2019-06-04 03:15:23 iteration: 172050 loss: 0.0016 lr: 0.02
2019-06-04 03:15:34 iteration: 172100 loss: 0.0015 lr: 0.02
2019-06-04 03:15:45 iteration: 172150 loss: 0.0014 lr: 0.02
2019-06-04 03:15:55 iteration: 172200 loss: 0.0014 lr: 0.02
2019-06-04 03:16:06 iteration: 172250 loss: 0.0013 lr: 0.02
2019-06-04 03:16:16 iteration: 172300 loss: 0.0014 lr: 0.02
2019-06-04 03:16:27 iteration: 172350 loss: 0.0015 lr: 0.02
2019-06-04 03:16:38 iteration: 172400 loss: 0.0014 lr: 0.02
2019-06-04 03:16:49 iteration: 172450 loss: 0.0010 lr: 0.02
2019-06-04 03:17:00 iteration: 172500 loss: 0.0013 lr: 0.02
2019-06-04 03:17:14 iteration: 172550 loss: 0.0011 lr: 0.02
2019-06-04 03:17:25 iteration: 172600 loss: 0.0013 lr: 0.02
2019-06-04 03:17:35 iteration: 172650 loss: 0.0013 lr: 0.02
2019-06-04 03:17:46 iteration: 172700 loss: 0.0012 lr: 0.02
2019-06-04 03:17:57 iteration: 172750 loss: 0.0013 lr: 0.02
2019-06-04 03:18:07 iteration: 172800 loss: 0.0014 lr: 0.02
2019-06-04 03:18:17 iteration: 172850 loss: 0.0013 lr: 0.02
2019-06-04 03:18:28 iteration: 172900 loss: 0.0014 lr: 0.02
2019-06-04 03:18:38 iteration: 172950 loss: 0.0014 lr: 0.02
2019-06-04 03:18:49 iteration: 173000 loss: 0.0013 lr: 0.02
2019-06-04 03:19:02 iteration: 173050 loss: 0.0014 lr: 0.02
2019-06-04 03:19:13 iteration: 173100 loss: 0.0011 lr: 0.02
2019-06-04 03:19:24 iteration: 173150 loss: 0.0014 lr: 0.02
2019-06-04 03:19:35 iteration: 173200 loss: 0.0014 lr: 0.02
2019-06-04 03:19:46 iteration: 173250 loss: 0.0013 lr: 0.02
2019-06-04 03:19:56 iteration: 173300 loss: 0.0014 lr: 0.02
2019-06-04 03:20:06 iteration: 173350 loss: 0.0014 lr: 0.02
2019-06-04 03:20:16 iteration: 173400 loss: 0.0016 lr: 0.02
2019-06-04 03:20:26 iteration: 173450 loss: 0.0018 lr: 0.02
2019-06-04 03:20:37 iteration: 173500 loss: 0.0013 lr: 0.02
2019-06-04 03:20:51 iteration: 173550 loss: 0.0013 lr: 0.02
2019-06-04 03:21:01 iteration: 173600 loss: 0.0014 lr: 0.02
2019-06-04 03:21:12 iteration: 173650 loss: 0.0013 lr: 0.02
2019-06-04 03:21:23 iteration: 173700 loss: 0.0014 lr: 0.02
2019-06-04 03:21:33 iteration: 173750 loss: 0.0011 lr: 0.02
2019-06-04 03:21:45 iteration: 173800 loss: 0.0012 lr: 0.02
2019-06-04 03:21:55 iteration: 173850 loss: 0.0013 lr: 0.02
2019-06-04 03:22:06 iteration: 173900 loss: 0.0013 lr: 0.02
2019-06-04 03:22:16 iteration: 173950 loss: 0.0018 lr: 0.02
2019-06-04 03:22:26 iteration: 174000 loss: 0.0019 lr: 0.02
2019-06-04 03:22:40 iteration: 174050 loss: 0.0011 lr: 0.02
2019-06-04 03:22:50 iteration: 174100 loss: 0.0017 lr: 0.02
2019-06-04 03:23:01 iteration: 174150 loss: 0.0016 lr: 0.02
2019-06-04 03:23:11 iteration: 174200 loss: 0.0016 lr: 0.02
2019-06-04 03:23:21 iteration: 174250 loss: 0.0014 lr: 0.02
2019-06-04 03:23:32 iteration: 174300 loss: 0.0012 lr: 0.02
2019-06-04 03:23:43 iteration: 174350 loss: 0.0014 lr: 0.02
2019-06-04 03:23:53 iteration: 174400 loss: 0.0017 lr: 0.02
2019-06-04 03:24:03 iteration: 174450 loss: 0.0015 lr: 0.02
2019-06-04 03:24:13 iteration: 174500 loss: 0.0014 lr: 0.02
2019-06-04 03:24:27 iteration: 174550 loss: 0.0014 lr: 0.02
2019-06-04 03:24:37 iteration: 174600 loss: 0.0013 lr: 0.02
2019-06-04 03:24:48 iteration: 174650 loss: 0.0011 lr: 0.02
2019-06-04 03:24:59 iteration: 174700 loss: 0.0015 lr: 0.02
2019-06-04 03:25:09 iteration: 174750 loss: 0.0014 lr: 0.02
2019-06-04 03:25:20 iteration: 174800 loss: 0.0013 lr: 0.02
2019-06-04 03:25:30 iteration: 174850 loss: 0.0014 lr: 0.02
2019-06-04 03:25:42 iteration: 174900 loss: 0.0015 lr: 0.02
2019-06-04 03:25:52 iteration: 174950 loss: 0.0014 lr: 0.02
2019-06-04 03:26:02 iteration: 175000 loss: 0.0016 lr: 0.02
2019-06-04 03:26:17 iteration: 175050 loss: 0.0013 lr: 0.02
2019-06-04 03:26:27 iteration: 175100 loss: 0.0014 lr: 0.02
2019-06-04 03:26:37 iteration: 175150 loss: 0.0015 lr: 0.02
2019-06-04 03:26:47 iteration: 175200 loss: 0.0016 lr: 0.02
2019-06-04 03:26:57 iteration: 175250 loss: 0.0014 lr: 0.02
2019-06-04 03:27:09 iteration: 175300 loss: 0.0013 lr: 0.02
2019-06-04 03:27:19 iteration: 175350 loss: 0.0013 lr: 0.02
2019-06-04 03:27:30 iteration: 175400 loss: 0.0013 lr: 0.02
2019-06-04 03:27:40 iteration: 175450 loss: 0.0012 lr: 0.02
2019-06-04 03:27:50 iteration: 175500 loss: 0.0014 lr: 0.02
2019-06-04 03:28:04 iteration: 175550 loss: 0.0014 lr: 0.02
2019-06-04 03:28:15 iteration: 175600 loss: 0.0012 lr: 0.02
2019-06-04 03:28:26 iteration: 175650 loss: 0.0015 lr: 0.02
2019-06-04 03:28:37 iteration: 175700 loss: 0.0010 lr: 0.02
2019-06-04 03:28:48 iteration: 175750 loss: 0.0014 lr: 0.02
2019-06-04 03:28:59 iteration: 175800 loss: 0.0012 lr: 0.02
2019-06-04 03:29:10 iteration: 175850 loss: 0.0013 lr: 0.02
2019-06-04 03:29:21 iteration: 175900 loss: 0.0012 lr: 0.02
2019-06-04 03:29:31 iteration: 175950 loss: 0.0013 lr: 0.02
2019-06-04 03:29:42 iteration: 176000 loss: 0.0012 lr: 0.02
2019-06-04 03:29:56 iteration: 176050 loss: 0.0013 lr: 0.02
2019-06-04 03:30:07 iteration: 176100 loss: 0.0012 lr: 0.02
2019-06-04 03:30:18 iteration: 176150 loss: 0.0012 lr: 0.02
2019-06-04 03:30:29 iteration: 176200 loss: 0.0013 lr: 0.02
2019-06-04 03:30:40 iteration: 176250 loss: 0.0012 lr: 0.02
2019-06-04 03:30:50 iteration: 176300 loss: 0.0013 lr: 0.02
2019-06-04 03:31:01 iteration: 176350 loss: 0.0012 lr: 0.02
2019-06-04 03:31:11 iteration: 176400 loss: 0.0012 lr: 0.02
2019-06-04 03:31:21 iteration: 176450 loss: 0.0015 lr: 0.02
2019-06-04 03:31:32 iteration: 176500 loss: 0.0013 lr: 0.02
2019-06-04 03:31:46 iteration: 176550 loss: 0.0014 lr: 0.02
2019-06-04 03:31:56 iteration: 176600 loss: 0.0017 lr: 0.02
2019-06-04 03:32:07 iteration: 176650 loss: 0.0013 lr: 0.02
2019-06-04 03:32:18 iteration: 176700 loss: 0.0012 lr: 0.02
2019-06-04 03:32:28 iteration: 176750 loss: 0.0014 lr: 0.02
2019-06-04 03:32:38 iteration: 176800 loss: 0.0012 lr: 0.02
2019-06-04 03:32:50 iteration: 176850 loss: 0.0014 lr: 0.02
2019-06-04 03:33:00 iteration: 176900 loss: 0.0011 lr: 0.02
2019-06-04 03:33:10 iteration: 176950 loss: 0.0012 lr: 0.02
2019-06-04 03:33:21 iteration: 177000 loss: 0.0013 lr: 0.02
2019-06-04 03:33:35 iteration: 177050 loss: 0.0012 lr: 0.02
2019-06-04 03:33:46 iteration: 177100 loss: 0.0012 lr: 0.02
2019-06-04 03:33:57 iteration: 177150 loss: 0.0011 lr: 0.02
2019-06-04 03:34:08 iteration: 177200 loss: 0.0013 lr: 0.02
2019-06-04 03:34:18 iteration: 177250 loss: 0.0013 lr: 0.02
2019-06-04 03:34:29 iteration: 177300 loss: 0.0012 lr: 0.02
2019-06-04 03:34:40 iteration: 177350 loss: 0.0013 lr: 0.02
2019-06-04 03:34:51 iteration: 177400 loss: 0.0012 lr: 0.02
2019-06-04 03:35:01 iteration: 177450 loss: 0.0012 lr: 0.02
2019-06-04 03:35:12 iteration: 177500 loss: 0.0014 lr: 0.02
2019-06-04 03:35:26 iteration: 177550 loss: 0.0014 lr: 0.02
2019-06-04 03:35:36 iteration: 177600 loss: 0.0013 lr: 0.02
2019-06-04 03:35:47 iteration: 177650 loss: 0.0013 lr: 0.02
2019-06-04 03:35:57 iteration: 177700 loss: 0.0013 lr: 0.02
2019-06-04 03:36:08 iteration: 177750 loss: 0.0014 lr: 0.02
2019-06-04 03:36:19 iteration: 177800 loss: 0.0015 lr: 0.02
2019-06-04 03:36:29 iteration: 177850 loss: 0.0012 lr: 0.02
2019-06-04 03:36:40 iteration: 177900 loss: 0.0009 lr: 0.02
2019-06-04 03:36:51 iteration: 177950 loss: 0.0012 lr: 0.02
2019-06-04 03:37:02 iteration: 178000 loss: 0.0016 lr: 0.02
2019-06-04 03:37:15 iteration: 178050 loss: 0.0014 lr: 0.02
2019-06-04 03:37:26 iteration: 178100 loss: 0.0014 lr: 0.02
2019-06-04 03:37:35 iteration: 178150 loss: 0.0015 lr: 0.02
2019-06-04 03:37:46 iteration: 178200 loss: 0.0012 lr: 0.02
2019-06-04 03:37:57 iteration: 178250 loss: 0.0011 lr: 0.02
2019-06-04 03:38:08 iteration: 178300 loss: 0.0011 lr: 0.02
2019-06-04 03:38:18 iteration: 178350 loss: 0.0012 lr: 0.02
2019-06-04 03:38:29 iteration: 178400 loss: 0.0013 lr: 0.02
2019-06-04 03:38:39 iteration: 178450 loss: 0.0018 lr: 0.02
2019-06-04 03:38:49 iteration: 178500 loss: 0.0014 lr: 0.02
2019-06-04 03:39:03 iteration: 178550 loss: 0.0015 lr: 0.02
2019-06-04 03:39:13 iteration: 178600 loss: 0.0012 lr: 0.02
2019-06-04 03:39:24 iteration: 178650 loss: 0.0016 lr: 0.02
2019-06-04 03:39:34 iteration: 178700 loss: 0.0014 lr: 0.02
2019-06-04 03:39:44 iteration: 178750 loss: 0.0013 lr: 0.02
2019-06-04 03:39:55 iteration: 178800 loss: 0.0014 lr: 0.02
2019-06-04 03:40:06 iteration: 178850 loss: 0.0013 lr: 0.02
2019-06-04 03:40:16 iteration: 178900 loss: 0.0014 lr: 0.02
2019-06-04 03:40:27 iteration: 178950 loss: 0.0012 lr: 0.02
2019-06-04 03:40:37 iteration: 179000 loss: 0.0015 lr: 0.02
2019-06-04 03:40:51 iteration: 179050 loss: 0.0014 lr: 0.02
2019-06-04 03:41:01 iteration: 179100 loss: 0.0013 lr: 0.02
2019-06-04 03:41:12 iteration: 179150 loss: 0.0013 lr: 0.02
2019-06-04 03:41:23 iteration: 179200 loss: 0.0014 lr: 0.02
2019-06-04 03:41:33 iteration: 179250 loss: 0.0011 lr: 0.02
2019-06-04 03:41:44 iteration: 179300 loss: 0.0014 lr: 0.02
2019-06-04 03:41:55 iteration: 179350 loss: 0.0013 lr: 0.02
2019-06-04 03:42:05 iteration: 179400 loss: 0.0014 lr: 0.02
2019-06-04 03:42:16 iteration: 179450 loss: 0.0011 lr: 0.02
2019-06-04 03:42:26 iteration: 179500 loss: 0.0011 lr: 0.02
2019-06-04 03:42:39 iteration: 179550 loss: 0.0013 lr: 0.02
2019-06-04 03:42:50 iteration: 179600 loss: 0.0012 lr: 0.02
2019-06-04 03:43:01 iteration: 179650 loss: 0.0012 lr: 0.02
2019-06-04 03:43:11 iteration: 179700 loss: 0.0015 lr: 0.02
2019-06-04 03:43:21 iteration: 179750 loss: 0.0014 lr: 0.02
2019-06-04 03:43:32 iteration: 179800 loss: 0.0015 lr: 0.02
2019-06-04 03:43:43 iteration: 179850 loss: 0.0016 lr: 0.02
2019-06-04 03:43:53 iteration: 179900 loss: 0.0013 lr: 0.02
2019-06-04 03:44:03 iteration: 179950 loss: 0.0014 lr: 0.02
2019-06-04 03:44:14 iteration: 180000 loss: 0.0014 lr: 0.02
2019-06-04 03:44:29 iteration: 180050 loss: 0.0011 lr: 0.02
2019-06-04 03:44:38 iteration: 180100 loss: 0.0014 lr: 0.02
2019-06-04 03:44:50 iteration: 180150 loss: 0.0011 lr: 0.02
2019-06-04 03:45:00 iteration: 180200 loss: 0.0011 lr: 0.02
2019-06-04 03:45:10 iteration: 180250 loss: 0.0015 lr: 0.02
2019-06-04 03:45:21 iteration: 180300 loss: 0.0013 lr: 0.02
2019-06-04 03:45:31 iteration: 180350 loss: 0.0015 lr: 0.02
2019-06-04 03:45:42 iteration: 180400 loss: 0.0013 lr: 0.02
2019-06-04 03:45:52 iteration: 180450 loss: 0.0016 lr: 0.02
2019-06-04 03:46:02 iteration: 180500 loss: 0.0017 lr: 0.02
2019-06-04 03:46:16 iteration: 180550 loss: 0.0015 lr: 0.02
2019-06-04 03:46:25 iteration: 180600 loss: 0.0014 lr: 0.02
2019-06-04 03:46:36 iteration: 180650 loss: 0.0013 lr: 0.02
2019-06-04 03:46:47 iteration: 180700 loss: 0.0014 lr: 0.02
2019-06-04 03:46:58 iteration: 180750 loss: 0.0011 lr: 0.02
2019-06-04 03:47:08 iteration: 180800 loss: 0.0013 lr: 0.02
2019-06-04 03:47:18 iteration: 180850 loss: 0.0017 lr: 0.02
2019-06-04 03:47:29 iteration: 180900 loss: 0.0015 lr: 0.02
2019-06-04 03:47:39 iteration: 180950 loss: 0.0014 lr: 0.02
2019-06-04 03:47:50 iteration: 181000 loss: 0.0013 lr: 0.02
2019-06-04 03:48:04 iteration: 181050 loss: 0.0012 lr: 0.02
2019-06-04 03:48:15 iteration: 181100 loss: 0.0014 lr: 0.02
2019-06-04 03:48:25 iteration: 181150 loss: 0.0013 lr: 0.02
2019-06-04 03:48:36 iteration: 181200 loss: 0.0012 lr: 0.02
2019-06-04 03:48:46 iteration: 181250 loss: 0.0012 lr: 0.02
2019-06-04 03:48:57 iteration: 181300 loss: 0.0012 lr: 0.02
2019-06-04 03:49:07 iteration: 181350 loss: 0.0014 lr: 0.02
2019-06-04 03:49:17 iteration: 181400 loss: 0.0015 lr: 0.02
2019-06-04 03:49:27 iteration: 181450 loss: 0.0016 lr: 0.02
2019-06-04 03:49:38 iteration: 181500 loss: 0.0013 lr: 0.02
2019-06-04 03:49:51 iteration: 181550 loss: 0.0013 lr: 0.02
2019-06-04 03:50:02 iteration: 181600 loss: 0.0014 lr: 0.02
2019-06-04 03:50:12 iteration: 181650 loss: 0.0013 lr: 0.02
2019-06-04 03:50:22 iteration: 181700 loss: 0.0013 lr: 0.02
2019-06-04 03:50:32 iteration: 181750 loss: 0.0013 lr: 0.02
2019-06-04 03:50:44 iteration: 181800 loss: 0.0013 lr: 0.02
2019-06-04 03:50:54 iteration: 181850 loss: 0.0013 lr: 0.02
2019-06-04 03:51:05 iteration: 181900 loss: 0.0012 lr: 0.02
2019-06-04 03:51:16 iteration: 181950 loss: 0.0013 lr: 0.02
2019-06-04 03:51:26 iteration: 182000 loss: 0.0014 lr: 0.02
2019-06-04 03:51:39 iteration: 182050 loss: 0.0013 lr: 0.02
2019-06-04 03:51:49 iteration: 182100 loss: 0.0014 lr: 0.02
2019-06-04 03:51:59 iteration: 182150 loss: 0.0012 lr: 0.02
2019-06-04 03:52:09 iteration: 182200 loss: 0.0016 lr: 0.02
2019-06-04 03:52:20 iteration: 182250 loss: 0.0013 lr: 0.02
2019-06-04 03:52:30 iteration: 182300 loss: 0.0014 lr: 0.02
2019-06-04 03:52:41 iteration: 182350 loss: 0.0016 lr: 0.02
2019-06-04 03:52:52 iteration: 182400 loss: 0.0011 lr: 0.02
2019-06-04 03:53:02 iteration: 182450 loss: 0.0012 lr: 0.02
2019-06-04 03:53:12 iteration: 182500 loss: 0.0015 lr: 0.02
2019-06-04 03:53:26 iteration: 182550 loss: 0.0012 lr: 0.02
2019-06-04 03:53:36 iteration: 182600 loss: 0.0012 lr: 0.02
2019-06-04 03:53:47 iteration: 182650 loss: 0.0015 lr: 0.02
2019-06-04 03:53:57 iteration: 182700 loss: 0.0014 lr: 0.02
2019-06-04 03:54:08 iteration: 182750 loss: 0.0014 lr: 0.02
2019-06-04 03:54:19 iteration: 182800 loss: 0.0013 lr: 0.02
2019-06-04 03:54:29 iteration: 182850 loss: 0.0013 lr: 0.02
2019-06-04 03:54:39 iteration: 182900 loss: 0.0015 lr: 0.02
2019-06-04 03:54:50 iteration: 182950 loss: 0.0013 lr: 0.02
2019-06-04 03:55:01 iteration: 183000 loss: 0.0013 lr: 0.02
2019-06-04 03:55:14 iteration: 183050 loss: 0.0014 lr: 0.02
2019-06-04 03:55:25 iteration: 183100 loss: 0.0015 lr: 0.02
2019-06-04 03:55:36 iteration: 183150 loss: 0.0014 lr: 0.02
2019-06-04 03:55:46 iteration: 183200 loss: 0.0011 lr: 0.02
2019-06-04 03:55:57 iteration: 183250 loss: 0.0014 lr: 0.02
2019-06-04 03:56:08 iteration: 183300 loss: 0.0012 lr: 0.02
2019-06-04 03:56:18 iteration: 183350 loss: 0.0016 lr: 0.02
2019-06-04 03:56:29 iteration: 183400 loss: 0.0012 lr: 0.02
2019-06-04 03:56:39 iteration: 183450 loss: 0.0013 lr: 0.02
2019-06-04 03:56:50 iteration: 183500 loss: 0.0015 lr: 0.02
2019-06-04 03:57:03 iteration: 183550 loss: 0.0015 lr: 0.02
2019-06-04 03:57:13 iteration: 183600 loss: 0.0013 lr: 0.02
2019-06-04 03:57:24 iteration: 183650 loss: 0.0012 lr: 0.02
2019-06-04 03:57:34 iteration: 183700 loss: 0.0017 lr: 0.02
2019-06-04 03:57:45 iteration: 183750 loss: 0.0013 lr: 0.02
2019-06-04 03:57:56 iteration: 183800 loss: 0.0012 lr: 0.02
2019-06-04 03:58:06 iteration: 183850 loss: 0.0013 lr: 0.02
2019-06-04 03:58:16 iteration: 183900 loss: 0.0015 lr: 0.02
2019-06-04 03:58:27 iteration: 183950 loss: 0.0012 lr: 0.02
2019-06-04 03:58:37 iteration: 184000 loss: 0.0013 lr: 0.02
2019-06-04 03:58:51 iteration: 184050 loss: 0.0014 lr: 0.02
2019-06-04 03:59:02 iteration: 184100 loss: 0.0012 lr: 0.02
2019-06-04 03:59:13 iteration: 184150 loss: 0.0013 lr: 0.02
2019-06-04 03:59:24 iteration: 184200 loss: 0.0010 lr: 0.02
2019-06-04 03:59:35 iteration: 184250 loss: 0.0011 lr: 0.02
2019-06-04 03:59:46 iteration: 184300 loss: 0.0013 lr: 0.02
2019-06-04 03:59:56 iteration: 184350 loss: 0.0014 lr: 0.02
2019-06-04 04:00:07 iteration: 184400 loss: 0.0011 lr: 0.02
2019-06-04 04:00:18 iteration: 184450 loss: 0.0012 lr: 0.02
2019-06-04 04:00:29 iteration: 184500 loss: 0.0012 lr: 0.02
2019-06-04 04:00:43 iteration: 184550 loss: 0.0011 lr: 0.02
2019-06-04 04:00:53 iteration: 184600 loss: 0.0014 lr: 0.02
2019-06-04 04:01:03 iteration: 184650 loss: 0.0014 lr: 0.02
2019-06-04 04:01:14 iteration: 184700 loss: 0.0012 lr: 0.02
2019-06-04 04:01:24 iteration: 184750 loss: 0.0014 lr: 0.02
2019-06-04 04:01:34 iteration: 184800 loss: 0.0014 lr: 0.02
2019-06-04 04:01:44 iteration: 184850 loss: 0.0013 lr: 0.02
2019-06-04 04:01:55 iteration: 184900 loss: 0.0011 lr: 0.02
2019-06-04 04:02:05 iteration: 184950 loss: 0.0013 lr: 0.02
2019-06-04 04:02:15 iteration: 185000 loss: 0.0013 lr: 0.02
2019-06-04 04:02:28 iteration: 185050 loss: 0.0012 lr: 0.02
2019-06-04 04:02:39 iteration: 185100 loss: 0.0013 lr: 0.02
2019-06-04 04:02:51 iteration: 185150 loss: 0.0011 lr: 0.02
2019-06-04 04:03:01 iteration: 185200 loss: 0.0013 lr: 0.02
2019-06-04 04:03:12 iteration: 185250 loss: 0.0012 lr: 0.02
2019-06-04 04:03:22 iteration: 185300 loss: 0.0012 lr: 0.02
2019-06-04 04:03:33 iteration: 185350 loss: 0.0012 lr: 0.02
2019-06-04 04:03:44 iteration: 185400 loss: 0.0014 lr: 0.02
2019-06-04 04:03:54 iteration: 185450 loss: 0.0015 lr: 0.02
2019-06-04 04:04:04 iteration: 185500 loss: 0.0014 lr: 0.02
2019-06-04 04:04:17 iteration: 185550 loss: 0.0012 lr: 0.02
2019-06-04 04:04:27 iteration: 185600 loss: 0.0012 lr: 0.02
2019-06-04 04:04:37 iteration: 185650 loss: 0.0012 lr: 0.02
2019-06-04 04:04:48 iteration: 185700 loss: 0.0013 lr: 0.02
2019-06-04 04:04:59 iteration: 185750 loss: 0.0011 lr: 0.02
2019-06-04 04:05:10 iteration: 185800 loss: 0.0013 lr: 0.02
2019-06-04 04:05:19 iteration: 185850 loss: 0.0014 lr: 0.02
2019-06-04 04:05:30 iteration: 185900 loss: 0.0014 lr: 0.02
2019-06-04 04:05:40 iteration: 185950 loss: 0.0014 lr: 0.02
2019-06-04 04:05:50 iteration: 186000 loss: 0.0012 lr: 0.02
2019-06-04 04:06:03 iteration: 186050 loss: 0.0014 lr: 0.02
2019-06-04 04:06:14 iteration: 186100 loss: 0.0014 lr: 0.02
2019-06-04 04:06:25 iteration: 186150 loss: 0.0010 lr: 0.02
2019-06-04 04:06:35 iteration: 186200 loss: 0.0011 lr: 0.02
2019-06-04 04:06:45 iteration: 186250 loss: 0.0014 lr: 0.02
2019-06-04 04:06:56 iteration: 186300 loss: 0.0015 lr: 0.02
2019-06-04 04:07:06 iteration: 186350 loss: 0.0014 lr: 0.02
2019-06-04 04:07:16 iteration: 186400 loss: 0.0015 lr: 0.02
2019-06-04 04:07:27 iteration: 186450 loss: 0.0014 lr: 0.02
2019-06-04 04:07:38 iteration: 186500 loss: 0.0012 lr: 0.02
2019-06-04 04:07:51 iteration: 186550 loss: 0.0013 lr: 0.02
2019-06-04 04:08:02 iteration: 186600 loss: 0.0012 lr: 0.02
2019-06-04 04:08:13 iteration: 186650 loss: 0.0011 lr: 0.02
2019-06-04 04:08:23 iteration: 186700 loss: 0.0014 lr: 0.02
2019-06-04 04:08:34 iteration: 186750 loss: 0.0013 lr: 0.02
2019-06-04 04:08:45 iteration: 186800 loss: 0.0011 lr: 0.02
2019-06-04 04:08:55 iteration: 186850 loss: 0.0012 lr: 0.02
2019-06-04 04:09:05 iteration: 186900 loss: 0.0013 lr: 0.02
2019-06-04 04:09:15 iteration: 186950 loss: 0.0014 lr: 0.02
2019-06-04 04:09:26 iteration: 187000 loss: 0.0011 lr: 0.02
2019-06-04 04:09:39 iteration: 187050 loss: 0.0015 lr: 0.02
2019-06-04 04:09:50 iteration: 187100 loss: 0.0012 lr: 0.02
2019-06-04 04:10:00 iteration: 187150 loss: 0.0015 lr: 0.02
2019-06-04 04:10:11 iteration: 187200 loss: 0.0012 lr: 0.02
2019-06-04 04:10:22 iteration: 187250 loss: 0.0012 lr: 0.02
2019-06-04 04:10:32 iteration: 187300 loss: 0.0013 lr: 0.02
2019-06-04 04:10:43 iteration: 187350 loss: 0.0011 lr: 0.02
2019-06-04 04:10:54 iteration: 187400 loss: 0.0011 lr: 0.02
2019-06-04 04:11:04 iteration: 187450 loss: 0.0015 lr: 0.02
2019-06-04 04:11:14 iteration: 187500 loss: 0.0014 lr: 0.02
2019-06-04 04:11:28 iteration: 187550 loss: 0.0013 lr: 0.02
2019-06-04 04:11:39 iteration: 187600 loss: 0.0013 lr: 0.02
2019-06-04 04:11:49 iteration: 187650 loss: 0.0014 lr: 0.02
2019-06-04 04:12:00 iteration: 187700 loss: 0.0012 lr: 0.02
2019-06-04 04:12:11 iteration: 187750 loss: 0.0013 lr: 0.02
2019-06-04 04:12:22 iteration: 187800 loss: 0.0011 lr: 0.02
2019-06-04 04:12:33 iteration: 187850 loss: 0.0012 lr: 0.02
2019-06-04 04:12:43 iteration: 187900 loss: 0.0014 lr: 0.02
2019-06-04 04:12:53 iteration: 187950 loss: 0.0014 lr: 0.02
2019-06-04 04:13:04 iteration: 188000 loss: 0.0013 lr: 0.02
2019-06-04 04:13:17 iteration: 188050 loss: 0.0013 lr: 0.02
2019-06-04 04:13:27 iteration: 188100 loss: 0.0012 lr: 0.02
2019-06-04 04:13:38 iteration: 188150 loss: 0.0011 lr: 0.02
2019-06-04 04:13:48 iteration: 188200 loss: 0.0010 lr: 0.02
2019-06-04 04:13:57 iteration: 188250 loss: 0.0015 lr: 0.02
2019-06-04 04:14:08 iteration: 188300 loss: 0.0015 lr: 0.02
2019-06-04 04:14:18 iteration: 188350 loss: 0.0012 lr: 0.02
2019-06-04 04:14:29 iteration: 188400 loss: 0.0013 lr: 0.02
2019-06-04 04:14:39 iteration: 188450 loss: 0.0014 lr: 0.02
2019-06-04 04:14:50 iteration: 188500 loss: 0.0015 lr: 0.02
2019-06-04 04:15:03 iteration: 188550 loss: 0.0014 lr: 0.02
2019-06-04 04:15:13 iteration: 188600 loss: 0.0014 lr: 0.02
2019-06-04 04:15:24 iteration: 188650 loss: 0.0014 lr: 0.02
2019-06-04 04:15:34 iteration: 188700 loss: 0.0014 lr: 0.02
2019-06-04 04:15:45 iteration: 188750 loss: 0.0013 lr: 0.02
2019-06-04 04:15:55 iteration: 188800 loss: 0.0013 lr: 0.02
2019-06-04 04:16:05 iteration: 188850 loss: 0.0012 lr: 0.02
2019-06-04 04:16:16 iteration: 188900 loss: 0.0017 lr: 0.02
2019-06-04 04:16:26 iteration: 188950 loss: 0.0012 lr: 0.02
2019-06-04 04:16:37 iteration: 189000 loss: 0.0016 lr: 0.02
2019-06-04 04:16:51 iteration: 189050 loss: 0.0016 lr: 0.02
2019-06-04 04:17:01 iteration: 189100 loss: 0.0013 lr: 0.02
2019-06-04 04:17:11 iteration: 189150 loss: 0.0014 lr: 0.02
2019-06-04 04:17:22 iteration: 189200 loss: 0.0013 lr: 0.02
2019-06-04 04:17:32 iteration: 189250 loss: 0.0015 lr: 0.02
2019-06-04 04:17:43 iteration: 189300 loss: 0.0013 lr: 0.02
2019-06-04 04:17:53 iteration: 189350 loss: 0.0013 lr: 0.02
2019-06-04 04:18:04 iteration: 189400 loss: 0.0013 lr: 0.02
2019-06-04 04:18:15 iteration: 189450 loss: 0.0014 lr: 0.02
2019-06-04 04:18:26 iteration: 189500 loss: 0.0012 lr: 0.02
2019-06-04 04:18:39 iteration: 189550 loss: 0.0015 lr: 0.02
2019-06-04 04:18:49 iteration: 189600 loss: 0.0015 lr: 0.02
2019-06-04 04:19:00 iteration: 189650 loss: 0.0014 lr: 0.02
2019-06-04 04:19:10 iteration: 189700 loss: 0.0015 lr: 0.02
2019-06-04 04:19:21 iteration: 189750 loss: 0.0013 lr: 0.02
2019-06-04 04:19:32 iteration: 189800 loss: 0.0011 lr: 0.02
2019-06-04 04:19:43 iteration: 189850 loss: 0.0011 lr: 0.02
2019-06-04 04:19:53 iteration: 189900 loss: 0.0014 lr: 0.02
2019-06-04 04:20:04 iteration: 189950 loss: 0.0013 lr: 0.02
2019-06-04 04:20:14 iteration: 190000 loss: 0.0011 lr: 0.02
2019-06-04 04:20:28 iteration: 190050 loss: 0.0012 lr: 0.02
2019-06-04 04:20:38 iteration: 190100 loss: 0.0018 lr: 0.02
2019-06-04 04:20:49 iteration: 190150 loss: 0.0012 lr: 0.02
2019-06-04 04:20:59 iteration: 190200 loss: 0.0015 lr: 0.02
2019-06-04 04:21:10 iteration: 190250 loss: 0.0014 lr: 0.02
2019-06-04 04:21:21 iteration: 190300 loss: 0.0013 lr: 0.02
2019-06-04 04:21:31 iteration: 190350 loss: 0.0013 lr: 0.02
2019-06-04 04:21:41 iteration: 190400 loss: 0.0019 lr: 0.02
2019-06-04 04:21:51 iteration: 190450 loss: 0.0015 lr: 0.02
2019-06-04 04:22:01 iteration: 190500 loss: 0.0016 lr: 0.02
2019-06-04 04:22:15 iteration: 190550 loss: 0.0014 lr: 0.02
2019-06-04 04:22:26 iteration: 190600 loss: 0.0015 lr: 0.02
2019-06-04 04:22:36 iteration: 190650 loss: 0.0012 lr: 0.02
2019-06-04 04:22:47 iteration: 190700 loss: 0.0013 lr: 0.02
2019-06-04 04:22:59 iteration: 190750 loss: 0.0010 lr: 0.02
2019-06-04 04:23:10 iteration: 190800 loss: 0.0012 lr: 0.02
2019-06-04 04:23:20 iteration: 190850 loss: 0.0013 lr: 0.02
2019-06-04 04:23:31 iteration: 190900 loss: 0.0014 lr: 0.02
2019-06-04 04:23:42 iteration: 190950 loss: 0.0014 lr: 0.02
2019-06-04 04:23:51 iteration: 191000 loss: 0.0016 lr: 0.02
2019-06-04 04:24:05 iteration: 191050 loss: 0.0011 lr: 0.02
2019-06-04 04:24:15 iteration: 191100 loss: 0.0015 lr: 0.02
2019-06-04 04:24:25 iteration: 191150 loss: 0.0013 lr: 0.02
2019-06-04 04:24:36 iteration: 191200 loss: 0.0014 lr: 0.02
2019-06-04 04:24:46 iteration: 191250 loss: 0.0011 lr: 0.02
2019-06-04 04:24:57 iteration: 191300 loss: 0.0014 lr: 0.02
2019-06-04 04:25:08 iteration: 191350 loss: 0.0014 lr: 0.02
2019-06-04 04:25:18 iteration: 191400 loss: 0.0014 lr: 0.02
2019-06-04 04:25:29 iteration: 191450 loss: 0.0015 lr: 0.02
2019-06-04 04:25:39 iteration: 191500 loss: 0.0015 lr: 0.02
2019-06-04 04:25:52 iteration: 191550 loss: 0.0013 lr: 0.02
2019-06-04 04:26:03 iteration: 191600 loss: 0.0012 lr: 0.02
2019-06-04 04:26:14 iteration: 191650 loss: 0.0012 lr: 0.02
2019-06-04 04:26:25 iteration: 191700 loss: 0.0014 lr: 0.02
2019-06-04 04:26:35 iteration: 191750 loss: 0.0013 lr: 0.02
2019-06-04 04:26:46 iteration: 191800 loss: 0.0013 lr: 0.02
2019-06-04 04:26:56 iteration: 191850 loss: 0.0016 lr: 0.02
2019-06-04 04:27:07 iteration: 191900 loss: 0.0013 lr: 0.02
2019-06-04 04:27:17 iteration: 191950 loss: 0.0015 lr: 0.02
2019-06-04 04:27:27 iteration: 192000 loss: 0.0016 lr: 0.02
2019-06-04 04:27:41 iteration: 192050 loss: 0.0014 lr: 0.02
2019-06-04 04:27:51 iteration: 192100 loss: 0.0014 lr: 0.02
2019-06-04 04:28:02 iteration: 192150 loss: 0.0013 lr: 0.02
2019-06-04 04:28:12 iteration: 192200 loss: 0.0013 lr: 0.02
2019-06-04 04:28:23 iteration: 192250 loss: 0.0014 lr: 0.02
2019-06-04 04:28:33 iteration: 192300 loss: 0.0014 lr: 0.02
2019-06-04 04:28:43 iteration: 192350 loss: 0.0011 lr: 0.02
2019-06-04 04:28:54 iteration: 192400 loss: 0.0013 lr: 0.02
2019-06-04 04:29:05 iteration: 192450 loss: 0.0012 lr: 0.02
2019-06-04 04:29:15 iteration: 192500 loss: 0.0015 lr: 0.02
2019-06-04 04:29:29 iteration: 192550 loss: 0.0013 lr: 0.02
2019-06-04 04:29:40 iteration: 192600 loss: 0.0012 lr: 0.02
2019-06-04 04:29:50 iteration: 192650 loss: 0.0013 lr: 0.02
2019-06-04 04:30:00 iteration: 192700 loss: 0.0014 lr: 0.02
2019-06-04 04:30:11 iteration: 192750 loss: 0.0014 lr: 0.02
2019-06-04 04:30:22 iteration: 192800 loss: 0.0013 lr: 0.02
2019-06-04 04:30:32 iteration: 192850 loss: 0.0014 lr: 0.02
2019-06-04 04:30:43 iteration: 192900 loss: 0.0012 lr: 0.02
2019-06-04 04:30:53 iteration: 192950 loss: 0.0011 lr: 0.02
2019-06-04 04:31:04 iteration: 193000 loss: 0.0011 lr: 0.02
2019-06-04 04:31:17 iteration: 193050 loss: 0.0012 lr: 0.02
2019-06-04 04:31:28 iteration: 193100 loss: 0.0012 lr: 0.02
2019-06-04 04:31:38 iteration: 193150 loss: 0.0016 lr: 0.02
2019-06-04 04:31:49 iteration: 193200 loss: 0.0013 lr: 0.02
2019-06-04 04:32:00 iteration: 193250 loss: 0.0012 lr: 0.02
2019-06-04 04:32:10 iteration: 193300 loss: 0.0016 lr: 0.02
2019-06-04 04:32:20 iteration: 193350 loss: 0.0012 lr: 0.02
2019-06-04 04:32:31 iteration: 193400 loss: 0.0015 lr: 0.02
2019-06-04 04:32:41 iteration: 193450 loss: 0.0013 lr: 0.02
2019-06-04 04:32:52 iteration: 193500 loss: 0.0015 lr: 0.02
2019-06-04 04:33:05 iteration: 193550 loss: 0.0014 lr: 0.02
2019-06-04 04:33:16 iteration: 193600 loss: 0.0010 lr: 0.02
2019-06-04 04:33:27 iteration: 193650 loss: 0.0013 lr: 0.02
2019-06-04 04:33:37 iteration: 193700 loss: 0.0012 lr: 0.02
2019-06-04 04:33:47 iteration: 193750 loss: 0.0012 lr: 0.02
2019-06-04 04:33:57 iteration: 193800 loss: 0.0010 lr: 0.02
2019-06-04 04:34:08 iteration: 193850 loss: 0.0013 lr: 0.02
2019-06-04 04:34:18 iteration: 193900 loss: 0.0014 lr: 0.02
2019-06-04 04:34:28 iteration: 193950 loss: 0.0010 lr: 0.02
2019-06-04 04:34:39 iteration: 194000 loss: 0.0011 lr: 0.02
2019-06-04 04:34:52 iteration: 194050 loss: 0.0011 lr: 0.02
2019-06-04 04:35:03 iteration: 194100 loss: 0.0015 lr: 0.02
2019-06-04 04:35:13 iteration: 194150 loss: 0.0013 lr: 0.02
2019-06-04 04:35:24 iteration: 194200 loss: 0.0013 lr: 0.02
2019-06-04 04:35:34 iteration: 194250 loss: 0.0014 lr: 0.02
2019-06-04 04:35:44 iteration: 194300 loss: 0.0013 lr: 0.02
2019-06-04 04:35:55 iteration: 194350 loss: 0.0011 lr: 0.02
2019-06-04 04:36:06 iteration: 194400 loss: 0.0011 lr: 0.02
2019-06-04 04:36:16 iteration: 194450 loss: 0.0014 lr: 0.02
2019-06-04 04:36:26 iteration: 194500 loss: 0.0014 lr: 0.02
2019-06-04 04:36:39 iteration: 194550 loss: 0.0011 lr: 0.02
2019-06-04 04:36:50 iteration: 194600 loss: 0.0016 lr: 0.02
2019-06-04 04:37:01 iteration: 194650 loss: 0.0013 lr: 0.02
2019-06-04 04:37:11 iteration: 194700 loss: 0.0014 lr: 0.02
2019-06-04 04:37:21 iteration: 194750 loss: 0.0015 lr: 0.02
2019-06-04 04:37:31 iteration: 194800 loss: 0.0014 lr: 0.02
2019-06-04 04:37:42 iteration: 194850 loss: 0.0014 lr: 0.02
2019-06-04 04:37:52 iteration: 194900 loss: 0.0013 lr: 0.02
2019-06-04 04:38:03 iteration: 194950 loss: 0.0014 lr: 0.02
2019-06-04 04:38:14 iteration: 195000 loss: 0.0014 lr: 0.02
2019-06-04 04:38:27 iteration: 195050 loss: 0.0012 lr: 0.02
2019-06-04 04:38:37 iteration: 195100 loss: 0.0016 lr: 0.02
2019-06-04 04:38:49 iteration: 195150 loss: 0.0014 lr: 0.02
2019-06-04 04:39:00 iteration: 195200 loss: 0.0014 lr: 0.02
2019-06-04 04:39:10 iteration: 195250 loss: 0.0013 lr: 0.02
2019-06-04 04:39:21 iteration: 195300 loss: 0.0014 lr: 0.02
2019-06-04 04:39:31 iteration: 195350 loss: 0.0015 lr: 0.02
2019-06-04 04:39:41 iteration: 195400 loss: 0.0015 lr: 0.02
2019-06-04 04:39:53 iteration: 195450 loss: 0.0015 lr: 0.02
2019-06-04 04:40:03 iteration: 195500 loss: 0.0012 lr: 0.02
2019-06-04 04:40:16 iteration: 195550 loss: 0.0012 lr: 0.02
2019-06-04 04:40:27 iteration: 195600 loss: 0.0014 lr: 0.02
2019-06-04 04:40:37 iteration: 195650 loss: 0.0013 lr: 0.02
2019-06-04 04:40:48 iteration: 195700 loss: 0.0014 lr: 0.02
2019-06-04 04:40:58 iteration: 195750 loss: 0.0012 lr: 0.02
2019-06-04 04:41:09 iteration: 195800 loss: 0.0014 lr: 0.02
2019-06-04 04:41:19 iteration: 195850 loss: 0.0012 lr: 0.02
2019-06-04 04:41:30 iteration: 195900 loss: 0.0015 lr: 0.02
2019-06-04 04:41:41 iteration: 195950 loss: 0.0013 lr: 0.02
2019-06-04 04:41:51 iteration: 196000 loss: 0.0014 lr: 0.02
2019-06-04 04:42:05 iteration: 196050 loss: 0.0017 lr: 0.02
2019-06-04 04:42:15 iteration: 196100 loss: 0.0015 lr: 0.02
2019-06-04 04:42:25 iteration: 196150 loss: 0.0014 lr: 0.02
2019-06-04 04:42:36 iteration: 196200 loss: 0.0014 lr: 0.02
2019-06-04 04:42:47 iteration: 196250 loss: 0.0013 lr: 0.02
2019-06-04 04:42:57 iteration: 196300 loss: 0.0013 lr: 0.02
2019-06-04 04:43:08 iteration: 196350 loss: 0.0014 lr: 0.02
2019-06-04 04:43:18 iteration: 196400 loss: 0.0011 lr: 0.02
2019-06-04 04:43:29 iteration: 196450 loss: 0.0013 lr: 0.02
2019-06-04 04:43:39 iteration: 196500 loss: 0.0014 lr: 0.02
2019-06-04 04:43:53 iteration: 196550 loss: 0.0012 lr: 0.02
2019-06-04 04:44:03 iteration: 196600 loss: 0.0014 lr: 0.02
2019-06-04 04:44:13 iteration: 196650 loss: 0.0013 lr: 0.02
2019-06-04 04:44:24 iteration: 196700 loss: 0.0012 lr: 0.02
2019-06-04 04:44:35 iteration: 196750 loss: 0.0012 lr: 0.02
2019-06-04 04:44:46 iteration: 196800 loss: 0.0012 lr: 0.02
2019-06-04 04:44:56 iteration: 196850 loss: 0.0012 lr: 0.02
2019-06-04 04:45:07 iteration: 196900 loss: 0.0013 lr: 0.02
2019-06-04 04:45:18 iteration: 196950 loss: 0.0014 lr: 0.02
2019-06-04 04:45:28 iteration: 197000 loss: 0.0011 lr: 0.02
2019-06-04 04:45:42 iteration: 197050 loss: 0.0012 lr: 0.02
2019-06-04 04:45:52 iteration: 197100 loss: 0.0013 lr: 0.02
2019-06-04 04:46:03 iteration: 197150 loss: 0.0013 lr: 0.02
2019-06-04 04:46:13 iteration: 197200 loss: 0.0012 lr: 0.02
2019-06-04 04:46:24 iteration: 197250 loss: 0.0013 lr: 0.02
2019-06-04 04:46:33 iteration: 197300 loss: 0.0016 lr: 0.02
2019-06-04 04:46:44 iteration: 197350 loss: 0.0013 lr: 0.02
2019-06-04 04:46:55 iteration: 197400 loss: 0.0011 lr: 0.02
2019-06-04 04:47:05 iteration: 197450 loss: 0.0010 lr: 0.02
2019-06-04 04:47:16 iteration: 197500 loss: 0.0012 lr: 0.02
2019-06-04 04:47:29 iteration: 197550 loss: 0.0014 lr: 0.02
2019-06-04 04:47:40 iteration: 197600 loss: 0.0011 lr: 0.02
2019-06-04 04:47:50 iteration: 197650 loss: 0.0014 lr: 0.02
2019-06-04 04:48:00 iteration: 197700 loss: 0.0016 lr: 0.02
2019-06-04 04:48:11 iteration: 197750 loss: 0.0013 lr: 0.02
2019-06-04 04:48:22 iteration: 197800 loss: 0.0015 lr: 0.02
2019-06-04 04:48:32 iteration: 197850 loss: 0.0012 lr: 0.02
2019-06-04 04:48:43 iteration: 197900 loss: 0.0014 lr: 0.02
2019-06-04 04:48:53 iteration: 197950 loss: 0.0014 lr: 0.02
2019-06-04 04:49:04 iteration: 198000 loss: 0.0010 lr: 0.02
2019-06-04 04:49:17 iteration: 198050 loss: 0.0015 lr: 0.02
2019-06-04 04:49:27 iteration: 198100 loss: 0.0011 lr: 0.02
2019-06-04 04:49:38 iteration: 198150 loss: 0.0013 lr: 0.02
2019-06-04 04:49:49 iteration: 198200 loss: 0.0012 lr: 0.02
2019-06-04 04:50:00 iteration: 198250 loss: 0.0012 lr: 0.02
2019-06-04 04:50:10 iteration: 198300 loss: 0.0013 lr: 0.02
2019-06-04 04:50:20 iteration: 198350 loss: 0.0011 lr: 0.02
2019-06-04 04:50:30 iteration: 198400 loss: 0.0012 lr: 0.02
2019-06-04 04:50:41 iteration: 198450 loss: 0.0014 lr: 0.02
2019-06-04 04:50:52 iteration: 198500 loss: 0.0013 lr: 0.02
2019-06-04 04:51:05 iteration: 198550 loss: 0.0013 lr: 0.02
2019-06-04 04:51:16 iteration: 198600 loss: 0.0014 lr: 0.02
2019-06-04 04:51:26 iteration: 198650 loss: 0.0012 lr: 0.02
2019-06-04 04:51:37 iteration: 198700 loss: 0.0012 lr: 0.02
2019-06-04 04:51:47 iteration: 198750 loss: 0.0014 lr: 0.02
2019-06-04 04:51:58 iteration: 198800 loss: 0.0014 lr: 0.02
2019-06-04 04:52:08 iteration: 198850 loss: 0.0013 lr: 0.02
2019-06-04 04:52:19 iteration: 198900 loss: 0.0012 lr: 0.02
2019-06-04 04:52:29 iteration: 198950 loss: 0.0013 lr: 0.02
2019-06-04 04:52:40 iteration: 199000 loss: 0.0012 lr: 0.02
2019-06-04 04:52:54 iteration: 199050 loss: 0.0011 lr: 0.02
2019-06-04 04:53:04 iteration: 199100 loss: 0.0015 lr: 0.02
2019-06-04 04:53:14 iteration: 199150 loss: 0.0014 lr: 0.02
2019-06-04 04:53:25 iteration: 199200 loss: 0.0011 lr: 0.02
2019-06-04 04:53:35 iteration: 199250 loss: 0.0014 lr: 0.02
2019-06-04 04:53:46 iteration: 199300 loss: 0.0013 lr: 0.02
2019-06-04 04:53:57 iteration: 199350 loss: 0.0013 lr: 0.02
2019-06-04 04:54:08 iteration: 199400 loss: 0.0012 lr: 0.02
2019-06-04 04:54:18 iteration: 199450 loss: 0.0014 lr: 0.02
2019-06-04 04:54:28 iteration: 199500 loss: 0.0014 lr: 0.02
2019-06-04 04:54:42 iteration: 199550 loss: 0.0011 lr: 0.02
2019-06-04 04:54:52 iteration: 199600 loss: 0.0012 lr: 0.02
2019-06-04 04:55:03 iteration: 199650 loss: 0.0011 lr: 0.02
2019-06-04 04:55:13 iteration: 199700 loss: 0.0016 lr: 0.02
2019-06-04 04:55:23 iteration: 199750 loss: 0.0013 lr: 0.02
2019-06-04 04:55:34 iteration: 199800 loss: 0.0009 lr: 0.02
2019-06-04 04:55:44 iteration: 199850 loss: 0.0013 lr: 0.02
2019-06-04 04:55:55 iteration: 199900 loss: 0.0012 lr: 0.02
2019-06-04 04:56:06 iteration: 199950 loss: 0.0011 lr: 0.02
2019-06-04 04:56:16 iteration: 200000 loss: 0.0013 lr: 0.02
2019-06-04 04:56:29 iteration: 200050 loss: 0.0012 lr: 0.02
2019-06-04 04:56:39 iteration: 200100 loss: 0.0011 lr: 0.02
2019-06-04 04:56:49 iteration: 200150 loss: 0.0012 lr: 0.02
2019-06-04 04:57:00 iteration: 200200 loss: 0.0014 lr: 0.02
2019-06-04 04:57:11 iteration: 200250 loss: 0.0013 lr: 0.02
2019-06-04 04:57:21 iteration: 200300 loss: 0.0013 lr: 0.02
2019-06-04 04:57:31 iteration: 200350 loss: 0.0014 lr: 0.02
2019-06-04 04:57:41 iteration: 200400 loss: 0.0011 lr: 0.02
2019-06-04 04:57:52 iteration: 200450 loss: 0.0011 lr: 0.02
2019-06-04 04:58:02 iteration: 200500 loss: 0.0014 lr: 0.02
2019-06-04 04:58:16 iteration: 200550 loss: 0.0013 lr: 0.02
2019-06-04 04:58:26 iteration: 200600 loss: 0.0015 lr: 0.02
2019-06-04 04:58:37 iteration: 200650 loss: 0.0012 lr: 0.02
2019-06-04 04:58:47 iteration: 200700 loss: 0.0013 lr: 0.02
2019-06-04 04:58:58 iteration: 200750 loss: 0.0012 lr: 0.02
2019-06-04 04:59:08 iteration: 200800 loss: 0.0012 lr: 0.02
2019-06-04 04:59:19 iteration: 200850 loss: 0.0013 lr: 0.02
2019-06-04 04:59:29 iteration: 200900 loss: 0.0013 lr: 0.02
2019-06-04 04:59:40 iteration: 200950 loss: 0.0012 lr: 0.02
2019-06-04 04:59:51 iteration: 201000 loss: 0.0010 lr: 0.02
2019-06-04 05:00:05 iteration: 201050 loss: 0.0013 lr: 0.02
2019-06-04 05:00:15 iteration: 201100 loss: 0.0013 lr: 0.02
2019-06-04 05:00:26 iteration: 201150 loss: 0.0012 lr: 0.02
2019-06-04 05:00:37 iteration: 201200 loss: 0.0013 lr: 0.02
2019-06-04 05:00:48 iteration: 201250 loss: 0.0015 lr: 0.02
2019-06-04 05:00:59 iteration: 201300 loss: 0.0014 lr: 0.02
2019-06-04 05:01:09 iteration: 201350 loss: 0.0013 lr: 0.02
2019-06-04 05:01:20 iteration: 201400 loss: 0.0016 lr: 0.02
2019-06-04 05:01:30 iteration: 201450 loss: 0.0014 lr: 0.02
2019-06-04 05:01:40 iteration: 201500 loss: 0.0013 lr: 0.02
2019-06-04 05:01:54 iteration: 201550 loss: 0.0011 lr: 0.02
2019-06-04 05:02:04 iteration: 201600 loss: 0.0013 lr: 0.02
2019-06-04 05:02:15 iteration: 201650 loss: 0.0012 lr: 0.02
2019-06-04 05:02:25 iteration: 201700 loss: 0.0013 lr: 0.02
2019-06-04 05:02:36 iteration: 201750 loss: 0.0015 lr: 0.02
2019-06-04 05:02:46 iteration: 201800 loss: 0.0015 lr: 0.02
2019-06-04 05:02:56 iteration: 201850 loss: 0.0011 lr: 0.02
2019-06-04 05:03:07 iteration: 201900 loss: 0.0011 lr: 0.02
2019-06-04 05:03:17 iteration: 201950 loss: 0.0012 lr: 0.02
2019-06-04 05:03:29 iteration: 202000 loss: 0.0012 lr: 0.02
2019-06-04 05:03:41 iteration: 202050 loss: 0.0018 lr: 0.02
2019-06-04 05:03:52 iteration: 202100 loss: 0.0014 lr: 0.02
2019-06-04 05:04:02 iteration: 202150 loss: 0.0012 lr: 0.02
2019-06-04 05:04:13 iteration: 202200 loss: 0.0016 lr: 0.02
2019-06-04 05:04:23 iteration: 202250 loss: 0.0016 lr: 0.02
2019-06-04 05:04:33 iteration: 202300 loss: 0.0016 lr: 0.02
2019-06-04 05:04:43 iteration: 202350 loss: 0.0012 lr: 0.02
2019-06-04 05:04:54 iteration: 202400 loss: 0.0011 lr: 0.02
2019-06-04 05:05:05 iteration: 202450 loss: 0.0015 lr: 0.02
2019-06-04 05:05:15 iteration: 202500 loss: 0.0014 lr: 0.02
2019-06-04 05:05:28 iteration: 202550 loss: 0.0014 lr: 0.02
2019-06-04 05:05:39 iteration: 202600 loss: 0.0013 lr: 0.02
2019-06-04 05:05:50 iteration: 202650 loss: 0.0011 lr: 0.02
2019-06-04 05:06:01 iteration: 202700 loss: 0.0012 lr: 0.02
2019-06-04 05:06:11 iteration: 202750 loss: 0.0013 lr: 0.02
2019-06-04 05:06:21 iteration: 202800 loss: 0.0015 lr: 0.02
2019-06-04 05:06:31 iteration: 202850 loss: 0.0014 lr: 0.02
2019-06-04 05:06:42 iteration: 202900 loss: 0.0014 lr: 0.02
2019-06-04 05:06:52 iteration: 202950 loss: 0.0014 lr: 0.02
2019-06-04 05:07:03 iteration: 203000 loss: 0.0013 lr: 0.02
2019-06-04 05:07:16 iteration: 203050 loss: 0.0012 lr: 0.02
2019-06-04 05:07:27 iteration: 203100 loss: 0.0016 lr: 0.02
2019-06-04 05:07:37 iteration: 203150 loss: 0.0013 lr: 0.02
2019-06-04 05:07:48 iteration: 203200 loss: 0.0014 lr: 0.02
2019-06-04 05:07:59 iteration: 203250 loss: 0.0014 lr: 0.02
2019-06-04 05:08:09 iteration: 203300 loss: 0.0014 lr: 0.02
2019-06-04 05:08:19 iteration: 203350 loss: 0.0011 lr: 0.02
2019-06-04 05:08:30 iteration: 203400 loss: 0.0009 lr: 0.02
2019-06-04 05:08:40 iteration: 203450 loss: 0.0016 lr: 0.02
2019-06-04 05:08:50 iteration: 203500 loss: 0.0013 lr: 0.02
2019-06-04 05:09:04 iteration: 203550 loss: 0.0014 lr: 0.02
2019-06-04 05:09:15 iteration: 203600 loss: 0.0012 lr: 0.02
2019-06-04 05:09:25 iteration: 203650 loss: 0.0014 lr: 0.02
2019-06-04 05:09:36 iteration: 203700 loss: 0.0013 lr: 0.02
2019-06-04 05:09:46 iteration: 203750 loss: 0.0016 lr: 0.02
2019-06-04 05:09:57 iteration: 203800 loss: 0.0012 lr: 0.02
2019-06-04 05:10:07 iteration: 203850 loss: 0.0012 lr: 0.02
2019-06-04 05:10:18 iteration: 203900 loss: 0.0015 lr: 0.02
2019-06-04 05:10:28 iteration: 203950 loss: 0.0014 lr: 0.02
2019-06-04 05:10:38 iteration: 204000 loss: 0.0014 lr: 0.02
2019-06-04 05:10:52 iteration: 204050 loss: 0.0013 lr: 0.02
2019-06-04 05:11:03 iteration: 204100 loss: 0.0012 lr: 0.02
2019-06-04 05:11:13 iteration: 204150 loss: 0.0012 lr: 0.02
2019-06-04 05:11:24 iteration: 204200 loss: 0.0012 lr: 0.02
2019-06-04 05:11:34 iteration: 204250 loss: 0.0012 lr: 0.02
2019-06-04 05:11:44 iteration: 204300 loss: 0.0013 lr: 0.02
2019-06-04 05:11:55 iteration: 204350 loss: 0.0013 lr: 0.02
2019-06-04 05:12:06 iteration: 204400 loss: 0.0016 lr: 0.02
2019-06-04 05:12:16 iteration: 204450 loss: 0.0013 lr: 0.02
2019-06-04 05:12:27 iteration: 204500 loss: 0.0012 lr: 0.02
2019-06-04 05:12:41 iteration: 204550 loss: 0.0013 lr: 0.02
2019-06-04 05:12:51 iteration: 204600 loss: 0.0012 lr: 0.02
2019-06-04 05:13:02 iteration: 204650 loss: 0.0016 lr: 0.02
2019-06-04 05:13:12 iteration: 204700 loss: 0.0012 lr: 0.02
2019-06-04 05:13:22 iteration: 204750 loss: 0.0013 lr: 0.02
2019-06-04 05:13:33 iteration: 204800 loss: 0.0013 lr: 0.02
2019-06-04 05:13:43 iteration: 204850 loss: 0.0015 lr: 0.02
2019-06-04 05:13:53 iteration: 204900 loss: 0.0014 lr: 0.02
2019-06-04 05:14:04 iteration: 204950 loss: 0.0014 lr: 0.02
2019-06-04 05:14:15 iteration: 205000 loss: 0.0011 lr: 0.02
2019-06-04 05:14:28 iteration: 205050 loss: 0.0012 lr: 0.02
2019-06-04 05:14:37 iteration: 205100 loss: 0.0015 lr: 0.02
2019-06-04 05:14:48 iteration: 205150 loss: 0.0013 lr: 0.02
2019-06-04 05:14:58 iteration: 205200 loss: 0.0012 lr: 0.02
2019-06-04 05:15:09 iteration: 205250 loss: 0.0013 lr: 0.02
2019-06-04 05:15:20 iteration: 205300 loss: 0.0010 lr: 0.02
2019-06-04 05:15:30 iteration: 205350 loss: 0.0011 lr: 0.02
2019-06-04 05:15:40 iteration: 205400 loss: 0.0013 lr: 0.02
2019-06-04 05:15:51 iteration: 205450 loss: 0.0012 lr: 0.02
2019-06-04 05:16:01 iteration: 205500 loss: 0.0016 lr: 0.02
2019-06-04 05:16:15 iteration: 205550 loss: 0.0012 lr: 0.02
2019-06-04 05:16:26 iteration: 205600 loss: 0.0012 lr: 0.02
2019-06-04 05:16:36 iteration: 205650 loss: 0.0016 lr: 0.02
2019-06-04 05:16:47 iteration: 205700 loss: 0.0015 lr: 0.02
2019-06-04 05:16:57 iteration: 205750 loss: 0.0013 lr: 0.02
2019-06-04 05:17:08 iteration: 205800 loss: 0.0013 lr: 0.02
2019-06-04 05:17:18 iteration: 205850 loss: 0.0014 lr: 0.02
2019-06-04 05:17:28 iteration: 205900 loss: 0.0015 lr: 0.02
2019-06-04 05:17:38 iteration: 205950 loss: 0.0013 lr: 0.02
2019-06-04 05:17:49 iteration: 206000 loss: 0.0012 lr: 0.02
2019-06-04 05:18:02 iteration: 206050 loss: 0.0014 lr: 0.02
2019-06-04 05:18:13 iteration: 206100 loss: 0.0012 lr: 0.02
2019-06-04 05:18:24 iteration: 206150 loss: 0.0010 lr: 0.02
2019-06-04 05:18:35 iteration: 206200 loss: 0.0013 lr: 0.02
2019-06-04 05:18:45 iteration: 206250 loss: 0.0012 lr: 0.02
2019-06-04 05:18:56 iteration: 206300 loss: 0.0014 lr: 0.02
2019-06-04 05:19:06 iteration: 206350 loss: 0.0013 lr: 0.02
2019-06-04 05:19:16 iteration: 206400 loss: 0.0013 lr: 0.02
2019-06-04 05:19:27 iteration: 206450 loss: 0.0012 lr: 0.02
2019-06-04 05:19:39 iteration: 206500 loss: 0.0011 lr: 0.02
2019-06-04 05:19:52 iteration: 206550 loss: 0.0013 lr: 0.02
2019-06-04 05:20:02 iteration: 206600 loss: 0.0014 lr: 0.02
2019-06-04 05:20:12 iteration: 206650 loss: 0.0014 lr: 0.02
2019-06-04 05:20:23 iteration: 206700 loss: 0.0012 lr: 0.02
2019-06-04 05:20:34 iteration: 206750 loss: 0.0012 lr: 0.02
2019-06-04 05:20:44 iteration: 206800 loss: 0.0013 lr: 0.02
2019-06-04 05:20:55 iteration: 206850 loss: 0.0013 lr: 0.02
2019-06-04 05:21:05 iteration: 206900 loss: 0.0011 lr: 0.02
2019-06-04 05:21:15 iteration: 206950 loss: 0.0013 lr: 0.02
2019-06-04 05:21:26 iteration: 207000 loss: 0.0014 lr: 0.02
2019-06-04 05:21:40 iteration: 207050 loss: 0.0014 lr: 0.02
2019-06-04 05:21:50 iteration: 207100 loss: 0.0013 lr: 0.02
2019-06-04 05:22:01 iteration: 207150 loss: 0.0011 lr: 0.02
2019-06-04 05:22:11 iteration: 207200 loss: 0.0012 lr: 0.02
2019-06-04 05:22:21 iteration: 207250 loss: 0.0015 lr: 0.02
2019-06-04 05:22:32 iteration: 207300 loss: 0.0015 lr: 0.02
2019-06-04 05:22:43 iteration: 207350 loss: 0.0013 lr: 0.02
2019-06-04 05:22:53 iteration: 207400 loss: 0.0012 lr: 0.02
2019-06-04 05:23:04 iteration: 207450 loss: 0.0011 lr: 0.02
2019-06-04 05:23:14 iteration: 207500 loss: 0.0014 lr: 0.02
2019-06-04 05:23:27 iteration: 207550 loss: 0.0012 lr: 0.02
2019-06-04 05:23:37 iteration: 207600 loss: 0.0013 lr: 0.02
2019-06-04 05:23:48 iteration: 207650 loss: 0.0012 lr: 0.02
2019-06-04 05:23:58 iteration: 207700 loss: 0.0012 lr: 0.02
2019-06-04 05:24:09 iteration: 207750 loss: 0.0015 lr: 0.02
2019-06-04 05:24:19 iteration: 207800 loss: 0.0015 lr: 0.02
2019-06-04 05:24:30 iteration: 207850 loss: 0.0013 lr: 0.02
2019-06-04 05:24:40 iteration: 207900 loss: 0.0015 lr: 0.02
2019-06-04 05:24:51 iteration: 207950 loss: 0.0010 lr: 0.02
2019-06-04 05:25:01 iteration: 208000 loss: 0.0012 lr: 0.02
2019-06-04 05:25:16 iteration: 208050 loss: 0.0011 lr: 0.02
2019-06-04 05:25:26 iteration: 208100 loss: 0.0012 lr: 0.02
2019-06-04 05:25:37 iteration: 208150 loss: 0.0014 lr: 0.02
2019-06-04 05:25:47 iteration: 208200 loss: 0.0013 lr: 0.02
2019-06-04 05:25:58 iteration: 208250 loss: 0.0012 lr: 0.02
2019-06-04 05:26:08 iteration: 208300 loss: 0.0012 lr: 0.02
2019-06-04 05:26:18 iteration: 208350 loss: 0.0013 lr: 0.02
2019-06-04 05:26:29 iteration: 208400 loss: 0.0013 lr: 0.02
2019-06-04 05:26:40 iteration: 208450 loss: 0.0013 lr: 0.02
2019-06-04 05:26:51 iteration: 208500 loss: 0.0014 lr: 0.02
2019-06-04 05:27:04 iteration: 208550 loss: 0.0011 lr: 0.02
2019-06-04 05:27:14 iteration: 208600 loss: 0.0012 lr: 0.02
2019-06-04 05:27:26 iteration: 208650 loss: 0.0012 lr: 0.02
2019-06-04 05:27:37 iteration: 208700 loss: 0.0011 lr: 0.02
2019-06-04 05:27:48 iteration: 208750 loss: 0.0012 lr: 0.02
2019-06-04 05:27:59 iteration: 208800 loss: 0.0012 lr: 0.02
2019-06-04 05:28:10 iteration: 208850 loss: 0.0013 lr: 0.02
2019-06-04 05:28:20 iteration: 208900 loss: 0.0014 lr: 0.02
2019-06-04 05:28:30 iteration: 208950 loss: 0.0013 lr: 0.02
2019-06-04 05:28:41 iteration: 209000 loss: 0.0012 lr: 0.02
2019-06-04 05:28:54 iteration: 209050 loss: 0.0013 lr: 0.02
2019-06-04 05:29:05 iteration: 209100 loss: 0.0012 lr: 0.02
2019-06-04 05:29:16 iteration: 209150 loss: 0.0012 lr: 0.02
2019-06-04 05:29:26 iteration: 209200 loss: 0.0012 lr: 0.02
2019-06-04 05:29:37 iteration: 209250 loss: 0.0014 lr: 0.02
2019-06-04 05:29:47 iteration: 209300 loss: 0.0011 lr: 0.02
2019-06-04 05:29:57 iteration: 209350 loss: 0.0014 lr: 0.02
2019-06-04 05:30:08 iteration: 209400 loss: 0.0013 lr: 0.02
2019-06-04 05:30:19 iteration: 209450 loss: 0.0014 lr: 0.02
2019-06-04 05:30:29 iteration: 209500 loss: 0.0017 lr: 0.02
2019-06-04 05:30:42 iteration: 209550 loss: 0.0014 lr: 0.02
2019-06-04 05:30:53 iteration: 209600 loss: 0.0011 lr: 0.02
2019-06-04 05:31:04 iteration: 209650 loss: 0.0013 lr: 0.02
2019-06-04 05:31:14 iteration: 209700 loss: 0.0013 lr: 0.02
2019-06-04 05:31:25 iteration: 209750 loss: 0.0011 lr: 0.02
2019-06-04 05:31:36 iteration: 209800 loss: 0.0011 lr: 0.02
2019-06-04 05:31:46 iteration: 209850 loss: 0.0013 lr: 0.02
2019-06-04 05:31:56 iteration: 209900 loss: 0.0012 lr: 0.02
2019-06-04 05:32:07 iteration: 209950 loss: 0.0013 lr: 0.02
2019-06-04 05:32:18 iteration: 210000 loss: 0.0012 lr: 0.02
2019-06-04 05:32:31 iteration: 210050 loss: 0.0011 lr: 0.02
2019-06-04 05:32:41 iteration: 210100 loss: 0.0012 lr: 0.02
2019-06-04 05:32:52 iteration: 210150 loss: 0.0013 lr: 0.02
2019-06-04 05:33:03 iteration: 210200 loss: 0.0013 lr: 0.02
2019-06-04 05:33:14 iteration: 210250 loss: 0.0013 lr: 0.02
2019-06-04 05:33:24 iteration: 210300 loss: 0.0012 lr: 0.02
2019-06-04 05:33:34 iteration: 210350 loss: 0.0015 lr: 0.02
2019-06-04 05:33:45 iteration: 210400 loss: 0.0010 lr: 0.02
2019-06-04 05:33:55 iteration: 210450 loss: 0.0013 lr: 0.02
2019-06-04 05:34:05 iteration: 210500 loss: 0.0013 lr: 0.02
2019-06-04 05:34:18 iteration: 210550 loss: 0.0012 lr: 0.02
2019-06-04 05:34:29 iteration: 210600 loss: 0.0011 lr: 0.02
2019-06-04 05:34:39 iteration: 210650 loss: 0.0014 lr: 0.02
2019-06-04 05:34:50 iteration: 210700 loss: 0.0010 lr: 0.02
2019-06-04 05:35:00 iteration: 210750 loss: 0.0013 lr: 0.02
2019-06-04 05:35:10 iteration: 210800 loss: 0.0013 lr: 0.02
2019-06-04 05:35:21 iteration: 210850 loss: 0.0012 lr: 0.02
2019-06-04 05:35:32 iteration: 210900 loss: 0.0015 lr: 0.02
2019-06-04 05:35:43 iteration: 210950 loss: 0.0014 lr: 0.02
2019-06-04 05:35:53 iteration: 211000 loss: 0.0014 lr: 0.02
2019-06-04 05:36:07 iteration: 211050 loss: 0.0014 lr: 0.02
2019-06-04 05:36:18 iteration: 211100 loss: 0.0010 lr: 0.02
2019-06-04 05:36:28 iteration: 211150 loss: 0.0015 lr: 0.02
2019-06-04 05:36:39 iteration: 211200 loss: 0.0012 lr: 0.02
2019-06-04 05:36:49 iteration: 211250 loss: 0.0011 lr: 0.02
2019-06-04 05:37:00 iteration: 211300 loss: 0.0013 lr: 0.02
2019-06-04 05:37:10 iteration: 211350 loss: 0.0012 lr: 0.02
2019-06-04 05:37:20 iteration: 211400 loss: 0.0013 lr: 0.02
2019-06-04 05:37:31 iteration: 211450 loss: 0.0013 lr: 0.02
2019-06-04 05:37:41 iteration: 211500 loss: 0.0011 lr: 0.02
2019-06-04 05:37:55 iteration: 211550 loss: 0.0011 lr: 0.02
2019-06-04 05:38:06 iteration: 211600 loss: 0.0010 lr: 0.02
2019-06-04 05:38:16 iteration: 211650 loss: 0.0010 lr: 0.02
2019-06-04 05:38:27 iteration: 211700 loss: 0.0015 lr: 0.02
2019-06-04 05:38:37 iteration: 211750 loss: 0.0013 lr: 0.02
2019-06-04 05:38:47 iteration: 211800 loss: 0.0012 lr: 0.02
2019-06-04 05:38:58 iteration: 211850 loss: 0.0014 lr: 0.02
2019-06-04 05:39:09 iteration: 211900 loss: 0.0012 lr: 0.02
2019-06-04 05:39:19 iteration: 211950 loss: 0.0012 lr: 0.02
2019-06-04 05:39:30 iteration: 212000 loss: 0.0013 lr: 0.02
2019-06-04 05:39:43 iteration: 212050 loss: 0.0012 lr: 0.02
2019-06-04 05:39:54 iteration: 212100 loss: 0.0011 lr: 0.02
2019-06-04 05:40:04 iteration: 212150 loss: 0.0011 lr: 0.02
2019-06-04 05:40:15 iteration: 212200 loss: 0.0013 lr: 0.02
2019-06-04 05:40:25 iteration: 212250 loss: 0.0011 lr: 0.02
2019-06-04 05:40:36 iteration: 212300 loss: 0.0011 lr: 0.02
2019-06-04 05:40:47 iteration: 212350 loss: 0.0012 lr: 0.02
2019-06-04 05:40:57 iteration: 212400 loss: 0.0012 lr: 0.02
2019-06-04 05:41:08 iteration: 212450 loss: 0.0010 lr: 0.02
2019-06-04 05:41:19 iteration: 212500 loss: 0.0014 lr: 0.02
2019-06-04 05:41:32 iteration: 212550 loss: 0.0013 lr: 0.02
2019-06-04 05:41:42 iteration: 212600 loss: 0.0014 lr: 0.02
2019-06-04 05:41:52 iteration: 212650 loss: 0.0013 lr: 0.02
2019-06-04 05:42:02 iteration: 212700 loss: 0.0016 lr: 0.02
2019-06-04 05:42:12 iteration: 212750 loss: 0.0014 lr: 0.02
2019-06-04 05:42:23 iteration: 212800 loss: 0.0016 lr: 0.02
2019-06-04 05:42:33 iteration: 212850 loss: 0.0012 lr: 0.02
2019-06-04 05:42:44 iteration: 212900 loss: 0.0010 lr: 0.02
2019-06-04 05:42:55 iteration: 212950 loss: 0.0010 lr: 0.02
2019-06-04 05:43:05 iteration: 213000 loss: 0.0012 lr: 0.02
2019-06-04 05:43:19 iteration: 213050 loss: 0.0014 lr: 0.02
2019-06-04 05:43:30 iteration: 213100 loss: 0.0011 lr: 0.02
2019-06-04 05:43:40 iteration: 213150 loss: 0.0011 lr: 0.02
2019-06-04 05:43:50 iteration: 213200 loss: 0.0014 lr: 0.02
2019-06-04 05:44:01 iteration: 213250 loss: 0.0011 lr: 0.02
2019-06-04 05:44:11 iteration: 213300 loss: 0.0013 lr: 0.02
2019-06-04 05:44:21 iteration: 213350 loss: 0.0013 lr: 0.02
2019-06-04 05:44:32 iteration: 213400 loss: 0.0012 lr: 0.02
2019-06-04 05:44:43 iteration: 213450 loss: 0.0012 lr: 0.02
2019-06-04 05:44:53 iteration: 213500 loss: 0.0011 lr: 0.02
2019-06-04 05:45:07 iteration: 213550 loss: 0.0014 lr: 0.02
2019-06-04 05:45:17 iteration: 213600 loss: 0.0012 lr: 0.02
2019-06-04 05:45:28 iteration: 213650 loss: 0.0013 lr: 0.02
2019-06-04 05:45:38 iteration: 213700 loss: 0.0014 lr: 0.02
2019-06-04 05:45:49 iteration: 213750 loss: 0.0011 lr: 0.02
2019-06-04 05:45:59 iteration: 213800 loss: 0.0012 lr: 0.02
2019-06-04 05:46:11 iteration: 213850 loss: 0.0011 lr: 0.02
2019-06-04 05:46:22 iteration: 213900 loss: 0.0010 lr: 0.02
2019-06-04 05:46:32 iteration: 213950 loss: 0.0011 lr: 0.02
2019-06-04 05:46:42 iteration: 214000 loss: 0.0012 lr: 0.02
2019-06-04 05:46:55 iteration: 214050 loss: 0.0013 lr: 0.02
2019-06-04 05:47:06 iteration: 214100 loss: 0.0013 lr: 0.02
2019-06-04 05:47:16 iteration: 214150 loss: 0.0012 lr: 0.02
2019-06-04 05:47:26 iteration: 214200 loss: 0.0012 lr: 0.02
2019-06-04 05:47:37 iteration: 214250 loss: 0.0013 lr: 0.02
2019-06-04 05:47:48 iteration: 214300 loss: 0.0011 lr: 0.02
2019-06-04 05:47:58 iteration: 214350 loss: 0.0010 lr: 0.02
2019-06-04 05:48:08 iteration: 214400 loss: 0.0014 lr: 0.02
2019-06-04 05:48:19 iteration: 214450 loss: 0.0013 lr: 0.02
2019-06-04 05:48:29 iteration: 214500 loss: 0.0012 lr: 0.02
2019-06-04 05:48:42 iteration: 214550 loss: 0.0013 lr: 0.02
2019-06-04 05:48:52 iteration: 214600 loss: 0.0011 lr: 0.02
2019-06-04 05:49:04 iteration: 214650 loss: 0.0011 lr: 0.02
2019-06-04 05:49:14 iteration: 214700 loss: 0.0013 lr: 0.02
2019-06-04 05:49:23 iteration: 214750 loss: 0.0015 lr: 0.02
2019-06-04 05:49:35 iteration: 214800 loss: 0.0012 lr: 0.02
2019-06-04 05:49:45 iteration: 214850 loss: 0.0012 lr: 0.02
2019-06-04 05:49:56 iteration: 214900 loss: 0.0013 lr: 0.02
2019-06-04 05:50:05 iteration: 214950 loss: 0.0014 lr: 0.02
2019-06-04 05:50:16 iteration: 215000 loss: 0.0011 lr: 0.02
2019-06-04 05:50:30 iteration: 215050 loss: 0.0014 lr: 0.02
2019-06-04 05:50:40 iteration: 215100 loss: 0.0012 lr: 0.02
2019-06-04 05:50:51 iteration: 215150 loss: 0.0012 lr: 0.02
2019-06-04 05:51:01 iteration: 215200 loss: 0.0014 lr: 0.02
2019-06-04 05:51:11 iteration: 215250 loss: 0.0016 lr: 0.02
2019-06-04 05:51:22 iteration: 215300 loss: 0.0012 lr: 0.02
2019-06-04 05:51:33 iteration: 215350 loss: 0.0011 lr: 0.02
2019-06-04 05:51:43 iteration: 215400 loss: 0.0012 lr: 0.02
2019-06-04 05:51:53 iteration: 215450 loss: 0.0013 lr: 0.02
2019-06-04 05:52:04 iteration: 215500 loss: 0.0015 lr: 0.02
2019-06-04 05:52:17 iteration: 215550 loss: 0.0010 lr: 0.02
2019-06-04 05:52:27 iteration: 215600 loss: 0.0011 lr: 0.02
2019-06-04 05:52:38 iteration: 215650 loss: 0.0011 lr: 0.02
2019-06-04 05:52:49 iteration: 215700 loss: 0.0011 lr: 0.02
2019-06-04 05:52:59 iteration: 215750 loss: 0.0010 lr: 0.02
2019-06-04 05:53:09 iteration: 215800 loss: 0.0014 lr: 0.02
2019-06-04 05:53:19 iteration: 215850 loss: 0.0012 lr: 0.02
2019-06-04 05:53:30 iteration: 215900 loss: 0.0012 lr: 0.02
2019-06-04 05:53:41 iteration: 215950 loss: 0.0011 lr: 0.02
2019-06-04 05:53:51 iteration: 216000 loss: 0.0011 lr: 0.02
2019-06-04 05:54:04 iteration: 216050 loss: 0.0013 lr: 0.02
2019-06-04 05:54:15 iteration: 216100 loss: 0.0012 lr: 0.02
2019-06-04 05:54:26 iteration: 216150 loss: 0.0010 lr: 0.02
2019-06-04 05:54:37 iteration: 216200 loss: 0.0012 lr: 0.02
2019-06-04 05:54:47 iteration: 216250 loss: 0.0013 lr: 0.02
2019-06-04 05:54:57 iteration: 216300 loss: 0.0013 lr: 0.02
2019-06-04 05:55:08 iteration: 216350 loss: 0.0013 lr: 0.02
2019-06-04 05:55:19 iteration: 216400 loss: 0.0013 lr: 0.02
2019-06-04 05:55:29 iteration: 216450 loss: 0.0012 lr: 0.02
2019-06-04 05:55:40 iteration: 216500 loss: 0.0012 lr: 0.02
2019-06-04 05:55:53 iteration: 216550 loss: 0.0015 lr: 0.02
2019-06-04 05:56:04 iteration: 216600 loss: 0.0012 lr: 0.02
2019-06-04 05:56:15 iteration: 216650 loss: 0.0012 lr: 0.02
2019-06-04 05:56:26 iteration: 216700 loss: 0.0012 lr: 0.02
2019-06-04 05:56:36 iteration: 216750 loss: 0.0012 lr: 0.02
2019-06-04 05:56:47 iteration: 216800 loss: 0.0012 lr: 0.02
2019-06-04 05:56:58 iteration: 216850 loss: 0.0012 lr: 0.02
2019-06-04 05:57:08 iteration: 216900 loss: 0.0012 lr: 0.02
2019-06-04 05:57:18 iteration: 216950 loss: 0.0013 lr: 0.02
2019-06-04 05:57:28 iteration: 217000 loss: 0.0012 lr: 0.02
2019-06-04 05:57:42 iteration: 217050 loss: 0.0011 lr: 0.02
2019-06-04 05:57:53 iteration: 217100 loss: 0.0011 lr: 0.02
2019-06-04 05:58:03 iteration: 217150 loss: 0.0013 lr: 0.02
2019-06-04 05:58:14 iteration: 217200 loss: 0.0012 lr: 0.02
2019-06-04 05:58:25 iteration: 217250 loss: 0.0013 lr: 0.02
2019-06-04 05:58:34 iteration: 217300 loss: 0.0013 lr: 0.02
2019-06-04 05:58:45 iteration: 217350 loss: 0.0012 lr: 0.02
2019-06-04 05:58:56 iteration: 217400 loss: 0.0012 lr: 0.02
2019-06-04 05:59:07 iteration: 217450 loss: 0.0012 lr: 0.02
2019-06-04 05:59:17 iteration: 217500 loss: 0.0012 lr: 0.02
2019-06-04 05:59:30 iteration: 217550 loss: 0.0012 lr: 0.02
2019-06-04 05:59:41 iteration: 217600 loss: 0.0013 lr: 0.02
2019-06-04 05:59:51 iteration: 217650 loss: 0.0013 lr: 0.02
2019-06-04 06:00:02 iteration: 217700 loss: 0.0014 lr: 0.02
2019-06-04 06:00:12 iteration: 217750 loss: 0.0013 lr: 0.02
2019-06-04 06:00:23 iteration: 217800 loss: 0.0013 lr: 0.02
2019-06-04 06:00:33 iteration: 217850 loss: 0.0012 lr: 0.02
2019-06-04 06:00:44 iteration: 217900 loss: 0.0012 lr: 0.02
2019-06-04 06:00:54 iteration: 217950 loss: 0.0012 lr: 0.02
2019-06-04 06:01:04 iteration: 218000 loss: 0.0014 lr: 0.02
2019-06-04 06:01:18 iteration: 218050 loss: 0.0014 lr: 0.02
2019-06-04 06:01:28 iteration: 218100 loss: 0.0011 lr: 0.02
2019-06-04 06:01:39 iteration: 218150 loss: 0.0012 lr: 0.02
2019-06-04 06:01:50 iteration: 218200 loss: 0.0013 lr: 0.02
2019-06-04 06:02:01 iteration: 218250 loss: 0.0013 lr: 0.02
2019-06-04 06:02:11 iteration: 218300 loss: 0.0011 lr: 0.02
2019-06-04 06:02:21 iteration: 218350 loss: 0.0011 lr: 0.02
2019-06-04 06:02:32 iteration: 218400 loss: 0.0013 lr: 0.02
2019-06-04 06:02:42 iteration: 218450 loss: 0.0015 lr: 0.02
2019-06-04 06:02:53 iteration: 218500 loss: 0.0013 lr: 0.02
2019-06-04 06:03:07 iteration: 218550 loss: 0.0012 lr: 0.02
2019-06-04 06:03:17 iteration: 218600 loss: 0.0010 lr: 0.02
2019-06-04 06:03:27 iteration: 218650 loss: 0.0015 lr: 0.02
2019-06-04 06:03:38 iteration: 218700 loss: 0.0012 lr: 0.02
2019-06-04 06:03:49 iteration: 218750 loss: 0.0012 lr: 0.02
2019-06-04 06:03:59 iteration: 218800 loss: 0.0011 lr: 0.02
2019-06-04 06:04:10 iteration: 218850 loss: 0.0012 lr: 0.02
2019-06-04 06:04:21 iteration: 218900 loss: 0.0011 lr: 0.02
2019-06-04 06:04:31 iteration: 218950 loss: 0.0014 lr: 0.02
2019-06-04 06:04:41 iteration: 219000 loss: 0.0011 lr: 0.02
2019-06-04 06:04:53 iteration: 219050 loss: 0.0014 lr: 0.02
2019-06-04 06:05:04 iteration: 219100 loss: 0.0011 lr: 0.02
2019-06-04 06:05:15 iteration: 219150 loss: 0.0012 lr: 0.02
2019-06-04 06:05:26 iteration: 219200 loss: 0.0012 lr: 0.02
2019-06-04 06:05:36 iteration: 219250 loss: 0.0011 lr: 0.02
2019-06-04 06:05:47 iteration: 219300 loss: 0.0015 lr: 0.02
2019-06-04 06:05:57 iteration: 219350 loss: 0.0012 lr: 0.02
2019-06-04 06:06:08 iteration: 219400 loss: 0.0011 lr: 0.02
2019-06-04 06:06:19 iteration: 219450 loss: 0.0011 lr: 0.02
2019-06-04 06:06:29 iteration: 219500 loss: 0.0011 lr: 0.02
2019-06-04 06:06:43 iteration: 219550 loss: 0.0013 lr: 0.02
2019-06-04 06:06:52 iteration: 219600 loss: 0.0013 lr: 0.02
2019-06-04 06:07:03 iteration: 219650 loss: 0.0013 lr: 0.02
2019-06-04 06:07:13 iteration: 219700 loss: 0.0014 lr: 0.02
2019-06-04 06:07:24 iteration: 219750 loss: 0.0012 lr: 0.02
2019-06-04 06:07:34 iteration: 219800 loss: 0.0013 lr: 0.02
2019-06-04 06:07:45 iteration: 219850 loss: 0.0013 lr: 0.02
2019-06-04 06:07:55 iteration: 219900 loss: 0.0013 lr: 0.02
2019-06-04 06:08:05 iteration: 219950 loss: 0.0013 lr: 0.02
2019-06-04 06:08:16 iteration: 220000 loss: 0.0013 lr: 0.02
2019-06-04 06:08:30 iteration: 220050 loss: 0.0010 lr: 0.02
2019-06-04 06:08:40 iteration: 220100 loss: 0.0011 lr: 0.02
2019-06-04 06:08:51 iteration: 220150 loss: 0.0011 lr: 0.02
2019-06-04 06:09:01 iteration: 220200 loss: 0.0012 lr: 0.02
2019-06-04 06:09:12 iteration: 220250 loss: 0.0014 lr: 0.02
2019-06-04 06:09:23 iteration: 220300 loss: 0.0014 lr: 0.02
2019-06-04 06:09:33 iteration: 220350 loss: 0.0012 lr: 0.02
2019-06-04 06:09:43 iteration: 220400 loss: 0.0012 lr: 0.02
2019-06-04 06:09:54 iteration: 220450 loss: 0.0012 lr: 0.02
2019-06-04 06:10:04 iteration: 220500 loss: 0.0012 lr: 0.02
2019-06-04 06:10:18 iteration: 220550 loss: 0.0010 lr: 0.02
2019-06-04 06:10:28 iteration: 220600 loss: 0.0011 lr: 0.02
2019-06-04 06:10:39 iteration: 220650 loss: 0.0012 lr: 0.02
2019-06-04 06:10:50 iteration: 220700 loss: 0.0012 lr: 0.02
2019-06-04 06:11:00 iteration: 220750 loss: 0.0013 lr: 0.02
2019-06-04 06:11:11 iteration: 220800 loss: 0.0015 lr: 0.02
2019-06-04 06:11:21 iteration: 220850 loss: 0.0013 lr: 0.02
2019-06-04 06:11:31 iteration: 220900 loss: 0.0014 lr: 0.02
2019-06-04 06:11:42 iteration: 220950 loss: 0.0013 lr: 0.02
2019-06-04 06:11:52 iteration: 221000 loss: 0.0012 lr: 0.02
2019-06-04 06:12:05 iteration: 221050 loss: 0.0013 lr: 0.02
2019-06-04 06:12:15 iteration: 221100 loss: 0.0014 lr: 0.02
2019-06-04 06:12:26 iteration: 221150 loss: 0.0011 lr: 0.02
2019-06-04 06:12:37 iteration: 221200 loss: 0.0011 lr: 0.02
2019-06-04 06:12:48 iteration: 221250 loss: 0.0012 lr: 0.02
2019-06-04 06:12:58 iteration: 221300 loss: 0.0013 lr: 0.02
2019-06-04 06:13:09 iteration: 221350 loss: 0.0013 lr: 0.02
2019-06-04 06:13:19 iteration: 221400 loss: 0.0013 lr: 0.02
2019-06-04 06:13:29 iteration: 221450 loss: 0.0013 lr: 0.02
2019-06-04 06:13:41 iteration: 221500 loss: 0.0013 lr: 0.02
2019-06-04 06:13:54 iteration: 221550 loss: 0.0014 lr: 0.02
2019-06-04 06:14:05 iteration: 221600 loss: 0.0013 lr: 0.02
2019-06-04 06:14:15 iteration: 221650 loss: 0.0013 lr: 0.02
2019-06-04 06:14:26 iteration: 221700 loss: 0.0012 lr: 0.02
2019-06-04 06:14:36 iteration: 221750 loss: 0.0012 lr: 0.02
2019-06-04 06:14:47 iteration: 221800 loss: 0.0013 lr: 0.02
2019-06-04 06:14:58 iteration: 221850 loss: 0.0012 lr: 0.02
2019-06-04 06:15:08 iteration: 221900 loss: 0.0012 lr: 0.02
2019-06-04 06:15:19 iteration: 221950 loss: 0.0013 lr: 0.02
2019-06-04 06:15:29 iteration: 222000 loss: 0.0012 lr: 0.02
2019-06-04 06:15:42 iteration: 222050 loss: 0.0015 lr: 0.02
2019-06-04 06:15:52 iteration: 222100 loss: 0.0013 lr: 0.02
2019-06-04 06:16:03 iteration: 222150 loss: 0.0014 lr: 0.02
2019-06-04 06:16:13 iteration: 222200 loss: 0.0013 lr: 0.02
2019-06-04 06:16:23 iteration: 222250 loss: 0.0014 lr: 0.02
2019-06-04 06:16:33 iteration: 222300 loss: 0.0016 lr: 0.02
2019-06-04 06:16:44 iteration: 222350 loss: 0.0012 lr: 0.02
2019-06-04 06:16:55 iteration: 222400 loss: 0.0012 lr: 0.02
2019-06-04 06:17:05 iteration: 222450 loss: 0.0013 lr: 0.02
2019-06-04 06:17:15 iteration: 222500 loss: 0.0013 lr: 0.02
2019-06-04 06:17:29 iteration: 222550 loss: 0.0012 lr: 0.02
2019-06-04 06:17:40 iteration: 222600 loss: 0.0011 lr: 0.02
2019-06-04 06:17:50 iteration: 222650 loss: 0.0012 lr: 0.02
2019-06-04 06:18:01 iteration: 222700 loss: 0.0012 lr: 0.02
2019-06-04 06:18:11 iteration: 222750 loss: 0.0014 lr: 0.02
2019-06-04 06:18:22 iteration: 222800 loss: 0.0010 lr: 0.02
2019-06-04 06:18:33 iteration: 222850 loss: 0.0011 lr: 0.02
2019-06-04 06:18:43 iteration: 222900 loss: 0.0013 lr: 0.02
2019-06-04 06:18:54 iteration: 222950 loss: 0.0015 lr: 0.02
2019-06-04 06:19:04 iteration: 223000 loss: 0.0013 lr: 0.02
2019-06-04 06:19:17 iteration: 223050 loss: 0.0013 lr: 0.02
2019-06-04 06:19:29 iteration: 223100 loss: 0.0010 lr: 0.02
2019-06-04 06:19:39 iteration: 223150 loss: 0.0011 lr: 0.02
2019-06-04 06:19:50 iteration: 223200 loss: 0.0009 lr: 0.02
2019-06-04 06:20:01 iteration: 223250 loss: 0.0013 lr: 0.02
2019-06-04 06:20:12 iteration: 223300 loss: 0.0011 lr: 0.02
2019-06-04 06:20:23 iteration: 223350 loss: 0.0010 lr: 0.02
2019-06-04 06:20:33 iteration: 223400 loss: 0.0013 lr: 0.02
2019-06-04 06:20:44 iteration: 223450 loss: 0.0016 lr: 0.02
2019-06-04 06:20:54 iteration: 223500 loss: 0.0012 lr: 0.02
2019-06-04 06:21:08 iteration: 223550 loss: 0.0012 lr: 0.02
2019-06-04 06:21:19 iteration: 223600 loss: 0.0010 lr: 0.02
2019-06-04 06:21:29 iteration: 223650 loss: 0.0017 lr: 0.02
2019-06-04 06:21:39 iteration: 223700 loss: 0.0014 lr: 0.02
2019-06-04 06:21:49 iteration: 223750 loss: 0.0013 lr: 0.02
2019-06-04 06:22:00 iteration: 223800 loss: 0.0015 lr: 0.02
2019-06-04 06:22:09 iteration: 223850 loss: 0.0013 lr: 0.02
2019-06-04 06:22:20 iteration: 223900 loss: 0.0013 lr: 0.02
2019-06-04 06:22:30 iteration: 223950 loss: 0.0009 lr: 0.02
2019-06-04 06:22:40 iteration: 224000 loss: 0.0014 lr: 0.02
2019-06-04 06:22:53 iteration: 224050 loss: 0.0014 lr: 0.02
2019-06-04 06:23:03 iteration: 224100 loss: 0.0012 lr: 0.02
2019-06-04 06:23:14 iteration: 224150 loss: 0.0011 lr: 0.02
2019-06-04 06:23:25 iteration: 224200 loss: 0.0011 lr: 0.02
2019-06-04 06:23:34 iteration: 224250 loss: 0.0013 lr: 0.02
2019-06-04 06:23:45 iteration: 224300 loss: 0.0011 lr: 0.02
2019-06-04 06:23:55 iteration: 224350 loss: 0.0015 lr: 0.02
2019-06-04 06:24:06 iteration: 224400 loss: 0.0014 lr: 0.02
2019-06-04 06:24:16 iteration: 224450 loss: 0.0010 lr: 0.02
2019-06-04 06:24:27 iteration: 224500 loss: 0.0012 lr: 0.02
2019-06-04 06:24:40 iteration: 224550 loss: 0.0011 lr: 0.02
2019-06-04 06:24:51 iteration: 224600 loss: 0.0011 lr: 0.02
2019-06-04 06:25:02 iteration: 224650 loss: 0.0011 lr: 0.02
2019-06-04 06:25:13 iteration: 224700 loss: 0.0011 lr: 0.02
2019-06-04 06:25:24 iteration: 224750 loss: 0.0014 lr: 0.02
2019-06-04 06:25:35 iteration: 224800 loss: 0.0010 lr: 0.02
2019-06-04 06:25:45 iteration: 224850 loss: 0.0013 lr: 0.02
2019-06-04 06:25:56 iteration: 224900 loss: 0.0014 lr: 0.02
2019-06-04 06:26:07 iteration: 224950 loss: 0.0012 lr: 0.02
2019-06-04 06:26:17 iteration: 225000 loss: 0.0014 lr: 0.02
2019-06-04 06:26:31 iteration: 225050 loss: 0.0010 lr: 0.02
2019-06-04 06:26:42 iteration: 225100 loss: 0.0013 lr: 0.02
2019-06-04 06:26:53 iteration: 225150 loss: 0.0014 lr: 0.02
2019-06-04 06:27:03 iteration: 225200 loss: 0.0012 lr: 0.02
2019-06-04 06:27:14 iteration: 225250 loss: 0.0014 lr: 0.02
2019-06-04 06:27:24 iteration: 225300 loss: 0.0013 lr: 0.02
2019-06-04 06:27:34 iteration: 225350 loss: 0.0011 lr: 0.02
2019-06-04 06:27:45 iteration: 225400 loss: 0.0012 lr: 0.02
2019-06-04 06:27:56 iteration: 225450 loss: 0.0011 lr: 0.02
2019-06-04 06:28:06 iteration: 225500 loss: 0.0014 lr: 0.02
2019-06-04 06:28:20 iteration: 225550 loss: 0.0012 lr: 0.02
2019-06-04 06:28:30 iteration: 225600 loss: 0.0012 lr: 0.02
2019-06-04 06:28:40 iteration: 225650 loss: 0.0012 lr: 0.02
2019-06-04 06:28:51 iteration: 225700 loss: 0.0013 lr: 0.02
2019-06-04 06:29:02 iteration: 225750 loss: 0.0012 lr: 0.02
2019-06-04 06:29:13 iteration: 225800 loss: 0.0012 lr: 0.02
2019-06-04 06:29:23 iteration: 225850 loss: 0.0014 lr: 0.02
2019-06-04 06:29:33 iteration: 225900 loss: 0.0013 lr: 0.02
2019-06-04 06:29:44 iteration: 225950 loss: 0.0012 lr: 0.02
2019-06-04 06:29:54 iteration: 226000 loss: 0.0012 lr: 0.02
2019-06-04 06:30:08 iteration: 226050 loss: 0.0014 lr: 0.02
2019-06-04 06:30:18 iteration: 226100 loss: 0.0011 lr: 0.02
2019-06-04 06:30:29 iteration: 226150 loss: 0.0012 lr: 0.02
2019-06-04 06:30:40 iteration: 226200 loss: 0.0014 lr: 0.02
2019-06-04 06:30:51 iteration: 226250 loss: 0.0012 lr: 0.02
2019-06-04 06:31:01 iteration: 226300 loss: 0.0012 lr: 0.02
2019-06-04 06:31:11 iteration: 226350 loss: 0.0013 lr: 0.02
2019-06-04 06:31:22 iteration: 226400 loss: 0.0014 lr: 0.02
2019-06-04 06:31:32 iteration: 226450 loss: 0.0012 lr: 0.02
2019-06-04 06:31:43 iteration: 226500 loss: 0.0013 lr: 0.02
2019-06-04 06:31:56 iteration: 226550 loss: 0.0012 lr: 0.02
2019-06-04 06:32:06 iteration: 226600 loss: 0.0012 lr: 0.02
2019-06-04 06:32:17 iteration: 226650 loss: 0.0012 lr: 0.02
2019-06-04 06:32:27 iteration: 226700 loss: 0.0014 lr: 0.02
2019-06-04 06:32:38 iteration: 226750 loss: 0.0012 lr: 0.02
2019-06-04 06:32:48 iteration: 226800 loss: 0.0013 lr: 0.02
2019-06-04 06:32:59 iteration: 226850 loss: 0.0013 lr: 0.02
2019-06-04 06:33:10 iteration: 226900 loss: 0.0012 lr: 0.02
2019-06-04 06:33:20 iteration: 226950 loss: 0.0013 lr: 0.02
2019-06-04 06:33:31 iteration: 227000 loss: 0.0013 lr: 0.02
2019-06-04 06:33:45 iteration: 227050 loss: 0.0015 lr: 0.02
2019-06-04 06:33:56 iteration: 227100 loss: 0.0011 lr: 0.02
2019-06-04 06:34:06 iteration: 227150 loss: 0.0013 lr: 0.02
2019-06-04 06:34:17 iteration: 227200 loss: 0.0010 lr: 0.02
2019-06-04 06:34:27 iteration: 227250 loss: 0.0011 lr: 0.02
2019-06-04 06:34:38 iteration: 227300 loss: 0.0012 lr: 0.02
2019-06-04 06:34:49 iteration: 227350 loss: 0.0014 lr: 0.02
2019-06-04 06:34:59 iteration: 227400 loss: 0.0015 lr: 0.02
2019-06-04 06:35:09 iteration: 227450 loss: 0.0012 lr: 0.02
2019-06-04 06:35:20 iteration: 227500 loss: 0.0012 lr: 0.02
2019-06-04 06:35:33 iteration: 227550 loss: 0.0013 lr: 0.02
2019-06-04 06:35:43 iteration: 227600 loss: 0.0011 lr: 0.02
2019-06-04 06:35:54 iteration: 227650 loss: 0.0015 lr: 0.02
2019-06-04 06:36:05 iteration: 227700 loss: 0.0011 lr: 0.02
2019-06-04 06:36:15 iteration: 227750 loss: 0.0011 lr: 0.02
2019-06-04 06:36:26 iteration: 227800 loss: 0.0014 lr: 0.02
2019-06-04 06:36:37 iteration: 227850 loss: 0.0012 lr: 0.02
2019-06-04 06:36:47 iteration: 227900 loss: 0.0010 lr: 0.02
2019-06-04 06:36:57 iteration: 227950 loss: 0.0014 lr: 0.02
2019-06-04 06:37:07 iteration: 228000 loss: 0.0014 lr: 0.02
2019-06-04 06:37:21 iteration: 228050 loss: 0.0012 lr: 0.02
2019-06-04 06:37:31 iteration: 228100 loss: 0.0012 lr: 0.02
2019-06-04 06:37:42 iteration: 228150 loss: 0.0012 lr: 0.02
2019-06-04 06:37:53 iteration: 228200 loss: 0.0012 lr: 0.02
2019-06-04 06:38:03 iteration: 228250 loss: 0.0014 lr: 0.02
2019-06-04 06:38:14 iteration: 228300 loss: 0.0012 lr: 0.02
2019-06-04 06:38:25 iteration: 228350 loss: 0.0010 lr: 0.02
2019-06-04 06:38:35 iteration: 228400 loss: 0.0014 lr: 0.02
2019-06-04 06:38:45 iteration: 228450 loss: 0.0011 lr: 0.02
2019-06-04 06:38:56 iteration: 228500 loss: 0.0012 lr: 0.02
2019-06-04 06:39:10 iteration: 228550 loss: 0.0011 lr: 0.02
2019-06-04 06:39:20 iteration: 228600 loss: 0.0011 lr: 0.02
2019-06-04 06:39:30 iteration: 228650 loss: 0.0013 lr: 0.02
2019-06-04 06:39:42 iteration: 228700 loss: 0.0010 lr: 0.02
2019-06-04 06:39:52 iteration: 228750 loss: 0.0010 lr: 0.02
2019-06-04 06:40:03 iteration: 228800 loss: 0.0012 lr: 0.02
2019-06-04 06:40:13 iteration: 228850 loss: 0.0011 lr: 0.02
2019-06-04 06:40:24 iteration: 228900 loss: 0.0013 lr: 0.02
2019-06-04 06:40:34 iteration: 228950 loss: 0.0013 lr: 0.02
2019-06-04 06:40:44 iteration: 229000 loss: 0.0011 lr: 0.02
2019-06-04 06:40:57 iteration: 229050 loss: 0.0014 lr: 0.02
2019-06-04 06:41:07 iteration: 229100 loss: 0.0011 lr: 0.02
2019-06-04 06:41:18 iteration: 229150 loss: 0.0010 lr: 0.02
2019-06-04 06:41:29 iteration: 229200 loss: 0.0010 lr: 0.02
2019-06-04 06:41:40 iteration: 229250 loss: 0.0011 lr: 0.02
2019-06-04 06:41:51 iteration: 229300 loss: 0.0011 lr: 0.02
2019-06-04 06:42:02 iteration: 229350 loss: 0.0011 lr: 0.02
2019-06-04 06:42:12 iteration: 229400 loss: 0.0011 lr: 0.02
2019-06-04 06:42:23 iteration: 229450 loss: 0.0013 lr: 0.02
2019-06-04 06:42:34 iteration: 229500 loss: 0.0012 lr: 0.02
2019-06-04 06:42:47 iteration: 229550 loss: 0.0011 lr: 0.02
2019-06-04 06:42:57 iteration: 229600 loss: 0.0013 lr: 0.02
2019-06-04 06:43:08 iteration: 229650 loss: 0.0013 lr: 0.02
2019-06-04 06:43:19 iteration: 229700 loss: 0.0013 lr: 0.02
2019-06-04 06:43:30 iteration: 229750 loss: 0.0013 lr: 0.02
2019-06-04 06:43:40 iteration: 229800 loss: 0.0011 lr: 0.02
2019-06-04 06:43:51 iteration: 229850 loss: 0.0010 lr: 0.02
2019-06-04 06:44:01 iteration: 229900 loss: 0.0015 lr: 0.02
2019-06-04 06:44:12 iteration: 229950 loss: 0.0014 lr: 0.02
2019-06-04 06:44:22 iteration: 230000 loss: 0.0011 lr: 0.02
2019-06-04 06:44:36 iteration: 230050 loss: 0.0011 lr: 0.02
2019-06-04 06:44:47 iteration: 230100 loss: 0.0011 lr: 0.02
2019-06-04 06:44:58 iteration: 230150 loss: 0.0011 lr: 0.02
2019-06-04 06:45:09 iteration: 230200 loss: 0.0013 lr: 0.02
2019-06-04 06:45:20 iteration: 230250 loss: 0.0010 lr: 0.02
2019-06-04 06:45:30 iteration: 230300 loss: 0.0012 lr: 0.02
2019-06-04 06:45:41 iteration: 230350 loss: 0.0010 lr: 0.02
2019-06-04 06:45:52 iteration: 230400 loss: 0.0013 lr: 0.02
2019-06-04 06:46:03 iteration: 230450 loss: 0.0010 lr: 0.02
2019-06-04 06:46:13 iteration: 230500 loss: 0.0010 lr: 0.02
2019-06-04 06:46:26 iteration: 230550 loss: 0.0013 lr: 0.02
2019-06-04 06:46:37 iteration: 230600 loss: 0.0011 lr: 0.02
2019-06-04 06:46:46 iteration: 230650 loss: 0.0014 lr: 0.02
2019-06-04 06:46:57 iteration: 230700 loss: 0.0014 lr: 0.02
2019-06-04 06:47:07 iteration: 230750 loss: 0.0014 lr: 0.02
2019-06-04 06:47:17 iteration: 230800 loss: 0.0012 lr: 0.02
2019-06-04 06:47:28 iteration: 230850 loss: 0.0014 lr: 0.02
2019-06-04 06:47:38 iteration: 230900 loss: 0.0011 lr: 0.02
2019-06-04 06:47:49 iteration: 230950 loss: 0.0011 lr: 0.02
2019-06-04 06:47:58 iteration: 231000 loss: 0.0012 lr: 0.02
2019-06-04 06:48:12 iteration: 231050 loss: 0.0010 lr: 0.02
2019-06-04 06:48:23 iteration: 231100 loss: 0.0011 lr: 0.02
2019-06-04 06:48:34 iteration: 231150 loss: 0.0013 lr: 0.02
2019-06-04 06:48:44 iteration: 231200 loss: 0.0011 lr: 0.02
2019-06-04 06:48:56 iteration: 231250 loss: 0.0010 lr: 0.02
2019-06-04 06:49:06 iteration: 231300 loss: 0.0014 lr: 0.02
2019-06-04 06:49:17 iteration: 231350 loss: 0.0010 lr: 0.02
2019-06-04 06:49:28 iteration: 231400 loss: 0.0010 lr: 0.02
2019-06-04 06:49:39 iteration: 231450 loss: 0.0012 lr: 0.02
2019-06-04 06:49:50 iteration: 231500 loss: 0.0009 lr: 0.02
2019-06-04 06:50:04 iteration: 231550 loss: 0.0011 lr: 0.02
2019-06-04 06:50:14 iteration: 231600 loss: 0.0014 lr: 0.02
2019-06-04 06:50:25 iteration: 231650 loss: 0.0011 lr: 0.02
2019-06-04 06:50:36 iteration: 231700 loss: 0.0012 lr: 0.02
2019-06-04 06:50:46 iteration: 231750 loss: 0.0011 lr: 0.02
2019-06-04 06:50:57 iteration: 231800 loss: 0.0011 lr: 0.02
2019-06-04 06:51:07 iteration: 231850 loss: 0.0013 lr: 0.02
2019-06-04 06:51:18 iteration: 231900 loss: 0.0011 lr: 0.02
2019-06-04 06:51:29 iteration: 231950 loss: 0.0011 lr: 0.02
2019-06-04 06:51:40 iteration: 232000 loss: 0.0011 lr: 0.02
2019-06-04 06:51:53 iteration: 232050 loss: 0.0010 lr: 0.02
2019-06-04 06:52:04 iteration: 232100 loss: 0.0012 lr: 0.02
2019-06-04 06:52:15 iteration: 232150 loss: 0.0009 lr: 0.02
2019-06-04 06:52:26 iteration: 232200 loss: 0.0012 lr: 0.02
2019-06-04 06:52:36 iteration: 232250 loss: 0.0013 lr: 0.02
2019-06-04 06:52:47 iteration: 232300 loss: 0.0011 lr: 0.02
2019-06-04 06:52:58 iteration: 232350 loss: 0.0012 lr: 0.02
2019-06-04 06:53:09 iteration: 232400 loss: 0.0011 lr: 0.02
2019-06-04 06:53:20 iteration: 232450 loss: 0.0011 lr: 0.02
2019-06-04 06:53:30 iteration: 232500 loss: 0.0013 lr: 0.02
2019-06-04 06:53:44 iteration: 232550 loss: 0.0012 lr: 0.02
2019-06-04 06:53:54 iteration: 232600 loss: 0.0012 lr: 0.02
2019-06-04 06:54:05 iteration: 232650 loss: 0.0012 lr: 0.02
2019-06-04 06:54:16 iteration: 232700 loss: 0.0013 lr: 0.02
2019-06-04 06:54:26 iteration: 232750 loss: 0.0011 lr: 0.02
2019-06-04 06:54:37 iteration: 232800 loss: 0.0013 lr: 0.02
2019-06-04 06:54:47 iteration: 232850 loss: 0.0011 lr: 0.02
2019-06-04 06:54:57 iteration: 232900 loss: 0.0012 lr: 0.02
2019-06-04 06:55:08 iteration: 232950 loss: 0.0013 lr: 0.02
2019-06-04 06:55:18 iteration: 233000 loss: 0.0010 lr: 0.02
2019-06-04 06:55:32 iteration: 233050 loss: 0.0012 lr: 0.02
2019-06-04 06:55:42 iteration: 233100 loss: 0.0014 lr: 0.02
2019-06-04 06:55:53 iteration: 233150 loss: 0.0014 lr: 0.02
2019-06-04 06:56:03 iteration: 233200 loss: 0.0011 lr: 0.02
2019-06-04 06:56:14 iteration: 233250 loss: 0.0013 lr: 0.02
2019-06-04 06:56:24 iteration: 233300 loss: 0.0012 lr: 0.02
2019-06-04 06:56:35 iteration: 233350 loss: 0.0012 lr: 0.02
2019-06-04 06:56:46 iteration: 233400 loss: 0.0013 lr: 0.02
2019-06-04 06:56:55 iteration: 233450 loss: 0.0015 lr: 0.02
2019-06-04 06:57:06 iteration: 233500 loss: 0.0011 lr: 0.02
2019-06-04 06:57:20 iteration: 233550 loss: 0.0012 lr: 0.02
2019-06-04 06:57:30 iteration: 233600 loss: 0.0012 lr: 0.02
2019-06-04 06:57:41 iteration: 233650 loss: 0.0012 lr: 0.02
2019-06-04 06:57:51 iteration: 233700 loss: 0.0011 lr: 0.02
2019-06-04 06:58:02 iteration: 233750 loss: 0.0013 lr: 0.02
2019-06-04 06:58:12 iteration: 233800 loss: 0.0012 lr: 0.02
2019-06-04 06:58:22 iteration: 233850 loss: 0.0011 lr: 0.02
2019-06-04 06:58:32 iteration: 233900 loss: 0.0012 lr: 0.02
2019-06-04 06:58:43 iteration: 233950 loss: 0.0012 lr: 0.02
2019-06-04 06:58:52 iteration: 234000 loss: 0.0015 lr: 0.02
2019-06-04 06:59:06 iteration: 234050 loss: 0.0014 lr: 0.02
2019-06-04 06:59:16 iteration: 234100 loss: 0.0010 lr: 0.02
2019-06-04 06:59:27 iteration: 234150 loss: 0.0011 lr: 0.02
2019-06-04 06:59:37 iteration: 234200 loss: 0.0010 lr: 0.02
2019-06-04 06:59:48 iteration: 234250 loss: 0.0009 lr: 0.02
2019-06-04 06:59:59 iteration: 234300 loss: 0.0013 lr: 0.02
2019-06-04 07:00:09 iteration: 234350 loss: 0.0012 lr: 0.02
2019-06-04 07:00:19 iteration: 234400 loss: 0.0011 lr: 0.02
2019-06-04 07:00:29 iteration: 234450 loss: 0.0014 lr: 0.02
2019-06-04 07:00:40 iteration: 234500 loss: 0.0012 lr: 0.02
2019-06-04 07:00:53 iteration: 234550 loss: 0.0011 lr: 0.02
2019-06-04 07:01:04 iteration: 234600 loss: 0.0013 lr: 0.02
2019-06-04 07:01:15 iteration: 234650 loss: 0.0009 lr: 0.02
2019-06-04 07:01:26 iteration: 234700 loss: 0.0013 lr: 0.02
2019-06-04 07:01:36 iteration: 234750 loss: 0.0011 lr: 0.02
2019-06-04 07:01:47 iteration: 234800 loss: 0.0011 lr: 0.02
2019-06-04 07:01:58 iteration: 234850 loss: 0.0012 lr: 0.02
2019-06-04 07:02:09 iteration: 234900 loss: 0.0012 lr: 0.02
2019-06-04 07:02:19 iteration: 234950 loss: 0.0012 lr: 0.02
2019-06-04 07:02:30 iteration: 235000 loss: 0.0010 lr: 0.02
2019-06-04 07:02:43 iteration: 235050 loss: 0.0014 lr: 0.02
2019-06-04 07:02:54 iteration: 235100 loss: 0.0011 lr: 0.02
2019-06-04 07:03:04 iteration: 235150 loss: 0.0014 lr: 0.02
2019-06-04 07:03:15 iteration: 235200 loss: 0.0012 lr: 0.02
2019-06-04 07:03:26 iteration: 235250 loss: 0.0010 lr: 0.02
2019-06-04 07:03:36 iteration: 235300 loss: 0.0011 lr: 0.02
2019-06-04 07:03:47 iteration: 235350 loss: 0.0012 lr: 0.02
2019-06-04 07:03:58 iteration: 235400 loss: 0.0012 lr: 0.02
2019-06-04 07:04:08 iteration: 235450 loss: 0.0012 lr: 0.02
2019-06-04 07:04:19 iteration: 235500 loss: 0.0013 lr: 0.02
2019-06-04 07:04:33 iteration: 235550 loss: 0.0013 lr: 0.02
2019-06-04 07:04:44 iteration: 235600 loss: 0.0010 lr: 0.02
2019-06-04 07:04:54 iteration: 235650 loss: 0.0012 lr: 0.02
2019-06-04 07:05:05 iteration: 235700 loss: 0.0014 lr: 0.02
2019-06-04 07:05:16 iteration: 235750 loss: 0.0011 lr: 0.02
2019-06-04 07:05:27 iteration: 235800 loss: 0.0009 lr: 0.02
2019-06-04 07:05:38 iteration: 235850 loss: 0.0011 lr: 0.02
2019-06-04 07:05:48 iteration: 235900 loss: 0.0012 lr: 0.02
2019-06-04 07:05:59 iteration: 235950 loss: 0.0013 lr: 0.02
2019-06-04 07:06:09 iteration: 236000 loss: 0.0012 lr: 0.02
2019-06-04 07:06:23 iteration: 236050 loss: 0.0013 lr: 0.02
2019-06-04 07:06:34 iteration: 236100 loss: 0.0011 lr: 0.02
2019-06-04 07:06:44 iteration: 236150 loss: 0.0013 lr: 0.02
2019-06-04 07:06:54 iteration: 236200 loss: 0.0011 lr: 0.02
2019-06-04 07:07:05 iteration: 236250 loss: 0.0013 lr: 0.02
2019-06-04 07:07:15 iteration: 236300 loss: 0.0011 lr: 0.02
2019-06-04 07:07:27 iteration: 236350 loss: 0.0008 lr: 0.02
2019-06-04 07:07:37 iteration: 236400 loss: 0.0012 lr: 0.02
2019-06-04 07:07:47 iteration: 236450 loss: 0.0012 lr: 0.02
2019-06-04 07:07:58 iteration: 236500 loss: 0.0010 lr: 0.02
2019-06-04 07:08:12 iteration: 236550 loss: 0.0012 lr: 0.02
2019-06-04 07:08:23 iteration: 236600 loss: 0.0011 lr: 0.02
2019-06-04 07:08:33 iteration: 236650 loss: 0.0010 lr: 0.02
2019-06-04 07:08:44 iteration: 236700 loss: 0.0012 lr: 0.02
2019-06-04 07:08:55 iteration: 236750 loss: 0.0011 lr: 0.02
2019-06-04 07:09:05 iteration: 236800 loss: 0.0012 lr: 0.02
2019-06-04 07:09:16 iteration: 236850 loss: 0.0009 lr: 0.02
2019-06-04 07:09:28 iteration: 236900 loss: 0.0011 lr: 0.02
2019-06-04 07:09:38 iteration: 236950 loss: 0.0012 lr: 0.02
2019-06-04 07:09:48 iteration: 237000 loss: 0.0011 lr: 0.02
2019-06-04 07:10:01 iteration: 237050 loss: 0.0012 lr: 0.02
2019-06-04 07:10:11 iteration: 237100 loss: 0.0015 lr: 0.02
2019-06-04 07:10:22 iteration: 237150 loss: 0.0013 lr: 0.02
2019-06-04 07:10:33 iteration: 237200 loss: 0.0013 lr: 0.02
2019-06-04 07:10:43 iteration: 237250 loss: 0.0012 lr: 0.02
2019-06-04 07:10:54 iteration: 237300 loss: 0.0013 lr: 0.02
2019-06-04 07:11:05 iteration: 237350 loss: 0.0011 lr: 0.02
2019-06-04 07:11:15 iteration: 237400 loss: 0.0013 lr: 0.02
2019-06-04 07:11:26 iteration: 237450 loss: 0.0013 lr: 0.02
2019-06-04 07:11:36 iteration: 237500 loss: 0.0012 lr: 0.02
2019-06-04 07:11:49 iteration: 237550 loss: 0.0011 lr: 0.02
2019-06-04 07:11:59 iteration: 237600 loss: 0.0012 lr: 0.02
2019-06-04 07:12:10 iteration: 237650 loss: 0.0014 lr: 0.02
2019-06-04 07:12:20 iteration: 237700 loss: 0.0014 lr: 0.02
2019-06-04 07:12:31 iteration: 237750 loss: 0.0012 lr: 0.02
2019-06-04 07:12:42 iteration: 237800 loss: 0.0011 lr: 0.02
2019-06-04 07:12:53 iteration: 237850 loss: 0.0013 lr: 0.02
2019-06-04 07:13:03 iteration: 237900 loss: 0.0011 lr: 0.02
2019-06-04 07:13:14 iteration: 237950 loss: 0.0011 lr: 0.02
2019-06-04 07:13:25 iteration: 238000 loss: 0.0013 lr: 0.02
2019-06-04 07:13:38 iteration: 238050 loss: 0.0011 lr: 0.02
2019-06-04 07:13:48 iteration: 238100 loss: 0.0012 lr: 0.02
2019-06-04 07:13:59 iteration: 238150 loss: 0.0011 lr: 0.02
2019-06-04 07:14:10 iteration: 238200 loss: 0.0010 lr: 0.02
2019-06-04 07:14:21 iteration: 238250 loss: 0.0012 lr: 0.02
2019-06-04 07:14:32 iteration: 238300 loss: 0.0011 lr: 0.02
2019-06-04 07:14:42 iteration: 238350 loss: 0.0010 lr: 0.02
2019-06-04 07:14:53 iteration: 238400 loss: 0.0010 lr: 0.02
2019-06-04 07:15:03 iteration: 238450 loss: 0.0011 lr: 0.02
2019-06-04 07:15:14 iteration: 238500 loss: 0.0010 lr: 0.02
2019-06-04 07:15:28 iteration: 238550 loss: 0.0012 lr: 0.02
2019-06-04 07:15:38 iteration: 238600 loss: 0.0014 lr: 0.02
2019-06-04 07:15:49 iteration: 238650 loss: 0.0010 lr: 0.02
2019-06-04 07:15:59 iteration: 238700 loss: 0.0012 lr: 0.02
2019-06-04 07:16:10 iteration: 238750 loss: 0.0010 lr: 0.02
2019-06-04 07:16:21 iteration: 238800 loss: 0.0012 lr: 0.02
2019-06-04 07:16:32 iteration: 238850 loss: 0.0011 lr: 0.02
2019-06-04 07:16:42 iteration: 238900 loss: 0.0011 lr: 0.02
2019-06-04 07:16:52 iteration: 238950 loss: 0.0011 lr: 0.02
2019-06-04 07:17:03 iteration: 239000 loss: 0.0012 lr: 0.02
2019-06-04 07:17:16 iteration: 239050 loss: 0.0010 lr: 0.02
2019-06-04 07:17:27 iteration: 239100 loss: 0.0012 lr: 0.02
2019-06-04 07:17:37 iteration: 239150 loss: 0.0012 lr: 0.02
2019-06-04 07:17:47 iteration: 239200 loss: 0.0013 lr: 0.02
2019-06-04 07:17:57 iteration: 239250 loss: 0.0014 lr: 0.02
2019-06-04 07:18:09 iteration: 239300 loss: 0.0013 lr: 0.02
2019-06-04 07:18:19 iteration: 239350 loss: 0.0012 lr: 0.02
2019-06-04 07:18:30 iteration: 239400 loss: 0.0012 lr: 0.02
2019-06-04 07:18:40 iteration: 239450 loss: 0.0014 lr: 0.02
2019-06-04 07:18:51 iteration: 239500 loss: 0.0013 lr: 0.02
2019-06-04 07:19:04 iteration: 239550 loss: 0.0010 lr: 0.02
2019-06-04 07:19:14 iteration: 239600 loss: 0.0010 lr: 0.02
2019-06-04 07:19:25 iteration: 239650 loss: 0.0011 lr: 0.02
2019-06-04 07:19:35 iteration: 239700 loss: 0.0014 lr: 0.02
2019-06-04 07:19:46 iteration: 239750 loss: 0.0013 lr: 0.02
2019-06-04 07:19:56 iteration: 239800 loss: 0.0011 lr: 0.02
2019-06-04 07:20:06 iteration: 239850 loss: 0.0009 lr: 0.02
2019-06-04 07:20:16 iteration: 239900 loss: 0.0012 lr: 0.02
2019-06-04 07:20:26 iteration: 239950 loss: 0.0013 lr: 0.02
2019-06-04 07:20:36 iteration: 240000 loss: 0.0012 lr: 0.02
2019-06-04 07:20:50 iteration: 240050 loss: 0.0015 lr: 0.02
2019-06-04 07:21:01 iteration: 240100 loss: 0.0013 lr: 0.02
2019-06-04 07:21:11 iteration: 240150 loss: 0.0012 lr: 0.02
2019-06-04 07:21:21 iteration: 240200 loss: 0.0013 lr: 0.02
2019-06-04 07:21:32 iteration: 240250 loss: 0.0013 lr: 0.02
2019-06-04 07:21:42 iteration: 240300 loss: 0.0011 lr: 0.02
2019-06-04 07:21:52 iteration: 240350 loss: 0.0012 lr: 0.02
2019-06-04 07:22:03 iteration: 240400 loss: 0.0014 lr: 0.02
2019-06-04 07:22:13 iteration: 240450 loss: 0.0013 lr: 0.02
2019-06-04 07:22:24 iteration: 240500 loss: 0.0012 lr: 0.02
2019-06-04 07:22:37 iteration: 240550 loss: 0.0012 lr: 0.02
2019-06-04 07:22:48 iteration: 240600 loss: 0.0012 lr: 0.02
2019-06-04 07:22:58 iteration: 240650 loss: 0.0014 lr: 0.02
2019-06-04 07:23:09 iteration: 240700 loss: 0.0014 lr: 0.02
2019-06-04 07:23:19 iteration: 240750 loss: 0.0012 lr: 0.02
2019-06-04 07:23:30 iteration: 240800 loss: 0.0012 lr: 0.02
2019-06-04 07:23:40 iteration: 240850 loss: 0.0013 lr: 0.02
2019-06-04 07:23:50 iteration: 240900 loss: 0.0013 lr: 0.02
2019-06-04 07:24:01 iteration: 240950 loss: 0.0011 lr: 0.02
2019-06-04 07:24:11 iteration: 241000 loss: 0.0011 lr: 0.02
2019-06-04 07:24:25 iteration: 241050 loss: 0.0010 lr: 0.02
2019-06-04 07:24:36 iteration: 241100 loss: 0.0010 lr: 0.02
2019-06-04 07:24:46 iteration: 241150 loss: 0.0015 lr: 0.02
2019-06-04 07:24:57 iteration: 241200 loss: 0.0012 lr: 0.02
2019-06-04 07:25:07 iteration: 241250 loss: 0.0013 lr: 0.02
2019-06-04 07:25:17 iteration: 241300 loss: 0.0014 lr: 0.02
2019-06-04 07:25:28 iteration: 241350 loss: 0.0013 lr: 0.02
2019-06-04 07:25:38 iteration: 241400 loss: 0.0012 lr: 0.02
2019-06-04 07:25:48 iteration: 241450 loss: 0.0013 lr: 0.02
2019-06-04 07:25:58 iteration: 241500 loss: 0.0011 lr: 0.02
2019-06-04 07:26:12 iteration: 241550 loss: 0.0012 lr: 0.02
2019-06-04 07:26:22 iteration: 241600 loss: 0.0013 lr: 0.02
2019-06-04 07:26:33 iteration: 241650 loss: 0.0012 lr: 0.02
2019-06-04 07:26:44 iteration: 241700 loss: 0.0011 lr: 0.02
2019-06-04 07:26:54 iteration: 241750 loss: 0.0014 lr: 0.02
2019-06-04 07:27:05 iteration: 241800 loss: 0.0013 lr: 0.02
2019-06-04 07:27:15 iteration: 241850 loss: 0.0013 lr: 0.02
2019-06-04 07:27:25 iteration: 241900 loss: 0.0011 lr: 0.02
2019-06-04 07:27:36 iteration: 241950 loss: 0.0012 lr: 0.02
2019-06-04 07:27:46 iteration: 242000 loss: 0.0014 lr: 0.02
2019-06-04 07:28:00 iteration: 242050 loss: 0.0012 lr: 0.02
2019-06-04 07:28:10 iteration: 242100 loss: 0.0013 lr: 0.02
2019-06-04 07:28:21 iteration: 242150 loss: 0.0012 lr: 0.02
2019-06-04 07:28:32 iteration: 242200 loss: 0.0011 lr: 0.02
2019-06-04 07:28:42 iteration: 242250 loss: 0.0012 lr: 0.02
2019-06-04 07:28:53 iteration: 242300 loss: 0.0013 lr: 0.02
2019-06-04 07:29:03 iteration: 242350 loss: 0.0013 lr: 0.02
2019-06-04 07:29:14 iteration: 242400 loss: 0.0011 lr: 0.02
2019-06-04 07:29:23 iteration: 242450 loss: 0.0013 lr: 0.02
2019-06-04 07:29:34 iteration: 242500 loss: 0.0012 lr: 0.02
2019-06-04 07:29:48 iteration: 242550 loss: 0.0010 lr: 0.02
2019-06-04 07:29:58 iteration: 242600 loss: 0.0013 lr: 0.02
2019-06-04 07:30:09 iteration: 242650 loss: 0.0011 lr: 0.02
2019-06-04 07:30:20 iteration: 242700 loss: 0.0012 lr: 0.02
2019-06-04 07:30:31 iteration: 242750 loss: 0.0010 lr: 0.02
2019-06-04 07:30:42 iteration: 242800 loss: 0.0011 lr: 0.02
2019-06-04 07:30:53 iteration: 242850 loss: 0.0011 lr: 0.02
2019-06-04 07:31:03 iteration: 242900 loss: 0.0012 lr: 0.02
2019-06-04 07:31:13 iteration: 242950 loss: 0.0014 lr: 0.02
2019-06-04 07:31:24 iteration: 243000 loss: 0.0012 lr: 0.02
2019-06-04 07:31:38 iteration: 243050 loss: 0.0012 lr: 0.02
2019-06-04 07:31:49 iteration: 243100 loss: 0.0012 lr: 0.02
2019-06-04 07:31:59 iteration: 243150 loss: 0.0013 lr: 0.02
2019-06-04 07:32:10 iteration: 243200 loss: 0.0012 lr: 0.02
2019-06-04 07:32:21 iteration: 243250 loss: 0.0012 lr: 0.02
2019-06-04 07:32:32 iteration: 243300 loss: 0.0013 lr: 0.02
2019-06-04 07:32:42 iteration: 243350 loss: 0.0013 lr: 0.02
2019-06-04 07:32:53 iteration: 243400 loss: 0.0011 lr: 0.02
2019-06-04 07:33:04 iteration: 243450 loss: 0.0011 lr: 0.02
2019-06-04 07:33:14 iteration: 243500 loss: 0.0012 lr: 0.02
2019-06-04 07:33:27 iteration: 243550 loss: 0.0012 lr: 0.02
2019-06-04 07:33:38 iteration: 243600 loss: 0.0012 lr: 0.02
2019-06-04 07:33:48 iteration: 243650 loss: 0.0014 lr: 0.02
2019-06-04 07:33:59 iteration: 243700 loss: 0.0013 lr: 0.02
2019-06-04 07:34:09 iteration: 243750 loss: 0.0014 lr: 0.02
2019-06-04 07:34:19 iteration: 243800 loss: 0.0012 lr: 0.02
2019-06-04 07:34:29 iteration: 243850 loss: 0.0013 lr: 0.02
2019-06-04 07:34:39 iteration: 243900 loss: 0.0014 lr: 0.02
2019-06-04 07:34:50 iteration: 243950 loss: 0.0014 lr: 0.02
2019-06-04 07:35:00 iteration: 244000 loss: 0.0018 lr: 0.02
2019-06-04 07:35:13 iteration: 244050 loss: 0.0014 lr: 0.02
2019-06-04 07:35:24 iteration: 244100 loss: 0.0012 lr: 0.02
2019-06-04 07:35:34 iteration: 244150 loss: 0.0014 lr: 0.02
2019-06-04 07:35:45 iteration: 244200 loss: 0.0013 lr: 0.02
2019-06-04 07:35:55 iteration: 244250 loss: 0.0011 lr: 0.02
2019-06-04 07:36:06 iteration: 244300 loss: 0.0012 lr: 0.02
2019-06-04 07:36:17 iteration: 244350 loss: 0.0011 lr: 0.02
2019-06-04 07:36:27 iteration: 244400 loss: 0.0016 lr: 0.02
2019-06-04 07:36:37 iteration: 244450 loss: 0.0013 lr: 0.02
2019-06-04 07:36:48 iteration: 244500 loss: 0.0012 lr: 0.02
2019-06-04 07:37:02 iteration: 244550 loss: 0.0011 lr: 0.02
2019-06-04 07:37:12 iteration: 244600 loss: 0.0011 lr: 0.02
2019-06-04 07:37:22 iteration: 244650 loss: 0.0012 lr: 0.02
2019-06-04 07:37:33 iteration: 244700 loss: 0.0010 lr: 0.02
2019-06-04 07:37:44 iteration: 244750 loss: 0.0012 lr: 0.02
2019-06-04 07:37:54 iteration: 244800 loss: 0.0013 lr: 0.02
2019-06-04 07:38:05 iteration: 244850 loss: 0.0010 lr: 0.02
2019-06-04 07:38:16 iteration: 244900 loss: 0.0011 lr: 0.02
2019-06-04 07:38:27 iteration: 244950 loss: 0.0011 lr: 0.02
2019-06-04 07:38:37 iteration: 245000 loss: 0.0013 lr: 0.02
2019-06-04 07:38:51 iteration: 245050 loss: 0.0011 lr: 0.02
2019-06-04 07:39:01 iteration: 245100 loss: 0.0012 lr: 0.02
2019-06-04 07:39:12 iteration: 245150 loss: 0.0013 lr: 0.02
2019-06-04 07:39:22 iteration: 245200 loss: 0.0012 lr: 0.02
2019-06-04 07:39:33 iteration: 245250 loss: 0.0017 lr: 0.02
2019-06-04 07:39:43 iteration: 245300 loss: 0.0012 lr: 0.02
2019-06-04 07:39:54 iteration: 245350 loss: 0.0013 lr: 0.02
2019-06-04 07:40:05 iteration: 245400 loss: 0.0012 lr: 0.02
2019-06-04 07:40:16 iteration: 245450 loss: 0.0011 lr: 0.02
2019-06-04 07:40:27 iteration: 245500 loss: 0.0014 lr: 0.02
2019-06-04 07:40:39 iteration: 245550 loss: 0.0011 lr: 0.02
2019-06-04 07:40:50 iteration: 245600 loss: 0.0012 lr: 0.02
2019-06-04 07:41:00 iteration: 245650 loss: 0.0012 lr: 0.02
2019-06-04 07:41:11 iteration: 245700 loss: 0.0012 lr: 0.02
2019-06-04 07:41:21 iteration: 245750 loss: 0.0011 lr: 0.02
2019-06-04 07:41:32 iteration: 245800 loss: 0.0013 lr: 0.02
2019-06-04 07:41:42 iteration: 245850 loss: 0.0013 lr: 0.02
2019-06-04 07:41:53 iteration: 245900 loss: 0.0011 lr: 0.02
2019-06-04 07:42:04 iteration: 245950 loss: 0.0014 lr: 0.02
2019-06-04 07:42:14 iteration: 246000 loss: 0.0013 lr: 0.02
2019-06-04 07:42:27 iteration: 246050 loss: 0.0011 lr: 0.02
2019-06-04 07:42:38 iteration: 246100 loss: 0.0011 lr: 0.02
2019-06-04 07:42:50 iteration: 246150 loss: 0.0010 lr: 0.02
2019-06-04 07:43:00 iteration: 246200 loss: 0.0012 lr: 0.02
2019-06-04 07:43:10 iteration: 246250 loss: 0.0014 lr: 0.02
2019-06-04 07:43:20 iteration: 246300 loss: 0.0016 lr: 0.02
2019-06-04 07:43:30 iteration: 246350 loss: 0.0013 lr: 0.02
2019-06-04 07:43:40 iteration: 246400 loss: 0.0013 lr: 0.02
2019-06-04 07:43:50 iteration: 246450 loss: 0.0013 lr: 0.02
2019-06-04 07:44:01 iteration: 246500 loss: 0.0015 lr: 0.02
2019-06-04 07:44:14 iteration: 246550 loss: 0.0011 lr: 0.02
2019-06-04 07:44:25 iteration: 246600 loss: 0.0011 lr: 0.02
2019-06-04 07:44:36 iteration: 246650 loss: 0.0015 lr: 0.02
2019-06-04 07:44:46 iteration: 246700 loss: 0.0011 lr: 0.02
2019-06-04 07:44:56 iteration: 246750 loss: 0.0011 lr: 0.02
2019-06-04 07:45:07 iteration: 246800 loss: 0.0010 lr: 0.02
2019-06-04 07:45:17 iteration: 246850 loss: 0.0009 lr: 0.02
2019-06-04 07:45:28 iteration: 246900 loss: 0.0012 lr: 0.02
2019-06-04 07:45:38 iteration: 246950 loss: 0.0012 lr: 0.02
2019-06-04 07:45:48 iteration: 247000 loss: 0.0011 lr: 0.02
2019-06-04 07:46:02 iteration: 247050 loss: 0.0011 lr: 0.02
2019-06-04 07:46:13 iteration: 247100 loss: 0.0011 lr: 0.02
2019-06-04 07:46:24 iteration: 247150 loss: 0.0012 lr: 0.02
2019-06-04 07:46:34 iteration: 247200 loss: 0.0012 lr: 0.02
2019-06-04 07:46:45 iteration: 247250 loss: 0.0013 lr: 0.02
2019-06-04 07:46:55 iteration: 247300 loss: 0.0011 lr: 0.02
2019-06-04 07:47:06 iteration: 247350 loss: 0.0012 lr: 0.02
2019-06-04 07:47:16 iteration: 247400 loss: 0.0014 lr: 0.02
2019-06-04 07:47:27 iteration: 247450 loss: 0.0012 lr: 0.02
2019-06-04 07:47:38 iteration: 247500 loss: 0.0011 lr: 0.02
2019-06-04 07:47:51 iteration: 247550 loss: 0.0013 lr: 0.02
2019-06-04 07:48:01 iteration: 247600 loss: 0.0013 lr: 0.02
2019-06-04 07:48:11 iteration: 247650 loss: 0.0012 lr: 0.02
2019-06-04 07:48:22 iteration: 247700 loss: 0.0016 lr: 0.02
2019-06-04 07:48:32 iteration: 247750 loss: 0.0013 lr: 0.02
2019-06-04 07:48:42 iteration: 247800 loss: 0.0010 lr: 0.02
2019-06-04 07:48:53 iteration: 247850 loss: 0.0012 lr: 0.02
2019-06-04 07:49:04 iteration: 247900 loss: 0.0011 lr: 0.02
2019-06-04 07:49:14 iteration: 247950 loss: 0.0011 lr: 0.02
2019-06-04 07:49:25 iteration: 248000 loss: 0.0011 lr: 0.02
2019-06-04 07:49:39 iteration: 248050 loss: 0.0011 lr: 0.02
2019-06-04 07:49:50 iteration: 248100 loss: 0.0011 lr: 0.02
2019-06-04 07:50:00 iteration: 248150 loss: 0.0011 lr: 0.02
2019-06-04 07:50:11 iteration: 248200 loss: 0.0010 lr: 0.02
2019-06-04 07:50:21 iteration: 248250 loss: 0.0011 lr: 0.02
2019-06-04 07:50:31 iteration: 248300 loss: 0.0013 lr: 0.02
2019-06-04 07:50:42 iteration: 248350 loss: 0.0013 lr: 0.02
2019-06-04 07:50:52 iteration: 248400 loss: 0.0013 lr: 0.02
2019-06-04 07:51:02 iteration: 248450 loss: 0.0012 lr: 0.02
2019-06-04 07:51:12 iteration: 248500 loss: 0.0012 lr: 0.02
2019-06-04 07:51:26 iteration: 248550 loss: 0.0012 lr: 0.02
2019-06-04 07:51:36 iteration: 248600 loss: 0.0012 lr: 0.02
2019-06-04 07:51:47 iteration: 248650 loss: 0.0013 lr: 0.02
2019-06-04 07:51:58 iteration: 248700 loss: 0.0010 lr: 0.02
2019-06-04 07:52:08 iteration: 248750 loss: 0.0015 lr: 0.02
2019-06-04 07:52:19 iteration: 248800 loss: 0.0010 lr: 0.02
2019-06-04 07:52:30 iteration: 248850 loss: 0.0011 lr: 0.02
2019-06-04 07:52:41 iteration: 248900 loss: 0.0012 lr: 0.02
2019-06-04 07:52:51 iteration: 248950 loss: 0.0013 lr: 0.02
2019-06-04 07:53:01 iteration: 249000 loss: 0.0010 lr: 0.02
2019-06-04 07:53:14 iteration: 249050 loss: 0.0012 lr: 0.02
2019-06-04 07:53:24 iteration: 249100 loss: 0.0012 lr: 0.02
2019-06-04 07:53:34 iteration: 249150 loss: 0.0010 lr: 0.02
2019-06-04 07:53:44 iteration: 249200 loss: 0.0012 lr: 0.02
2019-06-04 07:53:55 iteration: 249250 loss: 0.0014 lr: 0.02
2019-06-04 07:54:05 iteration: 249300 loss: 0.0012 lr: 0.02
2019-06-04 07:54:16 iteration: 249350 loss: 0.0011 lr: 0.02
2019-06-04 07:54:26 iteration: 249400 loss: 0.0012 lr: 0.02
2019-06-04 07:54:36 iteration: 249450 loss: 0.0014 lr: 0.02
2019-06-04 07:54:46 iteration: 249500 loss: 0.0011 lr: 0.02
2019-06-04 07:54:59 iteration: 249550 loss: 0.0015 lr: 0.02
2019-06-04 07:55:10 iteration: 249600 loss: 0.0013 lr: 0.02
2019-06-04 07:55:20 iteration: 249650 loss: 0.0010 lr: 0.02
2019-06-04 07:55:31 iteration: 249700 loss: 0.0011 lr: 0.02
2019-06-04 07:55:42 iteration: 249750 loss: 0.0011 lr: 0.02
2019-06-04 07:55:52 iteration: 249800 loss: 0.0012 lr: 0.02
2019-06-04 07:56:02 iteration: 249850 loss: 0.0013 lr: 0.02
2019-06-04 07:56:13 iteration: 249900 loss: 0.0012 lr: 0.02
2019-06-04 07:56:23 iteration: 249950 loss: 0.0014 lr: 0.02
2019-06-04 07:56:33 iteration: 250000 loss: 0.0014 lr: 0.02
2019-06-04 07:56:47 iteration: 250050 loss: 0.0010 lr: 0.02
2019-06-04 07:56:58 iteration: 250100 loss: 0.0012 lr: 0.02
2019-06-04 07:57:09 iteration: 250150 loss: 0.0011 lr: 0.02
2019-06-04 07:57:20 iteration: 250200 loss: 0.0011 lr: 0.02
2019-06-04 07:57:30 iteration: 250250 loss: 0.0011 lr: 0.02
2019-06-04 07:57:41 iteration: 250300 loss: 0.0011 lr: 0.02
2019-06-04 07:57:51 iteration: 250350 loss: 0.0011 lr: 0.02
2019-06-04 07:58:02 iteration: 250400 loss: 0.0011 lr: 0.02
2019-06-04 07:58:13 iteration: 250450 loss: 0.0012 lr: 0.02
2019-06-04 07:58:24 iteration: 250500 loss: 0.0011 lr: 0.02
2019-06-04 07:58:37 iteration: 250550 loss: 0.0010 lr: 0.02
2019-06-04 07:58:47 iteration: 250600 loss: 0.0012 lr: 0.02
2019-06-04 07:58:58 iteration: 250650 loss: 0.0011 lr: 0.02
2019-06-04 07:59:09 iteration: 250700 loss: 0.0011 lr: 0.02
2019-06-04 07:59:20 iteration: 250750 loss: 0.0011 lr: 0.02
2019-06-04 07:59:30 iteration: 250800 loss: 0.0017 lr: 0.02
2019-06-04 07:59:40 iteration: 250850 loss: 0.0013 lr: 0.02
2019-06-04 07:59:51 iteration: 250900 loss: 0.0012 lr: 0.02
2019-06-04 08:00:01 iteration: 250950 loss: 0.0016 lr: 0.02
2019-06-04 08:00:12 iteration: 251000 loss: 0.0012 lr: 0.02
2019-06-04 08:00:25 iteration: 251050 loss: 0.0012 lr: 0.02
2019-06-04 08:00:36 iteration: 251100 loss: 0.0012 lr: 0.02
2019-06-04 08:00:46 iteration: 251150 loss: 0.0011 lr: 0.02
2019-06-04 08:00:57 iteration: 251200 loss: 0.0011 lr: 0.02
2019-06-04 08:01:07 iteration: 251250 loss: 0.0010 lr: 0.02
2019-06-04 08:01:18 iteration: 251300 loss: 0.0012 lr: 0.02
2019-06-04 08:01:27 iteration: 251350 loss: 0.0012 lr: 0.02
2019-06-04 08:01:38 iteration: 251400 loss: 0.0012 lr: 0.02
2019-06-04 08:01:48 iteration: 251450 loss: 0.0015 lr: 0.02
2019-06-04 08:01:58 iteration: 251500 loss: 0.0013 lr: 0.02
2019-06-04 08:02:11 iteration: 251550 loss: 0.0012 lr: 0.02
2019-06-04 08:02:21 iteration: 251600 loss: 0.0012 lr: 0.02
2019-06-04 08:02:32 iteration: 251650 loss: 0.0011 lr: 0.02
2019-06-04 08:02:42 iteration: 251700 loss: 0.0011 lr: 0.02
2019-06-04 08:02:52 iteration: 251750 loss: 0.0015 lr: 0.02
2019-06-04 08:03:03 iteration: 251800 loss: 0.0012 lr: 0.02
2019-06-04 08:03:14 iteration: 251850 loss: 0.0011 lr: 0.02
2019-06-04 08:03:25 iteration: 251900 loss: 0.0011 lr: 0.02
2019-06-04 08:03:35 iteration: 251950 loss: 0.0012 lr: 0.02
2019-06-04 08:03:45 iteration: 252000 loss: 0.0013 lr: 0.02
2019-06-04 08:03:59 iteration: 252050 loss: 0.0011 lr: 0.02
2019-06-04 08:04:09 iteration: 252100 loss: 0.0013 lr: 0.02
2019-06-04 08:04:20 iteration: 252150 loss: 0.0013 lr: 0.02
2019-06-04 08:04:30 iteration: 252200 loss: 0.0011 lr: 0.02
2019-06-04 08:04:41 iteration: 252250 loss: 0.0012 lr: 0.02
2019-06-04 08:04:51 iteration: 252300 loss: 0.0013 lr: 0.02
2019-06-04 08:05:02 iteration: 252350 loss: 0.0010 lr: 0.02
2019-06-04 08:05:12 iteration: 252400 loss: 0.0013 lr: 0.02
2019-06-04 08:05:23 iteration: 252450 loss: 0.0011 lr: 0.02
2019-06-04 08:05:33 iteration: 252500 loss: 0.0013 lr: 0.02
2019-06-04 08:05:46 iteration: 252550 loss: 0.0014 lr: 0.02
2019-06-04 08:05:57 iteration: 252600 loss: 0.0012 lr: 0.02
2019-06-04 08:06:08 iteration: 252650 loss: 0.0013 lr: 0.02
2019-06-04 08:06:18 iteration: 252700 loss: 0.0011 lr: 0.02
2019-06-04 08:06:28 iteration: 252750 loss: 0.0016 lr: 0.02
2019-06-04 08:06:39 iteration: 252800 loss: 0.0012 lr: 0.02
2019-06-04 08:06:50 iteration: 252850 loss: 0.0014 lr: 0.02
2019-06-04 08:07:00 iteration: 252900 loss: 0.0012 lr: 0.02
2019-06-04 08:07:11 iteration: 252950 loss: 0.0013 lr: 0.02
2019-06-04 08:07:21 iteration: 253000 loss: 0.0012 lr: 0.02
2019-06-04 08:07:35 iteration: 253050 loss: 0.0011 lr: 0.02
2019-06-04 08:07:46 iteration: 253100 loss: 0.0011 lr: 0.02
2019-06-04 08:07:56 iteration: 253150 loss: 0.0012 lr: 0.02
2019-06-04 08:08:07 iteration: 253200 loss: 0.0013 lr: 0.02
2019-06-04 08:08:17 iteration: 253250 loss: 0.0011 lr: 0.02
2019-06-04 08:08:27 iteration: 253300 loss: 0.0011 lr: 0.02
2019-06-04 08:08:38 iteration: 253350 loss: 0.0011 lr: 0.02
2019-06-04 08:08:48 iteration: 253400 loss: 0.0013 lr: 0.02
2019-06-04 08:08:59 iteration: 253450 loss: 0.0013 lr: 0.02
2019-06-04 08:09:09 iteration: 253500 loss: 0.0011 lr: 0.02
2019-06-04 08:09:22 iteration: 253550 loss: 0.0011 lr: 0.02
2019-06-04 08:09:32 iteration: 253600 loss: 0.0010 lr: 0.02
2019-06-04 08:09:43 iteration: 253650 loss: 0.0012 lr: 0.02
2019-06-04 08:09:53 iteration: 253700 loss: 0.0010 lr: 0.02
2019-06-04 08:10:04 iteration: 253750 loss: 0.0012 lr: 0.02
2019-06-04 08:10:15 iteration: 253800 loss: 0.0011 lr: 0.02
2019-06-04 08:10:25 iteration: 253850 loss: 0.0012 lr: 0.02
2019-06-04 08:10:35 iteration: 253900 loss: 0.0011 lr: 0.02
2019-06-04 08:10:45 iteration: 253950 loss: 0.0011 lr: 0.02
2019-06-04 08:10:55 iteration: 254000 loss: 0.0013 lr: 0.02
2019-06-04 08:11:08 iteration: 254050 loss: 0.0015 lr: 0.02
2019-06-04 08:11:19 iteration: 254100 loss: 0.0012 lr: 0.02
2019-06-04 08:11:29 iteration: 254150 loss: 0.0011 lr: 0.02
2019-06-04 08:11:41 iteration: 254200 loss: 0.0010 lr: 0.02
2019-06-04 08:11:52 iteration: 254250 loss: 0.0011 lr: 0.02
2019-06-04 08:12:02 iteration: 254300 loss: 0.0014 lr: 0.02
2019-06-04 08:12:13 iteration: 254350 loss: 0.0014 lr: 0.02
2019-06-04 08:12:23 iteration: 254400 loss: 0.0012 lr: 0.02
2019-06-04 08:12:33 iteration: 254450 loss: 0.0012 lr: 0.02
2019-06-04 08:12:44 iteration: 254500 loss: 0.0010 lr: 0.02
2019-06-04 08:12:58 iteration: 254550 loss: 0.0010 lr: 0.02
2019-06-04 08:13:09 iteration: 254600 loss: 0.0010 lr: 0.02
2019-06-04 08:13:20 iteration: 254650 loss: 0.0011 lr: 0.02
2019-06-04 08:13:30 iteration: 254700 loss: 0.0013 lr: 0.02
2019-06-04 08:13:41 iteration: 254750 loss: 0.0010 lr: 0.02
2019-06-04 08:13:51 iteration: 254800 loss: 0.0010 lr: 0.02
2019-06-04 08:14:02 iteration: 254850 loss: 0.0012 lr: 0.02
2019-06-04 08:14:12 iteration: 254900 loss: 0.0012 lr: 0.02
2019-06-04 08:14:23 iteration: 254950 loss: 0.0011 lr: 0.02
2019-06-04 08:14:33 iteration: 255000 loss: 0.0012 lr: 0.02
2019-06-04 08:14:47 iteration: 255050 loss: 0.0011 lr: 0.02
2019-06-04 08:14:57 iteration: 255100 loss: 0.0014 lr: 0.02
2019-06-04 08:15:08 iteration: 255150 loss: 0.0011 lr: 0.02
2019-06-04 08:15:19 iteration: 255200 loss: 0.0010 lr: 0.02
2019-06-04 08:15:29 iteration: 255250 loss: 0.0012 lr: 0.02
2019-06-04 08:15:39 iteration: 255300 loss: 0.0011 lr: 0.02
2019-06-04 08:15:50 iteration: 255350 loss: 0.0012 lr: 0.02
2019-06-04 08:16:00 iteration: 255400 loss: 0.0014 lr: 0.02
2019-06-04 08:16:11 iteration: 255450 loss: 0.0010 lr: 0.02
2019-06-04 08:16:22 iteration: 255500 loss: 0.0012 lr: 0.02
2019-06-04 08:16:35 iteration: 255550 loss: 0.0011 lr: 0.02
2019-06-04 08:16:46 iteration: 255600 loss: 0.0011 lr: 0.02
2019-06-04 08:16:57 iteration: 255650 loss: 0.0010 lr: 0.02
2019-06-04 08:17:07 iteration: 255700 loss: 0.0012 lr: 0.02
2019-06-04 08:17:17 iteration: 255750 loss: 0.0013 lr: 0.02
2019-06-04 08:17:28 iteration: 255800 loss: 0.0012 lr: 0.02
2019-06-04 08:17:39 iteration: 255850 loss: 0.0010 lr: 0.02
2019-06-04 08:17:50 iteration: 255900 loss: 0.0011 lr: 0.02
2019-06-04 08:18:00 iteration: 255950 loss: 0.0012 lr: 0.02
2019-06-04 08:18:11 iteration: 256000 loss: 0.0012 lr: 0.02
2019-06-04 08:18:25 iteration: 256050 loss: 0.0011 lr: 0.02
2019-06-04 08:18:35 iteration: 256100 loss: 0.0011 lr: 0.02
2019-06-04 08:18:45 iteration: 256150 loss: 0.0017 lr: 0.02
2019-06-04 08:18:56 iteration: 256200 loss: 0.0013 lr: 0.02
2019-06-04 08:19:07 iteration: 256250 loss: 0.0011 lr: 0.02
2019-06-04 08:19:17 iteration: 256300 loss: 0.0011 lr: 0.02
2019-06-04 08:19:29 iteration: 256350 loss: 0.0011 lr: 0.02
2019-06-04 08:19:40 iteration: 256400 loss: 0.0011 lr: 0.02
2019-06-04 08:19:50 iteration: 256450 loss: 0.0012 lr: 0.02
2019-06-04 08:20:01 iteration: 256500 loss: 0.0010 lr: 0.02
2019-06-04 08:20:15 iteration: 256550 loss: 0.0013 lr: 0.02
2019-06-04 08:20:26 iteration: 256600 loss: 0.0012 lr: 0.02
2019-06-04 08:20:37 iteration: 256650 loss: 0.0011 lr: 0.02
2019-06-04 08:20:47 iteration: 256700 loss: 0.0012 lr: 0.02
2019-06-04 08:20:58 iteration: 256750 loss: 0.0012 lr: 0.02
2019-06-04 08:21:08 iteration: 256800 loss: 0.0011 lr: 0.02
2019-06-04 08:21:20 iteration: 256850 loss: 0.0009 lr: 0.02
2019-06-04 08:21:29 iteration: 256900 loss: 0.0012 lr: 0.02
2019-06-04 08:21:40 iteration: 256950 loss: 0.0012 lr: 0.02
2019-06-04 08:21:50 iteration: 257000 loss: 0.0012 lr: 0.02
2019-06-04 08:22:03 iteration: 257050 loss: 0.0013 lr: 0.02
2019-06-04 08:22:14 iteration: 257100 loss: 0.0011 lr: 0.02
2019-06-04 08:22:25 iteration: 257150 loss: 0.0013 lr: 0.02
2019-06-04 08:22:36 iteration: 257200 loss: 0.0011 lr: 0.02
2019-06-04 08:22:47 iteration: 257250 loss: 0.0014 lr: 0.02
2019-06-04 08:22:57 iteration: 257300 loss: 0.0011 lr: 0.02
2019-06-04 08:23:08 iteration: 257350 loss: 0.0012 lr: 0.02
2019-06-04 08:23:19 iteration: 257400 loss: 0.0010 lr: 0.02
2019-06-04 08:23:30 iteration: 257450 loss: 0.0011 lr: 0.02
2019-06-04 08:23:40 iteration: 257500 loss: 0.0010 lr: 0.02
2019-06-04 08:23:53 iteration: 257550 loss: 0.0012 lr: 0.02
2019-06-04 08:24:04 iteration: 257600 loss: 0.0014 lr: 0.02
2019-06-04 08:24:14 iteration: 257650 loss: 0.0013 lr: 0.02
2019-06-04 08:24:24 iteration: 257700 loss: 0.0012 lr: 0.02
2019-06-04 08:24:35 iteration: 257750 loss: 0.0013 lr: 0.02
2019-06-04 08:24:46 iteration: 257800 loss: 0.0012 lr: 0.02
2019-06-04 08:24:56 iteration: 257850 loss: 0.0013 lr: 0.02
2019-06-04 08:25:07 iteration: 257900 loss: 0.0010 lr: 0.02
2019-06-04 08:25:17 iteration: 257950 loss: 0.0012 lr: 0.02
2019-06-04 08:25:27 iteration: 258000 loss: 0.0013 lr: 0.02
2019-06-04 08:25:40 iteration: 258050 loss: 0.0014 lr: 0.02
2019-06-04 08:25:51 iteration: 258100 loss: 0.0011 lr: 0.02
2019-06-04 08:26:01 iteration: 258150 loss: 0.0012 lr: 0.02
2019-06-04 08:26:12 iteration: 258200 loss: 0.0011 lr: 0.02
2019-06-04 08:26:23 iteration: 258250 loss: 0.0012 lr: 0.02
2019-06-04 08:26:33 iteration: 258300 loss: 0.0014 lr: 0.02
2019-06-04 08:26:44 iteration: 258350 loss: 0.0011 lr: 0.02
2019-06-04 08:26:54 iteration: 258400 loss: 0.0013 lr: 0.02
2019-06-04 08:27:04 iteration: 258450 loss: 0.0013 lr: 0.02
2019-06-04 08:27:15 iteration: 258500 loss: 0.0014 lr: 0.02
2019-06-04 08:27:28 iteration: 258550 loss: 0.0012 lr: 0.02
2019-06-04 08:27:39 iteration: 258600 loss: 0.0011 lr: 0.02
2019-06-04 08:27:50 iteration: 258650 loss: 0.0012 lr: 0.02
2019-06-04 08:28:00 iteration: 258700 loss: 0.0011 lr: 0.02
2019-06-04 08:28:10 iteration: 258750 loss: 0.0011 lr: 0.02
2019-06-04 08:28:22 iteration: 258800 loss: 0.0009 lr: 0.02
2019-06-04 08:28:32 iteration: 258850 loss: 0.0009 lr: 0.02
2019-06-04 08:28:42 iteration: 258900 loss: 0.0011 lr: 0.02
2019-06-04 08:28:53 iteration: 258950 loss: 0.0010 lr: 0.02
2019-06-04 08:29:04 iteration: 259000 loss: 0.0011 lr: 0.02
2019-06-04 08:29:17 iteration: 259050 loss: 0.0011 lr: 0.02
2019-06-04 08:29:27 iteration: 259100 loss: 0.0011 lr: 0.02
2019-06-04 08:29:38 iteration: 259150 loss: 0.0012 lr: 0.02
2019-06-04 08:29:48 iteration: 259200 loss: 0.0011 lr: 0.02
2019-06-04 08:29:59 iteration: 259250 loss: 0.0012 lr: 0.02
2019-06-04 08:30:09 iteration: 259300 loss: 0.0012 lr: 0.02
2019-06-04 08:30:19 iteration: 259350 loss: 0.0011 lr: 0.02
2019-06-04 08:30:30 iteration: 259400 loss: 0.0012 lr: 0.02
2019-06-04 08:30:40 iteration: 259450 loss: 0.0010 lr: 0.02
2019-06-04 08:30:51 iteration: 259500 loss: 0.0010 lr: 0.02
2019-06-04 08:31:04 iteration: 259550 loss: 0.0011 lr: 0.02
2019-06-04 08:31:15 iteration: 259600 loss: 0.0013 lr: 0.02
2019-06-04 08:31:25 iteration: 259650 loss: 0.0012 lr: 0.02
2019-06-04 08:31:35 iteration: 259700 loss: 0.0011 lr: 0.02
2019-06-04 08:31:45 iteration: 259750 loss: 0.0012 lr: 0.02
2019-06-04 08:31:55 iteration: 259800 loss: 0.0013 lr: 0.02
2019-06-04 08:32:06 iteration: 259850 loss: 0.0010 lr: 0.02
2019-06-04 08:32:16 iteration: 259900 loss: 0.0011 lr: 0.02
2019-06-04 08:32:26 iteration: 259950 loss: 0.0012 lr: 0.02
2019-06-04 08:32:37 iteration: 260000 loss: 0.0012 lr: 0.02
2019-06-04 08:32:50 iteration: 260050 loss: 0.0013 lr: 0.02
2019-06-04 08:33:01 iteration: 260100 loss: 0.0010 lr: 0.02
2019-06-04 08:33:11 iteration: 260150 loss: 0.0012 lr: 0.02
2019-06-04 08:33:22 iteration: 260200 loss: 0.0013 lr: 0.02
2019-06-04 08:33:32 iteration: 260250 loss: 0.0012 lr: 0.02
2019-06-04 08:33:43 iteration: 260300 loss: 0.0010 lr: 0.02
2019-06-04 08:33:54 iteration: 260350 loss: 0.0011 lr: 0.02
2019-06-04 08:34:05 iteration: 260400 loss: 0.0010 lr: 0.02
2019-06-04 08:34:15 iteration: 260450 loss: 0.0010 lr: 0.02
2019-06-04 08:34:26 iteration: 260500 loss: 0.0011 lr: 0.02
2019-06-04 08:34:39 iteration: 260550 loss: 0.0015 lr: 0.02
2019-06-04 08:34:50 iteration: 260600 loss: 0.0010 lr: 0.02
2019-06-04 08:35:00 iteration: 260650 loss: 0.0014 lr: 0.02
2019-06-04 08:35:11 iteration: 260700 loss: 0.0010 lr: 0.02
2019-06-04 08:35:22 iteration: 260750 loss: 0.0012 lr: 0.02
2019-06-04 08:35:32 iteration: 260800 loss: 0.0012 lr: 0.02
2019-06-04 08:35:42 iteration: 260850 loss: 0.0011 lr: 0.02
2019-06-04 08:35:53 iteration: 260900 loss: 0.0011 lr: 0.02
2019-06-04 08:36:04 iteration: 260950 loss: 0.0012 lr: 0.02
2019-06-04 08:36:14 iteration: 261000 loss: 0.0011 lr: 0.02
2019-06-04 08:36:28 iteration: 261050 loss: 0.0012 lr: 0.02
2019-06-04 08:36:38 iteration: 261100 loss: 0.0013 lr: 0.02
2019-06-04 08:36:49 iteration: 261150 loss: 0.0012 lr: 0.02
2019-06-04 08:36:59 iteration: 261200 loss: 0.0010 lr: 0.02
2019-06-04 08:37:10 iteration: 261250 loss: 0.0011 lr: 0.02
2019-06-04 08:37:21 iteration: 261300 loss: 0.0013 lr: 0.02
2019-06-04 08:37:31 iteration: 261350 loss: 0.0012 lr: 0.02
2019-06-04 08:37:42 iteration: 261400 loss: 0.0012 lr: 0.02
2019-06-04 08:37:51 iteration: 261450 loss: 0.0012 lr: 0.02
2019-06-04 08:38:02 iteration: 261500 loss: 0.0011 lr: 0.02
2019-06-04 08:38:15 iteration: 261550 loss: 0.0013 lr: 0.02
2019-06-04 08:38:26 iteration: 261600 loss: 0.0013 lr: 0.02
2019-06-04 08:38:36 iteration: 261650 loss: 0.0011 lr: 0.02
2019-06-04 08:38:47 iteration: 261700 loss: 0.0013 lr: 0.02
2019-06-04 08:38:58 iteration: 261750 loss: 0.0011 lr: 0.02
2019-06-04 08:39:09 iteration: 261800 loss: 0.0013 lr: 0.02
2019-06-04 08:39:19 iteration: 261850 loss: 0.0011 lr: 0.02
2019-06-04 08:39:30 iteration: 261900 loss: 0.0009 lr: 0.02
2019-06-04 08:39:40 iteration: 261950 loss: 0.0012 lr: 0.02
2019-06-04 08:39:50 iteration: 262000 loss: 0.0012 lr: 0.02
2019-06-04 08:40:04 iteration: 262050 loss: 0.0011 lr: 0.02
2019-06-04 08:40:15 iteration: 262100 loss: 0.0010 lr: 0.02
2019-06-04 08:40:25 iteration: 262150 loss: 0.0014 lr: 0.02
2019-06-04 08:40:36 iteration: 262200 loss: 0.0013 lr: 0.02
2019-06-04 08:40:46 iteration: 262250 loss: 0.0011 lr: 0.02
2019-06-04 08:40:57 iteration: 262300 loss: 0.0011 lr: 0.02
2019-06-04 08:41:08 iteration: 262350 loss: 0.0012 lr: 0.02
2019-06-04 08:41:18 iteration: 262400 loss: 0.0012 lr: 0.02
2019-06-04 08:41:29 iteration: 262450 loss: 0.0013 lr: 0.02
2019-06-04 08:41:38 iteration: 262500 loss: 0.0015 lr: 0.02
2019-06-04 08:41:51 iteration: 262550 loss: 0.0014 lr: 0.02
2019-06-04 08:42:01 iteration: 262600 loss: 0.0012 lr: 0.02
2019-06-04 08:42:12 iteration: 262650 loss: 0.0012 lr: 0.02
2019-06-04 08:42:23 iteration: 262700 loss: 0.0011 lr: 0.02
2019-06-04 08:42:33 iteration: 262750 loss: 0.0012 lr: 0.02
2019-06-04 08:42:44 iteration: 262800 loss: 0.0011 lr: 0.02
2019-06-04 08:42:55 iteration: 262850 loss: 0.0011 lr: 0.02
2019-06-04 08:43:05 iteration: 262900 loss: 0.0011 lr: 0.02
2019-06-04 08:43:16 iteration: 262950 loss: 0.0011 lr: 0.02
2019-06-04 08:43:26 iteration: 263000 loss: 0.0013 lr: 0.02
2019-06-04 08:43:40 iteration: 263050 loss: 0.0011 lr: 0.02
2019-06-04 08:43:49 iteration: 263100 loss: 0.0013 lr: 0.02
2019-06-04 08:43:59 iteration: 263150 loss: 0.0013 lr: 0.02
2019-06-04 08:44:10 iteration: 263200 loss: 0.0011 lr: 0.02
2019-06-04 08:44:21 iteration: 263250 loss: 0.0013 lr: 0.02
2019-06-04 08:44:32 iteration: 263300 loss: 0.0011 lr: 0.02
2019-06-04 08:44:43 iteration: 263350 loss: 0.0014 lr: 0.02
2019-06-04 08:44:53 iteration: 263400 loss: 0.0017 lr: 0.02
2019-06-04 08:45:03 iteration: 263450 loss: 0.0011 lr: 0.02
2019-06-04 08:45:14 iteration: 263500 loss: 0.0011 lr: 0.02
2019-06-04 08:45:27 iteration: 263550 loss: 0.0011 lr: 0.02
2019-06-04 08:45:39 iteration: 263600 loss: 0.0010 lr: 0.02
2019-06-04 08:45:49 iteration: 263650 loss: 0.0011 lr: 0.02
2019-06-04 08:46:00 iteration: 263700 loss: 0.0010 lr: 0.02
2019-06-04 08:46:10 iteration: 263750 loss: 0.0011 lr: 0.02
2019-06-04 08:46:20 iteration: 263800 loss: 0.0013 lr: 0.02
2019-06-04 08:46:30 iteration: 263850 loss: 0.0011 lr: 0.02
2019-06-04 08:46:41 iteration: 263900 loss: 0.0012 lr: 0.02
2019-06-04 08:46:51 iteration: 263950 loss: 0.0011 lr: 0.02
2019-06-04 08:47:02 iteration: 264000 loss: 0.0013 lr: 0.02
2019-06-04 08:47:16 iteration: 264050 loss: 0.0011 lr: 0.02
2019-06-04 08:47:26 iteration: 264100 loss: 0.0014 lr: 0.02
2019-06-04 08:47:36 iteration: 264150 loss: 0.0014 lr: 0.02
2019-06-04 08:47:47 iteration: 264200 loss: 0.0010 lr: 0.02
2019-06-04 08:47:57 iteration: 264250 loss: 0.0012 lr: 0.02
2019-06-04 08:48:08 iteration: 264300 loss: 0.0013 lr: 0.02
2019-06-04 08:48:18 iteration: 264350 loss: 0.0011 lr: 0.02
2019-06-04 08:48:29 iteration: 264400 loss: 0.0012 lr: 0.02
2019-06-04 08:48:39 iteration: 264450 loss: 0.0012 lr: 0.02
2019-06-04 08:48:50 iteration: 264500 loss: 0.0012 lr: 0.02
2019-06-04 08:49:04 iteration: 264550 loss: 0.0009 lr: 0.02
2019-06-04 08:49:13 iteration: 264600 loss: 0.0012 lr: 0.02
2019-06-04 08:49:23 iteration: 264650 loss: 0.0012 lr: 0.02
2019-06-04 08:49:34 iteration: 264700 loss: 0.0010 lr: 0.02
2019-06-04 08:49:45 iteration: 264750 loss: 0.0013 lr: 0.02
2019-06-04 08:49:55 iteration: 264800 loss: 0.0011 lr: 0.02
2019-06-04 08:50:05 iteration: 264850 loss: 0.0011 lr: 0.02
2019-06-04 08:50:16 iteration: 264900 loss: 0.0013 lr: 0.02
2019-06-04 08:50:26 iteration: 264950 loss: 0.0010 lr: 0.02
2019-06-04 08:50:37 iteration: 265000 loss: 0.0012 lr: 0.02
2019-06-04 08:50:50 iteration: 265050 loss: 0.0013 lr: 0.02
2019-06-04 08:51:01 iteration: 265100 loss: 0.0013 lr: 0.02
2019-06-04 08:51:11 iteration: 265150 loss: 0.0011 lr: 0.02
2019-06-04 08:51:22 iteration: 265200 loss: 0.0011 lr: 0.02
2019-06-04 08:51:33 iteration: 265250 loss: 0.0015 lr: 0.02
2019-06-04 08:51:43 iteration: 265300 loss: 0.0013 lr: 0.02
2019-06-04 08:51:54 iteration: 265350 loss: 0.0013 lr: 0.02
2019-06-04 08:52:04 iteration: 265400 loss: 0.0012 lr: 0.02
2019-06-04 08:52:15 iteration: 265450 loss: 0.0010 lr: 0.02
2019-06-04 08:52:26 iteration: 265500 loss: 0.0012 lr: 0.02
2019-06-04 08:52:39 iteration: 265550 loss: 0.0011 lr: 0.02
2019-06-04 08:52:50 iteration: 265600 loss: 0.0010 lr: 0.02
2019-06-04 08:53:01 iteration: 265650 loss: 0.0010 lr: 0.02
2019-06-04 08:53:11 iteration: 265700 loss: 0.0010 lr: 0.02
2019-06-04 08:53:21 iteration: 265750 loss: 0.0011 lr: 0.02
2019-06-04 08:53:32 iteration: 265800 loss: 0.0012 lr: 0.02
2019-06-04 08:53:42 iteration: 265850 loss: 0.0013 lr: 0.02
2019-06-04 08:53:53 iteration: 265900 loss: 0.0014 lr: 0.02
2019-06-04 08:54:03 iteration: 265950 loss: 0.0012 lr: 0.02
2019-06-04 08:54:14 iteration: 266000 loss: 0.0011 lr: 0.02
2019-06-04 08:54:27 iteration: 266050 loss: 0.0010 lr: 0.02
2019-06-04 08:54:38 iteration: 266100 loss: 0.0012 lr: 0.02
2019-06-04 08:54:48 iteration: 266150 loss: 0.0011 lr: 0.02
2019-06-04 08:54:59 iteration: 266200 loss: 0.0015 lr: 0.02
2019-06-04 08:55:10 iteration: 266250 loss: 0.0011 lr: 0.02
2019-06-04 08:55:21 iteration: 266300 loss: 0.0011 lr: 0.02
2019-06-04 08:55:32 iteration: 266350 loss: 0.0013 lr: 0.02
2019-06-04 08:55:42 iteration: 266400 loss: 0.0012 lr: 0.02
2019-06-04 08:55:52 iteration: 266450 loss: 0.0013 lr: 0.02
2019-06-04 08:56:02 iteration: 266500 loss: 0.0011 lr: 0.02
2019-06-04 08:56:16 iteration: 266550 loss: 0.0013 lr: 0.02
2019-06-04 08:56:26 iteration: 266600 loss: 0.0011 lr: 0.02
2019-06-04 08:56:36 iteration: 266650 loss: 0.0010 lr: 0.02
2019-06-04 08:56:47 iteration: 266700 loss: 0.0011 lr: 0.02
2019-06-04 08:56:58 iteration: 266750 loss: 0.0011 lr: 0.02
2019-06-04 08:57:08 iteration: 266800 loss: 0.0011 lr: 0.02
2019-06-04 08:57:18 iteration: 266850 loss: 0.0009 lr: 0.02
2019-06-04 08:57:29 iteration: 266900 loss: 0.0013 lr: 0.02
2019-06-04 08:57:39 iteration: 266950 loss: 0.0013 lr: 0.02
2019-06-04 08:57:49 iteration: 267000 loss: 0.0015 lr: 0.02
2019-06-04 08:58:02 iteration: 267050 loss: 0.0012 lr: 0.02
2019-06-04 08:58:12 iteration: 267100 loss: 0.0013 lr: 0.02
2019-06-04 08:58:23 iteration: 267150 loss: 0.0010 lr: 0.02
2019-06-04 08:58:33 iteration: 267200 loss: 0.0012 lr: 0.02
2019-06-04 08:58:43 iteration: 267250 loss: 0.0011 lr: 0.02
2019-06-04 08:58:54 iteration: 267300 loss: 0.0009 lr: 0.02
2019-06-04 08:59:04 iteration: 267350 loss: 0.0012 lr: 0.02
2019-06-04 08:59:15 iteration: 267400 loss: 0.0010 lr: 0.02
2019-06-04 08:59:26 iteration: 267450 loss: 0.0010 lr: 0.02
2019-06-04 08:59:36 iteration: 267500 loss: 0.0012 lr: 0.02
2019-06-04 08:59:50 iteration: 267550 loss: 0.0011 lr: 0.02
2019-06-04 09:00:01 iteration: 267600 loss: 0.0011 lr: 0.02
2019-06-04 09:00:11 iteration: 267650 loss: 0.0015 lr: 0.02
2019-06-04 09:00:21 iteration: 267700 loss: 0.0012 lr: 0.02
2019-06-04 09:00:32 iteration: 267750 loss: 0.0010 lr: 0.02
2019-06-04 09:00:43 iteration: 267800 loss: 0.0013 lr: 0.02
2019-06-04 09:00:53 iteration: 267850 loss: 0.0012 lr: 0.02
2019-06-04 09:01:04 iteration: 267900 loss: 0.0010 lr: 0.02
2019-06-04 09:01:15 iteration: 267950 loss: 0.0012 lr: 0.02
2019-06-04 09:01:25 iteration: 268000 loss: 0.0011 lr: 0.02
2019-06-04 09:01:38 iteration: 268050 loss: 0.0013 lr: 0.02
2019-06-04 09:01:50 iteration: 268100 loss: 0.0010 lr: 0.02
2019-06-04 09:02:01 iteration: 268150 loss: 0.0011 lr: 0.02
2019-06-04 09:02:11 iteration: 268200 loss: 0.0012 lr: 0.02
2019-06-04 09:02:22 iteration: 268250 loss: 0.0011 lr: 0.02
2019-06-04 09:02:33 iteration: 268300 loss: 0.0010 lr: 0.02
2019-06-04 09:02:44 iteration: 268350 loss: 0.0010 lr: 0.02
2019-06-04 09:02:54 iteration: 268400 loss: 0.0011 lr: 0.02
2019-06-04 09:03:04 iteration: 268450 loss: 0.0011 lr: 0.02
2019-06-04 09:03:15 iteration: 268500 loss: 0.0011 lr: 0.02
2019-06-04 09:03:29 iteration: 268550 loss: 0.0012 lr: 0.02
2019-06-04 09:03:39 iteration: 268600 loss: 0.0012 lr: 0.02
2019-06-04 09:03:50 iteration: 268650 loss: 0.0012 lr: 0.02
2019-06-04 09:04:01 iteration: 268700 loss: 0.0010 lr: 0.02
2019-06-04 09:04:12 iteration: 268750 loss: 0.0009 lr: 0.02
2019-06-04 09:04:21 iteration: 268800 loss: 0.0012 lr: 0.02
2019-06-04 09:04:32 iteration: 268850 loss: 0.0011 lr: 0.02
2019-06-04 09:04:43 iteration: 268900 loss: 0.0011 lr: 0.02
2019-06-04 09:04:54 iteration: 268950 loss: 0.0010 lr: 0.02
2019-06-04 09:05:05 iteration: 269000 loss: 0.0010 lr: 0.02
2019-06-04 09:05:18 iteration: 269050 loss: 0.0012 lr: 0.02
2019-06-04 09:05:28 iteration: 269100 loss: 0.0013 lr: 0.02
2019-06-04 09:05:39 iteration: 269150 loss: 0.0009 lr: 0.02
2019-06-04 09:05:49 iteration: 269200 loss: 0.0012 lr: 0.02
2019-06-04 09:06:00 iteration: 269250 loss: 0.0010 lr: 0.02
2019-06-04 09:06:11 iteration: 269300 loss: 0.0011 lr: 0.02
2019-06-04 09:06:22 iteration: 269350 loss: 0.0011 lr: 0.02
2019-06-04 09:06:32 iteration: 269400 loss: 0.0012 lr: 0.02
2019-06-04 09:06:42 iteration: 269450 loss: 0.0010 lr: 0.02
2019-06-04 09:06:54 iteration: 269500 loss: 0.0012 lr: 0.02
2019-06-04 09:07:07 iteration: 269550 loss: 0.0011 lr: 0.02
2019-06-04 09:07:18 iteration: 269600 loss: 0.0009 lr: 0.02
2019-06-04 09:07:29 iteration: 269650 loss: 0.0010 lr: 0.02
2019-06-04 09:07:39 iteration: 269700 loss: 0.0012 lr: 0.02
2019-06-04 09:07:50 iteration: 269750 loss: 0.0012 lr: 0.02
2019-06-04 09:08:01 iteration: 269800 loss: 0.0012 lr: 0.02
2019-06-04 09:08:12 iteration: 269850 loss: 0.0012 lr: 0.02
2019-06-04 09:08:22 iteration: 269900 loss: 0.0012 lr: 0.02
2019-06-04 09:08:33 iteration: 269950 loss: 0.0011 lr: 0.02
2019-06-04 09:08:43 iteration: 270000 loss: 0.0014 lr: 0.02
2019-06-04 09:08:57 iteration: 270050 loss: 0.0012 lr: 0.02
2019-06-04 09:09:07 iteration: 270100 loss: 0.0011 lr: 0.02
2019-06-04 09:09:17 iteration: 270150 loss: 0.0012 lr: 0.02
2019-06-04 09:09:27 iteration: 270200 loss: 0.0013 lr: 0.02
2019-06-04 09:09:37 iteration: 270250 loss: 0.0013 lr: 0.02
2019-06-04 09:09:48 iteration: 270300 loss: 0.0012 lr: 0.02
2019-06-04 09:09:58 iteration: 270350 loss: 0.0012 lr: 0.02
2019-06-04 09:10:08 iteration: 270400 loss: 0.0012 lr: 0.02
2019-06-04 09:10:19 iteration: 270450 loss: 0.0011 lr: 0.02
2019-06-04 09:10:30 iteration: 270500 loss: 0.0010 lr: 0.02
2019-06-04 09:10:44 iteration: 270550 loss: 0.0011 lr: 0.02
2019-06-04 09:10:54 iteration: 270600 loss: 0.0011 lr: 0.02
2019-06-04 09:11:04 iteration: 270650 loss: 0.0012 lr: 0.02
2019-06-04 09:11:14 iteration: 270700 loss: 0.0012 lr: 0.02
2019-06-04 09:11:24 iteration: 270750 loss: 0.0012 lr: 0.02
2019-06-04 09:11:35 iteration: 270800 loss: 0.0011 lr: 0.02
2019-06-04 09:11:45 iteration: 270850 loss: 0.0012 lr: 0.02
2019-06-04 09:11:56 iteration: 270900 loss: 0.0012 lr: 0.02
2019-06-04 09:12:07 iteration: 270950 loss: 0.0009 lr: 0.02
2019-06-04 09:12:18 iteration: 271000 loss: 0.0011 lr: 0.02
2019-06-04 09:12:31 iteration: 271050 loss: 0.0012 lr: 0.02
2019-06-04 09:12:41 iteration: 271100 loss: 0.0012 lr: 0.02
2019-06-04 09:12:52 iteration: 271150 loss: 0.0012 lr: 0.02
2019-06-04 09:13:03 iteration: 271200 loss: 0.0011 lr: 0.02
2019-06-04 09:13:13 iteration: 271250 loss: 0.0013 lr: 0.02
2019-06-04 09:13:24 iteration: 271300 loss: 0.0013 lr: 0.02
2019-06-04 09:13:35 iteration: 271350 loss: 0.0012 lr: 0.02
2019-06-04 09:13:46 iteration: 271400 loss: 0.0011 lr: 0.02
2019-06-04 09:13:56 iteration: 271450 loss: 0.0012 lr: 0.02
2019-06-04 09:14:07 iteration: 271500 loss: 0.0011 lr: 0.02
2019-06-04 09:14:20 iteration: 271550 loss: 0.0011 lr: 0.02
2019-06-04 09:14:30 iteration: 271600 loss: 0.0014 lr: 0.02
2019-06-04 09:14:41 iteration: 271650 loss: 0.0012 lr: 0.02
2019-06-04 09:14:52 iteration: 271700 loss: 0.0014 lr: 0.02
2019-06-04 09:15:03 iteration: 271750 loss: 0.0011 lr: 0.02
2019-06-04 09:15:13 iteration: 271800 loss: 0.0015 lr: 0.02
2019-06-04 09:15:23 iteration: 271850 loss: 0.0014 lr: 0.02
2019-06-04 09:15:34 iteration: 271900 loss: 0.0010 lr: 0.02
2019-06-04 09:15:44 iteration: 271950 loss: 0.0012 lr: 0.02
2019-06-04 09:15:55 iteration: 272000 loss: 0.0011 lr: 0.02
2019-06-04 09:16:09 iteration: 272050 loss: 0.0012 lr: 0.02
2019-06-04 09:16:20 iteration: 272100 loss: 0.0012 lr: 0.02
2019-06-04 09:16:31 iteration: 272150 loss: 0.0010 lr: 0.02
2019-06-04 09:16:42 iteration: 272200 loss: 0.0011 lr: 0.02
2019-06-04 09:16:52 iteration: 272250 loss: 0.0013 lr: 0.02
2019-06-04 09:17:02 iteration: 272300 loss: 0.0012 lr: 0.02
2019-06-04 09:17:12 iteration: 272350 loss: 0.0011 lr: 0.02
2019-06-04 09:17:23 iteration: 272400 loss: 0.0011 lr: 0.02
2019-06-04 09:17:33 iteration: 272450 loss: 0.0010 lr: 0.02
2019-06-04 09:17:44 iteration: 272500 loss: 0.0011 lr: 0.02
2019-06-04 09:17:57 iteration: 272550 loss: 0.0011 lr: 0.02
2019-06-04 09:18:07 iteration: 272600 loss: 0.0013 lr: 0.02
2019-06-04 09:18:18 iteration: 272650 loss: 0.0013 lr: 0.02
2019-06-04 09:18:28 iteration: 272700 loss: 0.0010 lr: 0.02
2019-06-04 09:18:39 iteration: 272750 loss: 0.0010 lr: 0.02
2019-06-04 09:18:50 iteration: 272800 loss: 0.0011 lr: 0.02
2019-06-04 09:19:00 iteration: 272850 loss: 0.0012 lr: 0.02
2019-06-04 09:19:11 iteration: 272900 loss: 0.0010 lr: 0.02
2019-06-04 09:19:21 iteration: 272950 loss: 0.0011 lr: 0.02
2019-06-04 09:19:32 iteration: 273000 loss: 0.0012 lr: 0.02
2019-06-04 09:19:44 iteration: 273050 loss: 0.0014 lr: 0.02
2019-06-04 09:19:55 iteration: 273100 loss: 0.0011 lr: 0.02
2019-06-04 09:20:06 iteration: 273150 loss: 0.0013 lr: 0.02
2019-06-04 09:20:16 iteration: 273200 loss: 0.0012 lr: 0.02
2019-06-04 09:20:27 iteration: 273250 loss: 0.0011 lr: 0.02
2019-06-04 09:20:37 iteration: 273300 loss: 0.0014 lr: 0.02
2019-06-04 09:20:48 iteration: 273350 loss: 0.0012 lr: 0.02
2019-06-04 09:20:58 iteration: 273400 loss: 0.0011 lr: 0.02
2019-06-04 09:21:09 iteration: 273450 loss: 0.0010 lr: 0.02
2019-06-04 09:21:19 iteration: 273500 loss: 0.0014 lr: 0.02
2019-06-04 09:21:34 iteration: 273550 loss: 0.0012 lr: 0.02
2019-06-04 09:21:44 iteration: 273600 loss: 0.0012 lr: 0.02
2019-06-04 09:21:55 iteration: 273650 loss: 0.0011 lr: 0.02
2019-06-04 09:22:05 iteration: 273700 loss: 0.0012 lr: 0.02
2019-06-04 09:22:16 iteration: 273750 loss: 0.0010 lr: 0.02
2019-06-04 09:22:27 iteration: 273800 loss: 0.0011 lr: 0.02
2019-06-04 09:22:37 iteration: 273850 loss: 0.0012 lr: 0.02
2019-06-04 09:22:47 iteration: 273900 loss: 0.0012 lr: 0.02
2019-06-04 09:22:57 iteration: 273950 loss: 0.0011 lr: 0.02
2019-06-04 09:23:08 iteration: 274000 loss: 0.0010 lr: 0.02
2019-06-04 09:23:22 iteration: 274050 loss: 0.0010 lr: 0.02
2019-06-04 09:23:33 iteration: 274100 loss: 0.0011 lr: 0.02
2019-06-04 09:23:43 iteration: 274150 loss: 0.0011 lr: 0.02
2019-06-04 09:23:54 iteration: 274200 loss: 0.0010 lr: 0.02
2019-06-04 09:24:04 iteration: 274250 loss: 0.0013 lr: 0.02
2019-06-04 09:24:14 iteration: 274300 loss: 0.0010 lr: 0.02
2019-06-04 09:24:25 iteration: 274350 loss: 0.0012 lr: 0.02
2019-06-04 09:24:35 iteration: 274400 loss: 0.0011 lr: 0.02
2019-06-04 09:24:45 iteration: 274450 loss: 0.0013 lr: 0.02
2019-06-04 09:24:56 iteration: 274500 loss: 0.0011 lr: 0.02
2019-06-04 09:25:09 iteration: 274550 loss: 0.0011 lr: 0.02
2019-06-04 09:25:19 iteration: 274600 loss: 0.0011 lr: 0.02
2019-06-04 09:25:30 iteration: 274650 loss: 0.0012 lr: 0.02
2019-06-04 09:25:41 iteration: 274700 loss: 0.0012 lr: 0.02
2019-06-04 09:25:52 iteration: 274750 loss: 0.0011 lr: 0.02
2019-06-04 09:26:03 iteration: 274800 loss: 0.0015 lr: 0.02
2019-06-04 09:26:12 iteration: 274850 loss: 0.0012 lr: 0.02
2019-06-04 09:26:24 iteration: 274900 loss: 0.0011 lr: 0.02
2019-06-04 09:26:34 iteration: 274950 loss: 0.0012 lr: 0.02
2019-06-04 09:26:45 iteration: 275000 loss: 0.0013 lr: 0.02
2019-06-04 09:26:58 iteration: 275050 loss: 0.0011 lr: 0.02
2019-06-04 09:27:08 iteration: 275100 loss: 0.0011 lr: 0.02
2019-06-04 09:27:19 iteration: 275150 loss: 0.0011 lr: 0.02
2019-06-04 09:27:30 iteration: 275200 loss: 0.0013 lr: 0.02
2019-06-04 09:27:40 iteration: 275250 loss: 0.0013 lr: 0.02
2019-06-04 09:27:51 iteration: 275300 loss: 0.0011 lr: 0.02
2019-06-04 09:28:01 iteration: 275350 loss: 0.0010 lr: 0.02
2019-06-04 09:28:12 iteration: 275400 loss: 0.0016 lr: 0.02
2019-06-04 09:28:23 iteration: 275450 loss: 0.0011 lr: 0.02
2019-06-04 09:28:33 iteration: 275500 loss: 0.0011 lr: 0.02
2019-06-04 09:28:46 iteration: 275550 loss: 0.0010 lr: 0.02
2019-06-04 09:28:57 iteration: 275600 loss: 0.0012 lr: 0.02
2019-06-04 09:29:08 iteration: 275650 loss: 0.0010 lr: 0.02
2019-06-04 09:29:19 iteration: 275700 loss: 0.0011 lr: 0.02
2019-06-04 09:29:29 iteration: 275750 loss: 0.0010 lr: 0.02
2019-06-04 09:29:40 iteration: 275800 loss: 0.0010 lr: 0.02
2019-06-04 09:29:50 iteration: 275850 loss: 0.0009 lr: 0.02
2019-06-04 09:30:00 iteration: 275900 loss: 0.0011 lr: 0.02
2019-06-04 09:30:11 iteration: 275950 loss: 0.0010 lr: 0.02
2019-06-04 09:30:22 iteration: 276000 loss: 0.0012 lr: 0.02
2019-06-04 09:30:36 iteration: 276050 loss: 0.0012 lr: 0.02
2019-06-04 09:30:45 iteration: 276100 loss: 0.0010 lr: 0.02
2019-06-04 09:30:56 iteration: 276150 loss: 0.0012 lr: 0.02
2019-06-04 09:31:06 iteration: 276200 loss: 0.0012 lr: 0.02
2019-06-04 09:31:16 iteration: 276250 loss: 0.0014 lr: 0.02
2019-06-04 09:31:27 iteration: 276300 loss: 0.0012 lr: 0.02
2019-06-04 09:31:37 iteration: 276350 loss: 0.0010 lr: 0.02
2019-06-04 09:31:48 iteration: 276400 loss: 0.0011 lr: 0.02
2019-06-04 09:31:58 iteration: 276450 loss: 0.0010 lr: 0.02
2019-06-04 09:32:09 iteration: 276500 loss: 0.0011 lr: 0.02
2019-06-04 09:32:23 iteration: 276550 loss: 0.0010 lr: 0.02
2019-06-04 09:32:33 iteration: 276600 loss: 0.0010 lr: 0.02
2019-06-04 09:32:44 iteration: 276650 loss: 0.0011 lr: 0.02
2019-06-04 09:32:54 iteration: 276700 loss: 0.0011 lr: 0.02
2019-06-04 09:33:05 iteration: 276750 loss: 0.0012 lr: 0.02
2019-06-04 09:33:15 iteration: 276800 loss: 0.0012 lr: 0.02
2019-06-04 09:33:26 iteration: 276850 loss: 0.0013 lr: 0.02
2019-06-04 09:33:37 iteration: 276900 loss: 0.0011 lr: 0.02
2019-06-04 09:33:48 iteration: 276950 loss: 0.0011 lr: 0.02
2019-06-04 09:33:58 iteration: 277000 loss: 0.0011 lr: 0.02
2019-06-04 09:34:12 iteration: 277050 loss: 0.0010 lr: 0.02
2019-06-04 09:34:22 iteration: 277100 loss: 0.0010 lr: 0.02
2019-06-04 09:34:32 iteration: 277150 loss: 0.0012 lr: 0.02
2019-06-04 09:34:43 iteration: 277200 loss: 0.0013 lr: 0.02
2019-06-04 09:34:54 iteration: 277250 loss: 0.0010 lr: 0.02
2019-06-04 09:35:04 iteration: 277300 loss: 0.0011 lr: 0.02
2019-06-04 09:35:14 iteration: 277350 loss: 0.0010 lr: 0.02
2019-06-04 09:35:24 iteration: 277400 loss: 0.0012 lr: 0.02
2019-06-04 09:35:35 iteration: 277450 loss: 0.0010 lr: 0.02
2019-06-04 09:35:46 iteration: 277500 loss: 0.0010 lr: 0.02
2019-06-04 09:35:59 iteration: 277550 loss: 0.0012 lr: 0.02
2019-06-04 09:36:10 iteration: 277600 loss: 0.0011 lr: 0.02
2019-06-04 09:36:21 iteration: 277650 loss: 0.0011 lr: 0.02
2019-06-04 09:36:32 iteration: 277700 loss: 0.0009 lr: 0.02
2019-06-04 09:36:44 iteration: 277750 loss: 0.0009 lr: 0.02
2019-06-04 09:36:53 iteration: 277800 loss: 0.0012 lr: 0.02
2019-06-04 09:37:04 iteration: 277850 loss: 0.0010 lr: 0.02
2019-06-04 09:37:14 iteration: 277900 loss: 0.0012 lr: 0.02
2019-06-04 09:37:25 iteration: 277950 loss: 0.0011 lr: 0.02
2019-06-04 09:37:36 iteration: 278000 loss: 0.0012 lr: 0.02
2019-06-04 09:37:49 iteration: 278050 loss: 0.0012 lr: 0.02
2019-06-04 09:37:59 iteration: 278100 loss: 0.0012 lr: 0.02
2019-06-04 09:38:09 iteration: 278150 loss: 0.0011 lr: 0.02
2019-06-04 09:38:20 iteration: 278200 loss: 0.0011 lr: 0.02
2019-06-04 09:38:30 iteration: 278250 loss: 0.0011 lr: 0.02
2019-06-04 09:38:41 iteration: 278300 loss: 0.0013 lr: 0.02
2019-06-04 09:38:51 iteration: 278350 loss: 0.0012 lr: 0.02
2019-06-04 09:39:01 iteration: 278400 loss: 0.0014 lr: 0.02
2019-06-04 09:39:11 iteration: 278450 loss: 0.0011 lr: 0.02
2019-06-04 09:39:22 iteration: 278500 loss: 0.0012 lr: 0.02
2019-06-04 09:39:36 iteration: 278550 loss: 0.0010 lr: 0.02
2019-06-04 09:39:46 iteration: 278600 loss: 0.0012 lr: 0.02
2019-06-04 09:39:56 iteration: 278650 loss: 0.0013 lr: 0.02
2019-06-04 09:40:07 iteration: 278700 loss: 0.0014 lr: 0.02
2019-06-04 09:40:17 iteration: 278750 loss: 0.0014 lr: 0.02
2019-06-04 09:40:27 iteration: 278800 loss: 0.0012 lr: 0.02
2019-06-04 09:40:38 iteration: 278850 loss: 0.0012 lr: 0.02
2019-06-04 09:40:48 iteration: 278900 loss: 0.0013 lr: 0.02
2019-06-04 09:40:59 iteration: 278950 loss: 0.0011 lr: 0.02
2019-06-04 09:41:09 iteration: 279000 loss: 0.0012 lr: 0.02
2019-06-04 09:41:23 iteration: 279050 loss: 0.0012 lr: 0.02
2019-06-04 09:41:33 iteration: 279100 loss: 0.0013 lr: 0.02
2019-06-04 09:41:43 iteration: 279150 loss: 0.0011 lr: 0.02
2019-06-04 09:41:54 iteration: 279200 loss: 0.0012 lr: 0.02
2019-06-04 09:42:04 iteration: 279250 loss: 0.0012 lr: 0.02
2019-06-04 09:42:15 iteration: 279300 loss: 0.0010 lr: 0.02
2019-06-04 09:42:25 iteration: 279350 loss: 0.0012 lr: 0.02
2019-06-04 09:42:36 iteration: 279400 loss: 0.0009 lr: 0.02
2019-06-04 09:42:46 iteration: 279450 loss: 0.0013 lr: 0.02
2019-06-04 09:42:57 iteration: 279500 loss: 0.0015 lr: 0.02
2019-06-04 09:43:09 iteration: 279550 loss: 0.0013 lr: 0.02
2019-06-04 09:43:20 iteration: 279600 loss: 0.0010 lr: 0.02
2019-06-04 09:43:31 iteration: 279650 loss: 0.0012 lr: 0.02
2019-06-04 09:43:41 iteration: 279700 loss: 0.0010 lr: 0.02
2019-06-04 09:43:52 iteration: 279750 loss: 0.0013 lr: 0.02
2019-06-04 09:44:02 iteration: 279800 loss: 0.0013 lr: 0.02
2019-06-04 09:44:13 iteration: 279850 loss: 0.0011 lr: 0.02
2019-06-04 09:44:24 iteration: 279900 loss: 0.0013 lr: 0.02
2019-06-04 09:44:34 iteration: 279950 loss: 0.0011 lr: 0.02
2019-06-04 09:44:45 iteration: 280000 loss: 0.0011 lr: 0.02
2019-06-04 09:44:58 iteration: 280050 loss: 0.0011 lr: 0.02
2019-06-04 09:45:08 iteration: 280100 loss: 0.0012 lr: 0.02
2019-06-04 09:45:19 iteration: 280150 loss: 0.0013 lr: 0.02
2019-06-04 09:45:29 iteration: 280200 loss: 0.0012 lr: 0.02
2019-06-04 09:45:40 iteration: 280250 loss: 0.0011 lr: 0.02
2019-06-04 09:45:51 iteration: 280300 loss: 0.0011 lr: 0.02
2019-06-04 09:46:01 iteration: 280350 loss: 0.0015 lr: 0.02
2019-06-04 09:46:11 iteration: 280400 loss: 0.0013 lr: 0.02
2019-06-04 09:46:21 iteration: 280450 loss: 0.0010 lr: 0.02
2019-06-04 09:46:31 iteration: 280500 loss: 0.0013 lr: 0.02
2019-06-04 09:46:44 iteration: 280550 loss: 0.0011 lr: 0.02
2019-06-04 09:46:55 iteration: 280600 loss: 0.0011 lr: 0.02
2019-06-04 09:47:05 iteration: 280650 loss: 0.0014 lr: 0.02
2019-06-04 09:47:16 iteration: 280700 loss: 0.0012 lr: 0.02
2019-06-04 09:47:27 iteration: 280750 loss: 0.0010 lr: 0.02
2019-06-04 09:47:37 iteration: 280800 loss: 0.0010 lr: 0.02
2019-06-04 09:47:48 iteration: 280850 loss: 0.0011 lr: 0.02
2019-06-04 09:47:59 iteration: 280900 loss: 0.0012 lr: 0.02
2019-06-04 09:48:09 iteration: 280950 loss: 0.0011 lr: 0.02
2019-06-04 09:48:20 iteration: 281000 loss: 0.0009 lr: 0.02
2019-06-04 09:48:33 iteration: 281050 loss: 0.0012 lr: 0.02
2019-06-04 09:48:44 iteration: 281100 loss: 0.0012 lr: 0.02
2019-06-04 09:48:54 iteration: 281150 loss: 0.0012 lr: 0.02
2019-06-04 09:49:05 iteration: 281200 loss: 0.0010 lr: 0.02
2019-06-04 09:49:15 iteration: 281250 loss: 0.0012 lr: 0.02
2019-06-04 09:49:26 iteration: 281300 loss: 0.0011 lr: 0.02
2019-06-04 09:49:36 iteration: 281350 loss: 0.0012 lr: 0.02
2019-06-04 09:49:47 iteration: 281400 loss: 0.0013 lr: 0.02
2019-06-04 09:49:57 iteration: 281450 loss: 0.0012 lr: 0.02
2019-06-04 09:50:08 iteration: 281500 loss: 0.0012 lr: 0.02
2019-06-04 09:50:21 iteration: 281550 loss: 0.0012 lr: 0.02
2019-06-04 09:50:33 iteration: 281600 loss: 0.0009 lr: 0.02
2019-06-04 09:50:43 iteration: 281650 loss: 0.0010 lr: 0.02
2019-06-04 09:50:54 iteration: 281700 loss: 0.0010 lr: 0.02
2019-06-04 09:51:03 iteration: 281750 loss: 0.0014 lr: 0.02
2019-06-04 09:51:14 iteration: 281800 loss: 0.0012 lr: 0.02
2019-06-04 09:51:24 iteration: 281850 loss: 0.0011 lr: 0.02
2019-06-04 09:51:35 iteration: 281900 loss: 0.0011 lr: 0.02
2019-06-04 09:51:45 iteration: 281950 loss: 0.0011 lr: 0.02
2019-06-04 09:51:55 iteration: 282000 loss: 0.0013 lr: 0.02
2019-06-04 09:52:09 iteration: 282050 loss: 0.0013 lr: 0.02
2019-06-04 09:52:19 iteration: 282100 loss: 0.0012 lr: 0.02
2019-06-04 09:52:30 iteration: 282150 loss: 0.0011 lr: 0.02
2019-06-04 09:52:40 iteration: 282200 loss: 0.0011 lr: 0.02
2019-06-04 09:52:50 iteration: 282250 loss: 0.0012 lr: 0.02
2019-06-04 09:53:00 iteration: 282300 loss: 0.0011 lr: 0.02
2019-06-04 09:53:11 iteration: 282350 loss: 0.0010 lr: 0.02
2019-06-04 09:53:21 iteration: 282400 loss: 0.0013 lr: 0.02
2019-06-04 09:53:32 iteration: 282450 loss: 0.0011 lr: 0.02
2019-06-04 09:53:42 iteration: 282500 loss: 0.0012 lr: 0.02
2019-06-04 09:53:55 iteration: 282550 loss: 0.0013 lr: 0.02
2019-06-04 09:54:05 iteration: 282600 loss: 0.0010 lr: 0.02
2019-06-04 09:54:15 iteration: 282650 loss: 0.0013 lr: 0.02
2019-06-04 09:54:26 iteration: 282700 loss: 0.0009 lr: 0.02
2019-06-04 09:54:37 iteration: 282750 loss: 0.0012 lr: 0.02
2019-06-04 09:54:47 iteration: 282800 loss: 0.0012 lr: 0.02
2019-06-04 09:54:57 iteration: 282850 loss: 0.0011 lr: 0.02
2019-06-04 09:55:07 iteration: 282900 loss: 0.0014 lr: 0.02
2019-06-04 09:55:18 iteration: 282950 loss: 0.0011 lr: 0.02
2019-06-04 09:55:29 iteration: 283000 loss: 0.0012 lr: 0.02
2019-06-04 09:55:42 iteration: 283050 loss: 0.0012 lr: 0.02
2019-06-04 09:55:52 iteration: 283100 loss: 0.0010 lr: 0.02
2019-06-04 09:56:03 iteration: 283150 loss: 0.0011 lr: 0.02
2019-06-04 09:56:14 iteration: 283200 loss: 0.0010 lr: 0.02
2019-06-04 09:56:24 iteration: 283250 loss: 0.0011 lr: 0.02
2019-06-04 09:56:35 iteration: 283300 loss: 0.0010 lr: 0.02
2019-06-04 09:56:45 iteration: 283350 loss: 0.0012 lr: 0.02
2019-06-04 09:56:56 iteration: 283400 loss: 0.0011 lr: 0.02
2019-06-04 09:57:07 iteration: 283450 loss: 0.0011 lr: 0.02
2019-06-04 09:57:18 iteration: 283500 loss: 0.0011 lr: 0.02
2019-06-04 09:57:31 iteration: 283550 loss: 0.0010 lr: 0.02
2019-06-04 09:57:41 iteration: 283600 loss: 0.0012 lr: 0.02
2019-06-04 09:57:52 iteration: 283650 loss: 0.0011 lr: 0.02
2019-06-04 09:58:02 iteration: 283700 loss: 0.0012 lr: 0.02
2019-06-04 09:58:12 iteration: 283750 loss: 0.0009 lr: 0.02
2019-06-04 09:58:23 iteration: 283800 loss: 0.0009 lr: 0.02
2019-06-04 09:58:34 iteration: 283850 loss: 0.0012 lr: 0.02
2019-06-04 09:58:44 iteration: 283900 loss: 0.0011 lr: 0.02
2019-06-04 09:58:55 iteration: 283950 loss: 0.0012 lr: 0.02
2019-06-04 09:59:06 iteration: 284000 loss: 0.0012 lr: 0.02
2019-06-04 09:59:19 iteration: 284050 loss: 0.0011 lr: 0.02
2019-06-04 09:59:30 iteration: 284100 loss: 0.0010 lr: 0.02
2019-06-04 09:59:41 iteration: 284150 loss: 0.0010 lr: 0.02
2019-06-04 09:59:51 iteration: 284200 loss: 0.0009 lr: 0.02
2019-06-04 10:00:02 iteration: 284250 loss: 0.0011 lr: 0.02
2019-06-04 10:00:12 iteration: 284300 loss: 0.0011 lr: 0.02
2019-06-04 10:00:23 iteration: 284350 loss: 0.0010 lr: 0.02
2019-06-04 10:00:32 iteration: 284400 loss: 0.0011 lr: 0.02
2019-06-04 10:00:43 iteration: 284450 loss: 0.0010 lr: 0.02
2019-06-04 10:00:54 iteration: 284500 loss: 0.0012 lr: 0.02
2019-06-04 10:01:07 iteration: 284550 loss: 0.0011 lr: 0.02
2019-06-04 10:01:18 iteration: 284600 loss: 0.0010 lr: 0.02
2019-06-04 10:01:29 iteration: 284650 loss: 0.0013 lr: 0.02
2019-06-04 10:01:39 iteration: 284700 loss: 0.0011 lr: 0.02
2019-06-04 10:01:50 iteration: 284750 loss: 0.0011 lr: 0.02
2019-06-04 10:02:00 iteration: 284800 loss: 0.0011 lr: 0.02
2019-06-04 10:02:11 iteration: 284850 loss: 0.0011 lr: 0.02
2019-06-04 10:02:22 iteration: 284900 loss: 0.0010 lr: 0.02
2019-06-04 10:02:32 iteration: 284950 loss: 0.0012 lr: 0.02
2019-06-04 10:02:43 iteration: 285000 loss: 0.0010 lr: 0.02
2019-06-04 10:02:56 iteration: 285050 loss: 0.0014 lr: 0.02
2019-06-04 10:03:07 iteration: 285100 loss: 0.0012 lr: 0.02
2019-06-04 10:03:18 iteration: 285150 loss: 0.0011 lr: 0.02
2019-06-04 10:03:28 iteration: 285200 loss: 0.0011 lr: 0.02
2019-06-04 10:03:38 iteration: 285250 loss: 0.0012 lr: 0.02
2019-06-04 10:03:49 iteration: 285300 loss: 0.0011 lr: 0.02
2019-06-04 10:03:59 iteration: 285350 loss: 0.0013 lr: 0.02
2019-06-04 10:04:10 iteration: 285400 loss: 0.0011 lr: 0.02
2019-06-04 10:04:21 iteration: 285450 loss: 0.0009 lr: 0.02
2019-06-04 10:04:31 iteration: 285500 loss: 0.0010 lr: 0.02
2019-06-04 10:04:45 iteration: 285550 loss: 0.0010 lr: 0.02
2019-06-04 10:04:56 iteration: 285600 loss: 0.0011 lr: 0.02
2019-06-04 10:05:06 iteration: 285650 loss: 0.0011 lr: 0.02
2019-06-04 10:05:18 iteration: 285700 loss: 0.0012 lr: 0.02
2019-06-04 10:05:29 iteration: 285750 loss: 0.0012 lr: 0.02
2019-06-04 10:05:39 iteration: 285800 loss: 0.0011 lr: 0.02
2019-06-04 10:05:50 iteration: 285850 loss: 0.0010 lr: 0.02
2019-06-04 10:06:01 iteration: 285900 loss: 0.0011 lr: 0.02
2019-06-04 10:06:12 iteration: 285950 loss: 0.0012 lr: 0.02
2019-06-04 10:06:23 iteration: 286000 loss: 0.0013 lr: 0.02
2019-06-04 10:06:37 iteration: 286050 loss: 0.0011 lr: 0.02
2019-06-04 10:06:43 Config:
{'all_joints': [[0], [1], [2], [3]],
 'all_joints_names': ['LeftHand', 'RightHand', 'Nose', 'Pellet'],
 'batch_size': 1,
 'bottomheight': 400,
 'crop': True,
 'crop_pad': 0,
 'cropratio': 0.4,
 'dataset': 'training-datasets\\iteration-0\\UnaugmentedDataSet_front4k60fpszoom3.0_TrimJun3\\front4k60fpszoom3.0_Trim_nv95shuffle1.mat',
 'dataset_type': 'default',
 'display_iters': 1000,
 'fg_fraction': 0.25,
 'global_scale': 0.8,
 'init_weights': 'C:\\Users\\vjj14\\.conda\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\models\\pretrained\\resnet_v1_50.ckpt',
 'intermediate_supervision': False,
 'intermediate_supervision_layer': 12,
 'leftwidth': 400,
 'location_refinement': True,
 'locref_huber_loss': True,
 'locref_loss_weight': 0.05,
 'locref_stdev': 7.2801,
 'log_dir': 'log',
 'max_input_size': 1500,
 'mean_pixel': [123.68, 116.779, 103.939],
 'metadataset': 'training-datasets\\iteration-0\\UnaugmentedDataSet_front4k60fpszoom3.0_TrimJun3\\Documentation_data-front4k60fpszoom3.0_Trim_95shuffle1.pickle',
 'min_input_size': 64,
 'minsize': 100,
 'mirror': False,
 'multi_step': [[0.005, 10000],
                [0.02, 430000],
                [0.002, 730000],
                [0.001, 1030000]],
 'net_type': 'resnet_50',
 'num_joints': 4,
 'optimizer': 'sgd',
 'pos_dist_thresh': 17,
 'project_path': 'C:\\Users\\vjj14\\Desktop\\DeepLabCut\\front4k60fpszoom3.0_Trim-nv-2019-06-03',
 'regularize': False,
 'rightwidth': 400,
 'save_iters': 50000,
 'scale_jitter_lo': 0.5,
 'scale_jitter_up': 1.25,
 'scoremap_dir': 'test',
 'shuffle': True,
 'snapshot_prefix': 'C:\\Users\\vjj14\\Desktop\\DeepLabCut\\front4k60fpszoom3.0_Trim-nv-2019-06-03\\dlc-models\\iteration-0\\front4k60fpszoom3.0_TrimJun3-trainset95shuffle1\\test\\snapshot',
 'stride': 8.0,
 'topheight': 400,
 'use_gt_segm': False,
 'video': False,
 'video_batch': False,
 'weigh_negatives': False,
 'weigh_only_present_joints': False,
 'weigh_part_predictions': False,
 'weight_decay': 0.0001}
2019-06-04 10:10:02 Config:
{'all_joints': [[0], [1], [2], [3]],
 'all_joints_names': ['LeftHand', 'RightHand', 'Nose', 'Pellet'],
 'batch_size': 1,
 'bottomheight': 400,
 'crop': True,
 'crop_pad': 0,
 'cropratio': 0.4,
 'dataset': 'training-datasets\\iteration-0\\UnaugmentedDataSet_front4k60fpszoom3.0_TrimJun3\\front4k60fpszoom3.0_Trim_nv95shuffle1.mat',
 'dataset_type': 'default',
 'display_iters': 1000,
 'fg_fraction': 0.25,
 'global_scale': 0.8,
 'init_weights': 'C:\\Users\\vjj14\\.conda\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\models\\pretrained\\resnet_v1_50.ckpt',
 'intermediate_supervision': False,
 'intermediate_supervision_layer': 12,
 'leftwidth': 400,
 'location_refinement': True,
 'locref_huber_loss': True,
 'locref_loss_weight': 0.05,
 'locref_stdev': 7.2801,
 'log_dir': 'log',
 'max_input_size': 1500,
 'mean_pixel': [123.68, 116.779, 103.939],
 'metadataset': 'training-datasets\\iteration-0\\UnaugmentedDataSet_front4k60fpszoom3.0_TrimJun3\\Documentation_data-front4k60fpszoom3.0_Trim_95shuffle1.pickle',
 'min_input_size': 64,
 'minsize': 100,
 'mirror': False,
 'multi_step': [[0.005, 10000],
                [0.02, 430000],
                [0.002, 730000],
                [0.001, 1030000]],
 'net_type': 'resnet_50',
 'num_joints': 4,
 'optimizer': 'sgd',
 'pos_dist_thresh': 17,
 'project_path': 'C:\\Users\\vjj14\\Desktop\\DeepLabCut\\front4k60fpszoom3.0_Trim-nv-2019-06-03',
 'regularize': False,
 'rightwidth': 400,
 'save_iters': 50000,
 'scale_jitter_lo': 0.5,
 'scale_jitter_up': 1.25,
 'scoremap_dir': 'test',
 'shuffle': True,
 'snapshot_prefix': 'C:\\Users\\vjj14\\Desktop\\DeepLabCut\\front4k60fpszoom3.0_Trim-nv-2019-06-03\\dlc-models\\iteration-0\\front4k60fpszoom3.0_TrimJun3-trainset95shuffle1\\test\\snapshot',
 'stride': 8.0,
 'topheight': 400,
 'use_gt_segm': False,
 'video': False,
 'video_batch': False,
 'weigh_negatives': False,
 'weigh_only_present_joints': False,
 'weigh_part_predictions': False,
 'weight_decay': 0.0001}
2019-06-04 10:11:54 Config:
{'all_joints': [[0], [1], [2], [3]],
 'all_joints_names': ['LeftHand', 'RightHand', 'Nose', 'Pellet'],
 'batch_size': 4,
 'bottomheight': 400,
 'crop': True,
 'crop_pad': 0,
 'cropratio': 0.4,
 'dataset': 'training-datasets\\iteration-0\\UnaugmentedDataSet_front4k60fpszoom3.0_TrimJun3\\front4k60fpszoom3.0_Trim_nv95shuffle1.mat',
 'dataset_type': 'default',
 'display_iters': 1000,
 'fg_fraction': 0.25,
 'global_scale': 0.8,
 'init_weights': 'C:\\Users\\vjj14\\.conda\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\models\\pretrained\\resnet_v1_50.ckpt',
 'intermediate_supervision': False,
 'intermediate_supervision_layer': 12,
 'leftwidth': 400,
 'location_refinement': True,
 'locref_huber_loss': True,
 'locref_loss_weight': 0.05,
 'locref_stdev': 7.2801,
 'log_dir': 'log',
 'max_input_size': 1500,
 'mean_pixel': [123.68, 116.779, 103.939],
 'metadataset': 'training-datasets\\iteration-0\\UnaugmentedDataSet_front4k60fpszoom3.0_TrimJun3\\Documentation_data-front4k60fpszoom3.0_Trim_95shuffle1.pickle',
 'min_input_size': 64,
 'minsize': 100,
 'mirror': False,
 'multi_step': [[0.005, 10000],
                [0.02, 430000],
                [0.002, 730000],
                [0.001, 1030000]],
 'net_type': 'resnet_50',
 'num_joints': 4,
 'optimizer': 'sgd',
 'pos_dist_thresh': 17,
 'project_path': 'C:\\Users\\vjj14\\Desktop\\DeepLabCut\\front4k60fpszoom3.0_Trim-nv-2019-06-03',
 'regularize': False,
 'rightwidth': 400,
 'save_iters': 50000,
 'scale_jitter_lo': 0.5,
 'scale_jitter_up': 1.25,
 'scoremap_dir': 'test',
 'shuffle': True,
 'snapshot_prefix': 'C:\\Users\\vjj14\\Desktop\\DeepLabCut\\front4k60fpszoom3.0_Trim-nv-2019-06-03\\dlc-models\\iteration-0\\front4k60fpszoom3.0_TrimJun3-trainset95shuffle1\\test\\snapshot',
 'stride': 8.0,
 'topheight': 400,
 'use_gt_segm': False,
 'video': False,
 'video_batch': False,
 'weigh_negatives': False,
 'weigh_only_present_joints': False,
 'weigh_part_predictions': False,
 'weight_decay': 0.0001}
2019-06-04 10:37:18 Config:
{'all_joints': [[0], [1], [2], [3]],
 'all_joints_names': ['LeftHand', 'RightHand', 'Nose', 'Pellet'],
 'batch_size': 4,
 'bottomheight': 400,
 'crop': True,
 'crop_pad': 0,
 'cropratio': 0.4,
 'dataset': 'training-datasets\\iteration-0\\UnaugmentedDataSet_front4k60fpszoom3.0_TrimJun3\\front4k60fpszoom3.0_Trim_nv95shuffle1.mat',
 'dataset_type': 'default',
 'display_iters': 1000,
 'fg_fraction': 0.25,
 'global_scale': 0.8,
 'init_weights': 'C:\\Users\\vjj14\\.conda\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\models\\pretrained\\resnet_v1_50.ckpt',
 'intermediate_supervision': False,
 'intermediate_supervision_layer': 12,
 'leftwidth': 400,
 'location_refinement': True,
 'locref_huber_loss': True,
 'locref_loss_weight': 0.05,
 'locref_stdev': 7.2801,
 'log_dir': 'log',
 'max_input_size': 1500,
 'mean_pixel': [123.68, 116.779, 103.939],
 'metadataset': 'training-datasets\\iteration-0\\UnaugmentedDataSet_front4k60fpszoom3.0_TrimJun3\\Documentation_data-front4k60fpszoom3.0_Trim_95shuffle1.pickle',
 'min_input_size': 64,
 'minsize': 100,
 'mirror': False,
 'multi_step': [[0.005, 10000],
                [0.02, 430000],
                [0.002, 730000],
                [0.001, 1030000]],
 'net_type': 'resnet_50',
 'num_joints': 4,
 'optimizer': 'sgd',
 'pos_dist_thresh': 17,
 'project_path': 'C:\\Users\\vjj14\\Desktop\\DeepLabCut\\front4k60fpszoom3.0_Trim-nv-2019-06-03',
 'regularize': False,
 'rightwidth': 400,
 'save_iters': 50000,
 'scale_jitter_lo': 0.5,
 'scale_jitter_up': 1.25,
 'scoremap_dir': 'test',
 'shuffle': True,
 'snapshot_prefix': 'C:\\Users\\vjj14\\Desktop\\DeepLabCut\\front4k60fpszoom3.0_Trim-nv-2019-06-03\\dlc-models\\iteration-0\\front4k60fpszoom3.0_TrimJun3-trainset95shuffle1\\test\\snapshot',
 'stride': 8.0,
 'topheight': 400,
 'use_gt_segm': False,
 'video': False,
 'video_batch': False,
 'weigh_negatives': False,
 'weigh_only_present_joints': False,
 'weigh_part_predictions': False,
 'weight_decay': 0.0001}
2019-06-04 10:37:51 Config:
{'all_joints': [[0], [1], [2], [3]],
 'all_joints_names': ['LeftHand', 'RightHand', 'Nose', 'Pellet'],
 'batch_size': 16,
 'bottomheight': 400,
 'crop': True,
 'crop_pad': 0,
 'cropratio': 0.4,
 'dataset': 'training-datasets\\iteration-0\\UnaugmentedDataSet_front4k60fpszoom3.0_TrimJun3\\front4k60fpszoom3.0_Trim_nv95shuffle1.mat',
 'dataset_type': 'default',
 'display_iters': 1000,
 'fg_fraction': 0.25,
 'global_scale': 0.8,
 'init_weights': 'C:\\Users\\vjj14\\.conda\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\models\\pretrained\\resnet_v1_50.ckpt',
 'intermediate_supervision': False,
 'intermediate_supervision_layer': 12,
 'leftwidth': 400,
 'location_refinement': True,
 'locref_huber_loss': True,
 'locref_loss_weight': 0.05,
 'locref_stdev': 7.2801,
 'log_dir': 'log',
 'max_input_size': 1500,
 'mean_pixel': [123.68, 116.779, 103.939],
 'metadataset': 'training-datasets\\iteration-0\\UnaugmentedDataSet_front4k60fpszoom3.0_TrimJun3\\Documentation_data-front4k60fpszoom3.0_Trim_95shuffle1.pickle',
 'min_input_size': 64,
 'minsize': 100,
 'mirror': False,
 'multi_step': [[0.005, 10000],
                [0.02, 430000],
                [0.002, 730000],
                [0.001, 1030000]],
 'net_type': 'resnet_50',
 'num_joints': 4,
 'optimizer': 'sgd',
 'pos_dist_thresh': 17,
 'project_path': 'C:\\Users\\vjj14\\Desktop\\DeepLabCut\\front4k60fpszoom3.0_Trim-nv-2019-06-03',
 'regularize': False,
 'rightwidth': 400,
 'save_iters': 50000,
 'scale_jitter_lo': 0.5,
 'scale_jitter_up': 1.25,
 'scoremap_dir': 'test',
 'shuffle': True,
 'snapshot_prefix': 'C:\\Users\\vjj14\\Desktop\\DeepLabCut\\front4k60fpszoom3.0_Trim-nv-2019-06-03\\dlc-models\\iteration-0\\front4k60fpszoom3.0_TrimJun3-trainset95shuffle1\\test\\snapshot',
 'stride': 8.0,
 'topheight': 400,
 'use_gt_segm': False,
 'video': False,
 'video_batch': False,
 'weigh_negatives': False,
 'weigh_only_present_joints': False,
 'weigh_part_predictions': False,
 'weight_decay': 0.0001}
2019-06-04 10:38:56 Config:
{'all_joints': [[0], [1], [2], [3]],
 'all_joints_names': ['LeftHand', 'RightHand', 'Nose', 'Pellet'],
 'batch_size': 16,
 'bottomheight': 400,
 'crop': True,
 'crop_pad': 0,
 'cropratio': 0.4,
 'dataset': 'training-datasets\\iteration-0\\UnaugmentedDataSet_front4k60fpszoom3.0_TrimJun3\\front4k60fpszoom3.0_Trim_nv95shuffle1.mat',
 'dataset_type': 'default',
 'display_iters': 1000,
 'fg_fraction': 0.25,
 'global_scale': 0.8,
 'init_weights': 'C:\\Users\\vjj14\\.conda\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\models\\pretrained\\resnet_v1_50.ckpt',
 'intermediate_supervision': False,
 'intermediate_supervision_layer': 12,
 'leftwidth': 400,
 'location_refinement': True,
 'locref_huber_loss': True,
 'locref_loss_weight': 0.05,
 'locref_stdev': 7.2801,
 'log_dir': 'log',
 'max_input_size': 1500,
 'mean_pixel': [123.68, 116.779, 103.939],
 'metadataset': 'training-datasets\\iteration-0\\UnaugmentedDataSet_front4k60fpszoom3.0_TrimJun3\\Documentation_data-front4k60fpszoom3.0_Trim_95shuffle1.pickle',
 'min_input_size': 64,
 'minsize': 100,
 'mirror': False,
 'multi_step': [[0.005, 10000],
                [0.02, 430000],
                [0.002, 730000],
                [0.001, 1030000]],
 'net_type': 'resnet_50',
 'num_joints': 4,
 'optimizer': 'sgd',
 'pos_dist_thresh': 17,
 'project_path': 'C:\\Users\\vjj14\\Desktop\\DeepLabCut\\front4k60fpszoom3.0_Trim-nv-2019-06-03',
 'regularize': False,
 'rightwidth': 400,
 'save_iters': 50000,
 'scale_jitter_lo': 0.5,
 'scale_jitter_up': 1.25,
 'scoremap_dir': 'test',
 'shuffle': True,
 'snapshot_prefix': 'C:\\Users\\vjj14\\Desktop\\DeepLabCut\\front4k60fpszoom3.0_Trim-nv-2019-06-03\\dlc-models\\iteration-0\\front4k60fpszoom3.0_TrimJun3-trainset95shuffle1\\test\\snapshot',
 'stride': 8.0,
 'topheight': 400,
 'use_gt_segm': False,
 'video': False,
 'video_batch': False,
 'weigh_negatives': False,
 'weigh_only_present_joints': False,
 'weigh_part_predictions': False,
 'weight_decay': 0.0001}
2019-06-04 10:39:43 Config:
{'all_joints': [[0], [1], [2], [3]],
 'all_joints_names': ['LeftHand', 'RightHand', 'Nose', 'Pellet'],
 'batch_size': 8,
 'bottomheight': 400,
 'crop': True,
 'crop_pad': 0,
 'cropratio': 0.4,
 'dataset': 'training-datasets\\iteration-0\\UnaugmentedDataSet_front4k60fpszoom3.0_TrimJun3\\front4k60fpszoom3.0_Trim_nv95shuffle1.mat',
 'dataset_type': 'default',
 'display_iters': 1000,
 'fg_fraction': 0.25,
 'global_scale': 0.8,
 'init_weights': 'C:\\Users\\vjj14\\.conda\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\models\\pretrained\\resnet_v1_50.ckpt',
 'intermediate_supervision': False,
 'intermediate_supervision_layer': 12,
 'leftwidth': 400,
 'location_refinement': True,
 'locref_huber_loss': True,
 'locref_loss_weight': 0.05,
 'locref_stdev': 7.2801,
 'log_dir': 'log',
 'max_input_size': 1500,
 'mean_pixel': [123.68, 116.779, 103.939],
 'metadataset': 'training-datasets\\iteration-0\\UnaugmentedDataSet_front4k60fpszoom3.0_TrimJun3\\Documentation_data-front4k60fpszoom3.0_Trim_95shuffle1.pickle',
 'min_input_size': 64,
 'minsize': 100,
 'mirror': False,
 'multi_step': [[0.005, 10000],
                [0.02, 430000],
                [0.002, 730000],
                [0.001, 1030000]],
 'net_type': 'resnet_50',
 'num_joints': 4,
 'optimizer': 'sgd',
 'pos_dist_thresh': 17,
 'project_path': 'C:\\Users\\vjj14\\Desktop\\DeepLabCut\\front4k60fpszoom3.0_Trim-nv-2019-06-03',
 'regularize': False,
 'rightwidth': 400,
 'save_iters': 50000,
 'scale_jitter_lo': 0.5,
 'scale_jitter_up': 1.25,
 'scoremap_dir': 'test',
 'shuffle': True,
 'snapshot_prefix': 'C:\\Users\\vjj14\\Desktop\\DeepLabCut\\front4k60fpszoom3.0_Trim-nv-2019-06-03\\dlc-models\\iteration-0\\front4k60fpszoom3.0_TrimJun3-trainset95shuffle1\\test\\snapshot',
 'stride': 8.0,
 'topheight': 400,
 'use_gt_segm': False,
 'video': False,
 'video_batch': False,
 'weigh_negatives': False,
 'weigh_only_present_joints': False,
 'weigh_part_predictions': False,
 'weight_decay': 0.0001}
2019-06-04 10:40:48 Config:
{'all_joints': [[0], [1], [2], [3]],
 'all_joints_names': ['LeftHand', 'RightHand', 'Nose', 'Pellet'],
 'batch_size': 8,
 'bottomheight': 400,
 'crop': True,
 'crop_pad': 0,
 'cropratio': 0.4,
 'dataset': 'training-datasets\\iteration-0\\UnaugmentedDataSet_front4k60fpszoom3.0_TrimJun3\\front4k60fpszoom3.0_Trim_nv95shuffle1.mat',
 'dataset_type': 'default',
 'display_iters': 1000,
 'fg_fraction': 0.25,
 'global_scale': 0.8,
 'init_weights': 'C:\\Users\\vjj14\\.conda\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\models\\pretrained\\resnet_v1_50.ckpt',
 'intermediate_supervision': False,
 'intermediate_supervision_layer': 12,
 'leftwidth': 400,
 'location_refinement': True,
 'locref_huber_loss': True,
 'locref_loss_weight': 0.05,
 'locref_stdev': 7.2801,
 'log_dir': 'log',
 'max_input_size': 1500,
 'mean_pixel': [123.68, 116.779, 103.939],
 'metadataset': 'training-datasets\\iteration-0\\UnaugmentedDataSet_front4k60fpszoom3.0_TrimJun3\\Documentation_data-front4k60fpszoom3.0_Trim_95shuffle1.pickle',
 'min_input_size': 64,
 'minsize': 100,
 'mirror': False,
 'multi_step': [[0.005, 10000],
                [0.02, 430000],
                [0.002, 730000],
                [0.001, 1030000]],
 'net_type': 'resnet_50',
 'num_joints': 4,
 'optimizer': 'sgd',
 'pos_dist_thresh': 17,
 'project_path': 'C:\\Users\\vjj14\\Desktop\\DeepLabCut\\front4k60fpszoom3.0_Trim-nv-2019-06-03',
 'regularize': False,
 'rightwidth': 400,
 'save_iters': 50000,
 'scale_jitter_lo': 0.5,
 'scale_jitter_up': 1.25,
 'scoremap_dir': 'test',
 'shuffle': True,
 'snapshot_prefix': 'C:\\Users\\vjj14\\Desktop\\DeepLabCut\\front4k60fpszoom3.0_Trim-nv-2019-06-03\\dlc-models\\iteration-0\\front4k60fpszoom3.0_TrimJun3-trainset95shuffle1\\test\\snapshot',
 'stride': 8.0,
 'topheight': 400,
 'use_gt_segm': False,
 'video': False,
 'video_batch': False,
 'weigh_negatives': False,
 'weigh_only_present_joints': False,
 'weigh_part_predictions': False,
 'weight_decay': 0.0001}
2019-06-04 10:53:50 Config:
{'all_joints': [[0], [1], [2], [3]],
 'all_joints_names': ['LeftHand', 'RightHand', 'Nose', 'Pellet'],
 'batch_size': 2,
 'bottomheight': 400,
 'crop': True,
 'crop_pad': 0,
 'cropratio': 0.4,
 'dataset': 'training-datasets\\iteration-0\\UnaugmentedDataSet_front4k60fpszoom3.0_TrimJun3\\front4k60fpszoom3.0_Trim_nv95shuffle1.mat',
 'dataset_type': 'default',
 'display_iters': 1000,
 'fg_fraction': 0.25,
 'global_scale': 0.8,
 'init_weights': 'C:\\Users\\vjj14\\.conda\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\models\\pretrained\\resnet_v1_50.ckpt',
 'intermediate_supervision': False,
 'intermediate_supervision_layer': 12,
 'leftwidth': 400,
 'location_refinement': True,
 'locref_huber_loss': True,
 'locref_loss_weight': 0.05,
 'locref_stdev': 7.2801,
 'log_dir': 'log',
 'max_input_size': 1500,
 'mean_pixel': [123.68, 116.779, 103.939],
 'metadataset': 'training-datasets\\iteration-0\\UnaugmentedDataSet_front4k60fpszoom3.0_TrimJun3\\Documentation_data-front4k60fpszoom3.0_Trim_95shuffle1.pickle',
 'min_input_size': 64,
 'minsize': 100,
 'mirror': False,
 'multi_step': [[0.005, 10000],
                [0.02, 430000],
                [0.002, 730000],
                [0.001, 1030000]],
 'net_type': 'resnet_50',
 'num_joints': 4,
 'optimizer': 'sgd',
 'pos_dist_thresh': 17,
 'project_path': 'C:\\Users\\vjj14\\Desktop\\DeepLabCut\\front4k60fpszoom3.0_Trim-nv-2019-06-03',
 'regularize': False,
 'rightwidth': 400,
 'save_iters': 50000,
 'scale_jitter_lo': 0.5,
 'scale_jitter_up': 1.25,
 'scoremap_dir': 'test',
 'shuffle': True,
 'snapshot_prefix': 'C:\\Users\\vjj14\\Desktop\\DeepLabCut\\front4k60fpszoom3.0_Trim-nv-2019-06-03\\dlc-models\\iteration-0\\front4k60fpszoom3.0_TrimJun3-trainset95shuffle1\\test\\snapshot',
 'stride': 8.0,
 'topheight': 400,
 'use_gt_segm': False,
 'video': False,
 'video_batch': False,
 'weigh_negatives': False,
 'weigh_only_present_joints': False,
 'weigh_part_predictions': False,
 'weight_decay': 0.0001}
2019-06-04 10:54:30 Config:
{'all_joints': [[0], [1], [2], [3]],
 'all_joints_names': ['LeftHand', 'RightHand', 'Nose', 'Pellet'],
 'batch_size': 2,
 'bottomheight': 400,
 'crop': True,
 'crop_pad': 0,
 'cropratio': 0.4,
 'dataset': 'training-datasets\\iteration-0\\UnaugmentedDataSet_front4k60fpszoom3.0_TrimJun3\\front4k60fpszoom3.0_Trim_nv95shuffle1.mat',
 'dataset_type': 'default',
 'display_iters': 1000,
 'fg_fraction': 0.25,
 'global_scale': 0.8,
 'init_weights': 'C:\\Users\\vjj14\\.conda\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\models\\pretrained\\resnet_v1_50.ckpt',
 'intermediate_supervision': False,
 'intermediate_supervision_layer': 12,
 'leftwidth': 400,
 'location_refinement': True,
 'locref_huber_loss': True,
 'locref_loss_weight': 0.05,
 'locref_stdev': 7.2801,
 'log_dir': 'log',
 'max_input_size': 1500,
 'mean_pixel': [123.68, 116.779, 103.939],
 'metadataset': 'training-datasets\\iteration-0\\UnaugmentedDataSet_front4k60fpszoom3.0_TrimJun3\\Documentation_data-front4k60fpszoom3.0_Trim_95shuffle1.pickle',
 'min_input_size': 64,
 'minsize': 100,
 'mirror': False,
 'multi_step': [[0.005, 10000],
                [0.02, 430000],
                [0.002, 730000],
                [0.001, 1030000]],
 'net_type': 'resnet_50',
 'num_joints': 4,
 'optimizer': 'sgd',
 'pos_dist_thresh': 17,
 'project_path': 'C:\\Users\\vjj14\\Desktop\\DeepLabCut\\front4k60fpszoom3.0_Trim-nv-2019-06-03',
 'regularize': False,
 'rightwidth': 400,
 'save_iters': 50000,
 'scale_jitter_lo': 0.5,
 'scale_jitter_up': 1.25,
 'scoremap_dir': 'test',
 'shuffle': True,
 'snapshot_prefix': 'C:\\Users\\vjj14\\Desktop\\DeepLabCut\\front4k60fpszoom3.0_Trim-nv-2019-06-03\\dlc-models\\iteration-0\\front4k60fpszoom3.0_TrimJun3-trainset95shuffle1\\test\\snapshot',
 'stride': 8.0,
 'topheight': 400,
 'use_gt_segm': False,
 'video': False,
 'video_batch': False,
 'weigh_negatives': False,
 'weigh_only_present_joints': False,
 'weigh_part_predictions': False,
 'weight_decay': 0.0001}
2019-06-04 11:01:50 Config:
{'all_joints': [[0], [1], [2], [3]],
 'all_joints_names': ['LeftHand', 'RightHand', 'Nose', 'Pellet'],
 'batch_size': 2,
 'bottomheight': 400,
 'crop': True,
 'crop_pad': 0,
 'cropratio': 0.4,
 'dataset': 'training-datasets\\iteration-0\\UnaugmentedDataSet_front4k60fpszoom3.0_TrimJun3\\front4k60fpszoom3.0_Trim_nv95shuffle1.mat',
 'dataset_type': 'default',
 'display_iters': 1000,
 'fg_fraction': 0.25,
 'global_scale': 0.8,
 'init_weights': 'C:\\Users\\vjj14\\.conda\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\models\\pretrained\\resnet_v1_50.ckpt',
 'intermediate_supervision': False,
 'intermediate_supervision_layer': 12,
 'leftwidth': 400,
 'location_refinement': True,
 'locref_huber_loss': True,
 'locref_loss_weight': 0.05,
 'locref_stdev': 7.2801,
 'log_dir': 'log',
 'max_input_size': 1500,
 'mean_pixel': [123.68, 116.779, 103.939],
 'metadataset': 'training-datasets\\iteration-0\\UnaugmentedDataSet_front4k60fpszoom3.0_TrimJun3\\Documentation_data-front4k60fpszoom3.0_Trim_95shuffle1.pickle',
 'min_input_size': 64,
 'minsize': 100,
 'mirror': False,
 'multi_step': [[0.005, 10000],
                [0.02, 430000],
                [0.002, 730000],
                [0.001, 1030000]],
 'net_type': 'resnet_50',
 'num_joints': 4,
 'optimizer': 'sgd',
 'pos_dist_thresh': 17,
 'project_path': 'C:\\Users\\vjj14\\Desktop\\DeepLabCut\\front4k60fpszoom3.0_Trim-nv-2019-06-03',
 'regularize': False,
 'rightwidth': 400,
 'save_iters': 50000,
 'scale_jitter_lo': 0.5,
 'scale_jitter_up': 1.25,
 'scoremap_dir': 'test',
 'shuffle': True,
 'snapshot_prefix': 'C:\\Users\\vjj14\\Desktop\\DeepLabCut\\front4k60fpszoom3.0_Trim-nv-2019-06-03\\dlc-models\\iteration-0\\front4k60fpszoom3.0_TrimJun3-trainset95shuffle1\\test\\snapshot',
 'stride': 8.0,
 'topheight': 400,
 'use_gt_segm': False,
 'video': False,
 'video_batch': False,
 'weigh_negatives': False,
 'weigh_only_present_joints': False,
 'weigh_part_predictions': False,
 'weight_decay': 0.0001}
2019-06-04 11:02:07 Config:
{'all_joints': [[0], [1], [2], [3]],
 'all_joints_names': ['LeftHand', 'RightHand', 'Nose', 'Pellet'],
 'batch_size': 8,
 'bottomheight': 400,
 'crop': True,
 'crop_pad': 0,
 'cropratio': 0.4,
 'dataset': 'training-datasets\\iteration-0\\UnaugmentedDataSet_front4k60fpszoom3.0_TrimJun3\\front4k60fpszoom3.0_Trim_nv95shuffle1.mat',
 'dataset_type': 'default',
 'display_iters': 1000,
 'fg_fraction': 0.25,
 'global_scale': 0.8,
 'init_weights': 'C:\\Users\\vjj14\\.conda\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\models\\pretrained\\resnet_v1_50.ckpt',
 'intermediate_supervision': False,
 'intermediate_supervision_layer': 12,
 'leftwidth': 400,
 'location_refinement': True,
 'locref_huber_loss': True,
 'locref_loss_weight': 0.05,
 'locref_stdev': 7.2801,
 'log_dir': 'log',
 'max_input_size': 1500,
 'mean_pixel': [123.68, 116.779, 103.939],
 'metadataset': 'training-datasets\\iteration-0\\UnaugmentedDataSet_front4k60fpszoom3.0_TrimJun3\\Documentation_data-front4k60fpszoom3.0_Trim_95shuffle1.pickle',
 'min_input_size': 64,
 'minsize': 100,
 'mirror': False,
 'multi_step': [[0.005, 10000],
                [0.02, 430000],
                [0.002, 730000],
                [0.001, 1030000]],
 'net_type': 'resnet_50',
 'num_joints': 4,
 'optimizer': 'sgd',
 'pos_dist_thresh': 17,
 'project_path': 'C:\\Users\\vjj14\\Desktop\\DeepLabCut\\front4k60fpszoom3.0_Trim-nv-2019-06-03',
 'regularize': False,
 'rightwidth': 400,
 'save_iters': 50000,
 'scale_jitter_lo': 0.5,
 'scale_jitter_up': 1.25,
 'scoremap_dir': 'test',
 'shuffle': True,
 'snapshot_prefix': 'C:\\Users\\vjj14\\Desktop\\DeepLabCut\\front4k60fpszoom3.0_Trim-nv-2019-06-03\\dlc-models\\iteration-0\\front4k60fpszoom3.0_TrimJun3-trainset95shuffle1\\test\\snapshot',
 'stride': 8.0,
 'topheight': 400,
 'use_gt_segm': False,
 'video': False,
 'video_batch': False,
 'weigh_negatives': False,
 'weigh_only_present_joints': False,
 'weigh_part_predictions': False,
 'weight_decay': 0.0001}
2019-06-04 11:02:41 Config:
{'all_joints': [[0], [1], [2], [3]],
 'all_joints_names': ['LeftHand', 'RightHand', 'Nose', 'Pellet'],
 'batch_size': 8,
 'bottomheight': 400,
 'crop': True,
 'crop_pad': 0,
 'cropratio': 0.4,
 'dataset': 'training-datasets\\iteration-0\\UnaugmentedDataSet_front4k60fpszoom3.0_TrimJun3\\front4k60fpszoom3.0_Trim_nv95shuffle1.mat',
 'dataset_type': 'default',
 'display_iters': 1000,
 'fg_fraction': 0.25,
 'global_scale': 0.8,
 'init_weights': 'C:\\Users\\vjj14\\.conda\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\models\\pretrained\\resnet_v1_50.ckpt',
 'intermediate_supervision': False,
 'intermediate_supervision_layer': 12,
 'leftwidth': 400,
 'location_refinement': True,
 'locref_huber_loss': True,
 'locref_loss_weight': 0.05,
 'locref_stdev': 7.2801,
 'log_dir': 'log',
 'max_input_size': 1500,
 'mean_pixel': [123.68, 116.779, 103.939],
 'metadataset': 'training-datasets\\iteration-0\\UnaugmentedDataSet_front4k60fpszoom3.0_TrimJun3\\Documentation_data-front4k60fpszoom3.0_Trim_95shuffle1.pickle',
 'min_input_size': 64,
 'minsize': 100,
 'mirror': False,
 'multi_step': [[0.005, 10000],
                [0.02, 430000],
                [0.002, 730000],
                [0.001, 1030000]],
 'net_type': 'resnet_50',
 'num_joints': 4,
 'optimizer': 'sgd',
 'pos_dist_thresh': 17,
 'project_path': 'C:\\Users\\vjj14\\Desktop\\DeepLabCut\\front4k60fpszoom3.0_Trim-nv-2019-06-03',
 'regularize': False,
 'rightwidth': 400,
 'save_iters': 50000,
 'scale_jitter_lo': 0.5,
 'scale_jitter_up': 1.25,
 'scoremap_dir': 'test',
 'shuffle': True,
 'snapshot_prefix': 'C:\\Users\\vjj14\\Desktop\\DeepLabCut\\front4k60fpszoom3.0_Trim-nv-2019-06-03\\dlc-models\\iteration-0\\front4k60fpszoom3.0_TrimJun3-trainset95shuffle1\\test\\snapshot',
 'stride': 8.0,
 'topheight': 400,
 'use_gt_segm': False,
 'video': False,
 'video_batch': False,
 'weigh_negatives': False,
 'weigh_only_present_joints': False,
 'weigh_part_predictions': False,
 'weight_decay': 0.0001}
2019-06-04 11:03:29 Config:
{'all_joints': [[0], [1], [2], [3]],
 'all_joints_names': ['LeftHand', 'RightHand', 'Nose', 'Pellet'],
 'batch_size': 8,
 'bottomheight': 400,
 'crop': True,
 'crop_pad': 0,
 'cropratio': 0.4,
 'dataset': 'training-datasets\\iteration-0\\UnaugmentedDataSet_front4k60fpszoom3.0_TrimJun3\\front4k60fpszoom3.0_Trim_nv95shuffle1.mat',
 'dataset_type': 'default',
 'display_iters': 1000,
 'fg_fraction': 0.25,
 'global_scale': 0.8,
 'init_weights': 'C:\\Users\\vjj14\\.conda\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\models\\pretrained\\resnet_v1_50.ckpt',
 'intermediate_supervision': False,
 'intermediate_supervision_layer': 12,
 'leftwidth': 400,
 'location_refinement': True,
 'locref_huber_loss': True,
 'locref_loss_weight': 0.05,
 'locref_stdev': 7.2801,
 'log_dir': 'log',
 'max_input_size': 1500,
 'mean_pixel': [123.68, 116.779, 103.939],
 'metadataset': 'training-datasets\\iteration-0\\UnaugmentedDataSet_front4k60fpszoom3.0_TrimJun3\\Documentation_data-front4k60fpszoom3.0_Trim_95shuffle1.pickle',
 'min_input_size': 64,
 'minsize': 100,
 'mirror': False,
 'multi_step': [[0.005, 10000],
                [0.02, 430000],
                [0.002, 730000],
                [0.001, 1030000]],
 'net_type': 'resnet_50',
 'num_joints': 4,
 'optimizer': 'sgd',
 'pos_dist_thresh': 17,
 'project_path': 'C:\\Users\\vjj14\\Desktop\\DeepLabCut\\front4k60fpszoom3.0_Trim-nv-2019-06-03',
 'regularize': False,
 'rightwidth': 400,
 'save_iters': 50000,
 'scale_jitter_lo': 0.5,
 'scale_jitter_up': 1.25,
 'scoremap_dir': 'test',
 'shuffle': True,
 'snapshot_prefix': 'C:\\Users\\vjj14\\Desktop\\DeepLabCut\\front4k60fpszoom3.0_Trim-nv-2019-06-03\\dlc-models\\iteration-0\\front4k60fpszoom3.0_TrimJun3-trainset95shuffle1\\test\\snapshot',
 'stride': 8.0,
 'topheight': 400,
 'use_gt_segm': False,
 'video': False,
 'video_batch': False,
 'weigh_negatives': False,
 'weigh_only_present_joints': False,
 'weigh_part_predictions': False,
 'weight_decay': 0.0001}
2019-06-04 11:03:36 Config:
{'all_joints': [[0], [1], [2], [3]],
 'all_joints_names': ['LeftHand', 'RightHand', 'Nose', 'Pellet'],
 'batch_size': 4,
 'bottomheight': 400,
 'crop': True,
 'crop_pad': 0,
 'cropratio': 0.4,
 'dataset': 'training-datasets\\iteration-0\\UnaugmentedDataSet_front4k60fpszoom3.0_TrimJun3\\front4k60fpszoom3.0_Trim_nv95shuffle1.mat',
 'dataset_type': 'default',
 'display_iters': 1000,
 'fg_fraction': 0.25,
 'global_scale': 0.8,
 'init_weights': 'C:\\Users\\vjj14\\.conda\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\models\\pretrained\\resnet_v1_50.ckpt',
 'intermediate_supervision': False,
 'intermediate_supervision_layer': 12,
 'leftwidth': 400,
 'location_refinement': True,
 'locref_huber_loss': True,
 'locref_loss_weight': 0.05,
 'locref_stdev': 7.2801,
 'log_dir': 'log',
 'max_input_size': 1500,
 'mean_pixel': [123.68, 116.779, 103.939],
 'metadataset': 'training-datasets\\iteration-0\\UnaugmentedDataSet_front4k60fpszoom3.0_TrimJun3\\Documentation_data-front4k60fpszoom3.0_Trim_95shuffle1.pickle',
 'min_input_size': 64,
 'minsize': 100,
 'mirror': False,
 'multi_step': [[0.005, 10000],
                [0.02, 430000],
                [0.002, 730000],
                [0.001, 1030000]],
 'net_type': 'resnet_50',
 'num_joints': 4,
 'optimizer': 'sgd',
 'pos_dist_thresh': 17,
 'project_path': 'C:\\Users\\vjj14\\Desktop\\DeepLabCut\\front4k60fpszoom3.0_Trim-nv-2019-06-03',
 'regularize': False,
 'rightwidth': 400,
 'save_iters': 50000,
 'scale_jitter_lo': 0.5,
 'scale_jitter_up': 1.25,
 'scoremap_dir': 'test',
 'shuffle': True,
 'snapshot_prefix': 'C:\\Users\\vjj14\\Desktop\\DeepLabCut\\front4k60fpszoom3.0_Trim-nv-2019-06-03\\dlc-models\\iteration-0\\front4k60fpszoom3.0_TrimJun3-trainset95shuffle1\\test\\snapshot',
 'stride': 8.0,
 'topheight': 400,
 'use_gt_segm': False,
 'video': False,
 'video_batch': False,
 'weigh_negatives': False,
 'weigh_only_present_joints': False,
 'weigh_part_predictions': False,
 'weight_decay': 0.0001}
2019-06-04 11:29:45 Config:
{'all_joints': [[0], [1], [2], [3]],
 'all_joints_names': ['LeftHand', 'RightHand', 'Nose', 'Pellet'],
 'batch_size': 4,
 'bottomheight': 400,
 'crop': True,
 'crop_pad': 0,
 'cropratio': 0.4,
 'dataset': 'training-datasets\\iteration-0\\UnaugmentedDataSet_front4k60fpszoom3.0_TrimJun3\\front4k60fpszoom3.0_Trim_nv95shuffle1.mat',
 'dataset_type': 'default',
 'display_iters': 1000,
 'fg_fraction': 0.25,
 'global_scale': 0.8,
 'init_weights': 'C:\\Users\\vjj14\\.conda\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\models\\pretrained\\resnet_v1_50.ckpt',
 'intermediate_supervision': False,
 'intermediate_supervision_layer': 12,
 'leftwidth': 400,
 'location_refinement': True,
 'locref_huber_loss': True,
 'locref_loss_weight': 0.05,
 'locref_stdev': 7.2801,
 'log_dir': 'log',
 'max_input_size': 1500,
 'mean_pixel': [123.68, 116.779, 103.939],
 'metadataset': 'training-datasets\\iteration-0\\UnaugmentedDataSet_front4k60fpszoom3.0_TrimJun3\\Documentation_data-front4k60fpszoom3.0_Trim_95shuffle1.pickle',
 'min_input_size': 64,
 'minsize': 100,
 'mirror': False,
 'multi_step': [[0.005, 10000],
                [0.02, 430000],
                [0.002, 730000],
                [0.001, 1030000]],
 'net_type': 'resnet_50',
 'num_joints': 4,
 'optimizer': 'sgd',
 'pos_dist_thresh': 17,
 'project_path': 'C:\\Users\\vjj14\\Desktop\\DeepLabCut\\front4k60fpszoom3.0_Trim-nv-2019-06-03',
 'regularize': False,
 'rightwidth': 400,
 'save_iters': 50000,
 'scale_jitter_lo': 0.5,
 'scale_jitter_up': 1.25,
 'scoremap_dir': 'test',
 'shuffle': True,
 'snapshot_prefix': 'C:\\Users\\vjj14\\Desktop\\DeepLabCut\\front4k60fpszoom3.0_Trim-nv-2019-06-03\\dlc-models\\iteration-0\\front4k60fpszoom3.0_TrimJun3-trainset95shuffle1\\test\\snapshot',
 'stride': 8.0,
 'topheight': 400,
 'use_gt_segm': False,
 'video': False,
 'video_batch': False,
 'weigh_negatives': False,
 'weigh_only_present_joints': False,
 'weigh_part_predictions': False,
 'weight_decay': 0.0001}
2019-06-04 11:49:11 Config:
{'all_joints': [[0], [1], [2], [3]],
 'all_joints_names': ['LeftHand', 'RightHand', 'Nose', 'Pellet'],
 'batch_size': 4,
 'bottomheight': 400,
 'crop': True,
 'crop_pad': 0,
 'cropratio': 0.4,
 'dataset': 'training-datasets\\iteration-0\\UnaugmentedDataSet_front4k60fpszoom3.0_TrimJun3\\front4k60fpszoom3.0_Trim_nv95shuffle1.mat',
 'dataset_type': 'default',
 'display_iters': 1000,
 'fg_fraction': 0.25,
 'global_scale': 0.8,
 'init_weights': 'C:\\Users\\vjj14\\.conda\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\models\\pretrained\\resnet_v1_50.ckpt',
 'intermediate_supervision': False,
 'intermediate_supervision_layer': 12,
 'leftwidth': 400,
 'location_refinement': True,
 'locref_huber_loss': True,
 'locref_loss_weight': 0.05,
 'locref_stdev': 7.2801,
 'log_dir': 'log',
 'max_input_size': 1500,
 'mean_pixel': [123.68, 116.779, 103.939],
 'metadataset': 'training-datasets\\iteration-0\\UnaugmentedDataSet_front4k60fpszoom3.0_TrimJun3\\Documentation_data-front4k60fpszoom3.0_Trim_95shuffle1.pickle',
 'min_input_size': 64,
 'minsize': 100,
 'mirror': False,
 'multi_step': [[0.005, 10000],
                [0.02, 430000],
                [0.002, 730000],
                [0.001, 1030000]],
 'net_type': 'resnet_50',
 'num_joints': 4,
 'optimizer': 'sgd',
 'pos_dist_thresh': 17,
 'project_path': 'C:\\Users\\vjj14\\Desktop\\DeepLabCut\\front4k60fpszoom3.0_Trim-nv-2019-06-03',
 'regularize': False,
 'rightwidth': 400,
 'save_iters': 50000,
 'scale_jitter_lo': 0.5,
 'scale_jitter_up': 1.25,
 'scoremap_dir': 'test',
 'shuffle': True,
 'snapshot_prefix': 'C:\\Users\\vjj14\\Desktop\\DeepLabCut\\front4k60fpszoom3.0_Trim-nv-2019-06-03\\dlc-models\\iteration-0\\front4k60fpszoom3.0_TrimJun3-trainset95shuffle1\\test\\snapshot',
 'stride': 8.0,
 'topheight': 400,
 'use_gt_segm': False,
 'video': False,
 'video_batch': False,
 'weigh_negatives': False,
 'weigh_only_present_joints': False,
 'weigh_part_predictions': False,
 'weight_decay': 0.0001}
2019-06-04 11:55:52 Config:
{'all_joints': [[0], [1], [2], [3]],
 'all_joints_names': ['LeftHand', 'RightHand', 'Nose', 'Pellet'],
 'batch_size': 4,
 'bottomheight': 400,
 'crop': True,
 'crop_pad': 0,
 'cropratio': 0.4,
 'dataset': 'training-datasets\\iteration-0\\UnaugmentedDataSet_front4k60fpszoom3.0_TrimJun3\\front4k60fpszoom3.0_Trim_nv95shuffle1.mat',
 'dataset_type': 'default',
 'display_iters': 1000,
 'fg_fraction': 0.25,
 'global_scale': 0.8,
 'init_weights': 'C:\\Users\\vjj14\\.conda\\envs\\dlc-windowsGPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\models\\pretrained\\resnet_v1_50.ckpt',
 'intermediate_supervision': False,
 'intermediate_supervision_layer': 12,
 'leftwidth': 400,
 'location_refinement': True,
 'locref_huber_loss': True,
 'locref_loss_weight': 0.05,
 'locref_stdev': 7.2801,
 'log_dir': 'log',
 'max_input_size': 1500,
 'mean_pixel': [123.68, 116.779, 103.939],
 'metadataset': 'training-datasets\\iteration-0\\UnaugmentedDataSet_front4k60fpszoom3.0_TrimJun3\\Documentation_data-front4k60fpszoom3.0_Trim_95shuffle1.pickle',
 'min_input_size': 64,
 'minsize': 100,
 'mirror': False,
 'multi_step': [[0.005, 10000],
                [0.02, 430000],
                [0.002, 730000],
                [0.001, 1030000]],
 'net_type': 'resnet_50',
 'num_joints': 4,
 'optimizer': 'sgd',
 'pos_dist_thresh': 17,
 'project_path': 'C:\\Users\\vjj14\\Desktop\\DeepLabCut\\front4k60fpszoom3.0_Trim-nv-2019-06-03',
 'regularize': False,
 'rightwidth': 400,
 'save_iters': 50000,
 'scale_jitter_lo': 0.5,
 'scale_jitter_up': 1.25,
 'scoremap_dir': 'test',
 'shuffle': True,
 'snapshot_prefix': 'C:\\Users\\vjj14\\Desktop\\DeepLabCut\\front4k60fpszoom3.0_Trim-nv-2019-06-03\\dlc-models\\iteration-0\\front4k60fpszoom3.0_TrimJun3-trainset95shuffle1\\test\\snapshot',
 'stride': 8.0,
 'topheight': 400,
 'use_gt_segm': False,
 'video': False,
 'video_batch': False,
 'weigh_negatives': False,
 'weigh_only_present_joints': False,
 'weigh_part_predictions': False,
 'weight_decay': 0.0001}
